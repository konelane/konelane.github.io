<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>KOneLane</title>
  
  <subtitle>一团代码，两行歌词，三篇文章</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://konelane.github.io/"/>
  <updated>2021-10-14T04:49:16.072Z</updated>
  <id>https://konelane.github.io/</id>
  
  <author>
    <name>Little Hehe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>算法准备|刷题，变强</title>
    <link href="https://konelane.github.io/2021/10/12/%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/"/>
    <id>https://konelane.github.io/2021/10/12/%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/</id>
    <published>2021-10-11T16:00:00.000Z</published>
    <updated>2021-10-14T04:49:16.072Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="努力"><a href="#努力" class="headerlink" title="努力"></a>努力</h2><p>力扣-都得学一学啊，不刷题被好几位面试官gank了。我也真是可以，一路过关斩将，与那么多智者不谋而合，项目还行，算法题的思路全对，但是代码一个不会，一写就废。大概是眼高手低了。最难受是面试官反问：“你难道没有刷题吗？”的时候，察觉机会从眼前溜走。</p><p>哪怕再忙碌，也要做题啊。绝知此事要躬行！</p><a id="more"></a><h2 id="力扣"><a href="#力扣" class="headerlink" title="力扣"></a>力扣</h2><div class="table-container"><table><thead><tr><th>日期</th><th>题目</th><th>难度</th><th>备注</th></tr></thead><tbody><tr><td>10.12</td><td><a href="https://leetcode-cn.com/problems/subsets/" target="_blank" rel="noopener">78. 子集</a></td><td>中</td><td>遍历迭代(快)/回溯(官方)</td></tr><tr><td>10.13</td><td><a href="https://leetcode-cn.com/problems/subsets-ii/submissions/" target="_blank" rel="noopener">90. 子集 II</a></td><td>中</td><td>去重，利用排序巧妙去重</td></tr><tr><td>10.13</td><td><a href="https://leetcode-cn.com/problems/populating-next-right-pointers-in-each-node-ii/" target="_blank" rel="noopener">117. 填充每个节点的下一个右侧节点指针 II</a></td><td>中</td><td>层序遍历-队列BFS，进阶要求O(1)的空间复杂度，相当于多一个指针next，检查当前节点有没有下一个可连的，并随之移动</td></tr><tr><td>10.13</td><td><a href="https://leetcode-cn.com/problems/permutations/" target="_blank" rel="noopener">46. 全排列</a></td><td>中</td><td>来自移动研究院笔试……递归调用排列/或者用那个<strong>xy换翻</strong>的四步法，如果想要字典序，则大概需要sort一下</td></tr><tr><td>10.13</td><td><a href="https://leetcode-cn.com/problems/find-all-duplicates-in-an-array/" target="_blank" rel="noopener">442. 数组中重复的数据</a></td><td>易</td><td>来自室友的笔试（非算法岗）……力扣上AC了但牛客却无论如何只给50%</td></tr><tr><td>10.14</td><td><a href="https://leetcode-cn.com/problems/subtree-of-another-tree/" target="_blank" rel="noopener">572. 另一棵树的子树</a></td><td>易</td><td>其实是两道题-两棵树是否一样+寻找是否子树（学习一下递归）</td></tr><tr><td>10.14</td><td><a href="https://leetcode-cn.com/problems/permutations-ii/" target="_blank" rel="noopener">47. 全排列 II</a></td><td>中</td><td>巩固一下昨天的知识……还是不熟，采用指针换位法</td></tr></tbody></table></div><h2 id="面试-笔试的一些题"><a href="#面试-笔试的一些题" class="headerlink" title="面试/笔试的一些题"></a>面试/笔试的一些题</h2><div class="table-container"><table><thead><tr><th>日期</th><th>题目</th><th>备注</th></tr></thead><tbody><tr><td>09.22</td><td>找到一个数组的中位数，要求时间复杂度O(n)</td><td>快排</td></tr><tr><td>09.23</td><td>梯度下降法解根号5的精确值。</td><td>重要的是写损失函数的导数</td></tr></tbody></table></div>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;努力&quot;&gt;&lt;a href=&quot;#努力&quot; class=&quot;headerlink&quot; title=&quot;努力&quot;&gt;&lt;/a&gt;努力&lt;/h2&gt;&lt;p&gt;力扣-都得学一学啊，不刷题被好几位面试官gank了。我也真是可以，一路过关斩将，与那么多智者不谋而合，项目还行，算法题的思路全对，但是代码一个不会，一写就废。大概是眼高手低了。最难受是面试官反问：“你难道没有刷题吗？”的时候，察觉机会从眼前溜走。&lt;/p&gt;
&lt;p&gt;哪怕再忙碌，也要做题啊。绝知此事要躬行！&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="算法" scheme="https://konelane.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>深度学习|站在巨人的肩膀上——迁移学习</title>
    <link href="https://konelane.github.io/2021/09/22/210922transfer/"/>
    <id>https://konelane.github.io/2021/09/22/210922transfer/</id>
    <published>2021-09-21T16:00:00.000Z</published>
    <updated>2021-09-23T16:10:13.758Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>又是一学期过去了，博客也许久未更新，生活在鸡零狗碎中仓皇逃窜，留下一地的残篇断页，无人捡拾。而我，总算是鼓起勇气，拿起笔开始写一些总结了。</p><p>本文介绍的是深度学习中<strong>迁移学习</strong>的入门级知识。项目是<strong>迪士尼公主</strong>图像识别。</p><p>苦了我了！</p><a id="more"></a><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>说起来，我作为一个大老爷们，从来没有注意过迪士尼公主的事，直到有一天，在这门名叫“大数据统计建模与深度学习”的课上，我与四位女同学组队，找感兴趣的话题时，才第一次知道迪士尼有这么多公主（我本身的推荐是识别军用船和民用船，被直接pass=.=），而队友们跃跃欲试，我大呼上当快跑，可为时已晚。</p><p>本文用到的数据，竟然是我们几个现场爬下来的（因此，预期也不是很高），百度、bilibili的视频截图，一共十四类，2333张。</p><blockquote><p>公主们的名字：<br>乐佩  宝嘉康蒂    灰姑娘  爱洛公主    艾莎    茉莉公主  蒂安娜公主<br>安娜  梅丽达公主  爱丽儿  白雪公主    花木兰    莫安娜      贝儿公主  </p></blockquote><p>这里随口一提，tf2.0与keras组合绝对是萌新的不二之选。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Activation, Conv2D, BatchNormalization, Dense, add <span class="comment"># 实现相加的模块</span></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout, Flatten, Input, MaxPooling2D, ZeroPadding2D, AveragePooling2D,GlobalAveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"><span class="comment"># 基础</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画图</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将中文转成拼音</span></span><br><span class="line"><span class="keyword">import</span> pinyin.cedict</span><br><span class="line"></span><br><span class="line"><span class="comment">#### -------- TF-GPU --------</span></span><br><span class="line">gpus = tf.config.experimental.list_physical_devices(<span class="string">'GPU'</span>)</span><br><span class="line"><span class="keyword">if</span> gpus:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># Currently, memory growth needs to be the same across GPUs</span></span><br><span class="line">        <span class="keyword">for</span> gpu <span class="keyword">in</span> gpus:</span><br><span class="line">            tf.config.experimental.set_memory_growth(gpu, <span class="keyword">True</span>)</span><br><span class="line">            logical_gpus = tf.config.experimental.list_logical_devices(<span class="string">'GPU'</span>)</span><br><span class="line">            print(len(gpus), <span class="string">"Physical GPUs,"</span>, len(logical_gpus), <span class="string">"Logical GPUs"</span>)</span><br><span class="line">    <span class="keyword">except</span> RuntimeError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="comment"># Memory growth must be set before GPUs have been initialized</span></span><br><span class="line">        print(e)</span><br></pre></td></tr></table></figure><p>调包的过程其实可以一段一段来，我们进行了整理。如果需要使用GPU，可以用这段代码查看是否有可用的GPU。（当然，需要TensorFlow-gpu版本。）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定公主列表</span></span><br><span class="line">princess_list = [<span class="string">'艾莎'</span>,<span class="string">'爱丽儿'</span>,<span class="string">'爱洛'</span>,<span class="string">'安娜'</span>,<span class="string">'白雪'</span>,<span class="string">'宝嘉康蒂'</span>,<span class="string">'贝儿'</span>,<span class="string">'蒂安娜'</span>,</span><br><span class="line">              <span class="string">'花木兰'</span>,<span class="string">'灰姑娘'</span>,<span class="string">'乐佩'</span>,<span class="string">'梅丽达公主'</span>,<span class="string">'茉莉公主'</span>,<span class="string">'莫安娜'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设定数据文件夹和保存output文件夹</span></span><br><span class="line"><span class="comment"># data_dir = "/mnt/princess/data"</span></span><br><span class="line">data_dir = <span class="string">'./data'</span> <span class="comment"># yuanhe</span></span><br><span class="line"><span class="comment"># output_path = "/mnt/princess/output"</span></span><br><span class="line">output_path = <span class="string">'./output'</span> <span class="comment"># yuanhe</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(output_path) == <span class="keyword">False</span> : os.mkdir(output_path)</span><br></pre></td></tr></table></figure><p>上面的代码是对图片数据的位置进行了整理。都是准备工作。下面正片就要开始了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据集拆分函数(由于每个网络的输入size不同,需要指定target_size)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(im_size, batch_size=<span class="number">64</span>)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 数据增强</span></span><br><span class="line">    datagen = ImageDataGenerator(   </span><br><span class="line"></span><br><span class="line">        rescale=<span class="number">1.</span>/<span class="number">255</span>,           </span><br><span class="line">        shear_range=<span class="number">0.5</span>,                        <span class="comment"># 拉伸变换</span></span><br><span class="line">        rotation_range=<span class="number">30</span>,                      <span class="comment"># 左右旋转角度</span></span><br><span class="line">        zoom_range=<span class="number">0.2</span>,                         <span class="comment"># 放大和缩小的比例不超过1.2</span></span><br><span class="line">        width_shift_range=<span class="number">0.2</span>,                  <span class="comment"># 水平方向上平移的尺度</span></span><br><span class="line">        height_shift_range=<span class="number">0.2</span>,                 <span class="comment"># 垂直方向</span></span><br><span class="line">        horizontal_flip=<span class="keyword">True</span>,</span><br><span class="line">        validation_split = <span class="number">0.2</span>                  <span class="comment"># 训练集和验证集拆分比例</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练集数据</span></span><br><span class="line">    train_generator = datagen.flow_from_directory(</span><br><span class="line">        data_dir,</span><br><span class="line">        target_size=(im_size, im_size),</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        classes=princess_list,</span><br><span class="line">        class_mode=<span class="string">'categorical'</span>,</span><br><span class="line">        seed=<span class="number">1024</span>,</span><br><span class="line">        subset=<span class="string">'training'</span>) <span class="comment"># set as training data</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 验证集数据</span></span><br><span class="line">    validation_generator = datagen.flow_from_directory(</span><br><span class="line">        data_dir, </span><br><span class="line">        target_size=(im_size, im_size),</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        classes=princess_list,</span><br><span class="line">        class_mode=<span class="string">'categorical'</span>,</span><br><span class="line">        shuffle=<span class="keyword">False</span>,</span><br><span class="line">        seed=<span class="number">1024</span>,</span><br><span class="line">        subset=<span class="string">'validation'</span>) <span class="comment"># set as validation data</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> (train_generator,validation_generator)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 拆分训练集</span></span><br><span class="line">(train_generator,validation_generator) = load_data(im_size=<span class="number">224</span>, batch_size=<span class="number">64</span>)</span><br><span class="line">X_train,y_train = next(train_generator)</span><br><span class="line">X_test ,y_test  = next(validation_generator)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一个batch的数据集数量</span></span><br><span class="line">print(X_train.shape)</span><br><span class="line">print(y_train.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示标签对应字典</span></span><br><span class="line">train_generator.class_indices</span><br></pre></td></tr></table></figure><p>数据增强是一种常见的扩大训练集的方式，通过旋转、镜像、变化、裁切等方式进行数据扩充。</p><p>最终输出如下：</p><blockquote><p>Found 1873 images belonging to 14 classes.<br>Found 460 images belonging to 14 classes.<br>(64, 224, 224, 3)<br>(64, 14)<br>{‘艾莎’: 0,<br>‘爱丽儿’: 1,<br>‘爱洛’: 2,<br>‘安娜’: 3,<br>‘白雪’: 4,<br>‘宝嘉康蒂’: 5,<br>‘贝儿’: 6,<br>‘蒂安娜’: 7,<br>‘花木兰’: 8,<br>‘灰姑娘’: 9,<br>‘乐佩’: 10,<br>‘梅丽达公主’: 11,<br>‘茉莉公主’: 12,<br>‘莫安娜’: 13}  </p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 预览图片</span></span><br><span class="line">plt.figure()</span><br><span class="line">fig,ax = plt.subplots(<span class="number">2</span>,<span class="number">7</span>)</span><br><span class="line">fig.set_figheight(<span class="number">5</span>)</span><br><span class="line">fig.set_figwidth(<span class="number">15</span>)</span><br><span class="line">ax = ax.flatten()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">14</span>):</span><br><span class="line">    ax[i].imshow(X_train[i,:,:,:])</span><br><span class="line">    <span class="comment"># 标题显示公主名字</span></span><br><span class="line">    prin_name = princess_list[np.where(y_train[i]==<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]]</span><br><span class="line">    <span class="comment"># ax[i].set_title(prin_name)</span></span><br><span class="line">    <span class="comment"># 用拼音显示</span></span><br><span class="line">    ax[i].set_title(pinyin.get(prin_name, format=<span class="string">"strip"</span>, delimiter=<span class="string">" "</span>))</span><br></pre></td></tr></table></figure><p>公主们的样貌也展示如下。</p><img src="/2021/09/22/210922transfer/princess.png" title="princess"><h2 id="模型应用"><a href="#模型应用" class="headerlink" title="模型应用"></a>模型应用</h2><p>本节均使用通过<code>imagenet</code>预训练好的<code>VGG16</code>、<code>ResNet</code>、<code>InceptionV3</code>、<code>MobileNet</code>卷积层参数，并在此基础上训练14分类的全连接层。</p><h3 id="VGG16"><a href="#VGG16" class="headerlink" title="VGG16"></a>VGG16</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新启动keras内存</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line">K.clear_session()</span><br><span class="line"><span class="keyword">from</span> keras.applications.vgg16 <span class="keyword">import</span> VGG16</span><br><span class="line"></span><br><span class="line"><span class="comment"># vgg16默认输入尺寸是 224x224，指定im_size为224</span></span><br><span class="line">(train_vgg16,validation_vgg16) = load_data(im_size = <span class="number">224</span>, batch_size = <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建模型</span></span><br><span class="line"><span class="comment"># 导入已训练参数</span></span><br><span class="line">vgg_base = VGG16(weights=<span class="string">'imagenet'</span>, include_top=<span class="keyword">False</span>)</span><br><span class="line">vgg_x = vgg_base.output</span><br><span class="line">vgg_x = GlobalAveragePooling2D()(vgg_x)</span><br><span class="line"></span><br><span class="line">vgg_x = Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>)(vgg_x)</span><br><span class="line">vgg_pred = Dense(<span class="number">14</span>,activation=<span class="string">'softmax'</span>)(vgg_x)</span><br><span class="line">vgg_model = Model(inputs=vgg_base.input,</span><br><span class="line">                  outputs=vgg_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不再训练前面层</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> vgg_base.layers:</span><br><span class="line">    layer.trainable = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">vgg_model.summary()</span><br></pre></td></tr></table></figure><p>输出如下（即VGG16网络的结构）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">Model: &quot;model_1&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">input_1 (InputLayer)         (None, None, None, 3)     0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block1_conv1 (Conv2D)        (None, None, None, 64)    1792      </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block1_conv2 (Conv2D)        (None, None, None, 64)    36928     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block1_pool (MaxPooling2D)   (None, None, None, 64)    0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block2_conv1 (Conv2D)        (None, None, None, 128)   73856     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block2_conv2 (Conv2D)        (None, None, None, 128)   147584    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block2_pool (MaxPooling2D)   (None, None, None, 128)   0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block3_conv1 (Conv2D)        (None, None, None, 256)   295168    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block3_conv2 (Conv2D)        (None, None, None, 256)   590080    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block3_conv3 (Conv2D)        (None, None, None, 256)   590080    </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block3_pool (MaxPooling2D)   (None, None, None, 256)   0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block4_pool (MaxPooling2D)   (None, None, None, 512)   0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   </span><br><span class="line">_________________________________________________________________</span><br><span class="line">block5_pool (MaxPooling2D)   (None, None, None, 512)   0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">global_average_pooling2d_1 ( (None, 512)               0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (None, 128)               65664     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_2 (Dense)              (None, 14)                1806      </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 14,782,158</span><br><span class="line">Trainable params: 67,470</span><br><span class="line">Non-trainable params: 14,714,688</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure><p>训练的过程就是让原有的权重对现有数据进行过拟合的过程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练</span></span><br><span class="line">vgg_model.compile(loss=<span class="string">'categorical_crossentropy'</span>, </span><br><span class="line">                  optimizer=Adam(lr=<span class="number">0.001</span>), </span><br><span class="line">                  metrics=[<span class="string">'accuracy'</span>]</span><br><span class="line">                 )</span><br><span class="line">vgg_history = vgg_model.fit_generator(train_vgg16</span><br><span class="line">                                      ,validation_data=validation_vgg16</span><br><span class="line"><span class="comment">#                                       ,epochs=100</span></span><br><span class="line">                                      ,epochs=<span class="number">1</span></span><br><span class="line">                                     ) </span><br><span class="line">                                     </span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存结果</span></span><br><span class="line"><span class="comment"># 创建结果保存文件夹</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(output_path + <span class="string">'/model'</span>) == <span class="keyword">False</span> : os.mkdir(output_path + <span class="string">'/model'</span>)</span><br><span class="line"><span class="keyword">if</span> os.path.exists(output_path + <span class="string">'/acc'</span>) == <span class="keyword">False</span> : os.mkdir(output_path + <span class="string">'/acc'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存正确率结果</span></span><br><span class="line"><span class="keyword">with</span> open(output_path + <span class="string">'/acc/vgg16_history.txt'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(vgg_history.history, f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型结果</span></span><br><span class="line">vgg_model.save(output_path + <span class="string">"/model/vgg16.h5"</span>)</span><br></pre></td></tr></table></figure><h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新启动keras内存</span></span><br><span class="line">K.clear_session()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.applications.resnet <span class="keyword">import</span> ResNet50</span><br><span class="line"></span><br><span class="line"><span class="comment"># resnet50默认输入尺寸是 224x224</span></span><br><span class="line">(train_resnet50,validation_resnet50) = load_data(im_size=<span class="number">224</span>, batch_size = <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入已训练参数</span></span><br><span class="line">resnet_base = ResNet50(weights=<span class="string">'imagenet'</span>,include_top=<span class="keyword">False</span>)</span><br><span class="line">resnet_x = resnet_base.output</span><br><span class="line">resnet_x = GlobalAveragePooling2D()(resnet_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在最后加入14分类的全连接层</span></span><br><span class="line">resnet_x = Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>)(resnet_x)</span><br><span class="line">resnet_pred = Dense(<span class="number">14</span>,activation=<span class="string">'softmax'</span>)(resnet_x)</span><br><span class="line">resnet_model = Model(inputs = resnet_base.input</span><br><span class="line">                  ,outputs = resnet_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只训练最后一层</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> resnet_base.layers:</span><br><span class="line">    layer.trainable = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">resnet_model.summary()</span><br></pre></td></tr></table></figure><p>我本来想对模型进行最完整的展示，但其实适合放一张图上来。中间的网络细节就不展示了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Model: &quot;model_1&quot;</span><br><span class="line">                </span><br><span class="line">==================================================================================================</span><br><span class="line">Total params: 23,851,790</span><br><span class="line">Trainable params: 264,078</span><br><span class="line">Non-trainable params: 23,587,712</span><br><span class="line">__________________________________________________________________________________________________</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练</span></span><br><span class="line">resnet_model.compile(loss=<span class="string">'categorical_crossentropy'</span>, </span><br><span class="line">              optimizer=Adam(lr=<span class="number">0.001</span>), </span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>]</span><br><span class="line">             )</span><br><span class="line">resnet_history = resnet_model.fit_generator(train_resnet50</span><br><span class="line">                                      ,validation_data=validation_resnet50</span><br><span class="line"><span class="comment">#                                       ,epochs=100</span></span><br><span class="line">                                      ,epochs=<span class="number">1</span></span><br><span class="line">                                     ) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存结果</span></span><br><span class="line"><span class="comment"># 创建结果保存文件夹</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(output_path + <span class="string">'/model'</span>) == <span class="keyword">False</span> : os.mkdir(output_path + <span class="string">'/model'</span>)</span><br><span class="line"><span class="keyword">if</span> os.path.exists(output_path + <span class="string">'/acc'</span>) == <span class="keyword">False</span> : os.mkdir(output_path + <span class="string">'/acc'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存正确率结果</span></span><br><span class="line"><span class="keyword">with</span> open(output_path + <span class="string">'/acc/resnet_history.txt'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(vgg_history.history, f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型结果</span></span><br><span class="line">resnet_model.save(output_path + <span class="string">"/model/resnet.h5"</span>)</span><br></pre></td></tr></table></figure><h3 id="其他模型（InceptionV3）"><a href="#其他模型（InceptionV3）" class="headerlink" title="其他模型（InceptionV3）"></a>其他模型（InceptionV3）</h3><p>甚至，后面的代码我想一并贴出来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新启动keras内存</span></span><br><span class="line">K.clear_session()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.applications.inception_v3 <span class="keyword">import</span> InceptionV3</span><br><span class="line"></span><br><span class="line">(train_InceptionV3, validation_InceptionV3) = load_data(im_size=<span class="number">224</span>, batch_size= <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入已训练参数</span></span><br><span class="line">inceV3_base = InceptionV3(weights=<span class="string">'imagenet'</span>,include_top=<span class="keyword">False</span>)</span><br><span class="line">inceV3_x = inceV3_base.output</span><br><span class="line">inceV3_x = GlobalAveragePooling2D()(inceV3_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在最后加入14分类的全连接层</span></span><br><span class="line">inceV3_x = Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>)(inceV3_x)</span><br><span class="line">inceV3_pred = Dense(<span class="number">14</span>,activation=<span class="string">'softmax'</span>)(inceV3_x)</span><br><span class="line">InceptionV3_model = Model(inputs = inceV3_base.input</span><br><span class="line">                    ,outputs = inceV3_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只训练最后一层</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> inceV3_base.layers:</span><br><span class="line">    layer.trainable = <span class="keyword">False</span></span><br><span class="line">    </span><br><span class="line">InceptionV3_model.summary()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">InceptionV3_model.compile(loss=<span class="string">'categorical_crossentropy'</span>, </span><br><span class="line">                          optimizer=Adam(lr=<span class="number">0.001</span>), </span><br><span class="line">                          metrics=[<span class="string">'accuracy'</span>]</span><br><span class="line">                         )</span><br><span class="line">InceptionV3_history = InceptionV3_model.fit_generator(train_InceptionV3</span><br><span class="line">                                                      ,validation_data=validation_InceptionV3</span><br><span class="line">                                                      ,epochs=<span class="number">100</span></span><br><span class="line"><span class="comment">#                                                       ,epochs=1</span></span><br><span class="line">                                                     ) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存结果</span></span><br><span class="line"><span class="comment"># 创建结果保存文件夹</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(output_path + <span class="string">'/model'</span>) == <span class="keyword">False</span> : os.mkdir(output_path + <span class="string">'/model'</span>)</span><br><span class="line"><span class="keyword">if</span> os.path.exists(output_path + <span class="string">'/acc'</span>) == <span class="keyword">False</span> : os.mkdir(output_path + <span class="string">'/acc'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存正确率结果</span></span><br><span class="line"><span class="keyword">with</span> open(output_path + <span class="string">'/acc/InceptionV3_history.txt'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(InceptionV3_history.history, f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型结果</span></span><br><span class="line">InceptionV3_model.save(output_path + <span class="string">"/model/InceptionV3.h5"</span>)</span><br></pre></td></tr></table></figure><p>MobileNet</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新启动keras内存</span></span><br><span class="line">K.clear_session()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> MobileNet</span><br><span class="line"></span><br><span class="line">(train_MobileNet, validation_MobileNet) = load_data(im_size=<span class="number">224</span>, batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建模型</span></span><br><span class="line"><span class="comment"># 导入已训练参数</span></span><br><span class="line">mobile_base = MobileNet(weights=<span class="string">'imagenet'</span>,include_top=<span class="keyword">False</span>)</span><br><span class="line">mobile_x = mobile_base.output</span><br><span class="line">mobile_x = GlobalAveragePooling2D()(mobile_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在最后加入激活函数和14分类的全连接层</span></span><br><span class="line">mobile_x = Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>)(mobile_x)</span><br><span class="line">MobileNet_pred = Dense(<span class="number">14</span>, activation=<span class="string">'softmax'</span>)(mobile_x)</span><br><span class="line">MobileNet_model = Model(inputs = mobile_base.input</span><br><span class="line">                    ,outputs = MobileNet_pred)</span><br><span class="line"><span class="comment"># 只训练最后一层</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> mobile_base.layers:</span><br><span class="line">    layer.trainable = <span class="keyword">False</span></span><br><span class="line">    </span><br><span class="line">MobileNet_model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">MobileNet_model.compile(loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">                        optimizer=Adam(lr=<span class="number">0.001</span>),</span><br><span class="line">                        metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">MobileNet_history = MobileNet_model.fit_generator(train_MobileNet</span><br><span class="line">                                                  ,validation_data=validation_MobileNet</span><br><span class="line">                                                  ,epochs=<span class="number">100</span></span><br><span class="line"><span class="comment">#                                                   ,epochs=2</span></span><br><span class="line">                              )</span><br><span class="line"><span class="comment"># 保存结果</span></span><br><span class="line"><span class="comment"># 创建结果保存文件夹</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(output_path + <span class="string">'/model'</span>) == <span class="keyword">False</span> : os.mkdir(output_path + <span class="string">'/model'</span>)</span><br><span class="line"><span class="keyword">if</span> os.path.exists(output_path + <span class="string">'/acc'</span>) == <span class="keyword">False</span> : os.mkdir(output_path + <span class="string">'/acc'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存正确率结果</span></span><br><span class="line"><span class="keyword">with</span> open(output_path + <span class="string">'/acc/MobileNet_history.txt'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(MobileNet_history.history, f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型结果</span></span><br><span class="line">MobileNet_model.save(output_path + <span class="string">"/model/MobileNet.h5"</span>)</span><br></pre></td></tr></table></figure><p>训练的过程千篇一律，因为我们站在巨人的肩膀上，相当于只是对最后一层全连接进行了一定程度的“过拟合”。</p><p>而出乎所有人预料的是，效果竟然还可以。</p><h2 id="模型结果评价"><a href="#模型结果评价" class="headerlink" title="模型结果评价"></a>模型结果评价</h2><h3 id="模型学习曲线"><a href="#模型学习曲线" class="headerlink" title="模型学习曲线"></a>模型学习曲线</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出指定模型的学习曲线</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curves</span><span class="params">(history)</span>:</span></span><br><span class="line">    pd.DataFrame(history.history).plot(figsize = (<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line">    plt.grid(<span class="keyword">True</span>)</span><br><span class="line">    plt.gca().set_ylim(<span class="number">0.2</span>,<span class="number">1.2</span>)</span><br><span class="line"><span class="comment">#     plt.gca().set_xlim(0,100)</span></span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">plot_learning_curves(vgg_history)</span><br><span class="line">plot_learning_curves(resnet_history)</span><br><span class="line">plot_learning_curves(InceptionV3_history)</span><br><span class="line">plot_learning_curves(MobileNet_history)</span><br></pre></td></tr></table></figure><img src="/2021/09/22/210922transfer/res.png" title="res"><p>上面的图是我训练时候的（草稿里的），粘过来也看看。</p><img src="/2021/09/22/210922transfer/res2.jpg" title="res2"><p>总的来说，还是mobilenet最好，既满足了轻量化需求，又显示出超高的准确率，验证集上效果也不错。只是图有点糊了……没找到原图。</p><h3 id="模型准确率"><a href="#模型准确率" class="headerlink" title="模型准确率"></a>模型准确率</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从保存的结果导入每个模型的正确率</span></span><br><span class="line">model_name = []</span><br><span class="line">train_acc = []</span><br><span class="line">val_acc = []</span><br><span class="line"></span><br><span class="line">path_model_result = output_path + <span class="string">"/acc"</span>              <span class="comment"># 模型结果存储路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历取文件</span></span><br><span class="line"><span class="keyword">for</span> file_name <span class="keyword">in</span> os.listdir(path_model_result):</span><br><span class="line">    model_name.append(file_name.split(<span class="string">'_'</span>)[<span class="number">0</span>])              <span class="comment">#文件名都以_分隔，并且第一个元素都是模型名称</span></span><br><span class="line">    <span class="keyword">with</span> open(os.path.join(path_model_result, file_name), <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        model_history = pickle.load(f)</span><br><span class="line">        train_acc.append(model_history[<span class="string">"accuracy"</span>])</span><br><span class="line">        val_acc.append(model_history[<span class="string">"val_accuracy"</span>])</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 测试集和验证集的正确率对比</span></span><br><span class="line">plt.figure(dpi=<span class="number">100</span>)</span><br><span class="line">epoch_list = range(<span class="number">1</span>, <span class="number">101</span>)</span><br><span class="line">color_set=[<span class="string">'red'</span>,<span class="string">'blue'</span>,<span class="string">'green'</span>,<span class="string">'yellow'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> model_loc <span class="keyword">in</span> range(len(model_name)):</span><br><span class="line">    plt.plot(epoch_list, </span><br><span class="line">             train_acc[model_loc], </span><br><span class="line">             marker=<span class="string">'o'</span>, </span><br><span class="line"><span class="comment">#              color=color_set[model_loc], </span></span><br><span class="line">             label=model_name[model_loc]+<span class="string">'Train'</span>)    <span class="comment"># 训练集正确率</span></span><br><span class="line">    plt.plot(epoch_list, </span><br><span class="line">             val_acc[model_loc],</span><br><span class="line">             marker=<span class="string">'*'</span>, </span><br><span class="line"><span class="comment">#              color=color_set[model_loc],</span></span><br><span class="line">             label=model_name[model_loc]+<span class="string">'Validation'</span>) <span class="comment"># 验证集正确率</span></span><br><span class="line">plt.ylim(<span class="number">0.2</span>, <span class="number">1.0</span>)</span><br><span class="line">plt.legend()                                                                                 <span class="comment"># 让图例生效</span></span><br><span class="line">plt.xticks(epoch_list)                                                                       <span class="comment"># 横坐标显示为整数</span></span><br><span class="line">plt.xlabel(<span class="string">u"epoch"</span>)                                                                         <span class="comment"># X轴标签</span></span><br><span class="line">plt.ylabel(<span class="string">"Accuracy"</span>)                                                                       <span class="comment"># Y轴标签</span></span><br><span class="line">plt.title(<span class="string">"Comparison of Accuracy"</span>)                                                          <span class="comment"># 标题</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>什么，我的代码这里竟然出现了些问题，存档时候丢了什么，没能跑出来qwq。请读者自行脑补（bushi</p><p>不放图的理由增加了，拒绝所有“云丹师”。</p><p>比较有学习意义的是下面这个，名叫“错分分析”的部分。目的是看一看这些模型的混淆矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_confusion_matrix</span><span class="params">(cm,</span></span></span><br><span class="line"><span class="function"><span class="params">                          target_names,</span></span></span><br><span class="line"><span class="function"><span class="params">                          title=<span class="string">'Confusion matrix'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                          cmap=plt.cm.Greens,#这个地方设置混淆矩阵的颜色主题</span></span></span><br><span class="line"><span class="function"><span class="params">                          normalize=True)</span>:</span></span><br><span class="line">    <span class="keyword">from</span> itertools <span class="keyword">import</span> product</span><br><span class="line">    </span><br><span class="line">    plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]  <span class="comment"># 用来正常显示中文标签</span></span><br><span class="line">    accuracy = np.trace(cm) / float(np.sum(cm))</span><br><span class="line">    misclass = <span class="number">1</span> - accuracy</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> cmap <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        cmap = plt.get_cmap(<span class="string">'Blues'</span>)</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(<span class="number">15</span>, <span class="number">12</span>))</span><br><span class="line">    plt.imshow(cm, interpolation=<span class="string">'nearest'</span>, cmap=cmap)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.colorbar()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> target_names <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">        tick_marks = np.arange(len(target_names))</span><br><span class="line">        plt.xticks(tick_marks, target_names, rotation=<span class="number">45</span>)</span><br><span class="line">        plt.yticks(tick_marks, target_names)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> normalize:</span><br><span class="line">        cm = cm.astype(<span class="string">'float'</span>) / cm.sum(axis=<span class="number">1</span>)[:, np.newaxis]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    thresh = cm.max() / <span class="number">1.5</span> <span class="keyword">if</span> normalize <span class="keyword">else</span> cm.max() / <span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> product(range(cm.shape[<span class="number">0</span>]), range(cm.shape[<span class="number">1</span>])):</span><br><span class="line">        <span class="keyword">if</span> normalize:</span><br><span class="line">            plt.text(j, i, <span class="string">"&#123;:0.4f&#125;"</span>.format(cm[i, j]),</span><br><span class="line">                     horizontalalignment=<span class="string">"center"</span>,</span><br><span class="line">                     color=<span class="string">"white"</span> <span class="keyword">if</span> cm[i, j] &gt; thresh <span class="keyword">else</span> <span class="string">"black"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            plt.text(j, i, <span class="string">"&#123;:,&#125;"</span>.format(cm[i, j]),</span><br><span class="line">                     horizontalalignment=<span class="string">"center"</span>,</span><br><span class="line">                     color=<span class="string">"white"</span> <span class="keyword">if</span> cm[i, j] &gt; thresh <span class="keyword">else</span> <span class="string">"black"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.ylabel(<span class="string">'True label'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'Predicted label\naccuracy=&#123;:0.4f&#125;; misclass=&#123;:0.4f&#125;'</span>.format(accuracy, misclass))</span><br><span class="line">    <span class="comment">#这里这个savefig是保存图片，如果想把图存在什么地方就改一下下面的路径，然后dpi设一下分辨率即可。</span></span><br><span class="line">    plt.savefig(<span class="string">'./confusionmatrix_14.png'</span>,dpi=<span class="number">1000</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_confuse</span><span class="params">(predictions,true_label,target_names)</span>:</span></span><br><span class="line">    <span class="comment"># predictions = model.predict(x_val).argmax(axis=-1) </span></span><br><span class="line">    truelabel = true_label</span><br><span class="line">    conf_mat = confusion_matrix(y_true=truelabel, y_pred=predictions)</span><br><span class="line">    plt.figure()</span><br><span class="line">    plot_confusion_matrix(conf_mat, normalize=<span class="keyword">False</span>,target_names = target_names,title=<span class="string">'Confusion Matrix'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取模型</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line">model_path = output_path + <span class="string">"/model"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择一个最好的模型</span></span><br><span class="line">vgg_model = load_model(model_path + <span class="string">"/vgg16.h5"</span>)</span><br><span class="line"><span class="comment"># resnet_model = load_model(model_path + "/resnet.h5")</span></span><br><span class="line"><span class="comment"># InceptionV3_model = load_model(model_path + "/InceptionV3.h5")</span></span><br><span class="line"><span class="comment"># MobileNet_model = load_model(model_path + "/MobileNet.h5")</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 并读取对应的数据集(不用的模型im_size不同而已)</span></span><br><span class="line">model = vgg_model</span><br><span class="line">(train_generator,validation_generator) = load_data(im_size=<span class="number">224</span>, batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出每个图像的预测类别</span></span><br><span class="line">pred = model.predict_generator(validation_generator, verbose=<span class="number">1</span>)</span><br><span class="line">predicted_class_indices = np.argmax(pred, axis=<span class="number">1</span>) <span class="comment"># 画图也要用到</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集的真实类别</span></span><br><span class="line">true_label= validation_generator.classes</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用pd.crosstab来简单画出混淆矩阵</span></span><br><span class="line">table=pd.crosstab(true_label</span><br><span class="line">                  ,predicted_class_indices</span><br><span class="line">                  ,colnames=[<span class="string">'Predict label'</span>]</span><br><span class="line">                  ,rownames=[<span class="string">'True label'</span>],)</span><br><span class="line">print(table)</span><br></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 输出每个图像的预测类别</span><br><span class="line">pred = model.predict_generator(validation_generator, verbose=1)</span><br><span class="line">predicted_class_indices = np.argmax(pred, axis=1) # 画图也要用到</span><br><span class="line"></span><br><span class="line"># 测试集的真实类别</span><br><span class="line">true_label= validation_generator.classes</span><br><span class="line"></span><br><span class="line">#使用pd.crosstab来简单画出混淆矩阵</span><br><span class="line">table=pd.crosstab(true_label</span><br><span class="line">                  ,predicted_class_indices</span><br><span class="line">                  ,colnames=[&apos;Predict label&apos;]</span><br><span class="line">                  ,rownames=[&apos;True label&apos;],)</span><br><span class="line">print(table)</span><br></pre></td></tr></table></figure><p>课程作业的收尾自然是画一张有趣的图，混淆矩阵。用来具体分析判错样本的类别。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">princess_list = list(validation_generator.class_indices.keys())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用之前写的函数画混淆矩阵</span></span><br><span class="line">plot_confuse(predicted_class_indices</span><br><span class="line">             ,validation_generator.classes</span><br><span class="line">             ,princess_list)</span><br></pre></td></tr></table></figure><img src="/2021/09/22/210922transfer/confusion.png" title="confusion"><p>以及最后再补几句像模像样的分析。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型最爱的公主</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'公主的数量:\n'</span>,table.sum(axis=<span class="number">1</span>),<span class="string">'\n\n'</span>)</span><br><span class="line">print(<span class="string">'预测的公主数量:\n'</span>,table.sum(axis=<span class="number">0</span>),<span class="string">'\n\n'</span>)</span><br><span class="line"></span><br><span class="line">pred_true_ratio = table.sum(axis=<span class="number">0</span>) / table.sum(axis=<span class="number">1</span>) <span class="comment"># 按行加是正确的数量</span></span><br><span class="line">names = list(validation_generator.class_indices.keys())</span><br><span class="line">print(<span class="string">'各类的预测数量/真实数量的比例:\n'</span>, pred_true_ratio,<span class="string">'\n\n'</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'公主名称:\n'</span>,pd.Series(names),<span class="string">'\n\n'</span>)</span><br><span class="line">print(<span class="string">'比例最低的“小冷清”：'</span>,list(validation_generator.class_indices.keys())[np.argmin(pred_true_ratio)])</span><br><span class="line">print(<span class="string">'比例最高的“大众脸”：'</span>,list(validation_generator.class_indices.keys())[np.argmax(pred_true_ratio)])</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">公主的数量:</span><br><span class="line"> True label</span><br><span class="line">0     31</span><br><span class="line">1     56</span><br><span class="line">2     20</span><br><span class="line">3     22</span><br><span class="line">4     30</span><br><span class="line">5     44</span><br><span class="line">6     52</span><br><span class="line">7     20</span><br><span class="line">8     33</span><br><span class="line">9     24</span><br><span class="line">10    33</span><br><span class="line">11    36</span><br><span class="line">12    36</span><br><span class="line">13    23</span><br><span class="line">dtype: int64 </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">预测的公主数量:</span><br><span class="line"> Predict label</span><br><span class="line">0      11</span><br><span class="line">1     155</span><br><span class="line">3       3</span><br><span class="line">4       5</span><br><span class="line">5      96</span><br><span class="line">6      95</span><br><span class="line">8       5</span><br><span class="line">10     33</span><br><span class="line">11     50</span><br><span class="line">13      7</span><br><span class="line">dtype: int64 </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">各类的预测数量/真实数量的比例:</span><br><span class="line"> 0     0.354839</span><br><span class="line">1     2.767857</span><br><span class="line">2          NaN</span><br><span class="line">3     0.136364</span><br><span class="line">4     0.166667</span><br><span class="line">5     2.181818</span><br><span class="line">6     1.826923</span><br><span class="line">7          NaN</span><br><span class="line">8     0.151515</span><br><span class="line">9          NaN</span><br><span class="line">10    1.000000</span><br><span class="line">11    1.388889</span><br><span class="line">12         NaN</span><br><span class="line">13    0.304348</span><br><span class="line">dtype: float64 </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">公主名称:</span><br><span class="line"> 0        艾莎</span><br><span class="line">1       爱丽儿</span><br><span class="line">2      爱洛公主</span><br><span class="line">3        安娜</span><br><span class="line">4      白雪公主</span><br><span class="line">5      宝嘉康蒂</span><br><span class="line">6      贝儿公主</span><br><span class="line">7     蒂安娜公主</span><br><span class="line">8       花木兰</span><br><span class="line">9       灰姑娘</span><br><span class="line">10       乐佩</span><br><span class="line">11    梅丽达公主</span><br><span class="line">12     茉莉公主</span><br><span class="line">13      莫安娜</span><br><span class="line">dtype: object </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">比例最低的“小冷清”： 安娜</span><br><span class="line">比例最高的“大众脸”： 爱丽儿</span><br></pre></td></tr></table></figure><p>看一看错分样本，尝试找到错分的原因。主要还是训练集风格不统一，有2D有3D，有官方作品有同人作品，有漫画作品有电影作品……</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 展示错判的图（错分样本）</span></span><br><span class="line">datapred = predicted_class_indices.tolist()</span><br><span class="line">datatrue = validation_generator.classes.tolist()</span><br><span class="line"></span><br><span class="line">wrong_len = validation_generator.n - list(map(<span class="keyword">lambda</span> x: x[<span class="number">0</span>]-x[<span class="number">1</span>], zip(datapred, datatrue))).count(<span class="number">0</span>)</span><br><span class="line">print(<span class="string">'一共错误预判了 %d 张图片'</span> % wrong_len) <span class="comment">## 一共错误预判了 45 张图片</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重置数据集</span></span><br><span class="line">validation_generator.reset()</span><br><span class="line">X,Y = next(validation_generator)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置画布</span></span><br><span class="line">plt.figure()</span><br><span class="line">fig,ax = plt.subplots(wrong_len//<span class="number">5</span>+<span class="number">1</span>,<span class="number">5</span>)</span><br><span class="line">fig.set_figheight(wrong_len)</span><br><span class="line">fig.set_figwidth(<span class="number">15</span>)</span><br><span class="line">ax = ax.flatten()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历输出每一张错判的图</span></span><br><span class="line">wrong_list = []</span><br><span class="line">k = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(validation_generator.n):</span><br><span class="line">    <span class="comment"># 每一个X里只有64张图片 如果想打100以外的index 得再next一下</span></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">64</span> == <span class="number">0</span> <span class="keyword">and</span> i != <span class="number">0</span>:</span><br><span class="line">        X,Y = next(validation_generator)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> list(map(<span class="keyword">lambda</span> x: x[<span class="number">0</span>]-x[<span class="number">1</span>], zip(datapred, datatrue)))[i] != <span class="number">0</span>:</span><br><span class="line">        wrong_list.append(i)</span><br><span class="line">        ax[k].imshow(X[i%<span class="number">64</span>,:,:,:])</span><br><span class="line">        ax[k].set_title(<span class="string">'pred:'</span>+ str(princelist[datapred[i]]) + <span class="string">'true:'</span> + str(princelist[datatrue[i]]))</span><br><span class="line">        k += <span class="number">1</span></span><br></pre></td></tr></table></figure><img src="/2021/09/22/210922transfer/wrongpics.png" title="wrongpics"><p>分类正确率最高的为灰姑娘(100%:12/12)，最低的为爱洛(40%:4/10)；最容易被错认的公主为莫安娜(8次)，最不容易被错认的公主为茉莉公主(1次)。</p><p>其中，白雪公主有4个样本被错判成莫安娜，错分次数最高，而白雪公主的7个错判样本中，有6个都为黑发黑人公主，白雪公主为黑发白人公主，因此可以看出，发色是分类学习的重要特征之一。</p><p>双向被错判的公主为，乐佩和爱洛、宝嘉康蒂和爱丽儿、艾莎和爱丽儿、白雪公主和茉莉公主、花木兰和蒂安娜。其中，乐佩和爱洛同为白人金色长发公主，花木兰和蒂安娜同为深肤色黑色长发公主，具有较大相似性，白雪公主和茉莉公主同为黑发，艾莎和爱丽儿同为白人公主，也具有相似性。宝嘉康蒂和爱丽儿，为什么会被认错QAQ？</p><p>除了同肤色同发色的公主外，可以看到背景也是分类学习的重要特征，比如莫安娜的训练集图片背景都为海边，被错判的图片背景为白色，因此被错误分类为宝嘉康蒂。</p><h2 id="Fine-Tune"><a href="#Fine-Tune" class="headerlink" title="Fine-Tune"></a>Fine-Tune</h2><p>解放固有，来点属于自己的东西</p><p>既然是站在巨人的肩膀上，那索性做一些大胆的尝试。比如解放最后的卷积层，让模型重新训练一次，看看能不能有更好的效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选择之前效果最好的模型</span></span><br><span class="line"><span class="keyword">from</span> keras.applications.inception_v3 <span class="keyword">import</span> InceptionV3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入数据</span></span><br><span class="line">(train_finetune, validation_finetune) = load_data(im_size=<span class="number">224</span>, batch_size = <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入已训练参数</span></span><br><span class="line">base_model = InceptionV3(weights=<span class="string">'imagenet'</span>,include_top=<span class="keyword">False</span>)</span><br><span class="line">x = base_model.output</span><br><span class="line">x = GlobalAveragePooling2D()(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在最后加入14分类的全连接层</span></span><br><span class="line">x = Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">predictions = Dense(<span class="number">14</span>,activation=<span class="string">'softmax'</span>)(x)</span><br><span class="line">finetune_model = Model(inputs=base_model.input, outputs=predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解冻最后三层</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> base_model.layers[:len(base_model.layers)<span class="number">-3</span>]:</span><br><span class="line">    layer.trainable = <span class="keyword">False</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> base_model.layers[len(base_model.layers)<span class="number">-3</span>:]:</span><br><span class="line">    layer.trainable = <span class="keyword">True</span></span><br><span class="line">    </span><br><span class="line">finetune_model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment">## 这里输出依然略过</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">finetune_model.compile(loss=<span class="string">'categorical_crossentropy'</span>, </span><br><span class="line">                          optimizer=Adam(lr=<span class="number">0.001</span>), </span><br><span class="line">                          metrics=[<span class="string">'accuracy'</span>]</span><br><span class="line">                         )</span><br><span class="line">finetune_history = finetune_model.fit_generator(train_finetune</span><br><span class="line">                                                      ,validation_data=validation_finetune</span><br><span class="line">                                                      ,epochs=<span class="number">1</span></span><br><span class="line"><span class="comment">#                                                       ,epochs=100</span></span><br><span class="line">                                                     ) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存结果</span></span><br><span class="line"><span class="comment"># 创建结果保存文件夹</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(output_path + <span class="string">'/model'</span>) == <span class="keyword">False</span> : os.mkdir(output_path + <span class="string">'/model'</span>)</span><br><span class="line"><span class="keyword">if</span> os.path.exists(output_path + <span class="string">'/acc'</span>) == <span class="keyword">False</span> : os.mkdir(output_path + <span class="string">'/acc'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存正确率结果</span></span><br><span class="line"><span class="keyword">with</span> open(output_path + <span class="string">'/acc/finetune_history.txt'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(finetune_history.history, f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型结果</span></span><br><span class="line">finetune_model.save(output_path + <span class="string">"/model/finetune.h5"</span>)</span><br></pre></td></tr></table></figure><p>对比的结果不重要（其实也是找不到了）。但迁移学习给了我们很多的可能性，比如利用更好的资源做训练，而把训练好的模型参数放入轻量化的应用中。</p><p>最终验证集的正确率有60%+，着实出人意料。这或许就是神经网络的有趣之处。</p><p>记得老师的总结：“这组同学先用图片训练了一下组里唯一的男生，我估计这位男同学以后去迪士尼玩能当导游。”可惜我过了一个暑假就几乎全忘了呢，而迁移学习竟然能够把学习成果一直保留！（废话）</p><p>偶尔也想做个机器人呢。</p><p>（完，请享受深度学习之旅）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;又是一学期过去了，博客也许久未更新，生活在鸡零狗碎中仓皇逃窜，留下一地的残篇断页，无人捡拾。而我，总算是鼓起勇气，拿起笔开始写一些总结了。&lt;/p&gt;
&lt;p&gt;本文介绍的是深度学习中&lt;strong&gt;迁移学习&lt;/strong&gt;的入门级知识。项目是&lt;strong&gt;迪士尼公主&lt;/strong&gt;图像识别。&lt;/p&gt;
&lt;p&gt;苦了我了！&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>大数据|分布式计算课程笔记（持续更新）</title>
    <link href="https://konelane.github.io/2021/01/04/20-21%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%B1%87%E6%80%BB%E6%96%87%E4%BB%B6/"/>
    <id>https://konelane.github.io/2021/01/04/20-21%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%B1%87%E6%80%BB%E6%96%87%E4%BB%B6/</id>
    <published>2021-01-03T16:00:00.000Z</published>
    <updated>2021-01-04T08:39:12.325Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>还是熟悉的feng.li老师，还是熟悉的瓜皮禾禾，哈哈哈哈。</p><p>没想到研究生依然能听李丰老师的课。欢迎参观李丰老师<a href="https://feng.li/" target="_blank" rel="noopener">主页</a>，<a href="https://feng.li/teaching/distcomp/" target="_blank" rel="noopener">课程主页</a></p><p>李丰老师合著的<a href="https://feng.li/files/distcompbook/index.html" target="_blank" rel="noopener">参考书</a>依然在编</p><a id="more"></a><p>10.07记：被李丰老师表扬了！！甚至还被打赏了（笑</p><p>继续努力啊小禾禾</p><p><a href="https://konelane.github.io/2020/09/17/200917hadoop">分布式0917-遍历检索的多进程初试水</a></p><p><a href="https://konelane.github.io/2020/09/24/200924hadoop">分布式0924-分布式服务器基础Linux中主机的远程交互(ssh)</a></p><p><a href="https://konelane.github.io/2020/10/07/201007hadoop">分布式1007-Map-Reduce的文字流</a></p><p><a href="https://konelane.github.io/2020/10/21/201015hadoop">分布式1015-1021-分布式回归分析</a></p><p><a href="https://konelane.github.io/2020/11/02/201102hadoop">分布式1102-Hi,Hive!Hi,Spark!</a></p><p><a href="https://konelane.github.io/2020/11/12/201112hadoop">分布式1112-Spark简单功能补充介绍</a></p><p><a href="https://konelane.github.io/2020/11/19/201119hadoop">分布式1119-Spark做些实战-以及为之后的实战铺路</a></p><p><a href="https://konelane.github.io/2020/11/26/201126hadoop">分布式1126-Spark文本分析</a></p><p><a href="https://konelane.github.io/2020/12/10/201210hadoop">分布式1210-Spark与Scala</a></p><h3 id="做个综述-Why-Distributed-Statistical-Computing？"><a href="#做个综述-Why-Distributed-Statistical-Computing？" class="headerlink" title="做个综述-Why Distributed Statistical Computing？"></a>做个综述-Why Distributed Statistical Computing？</h3><p>现成的统计软件提供了常用的计算方式。</p><p>我们学牛顿迭代，学QR分解，可以用在广义线性模型里。</p><p>这些方法，可以适用于各种模型。并非是重复应用现成统计工具。统计计算旨在让你理解工具，并且实现新的目标。一个线性回归，也有很多的东西。</p><p>上面是传统的统计计算的目标。</p><p>下来类推到分布式计算。</p><p>spark里也可以做线性回归与逻辑回归。Spark.ml（里有机器学习，有回归）</p><p>为何要花时间学hadoop版本的线性回归，目的是能够<strong>把知识平行迁移到分布式平台上</strong>。</p><p>不仅仅是告诉我们ml下有什么模型，这个是初级阶段。</p><p>如果某一天，spark里没有机器学习模块了，而我们仍然有能力写自己的模型。</p><p>在很多时候，能够写出自己的模型是有优势的。</p><p>如，现有一份稠密的数据，我想做一个分布式的模型。我想做一个ar模型，我想做screening，我想做分位数回归，可是spark上没有。但是作为统计学背景的，我们知道很多统计方法，结合现在这个分布式计算的时代，适当地借助现有的工具，在spark上实现这样的操作，那么这门课就步入中级了。</p><p>如果自己开发了个spark，那就是高级了。（氦核：啊这）</p><p>r软件里写这样的相对容易。spark里则是有难度的。如果你不善于整理归纳，统计学很多方法、算法可能看起来非常混乱。真正意义上的统计学只有八十年，统计计算开始于上世纪90年代。</p><blockquote><p>1.数据状态（静态线下数据—动态实时大样本全量数据）</p><p>2.计算模式（单机存储单机计算—分布式存储分布式计算）</p><p>3.数据存储（统计模型与数据一体化—统计模型部署到数据）对y和x没要求，分布式中很挑剔，rdd还是dataframe，是稀疏矩阵还是稠密矩阵是sparkml（dataframe形式）还是mllab（rdd形式）</p><p>4.计算逻辑（单个模型对应单个算法实现—所有模型一体化计算框架）</p><p>5.需求实现（模型评估与应用—实时模型评估与预测需求）</p></blockquote><p>我们对数据要有一定的认识。比如数据必须保存成特征（feature）+标签（label）的形式。</p><p>先写一个目标函数，然后优化。常见的优化算法，列出来12345。计算机背景的人，首先定义一个损失函数Loss，第二选一个合适的数据，第三做优化（牛顿迭代，梯度下降）。一二三就是一个流水线，通过管道（pipe）来进行。</p><p>我们搞统计的，就应该适应这种<strong>管道形式</strong>的建模思路，分布式的建模策略。</p><p>很多时候，我们的模型假设性太强，但现在的分布式平台中，根本没法满足传统假设。原来的统计方法还能否适用？传统的统计学家不关心。这好吗，这不好。要迁移到分布式的计算上来，要有很多新的观念上的转变，要有持续的转变思维。</p><p>比如，时间序列数据在分布式平台上就很缺乏。如果我们做开发，那么我们的平台/接口一定要有计算性+可延展性：即需要易用性、通用性，能使用户拥有比较统一的输入和输出，全流程都能解决，通过统一的分布式接口，使你的平台将来能更好地被别人所接受。</p><blockquote><p>统计学，每个学科都要学。计算机，经济学，管理学，等等都要学统计。</p><p>——李丰老师</p></blockquote><p>我们要有新的平台，在最后做一个组合，能够完成大多数场景的统计计算，<strong>Hadoop就是一个足够好的分布式计算平台，但是hadoop不是足够好的统计计算平台</strong>。有一天你也能开发出足够好的统计计算平台。</p><p>海量数据下，现有应用场景，再想在应用场景下的工具。产品经理与算法工程师都是如此，用什么方法不重要，重要的是能够支持负载，能把这些都算出来，保证不宕机。</p><p>当前的情况不一样了，举一个例子：后台监管中，可能刻意回避一些东西。曾经有个跨境交易不能超过20w美元，风险点。于是各大银行会把跨境的交易全部拆成199美元。这些东西必须要学习模型来识别。核酸检测也是如此，识别feature。再比如，人类的基因组计划，ATCG的特征，每个人都要产生很大的核酸数据。</p><p>三步走： </p><blockquote><p>应用场景：稳定性检测预警+动态监测与预报+样本实时监测</p><p>1.实时数据</p><p>2.统计计算</p><p>3.需求：分布式模型选择，分布式模型选择准则，约束下模型选择与决策</p><p>实时数据源：历史数据集+实时采集数据集</p></blockquote><p>现在不像以前那么简单了。不过，蓝图应如此。 </p><h3 id="老师的研究"><a href="#老师的研究" class="headerlink" title="老师的研究"></a>老师的研究</h3><p><a href="https://github.com/feng-li/dlsa" target="_blank" rel="noopener">DLSA分布式的最小二乘近似</a></p><p>如何在现有平台上开发出自己的东西呢？</p><p>最小二乘近似，这是面对统计计算的接口。</p><p>能够使各种各样的统计模型都能应用在分布式平台上。</p><p>数据不动，最后算完合并。性质不好。</p><p>NIPS讨论了以更好方式重新对参数进行聚合，保证聚合的效果。2014</p><p>用在具体模型中，比如主成分。2017（范剑青老师的文章）</p><p>每次开发成本较高。每次一个新模型都要适配。</p><p>若采用一次性的估计，效率很有问题。而采用多次的时候迭代中通讯成本较高。</p><p>如果想把大数据合成小块，其实有个默认假设：数据随机分布。</p><p>一个桶倒满之后，再倒第二个桶，是增量的形式。如果完全利用one-shot（之前有介绍，是一种稀疏数据储存方式）会损失很多信息。</p><p>老师就希望提供一个解决方案。希望提供一个有效地估计，在计算节点上也有效，且有普适性，能够迁移到其他算法中。</p><p>此时，就轮到<strong>DLSA分布式的最小二乘近似</strong>出场了。（严格证明略）</p><p>给定某一个参数theta，似然函数就是当前数据所有特征最大的体现。</p><p>如果n个样本，这个似然函数可能是对n个密度的求和。</p><p>如果让似然函数除以n，则变成了一个损失函数。此时与机器学习中的方案对应起来了。</p><p>对似然函数没有任何假设。线性、非线性、时间序列都行。</p><p>对似然函数二阶导展开，展开后变换，之后新的似然函数会变成原始的似然减去新的目标，再加上一个常数c。就能近似写成某个形式。最后等价于一个加权最小二乘的表达式。极大化似然估计，就等价于如何对公式做最小二次近似。</p><p>这是一个标准的思路：<strong>统计理论，实现，组合成可应用形式。</strong></p><p>spark上能不能做到逻辑回归，是否有你的方法好，是否贡献了全新的接口，是否解决了问题（推荐航班（此处指那时候刚结束的air-delay数据清洗工作），不延误，省钱）。</p><p>还有很多工作待发掘，未来可期。</p><p>还发现一个repo，没来的及看：<a href="https://github.com/feng-li/darima" target="_blank" rel="noopener">分布式上的时间序列数据darima</a></p><p>（完）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;还是熟悉的feng.li老师，还是熟悉的瓜皮禾禾，哈哈哈哈。&lt;/p&gt;
&lt;p&gt;没想到研究生依然能听李丰老师的课。欢迎参观李丰老师&lt;a href=&quot;https://feng.li/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;主页&lt;/a&gt;，&lt;a href=&quot;https://feng.li/teaching/distcomp/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;课程主页&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;李丰老师合著的&lt;a href=&quot;https://feng.li/files/distcompbook/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考书&lt;/a&gt;依然在编&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式1210-Spark与Scala</title>
    <link href="https://konelane.github.io/2020/12/10/201210hadoop/"/>
    <id>https://konelane.github.io/2020/12/10/201210hadoop/</id>
    <published>2020-12-09T16:00:00.000Z</published>
    <updated>2021-01-04T08:13:26.339Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>spark的基础语法-Scala，做了一些思想性的介绍。</p><p>具体代码参考李丰老师课件<a href="https://github.com/feng-li/Distributed-Statistical-Computing/tree/master/L10-Spark-with-Scala" target="_blank" rel="noopener"><strong>L10.1-Introduction-to-Scala</strong></a>。</p><a id="more"></a><h3 id="一、Scala介绍"><a href="#一、Scala介绍" class="headerlink" title="一、Scala介绍"></a>一、Scala介绍</h3><p>scala语言，面向大数据编程的语言。</p><p>这个语言只有十来年的历史。这个语言没有排在前二十的常见语言上，但确实进步最快的语言。因为它可以对海量数据进行高强度高密度的计算。</p><p>c语言是编译语言，快，但是写的麻烦。89十年代改用写起来快，跑起来快的python之流。现在就是写起来好写，且跑起来快。</p><p>新版本的spark，<strong>底层语言</strong>大部分是scala了。java不支持交互式输入，必须编译成机器码。而现在的编程习惯更多是交互式的。一部分习惯于python，另一部分习惯于scala。下面来比较一下这两种语言。</p><p>scala比python快十倍以上。spark比python快100倍（nb）。使用了java虚拟机机制，允许程序在运行中进行编译，比起python这种纯解释性的动态语言要快一个量级。</p><p>传统的c和java快，但是机器语言不好写。</p><p>对应的库上看，spark同时有scala和python的库，很多最新的特性都从scala上出现，再传递给python。</p><p>scala可以当做普通变成语言，也可以单机上使用。可以与hadoop结合。</p><p>考虑scala的学习曲线，python很好上手，有循环基础基本上1周就能写程序。scala比python略复杂，scala有一些特殊特性是原来不具有的（保证了速度的提升）。如果简单操作，完全可以用python写。如果计算速度会成为项目的瓶颈，那么可以选择scala。</p><p>语法最简单的是c语言，c++更难，java甚之，python处于三者之中，好写，慢。</p><p>比起python，scala更擅长处理复杂工作模式。</p><p>易用性上，python上有很多机器学习库可以使用，scala没有那么多。</p><p>很难把python语句导入scala。在多线程中，python经常阻塞，出问题。scala是内置的。</p><p>比起java，scala对内存要求不贪婪。spark就是个例子。scala可以快速释放内存，能较好地管理内存。</p><p>对于用户，需要知道一些常用的库，上手之后就比较舒服了。但有些环境很少工具，离不开原来的环境。比如自然语言处理用的都是python，scala需要很多操作。spark上python就很好用。</p><p>最后，定义一下：</p><p>scala面向对象，高级语言。静态语言，语法有时候比python更可读。（主要是，python的numpy、pandas用法读法都不一样，不同的库用法也不同。）</p><h3 id="二、一些实用操作"><a href="#二、一些实用操作" class="headerlink" title="二、一些实用操作"></a>二、一些实用操作</h3><p>（上参考网站更全面更系统一些）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//注释</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line">可以注释多行</span><br><span class="line">*/</span><br></pre></td></tr></table></figure></p><p>scala在定义变量时，有个特有类型：mutable 与 immutable变量，广播的变量时不可修改的，是immutable的。可以定义更加方便使用的变量。val是value，凡是用val定义的，都不可修改，凡是用var定义的，都是可修改的。</p><p>spark里直接输入scala，可以进入scala的交互对话框。</p><p>1.0双精度，迭代次数很多时求导会接近0。因此需要一些超长精度的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Val b = 0 +: ints //往右侧加</span><br><span class="line"></span><br><span class="line">:+ // 往左侧加</span><br><span class="line"></span><br><span class="line">if（A）&#123;&#125;</span><br><span class="line"></span><br><span class="line">else&#123;B&#125;</span><br></pre></td></tr></table></figure><p>scala比python快，但是不一定比scala易用。但将来一定更易用。</p><p>（具体方法省略了很多，更多内容请上参考网站。scala在平时学习中用的不多，且有一定门槛）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;spark的基础语法-Scala，做了一些思想性的介绍。&lt;/p&gt;
&lt;p&gt;具体代码参考李丰老师课件&lt;a href=&quot;https://github.com/feng-li/Distributed-Statistical-Computing/tree/master/L10-Spark-with-Scala&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;strong&gt;L10.1-Introduction-to-Scala&lt;/strong&gt;&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式1126-Spark文本分析</title>
    <link href="https://konelane.github.io/2020/11/26/201126hadoop/"/>
    <id>https://konelane.github.io/2020/11/26/201126hadoop/</id>
    <published>2020-11-25T16:00:00.000Z</published>
    <updated>2021-01-04T08:45:01.025Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>spark的文本分析功能。</p><p>具体代码参考李丰老师课件<a href="https://github.com/feng-li/Distributed-Statistical-Computing/tree/master/L07-Machine-Learning-with-Spark" target="_blank" rel="noopener">L07.2-Text-Processing-with-Spark</a>。</p><a id="more"></a><h3 id="一、大数据文本分析的需求"><a href="#一、大数据文本分析的需求" class="headerlink" title="一、大数据文本分析的需求"></a>一、大数据文本分析的需求</h3><p>利用分布式系统，进行文本处理。</p><p>现在有很多文本型数据，到底会遇见什么不一样的地方，spark又提供了哪些工具？</p><p>从基本概念和流程开始。</p><blockquote><p>术语：</p><p>语料库。corpora。</p></blockquote><p>语料库是一个包含大量感兴趣文本的集合，比如说，人民日报创刊以来所有的新闻社论。每个版2-3篇文章，一天做成一个行向量（可以是个很长的字典/列表），写入系统。</p><p>语料库最早是语言学家使用，处理语言问题。如研究50年代的语法，用于习惯。有从各种角度建立的语料库：经济学角度，政治角度，统计学角度，等等。</p><p>几十年前，如果研究人文类，会成为纯文科的事。而今，可以利用计算机，做<strong>词频统计</strong>等等，理科人也能掺和进来了。</p><p>来源，可能是工作就有，可能是自己采集，甚至可以我们自己构建语料库。</p><p>n乘k的语料矩阵，可以转成n乘m的语义数值阵，这一步很难，且有争议。解读和设定都比较主观，没有统一的标准。如何提取稳定的信息，就需要统计模型。</p><p>语料和数值型差距较大。</p><p>一个外国（说英语的）大学生，词汇量有两万多。构成文章，是这些词的排列组合，会有非常非常多的可能，计算机无法处理。也就无法将词作为基本单元来处理了。</p><p>于是需要化简，在处理中就是：断句分词。</p><p>逗号之间，段落内拆分成很小很多的单元。</p><blockquote><p>我们学句读，就是在训练自己，把自己变成解释器。</p><p>——李丰老师</p></blockquote><p>拆分成单词，就会丢失句子的信息。</p><p>而当今很多语言模型不能就“序”进行建模。 我爱北京天安门，北京天安门爱我。这两句在家语言模型中可能是相同的。红黄蓝，蓝黄红，如果顺序有个权重，就完蛋了。（氦核：完蛋，全完蛋）</p><p>中文更特别，单词间没有空格，于是需要拆分词。在线翻译依然很垃圾，主要原因是文本实在是太难了。</p><p>新闻信息：语音录制工具（记录，转文本），做摘要，重新做新的填空，再做快报。</p><p>庭审记录员：解放书记员，书记员的记录会出错/有倾向性。背后有语义模型。</p><p>体育赛事：捕捉球员的用语，捕捉球员的兴奋状态。NBA以及是统计模型的竞赛了。</p><blockquote><p>好的文本处理工具，可以让我们对语言不再束手无策。</p><p>——李丰老师</p></blockquote><p>停词中，把相类似相近的东西都替换成相关的内容。语言处理需要大量经验。斯坦福的自然语言处理，中国中科院，哈工大，都有自己的语料库。有趣而无聊的操作。</p><p>很多互联网公司提供了免费的api，根据其语料库分词。造就了当今输入法。</p><p>举个海底捞的例子，海底捞商标，如果我注册一个河底捞商标，侵权了吗。（氦核：老师这举的啥例子。。笑）</p><h3 id="二、Spark的解决方案"><a href="#二、Spark的解决方案" class="headerlink" title="二、Spark的解决方案"></a>二、Spark的解决方案</h3><p>现在看看上面的操作，spark如何操作。</p><p>英文：对每一行都做了split拆分，得到一个词频矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HashingTF(inputCol = <span class="string">'words'</span>,outputCol = <span class="string">'rawFeatures'</span>)</span><br></pre></td></tr></table></figure><p>另一个工具叫IDF，每天要过滤很多网络信息，很多没用的信息。</p><p>三千封邮件中，有两份出现了“爆炸”“枪”，两个词同时出现。关联性的信息很强。就要适当放大权重。（这就是通过IDF来实现的）把那些我们在常用词里不关心，但低频词在多个文档都出现的，增加权重。</p><p>再比如，有很多政治新闻，会影响原油价格。我想回归，把政治新闻当做协变量。谷歌找了一个办法，把文本信息做成向量Word2VecModel（word2vec），里面还要信号强度。通过两层的神经网络，重新转化成一个数值型向量。</p><p>去除停词StopWordsRemover</p><h4 id="一些新的想法："><a href="#一些新的想法：" class="headerlink" title="一些新的想法："></a>一些新的想法：</h4><p>扩大相关性：</p><p>以一个词为中心，向左组词，向右组词，这个情况叫bi-gram，i向右扩1个，扩2个……信息的离散度越高。确定性的信息越少。不能无限扩大，常见的是2或3，能够体现相关性，重新构建词频矩阵。</p><p>我爱北京天安门</p><p>1我2爱3北京4天安门</p><p>5我爱6爱北京7我爱北京（567以爱为中心）</p><h4 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h4><p>根据相似性聚合在一起，这个过程叫狄利克雷过程，也叫中国餐馆过程。哈哈。</p><p>如果这里面每一个客人，都是单词，我们就能通过统计学的聚类工具，自动把文章分为不同的主题。</p><p><strong>主题模型建模</strong>发展目前正趋于成熟。</p><h3 id="三、实战"><a href="#三、实战" class="headerlink" title="三、实战"></a>三、实战</h3><p>略过建立sc的步骤</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br></pre></td><td class="code"><pre><span class="line">textFile = sc.textFile(<span class="string">"test.txt"</span>)</span><br><span class="line">textFile.first()</span><br><span class="line"><span class="comment">## 展示结果： </span></span><br><span class="line"><span class="comment">## 'Title: The Romance of Wills and Testaments'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">type(textFile)</span><br><span class="line"><span class="comment">## 展示结果： </span></span><br><span class="line"><span class="comment">## pyspark.rdd.RDD</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 去空行</span></span><br><span class="line">print(textFile.count())</span><br><span class="line">text0 = textFile.filter(<span class="keyword">lambda</span> x: len(x)&gt;<span class="number">1</span>) <span class="comment"># 留下符合要求的行</span></span><br><span class="line">print(text0.count())</span><br><span class="line"><span class="comment">## 展示结果： </span></span><br><span class="line"><span class="comment">## 1129</span></span><br><span class="line"><span class="comment">## 492</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> HashingTF, IDF, Tokenizer</span><br><span class="line">tokenizer = Tokenizer(inputCol=<span class="string">"sentence"</span>, outputCol=<span class="string">"words"</span>)</span><br><span class="line">tokenizer</span><br><span class="line"><span class="comment">## 展示结果： </span></span><br><span class="line"><span class="comment">## Tokenizer_39744db6461e</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意数据格式</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">sentenceData = spark.createDataFrame([</span></span><br><span class="line"><span class="string">    (0.0, "Hi I heard about Spark"),</span></span><br><span class="line"><span class="string">    (0.0, "I wish Java could use case classes"),</span></span><br><span class="line"><span class="string">    (1.0, "Logistic regression models are neat")</span></span><br><span class="line"><span class="string">], ["label", "sentence"])</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment"># 此处要用 开始创建的sparksession创建DataFrame</span></span><br><span class="line">sentenceData= ss.createDataFrame(</span><br><span class="line">    list(zip(list(map(float,range(len(text0.collect())<span class="number">-1</span>))), text0.collect())) <span class="comment"># 元祖信息</span></span><br><span class="line">,[<span class="string">'label'</span>,<span class="string">'sentence'</span>])</span><br><span class="line">sentenceData</span><br><span class="line"><span class="comment">## DataFrame[label: double, sentence: string]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 载入分词引擎</span></span><br><span class="line">wordsData = tokenizer.transform(sentenceData)</span><br><span class="line">wordsData.show()</span><br><span class="line"><span class="comment">## 展示结果： </span></span><br><span class="line"><span class="comment">## +-----+--------------------+--------------------+</span></span><br><span class="line"><span class="comment">## |label|            sentence|               words|</span></span><br><span class="line"><span class="comment">## +-----+--------------------+--------------------+</span></span><br><span class="line"><span class="comment">## |  0.0|Title: The Romanc...|[title:, the, rom...|</span></span><br><span class="line"><span class="comment">## |  1.0|Author: Edgar Vin...|[author:, edgar, ...|</span></span><br><span class="line"><span class="comment">## |  2.0|             PREFACE|           [preface]|</span></span><br><span class="line"><span class="comment">## |  3.0|By way of preface...|[by, way, of, pre...|</span></span><br><span class="line"><span class="comment">## |  4.0|As in death, so i...|[as, in, death,, ...|</span></span><br><span class="line"><span class="comment">## |  5.0|Different types a...|[different, types...|</span></span><br><span class="line"><span class="comment">## |  6.0|It is desired to ...|[it, is, desired,...|</span></span><br><span class="line"><span class="comment">## |  7.0|Again, there are ...|[again,, there, a...|</span></span><br><span class="line"><span class="comment">## |  8.0|Especial acknowle...|[especial, acknow...|</span></span><br><span class="line"><span class="comment">## |  9.0|The idea of this ...|[the, idea, of, t...|</span></span><br><span class="line"><span class="comment">## | 10.0|Since these essay...|[since, these, es...|</span></span><br><span class="line"><span class="comment">## | 11.0|Scattered about t...|[scattered, about...|</span></span><br><span class="line"><span class="comment">## | 12.0|Other references ...|[other, reference...|</span></span><br><span class="line"><span class="comment">## | 13.0|       E. VINE HALL.|   [e., vine, hall.]|</span></span><br><span class="line"><span class="comment">## | 14.0|          Wimbledon.|        [wimbledon.]|</span></span><br><span class="line"><span class="comment">## | 15.0|           CHAPTER I|        [chapter, i]|</span></span><br><span class="line"><span class="comment">## | 16.0|THE ROMANCE OF WILLS|[the, romance, of...|</span></span><br><span class="line"><span class="comment">## | 17.0|��The older I gro...|[��the, older, i,...|</span></span><br><span class="line"><span class="comment">## | 18.0|The words of the ...|[the, words, of, ...|</span></span><br><span class="line"><span class="comment">## | 19.0|Historically they...|[historically, th...|</span></span><br><span class="line"><span class="comment">## +-----+--------------------+--------------------+</span></span><br><span class="line"><span class="comment">## only showing top 20 rows</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hashingTF = HashingTF(inputCol=<span class="string">"words"</span>, outputCol=<span class="string">"rawFeatures"</span>, numFeatures=<span class="number">20</span>)</span><br><span class="line">featurizedData = hashingTF.transform(wordsData)</span><br><span class="line">featurizedData.show()</span><br><span class="line"><span class="comment">## 展示结果： </span></span><br><span class="line"><span class="comment">## +-----+--------------------+--------------------+--------------------+</span></span><br><span class="line"><span class="comment">## |label|            sentence|               words|         rawFeatures|</span></span><br><span class="line"><span class="comment">## +-----+--------------------+--------------------+--------------------+</span></span><br><span class="line"><span class="comment">## |  0.0|Title: The Romanc...|[title:, the, rom...|(20,[6,10,11,12,1...|</span></span><br><span class="line"><span class="comment">## |  1.0|Author: Edgar Vin...|[author:, edgar, ...|(20,[1,2,7,8],[1....|</span></span><br><span class="line"><span class="comment">## |  2.0|             PREFACE|           [preface]|      (20,[2],[1.0])|</span></span><br><span class="line"><span class="comment">## |  3.0|By way of preface...|[by, way, of, pre...|(20,[1,2,3,4,6,7,...|</span></span><br><span class="line"><span class="comment">## |  4.0|As in death, so i...|[as, in, death,, ...|(20,[0,1,2,3,4,5,...|</span></span><br><span class="line"><span class="comment">## |  5.0|Different types a...|[different, types...|(20,[0,1,3,4,5,6,...|</span></span><br><span class="line"><span class="comment">## |  6.0|It is desired to ...|[it, is, desired,...|(20,[0,1,2,3,4,5,...|</span></span><br><span class="line"><span class="comment">## |  7.0|Again, there are ...|[again,, there, a...|(20,[0,1,2,3,4,5,...|</span></span><br><span class="line"><span class="comment">## |  8.0|Especial acknowle...|[especial, acknow...|(20,[0,1,2,3,4,5,...|</span></span><br><span class="line"><span class="comment">## |  9.0|The idea of this ...|[the, idea, of, t...|(20,[0,1,2,3,4,5,...|</span></span><br><span class="line"><span class="comment">## | 10.0|Since these essay...|[since, these, es...|(20,[0,1,2,3,5,6,...|</span></span><br><span class="line"><span class="comment">## | 11.0|Scattered about t...|[scattered, about...|(20,[1,2,3,4,5,6,...|</span></span><br><span class="line"><span class="comment">## | 12.0|Other references ...|[other, reference...|(20,[0,1,3,4,5,6,...|</span></span><br><span class="line"><span class="comment">## | 13.0|       E. VINE HALL.|   [e., vine, hall.]|(20,[0,2,18],[1.0...|</span></span><br><span class="line"><span class="comment">## | 14.0|          Wimbledon.|        [wimbledon.]|      (20,[8],[1.0])|</span></span><br><span class="line"><span class="comment">## | 15.0|           CHAPTER I|        [chapter, i]|(20,[9,16],[1.0,1...|</span></span><br><span class="line"><span class="comment">## | 16.0|THE ROMANCE OF WILLS|[the, romance, of...|(20,[6,11,15,17],...|</span></span><br><span class="line"><span class="comment">## | 17.0|��The older I gro...|[��the, older, i,...|(20,[0,1,2,3,5,6,...|</span></span><br><span class="line"><span class="comment">## | 18.0|The words of the ...|[the, words, of, ...|(20,[0,1,2,3,4,5,...|</span></span><br><span class="line"><span class="comment">## | 19.0|Historically they...|[historically, th...|(20,[0,1,3,4,5,7,...|</span></span><br><span class="line"><span class="comment">## +-----+--------------------+--------------------+--------------------+</span></span><br><span class="line"><span class="comment">## only showing top 20 rows</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># alternatively, CountVectorizer can also be used to get term frequency vectors</span></span><br><span class="line">idf = IDF(inputCol=<span class="string">"rawFeatures"</span>, outputCol=<span class="string">"features"</span>)</span><br><span class="line">idfModel = idf.fit(featurizedData)</span><br><span class="line">rescaledData = idfModel.transform(featurizedData)</span><br><span class="line">rescaledData.select(<span class="string">"label"</span>, <span class="string">"features"</span>).show()</span><br><span class="line"><span class="comment">## 展示结果： </span></span><br><span class="line"><span class="comment">## +-----+--------------------+</span></span><br><span class="line"><span class="comment">## |label|            features|</span></span><br><span class="line"><span class="comment">## +-----+--------------------+</span></span><br><span class="line"><span class="comment">## |  0.0|(20,[6,10,11,12,1...|</span></span><br><span class="line"><span class="comment">## |  1.0|(20,[1,2,7,8],[0....|</span></span><br><span class="line"><span class="comment">## |  2.0|(20,[12],[0.07923...|</span></span><br><span class="line"><span class="comment">## |  3.0|(20,[2],[1.060380...|</span></span><br><span class="line"><span class="comment">## |  4.0|(20,[12],[0.07923...|</span></span><br><span class="line"><span class="comment">## |  5.0|(20,[1,2,3,4,6,7,...|</span></span><br><span class="line"><span class="comment">## |  6.0|(20,[12],[0.07923...|</span></span><br><span class="line"><span class="comment">## |  7.0|(20,[0,1,2,3,4,5,...|</span></span><br><span class="line"><span class="comment">## |  8.0|(20,[12],[0.07923...|</span></span><br><span class="line"><span class="comment">## |  9.0|(20,[0,1,3,4,5,6,...|</span></span><br><span class="line"><span class="comment">## | 10.0|(20,[12],[0.07923...|</span></span><br><span class="line"><span class="comment">## | 11.0|(20,[0,1,2,3,4,5,...|</span></span><br><span class="line"><span class="comment">## | 12.0|(20,[12],[0.07923...|</span></span><br><span class="line"><span class="comment">## | 13.0|(20,[0,1,2,3,4,5,...|</span></span><br><span class="line"><span class="comment">## | 14.0|(20,[12],[0.07923...|</span></span><br><span class="line"><span class="comment">## | 15.0|(20,[0,1,2,3,4,5,...|</span></span><br><span class="line"><span class="comment">## | 16.0|(20,[12],[0.07923...|</span></span><br><span class="line"><span class="comment">## | 17.0|(20,[0,1,2,3,4,5,...|</span></span><br><span class="line"><span class="comment">## | 18.0|(20,[12],[0.07923...|</span></span><br><span class="line"><span class="comment">## | 19.0|(20,[0,1,2,3,5,6,...|</span></span><br><span class="line"><span class="comment">## +-----+--------------------+</span></span><br><span class="line"><span class="comment">## only showing top 20 rows</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># word2Vec</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Word2Vec</span><br><span class="line"><span class="comment"># 每个向量代表文档的词汇表中每个词语出现的次数。</span></span><br><span class="line"><span class="comment"># Input data: Each row is a bag of words from a sentence or document.</span></span><br><span class="line">documentDF = ss.createDataFrame([</span><br><span class="line">    (<span class="string">"Hi I heard about Spark"</span>.split(<span class="string">" "</span>), ),</span><br><span class="line">    (<span class="string">"I wish Java could use case classes"</span>.split(<span class="string">" "</span>), ),</span><br><span class="line">    (<span class="string">"Logistic regression models are neat"</span>.split(<span class="string">" "</span>), )</span><br><span class="line">], [<span class="string">"text"</span>])</span><br><span class="line"></span><br><span class="line"><span class="string">'''textsplit = []</span></span><br><span class="line"><span class="string">## 太慢了，慎重运行</span></span><br><span class="line"><span class="string">for i in range(len(text0.collect())-1):</span></span><br><span class="line"><span class="string">    textsplit.append((text0.collect()[i].split(' '),))</span></span><br><span class="line"><span class="string">textsplit'''</span></span><br><span class="line"><span class="comment"># 对上一行操作的替代</span></span><br><span class="line">textsplit = text0.map(<span class="keyword">lambda</span> x:x.split(<span class="string">' '</span>) )</span><br><span class="line">textsplit</span><br><span class="line"><span class="comment">## 展示结果： </span></span><br><span class="line"><span class="comment">## [(['Title:', 'The', 'Romance', 'of', 'Wills', 'and', 'Testaments'],),</span></span><br><span class="line"><span class="comment">##  (['Author:', 'Edgar', 'Vine', 'Hall'],),</span></span><br><span class="line"><span class="comment">##  (['PREFACE'],),</span></span><br><span class="line"><span class="comment">##  (['By',</span></span><br><span class="line"><span class="comment">##    'way',</span></span><br><span class="line"><span class="comment">##    'of',</span></span><br><span class="line"><span class="comment">##    'preface',</span></span><br><span class="line"><span class="comment">##    'it',</span></span><br><span class="line"><span class="comment">##    'is',</span></span><br><span class="line"><span class="comment">##    'necessary',</span></span><br><span class="line"><span class="comment">##    'to',</span></span><br><span class="line"><span class="comment">##    'explain',</span></span><br><span class="line"><span class="comment">##    'the',</span></span><br><span class="line"><span class="comment">##    'sources',</span></span><br><span class="line"><span class="comment">##    'from',</span></span><br><span class="line"><span class="comment">##    'which'...</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># word2vec</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Word2Vec</span><br><span class="line">docDF = ss.createDataFrame(list(</span><br><span class="line">    zip(textsplit.collect())</span><br><span class="line">)).toDF(<span class="string">"text"</span>)</span><br><span class="line">word2Vec = Word2Vec(vectorSize=<span class="number">3</span>, minCount=<span class="number">0</span>, inputCol=<span class="string">"text"</span>, outputCol=<span class="string">"result"</span>)</span><br><span class="line">model = word2Vec.fit(docDF)</span><br><span class="line"></span><br><span class="line">result = model.transform(docDF)</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> result.collect():</span><br><span class="line">    text, vector = row</span><br><span class="line">    print(<span class="string">"Text: [%s] =&gt; \nVector: %s\n"</span> % (<span class="string">", "</span>.join(text), str(vector)))</span><br><span class="line"><span class="comment">## 展示结果：    </span></span><br><span class="line"><span class="comment">## Text: [Title:, The, Romance, of, Wills, and, Testaments] =&gt; </span></span><br><span class="line"><span class="comment">## Vector: [0.07510965237660067,0.10043827923280851,0.19377085047640968]</span></span><br><span class="line"><span class="comment">## </span></span><br><span class="line"><span class="comment">## Text: [Author:, Edgar, Vine, Hall] =&gt; </span></span><br><span class="line"><span class="comment">## Vector: [-0.07176287146285176,-0.10652108257636428,-0.012149352580308914]</span></span><br><span class="line"><span class="comment">## </span></span><br><span class="line"><span class="comment">## Text: [PREFACE] =&gt; </span></span><br><span class="line"><span class="comment">## Vector: [0.006923258304595947,-0.002445697784423828,0.12241993099451065]</span></span><br><span class="line"><span class="comment">## </span></span><br><span class="line"><span class="comment">## Text: [By, way, of, preface, it, is, necessary, to, explain, the, sources, from, which, the, material, for, the, following, pages, is, taken., The, chief, feature, of, these, essays, consists,, I, think,, in, the, large, amount, of, original, matter, rescued, from, the, multitudinous, MS., volumes, of, wills,, &amp;c.,, which, are, preserved, at, Somerset, House, and, elsewhere.] =&gt; </span></span><br><span class="line"><span class="comment">## Vector: [0.030354710200939463,0.10534696077445038,0.05815259900582195]</span></span><br></pre></td></tr></table></figure><p>（氦核：在本地看，我贴的代码其实很整齐的QAQ</p><p>（未完待续）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;spark的文本分析功能。&lt;/p&gt;
&lt;p&gt;具体代码参考李丰老师课件&lt;a href=&quot;https://github.com/feng-li/Distributed-Statistical-Computing/tree/master/L07-Machine-Learning-with-Spark&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;L07.2-Text-Processing-with-Spark&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式1119-Spark做些实战-以及为之后的实战铺路</title>
    <link href="https://konelane.github.io/2020/11/19/201119hadoop/"/>
    <id>https://konelane.github.io/2020/11/19/201119hadoop/</id>
    <published>2020-11-18T16:00:00.000Z</published>
    <updated>2021-01-04T03:01:30.805Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>讲解作业，炒鸡复杂（其实也罢了）的air-delay数据清洗。</p><p>附带可以认识spark的强大之处。</p><a id="more"></a><h3 id="一、作业集锦"><a href="#一、作业集锦" class="headerlink" title="一、作业集锦"></a>一、作业集锦</h3><p>上一次作业里提出，我们从kaggle上download了一份巨大的数据，一共有五百万行，但只有19列。老师希望大家能处理好这个数据，清洗到能够建模的地步。</p><p>我记录了一些汇报亮点，但是大部分都消散在那节课中了。</p><h4 id="1-数据展示"><a href="#1-数据展示" class="headerlink" title="1.数据展示"></a>1.数据展示</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">air.groupby(&apos;Month&apos;).count().collect() ## collect可以看到所有列</span><br><span class="line"># count默认不排序</span><br></pre></td></tr></table></figure><p>累计求和百分比，计算占比较大的类，作为重要的变量<br>结合sql语句<br>spark命令结合sql</p><h4 id="2-哑变量处理"><a href="#2-哑变量处理" class="headerlink" title="2.哑变量处理"></a>2.哑变量处理</h4><p>陈曦同学：对老师的代码的理解：<br>students/2020211004chenxi/1112work</p><h4 id="3-引入sql"><a href="#3-引入sql" class="headerlink" title="3.引入sql"></a>3.引入sql</h4><p>周童给出了引入sql的写法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sql_accumulated = f&quot;&quot;&quot;&#123;参数&#125;</span><br><span class="line">select *</span><br><span class="line">from ( select &#123;col_name&#125;</span><br><span class="line">&quot;&quot;&quot;</span><br></pre></td></tr></table></figure><h4 id="4-分类变量的问题"><a href="#4-分类变量的问题" class="headerlink" title="4.分类变量的问题"></a>4.分类变量的问题</h4><p>注意，3分类只要两个变量，否则有共线性。有k个变量都有可能哑变量，总体应该drop掉2的k次方-k个。全都是0-1的话，就如此。计算机里叫onehot，统计就叫哑变量。</p><p>特别地，onehot存储的形式就会改变：[40,38]一共40个数，第38个位为1</p><h4 id="5-小心使用toPandas"><a href="#5-小心使用toPandas" class="headerlink" title="5.小心使用toPandas"></a>5.小心使用toPandas</h4><p>有一种储存方式是选择将sdf转化成pandas，toPandas对于count都是单机的操作。如果数据量不大，可以这样，因为这样会把数据存上master。</p><h4 id="6-某种转化因子变量的方法（我的期末作业里是另一种方式）"><a href="#6-某种转化因子变量的方法（我的期末作业里是另一种方式）" class="headerlink" title="6.某种转化因子变量的方法（我的期末作业里是另一种方式）"></a>6.某种转化因子变量的方法（我的期末作业里是另一种方式）</h4><p>用一个if else，把所有factor变成0-1，不过这样生成的矩阵就不是稀疏矩阵（spark里可以）</p><blockquote><p>某同学构建了：是否延误-各种定性变量的不同取值情况列联表。</p><p>列联表，这看着像统计人干的。</p><p>——李丰老师</p></blockquote><h4 id="7-自己写个新函数get-sdummies"><a href="#7-自己写个新函数get-sdummies" class="headerlink" title="7.自己写个新函数get_sdummies"></a>7.自己写个新函数get_sdummies</h4><p>pandas里有个getdummy函数，于是老师写了一个sdummies，即get_sdummies。</p><p>输入spark的df，只能具体的哪一个dummycol做修改，保持累计比例，自动删除那一列，最后有一个dummy_info=[]</p><p>如何在spark上自己生成？</p><p>1，清理</p><p>2，多少行，对所有dummy列循环</p><p>如果info空，则创建一个新的，放入所有变量</p><p>3，spark里的数据框根据对应的dummycol做一个计数和排序。</p><p>对于所有count从上往下求和，分母是所有的行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Window.partitionby.orderby.rowsbetween(-sys.maxsize,<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>就能获取前%多少的dummy变量</p><p>cumperc是累计求和除以总行数。累计百分比只保留（filter）小于我的top值</p><p>于是就能找到topdummy，且不用算到结束，算到出结果就停止</p><h3 id="二、成果展示"><a href="#二、成果展示" class="headerlink" title="二、成果展示"></a>二、成果展示</h3><p>下面是李丰老师与cx同学代码的解析，太强了，点个赞！</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br></pre></td><td class="code"><pre><span class="line">#! /usr/bin/env python3</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">500000*19 去掉缺失值</span><br><span class="line">转化成delay 判断是否延误 √</span><br><span class="line">dlsa-project 参考</span><br><span class="line">常用变量继承，增加dummy列（航空公司）</span><br><span class="line">通过</span><br><span class="line">500000*180</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">###################################################开启</span><br><span class="line">import findspark</span><br><span class="line">findspark.init(&apos;/usr/lib/spark-current&apos;)</span><br><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">##session封装了conf</span><br><span class="line">spark = SparkSession.builder.appName(&quot;chenxi session&quot;).getOrCreate()</span><br><span class="line">###################################################读入数据</span><br><span class="line">#处理schema</span><br><span class="line">from pyspark.sql.types import *</span><br><span class="line">schema_sdf = StructType([</span><br><span class="line">        StructField(&apos;Year&apos;, IntegerType(), True),</span><br><span class="line">        StructField(&apos;Month&apos;, IntegerType(), True),</span><br><span class="line">        StructField(&apos;DayofMonth&apos;, IntegerType(), True),</span><br><span class="line">        StructField(&apos;DayOfWeek&apos;, IntegerType(), True),</span><br><span class="line">        StructField(&apos;DepTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;CRSDepTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;ArrTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;CRSArrTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;UniqueCarrier&apos;, StringType(), True),</span><br><span class="line">        StructField(&apos;FlightNum&apos;, StringType(), True),</span><br><span class="line">        StructField(&apos;TailNum&apos;, StringType(), True),</span><br><span class="line">        StructField(&apos;ActualElapsedTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;CRSElapsedTime&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;AirTime&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;ArrDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;DepDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;Origin&apos;, StringType(), True),</span><br><span class="line">        StructField(&apos;Dest&apos;,  StringType(), True),</span><br><span class="line">        StructField(&apos;Distance&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;TaxiIn&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;TaxiOut&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;Cancelled&apos;,  IntegerType(), True),</span><br><span class="line">        StructField(&apos;CancellationCode&apos;,  StringType(), True),</span><br><span class="line">        StructField(&apos;Diverted&apos;,  IntegerType(), True),</span><br><span class="line">        StructField(&apos;CarrierDelay&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;WeatherDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;NASDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;SecurityDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;LateAircraftDelay&apos;,  DoubleType(), True)</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">air00 = spark.read.options(header=&apos;true&apos;).schema(schema_sdf).csv(&quot;/data/airdelay_small.csv&quot;) #这是spark dataframe，不是pd的那个</span><br><span class="line">use_columns=[</span><br><span class="line">    &apos;ArrDelay&apos;, #double</span><br><span class="line">    &apos;Year&apos;, #int</span><br><span class="line">    &apos;Month&apos;, #int</span><br><span class="line">    &apos;DayofMonth&apos;, #int</span><br><span class="line">    &apos;DayOfWeek&apos;, #int</span><br><span class="line">    &apos;DepTime&apos;, #double</span><br><span class="line">    &apos;CRSDepTime&apos;, #double</span><br><span class="line">    &apos;CRSArrTime&apos;, #double</span><br><span class="line">    &apos;UniqueCarrier&apos;, #str</span><br><span class="line">    &apos;ActualElapsedTime&apos;,  #double&apos;,</span><br><span class="line">    &apos;Origin&apos;,#str</span><br><span class="line">    &apos;Dest&apos;, #str</span><br><span class="line">    &apos;Distance&apos; #double</span><br><span class="line">]</span><br><span class="line">air=air00.select(use_columns).na.drop()</span><br><span class="line">#####################################################处理因变量########################</span><br><span class="line">def delay(x):</span><br><span class="line">    if x&gt;0:</span><br><span class="line">        return 1</span><br><span class="line">    else :</span><br><span class="line">        return 0</span><br><span class="line"></span><br><span class="line">#参考 https://blog.csdn.net/wulishinian/article/details/105817409 spark中生成新列的各种方法，不能直接定义了</span><br><span class="line">import pyspark.sql.functions as F</span><br><span class="line">yfunc = F.udf(delay, StringType())#类似apply的使用，对该列每个数做个操作</span><br><span class="line">air = air.withColumn(&quot;delay_or_not&quot;, yfunc(&quot;ArrDelay&quot;))</span><br><span class="line"></span><br><span class="line">#####################################################处理自变量#########################</span><br><span class="line">#注意，pyspark好像识别不了空行和换行（在一行一行跑的时候）</span><br><span class="line">####################先把一些列转成others</span><br><span class="line">#使用老师给的代码统计哪些类别归入others</span><br><span class="line">import pickle</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import os</span><br><span class="line">from collections import Counter</span><br><span class="line"></span><br><span class="line">def dummy_factors_counts(pdf, dummy_columns):</span><br><span class="line">    &apos;&apos;&apos;Function to count unique dummy factors for given dummy columns</span><br><span class="line">    pdf: pandas data frame</span><br><span class="line">    dummy_columns: list. Numeric or strings are both accepted.</span><br><span class="line">    return: dict same as dummy columns</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    # Check if current argument is numeric or string</span><br><span class="line">    pdf_columns = pdf.columns # Fetch data frame header</span><br><span class="line">    dummy_columns_isint = all(isinstance(item, int) for item in dummy_columns)</span><br><span class="line">    #isinstance() 判断item是否是int</span><br><span class="line">    #all()用于判断给定的可迭代参数 iterable 中的所有元素是否都为 TRUE，如果是返回 True，否则返回 False</span><br><span class="line">    if dummy_columns_isint:</span><br><span class="line">        dummy_columns_names = [pdf_columns[i] for i in dummy_columns]</span><br><span class="line">    else:</span><br><span class="line">        dummy_columns_names = dummy_columns</span><br><span class="line">    factor_counts = &#123;&#125;</span><br><span class="line">    for i in dummy_columns_names:</span><br><span class="line">        factor_counts[i] = (pdf[i]).value_counts().to_dict()</span><br><span class="line">    #统计每一列里的不同值的个数</span><br><span class="line">    return factor_counts</span><br><span class="line"></span><br><span class="line">###合并两个字典，并计算同一key的和（两个字典都有子字典）</span><br><span class="line">def cumsum_dicts(dict1, dict2):</span><br><span class="line">    &apos;&apos;&apos;Merge two dictionaries and accumulate the sum for the same key where each dictionary</span><br><span class="line">    containing sub-dictionaries with elements and counts.</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    # If only one dict is supplied, do nothing.</span><br><span class="line">    if len(dict1) == 0:</span><br><span class="line">        dict_new = dict2</span><br><span class="line">    elif len(dict2) == 0:</span><br><span class="line">        dict_new = dict1</span><br><span class="line">    else:</span><br><span class="line">        dict_new = &#123;&#125;</span><br><span class="line">        for i in dict1.keys():</span><br><span class="line">            dict_new[i] = dict(Counter(dict1[i]) + Counter(dict2[i]))</span><br><span class="line">    return dict_new</span><br><span class="line">#counter是python计数器类，返回元素取值的字典,且按频数降序</span><br><span class="line"></span><br><span class="line">def select_dummy_factors(dummy_dict, keep_top, replace_with, pickle_file):</span><br><span class="line">    &apos;&apos;&apos;Merge dummy key with frequency in the given file</span><br><span class="line">    dummy_dict: dummy information in a dictionary format</span><br><span class="line">    keep_top: list</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    dummy_columns_name = list(dummy_dict)#本身词典里就是取值</span><br><span class="line">    # nobs = sum(dummy_dict[dummy_columns_name[1]].values())#没用到</span><br><span class="line">    factor_set = &#123;&#125;  # The full dummy sets——————注意，是空字典，不是集合</span><br><span class="line">    factor_selected = &#123;&#125;  # Used dummy sets</span><br><span class="line">    factor_dropped = &#123;&#125;  # Dropped dummy sets</span><br><span class="line">    factor_selected_names = &#123;&#125;  # Final revised factors</span><br><span class="line">    for i in range(len(dummy_columns_name)):</span><br><span class="line">        column_i = dummy_columns_name[i] #给出列来</span><br><span class="line">        factor_set[column_i] = list((dummy_dict[column_i]).keys())#第i列的可能取值表</span><br><span class="line">        factor_counts = list((dummy_dict[column_i]).values())#第i列的值的个数</span><br><span class="line">        factor_cumsum = np.cumsum(factor_counts)#累加</span><br><span class="line">        factor_cumpercent = factor_cumsum / factor_cumsum[-1]#累积比率</span><br><span class="line">        factor_selected_index = np.where(factor_cumpercent &lt;= keep_top[i])#top这个是给定的</span><br><span class="line">        factor_dropped_index = np.where(factor_cumpercent &gt; keep_top[i])</span><br><span class="line">        factor_selected[column_i] = list(</span><br><span class="line">            np.array(factor_set[column_i])[factor_selected_index])#一列有一堆可用取值</span><br><span class="line">        factor_dropped[column_i] = list(</span><br><span class="line">            np.array(factor_set[column_i])[factor_dropped_index])</span><br><span class="line">        # Replace dropped dummies with indicators like `others`</span><br><span class="line">        if len(factor_dropped_index[0]) == 0:</span><br><span class="line">            factor_new = []</span><br><span class="line">        else:</span><br><span class="line">            factor_new = [replace_with]</span><br><span class="line">        factor_new.extend(factor_selected[column_i])#extend列表末尾一次性追加另一个序列中的多个值</span><br><span class="line">        factor_selected_names[column_i] = [column_i + &apos;_&apos; + str(x) for x in factor_new]</span><br><span class="line">    dummy_info = &#123;</span><br><span class="line">        &apos;factor_set&apos;: factor_set,</span><br><span class="line">        &apos;factor_selected&apos;: factor_selected,</span><br><span class="line">        &apos;factor_dropped&apos;: factor_dropped,</span><br><span class="line">        &apos;factor_selected_names&apos;: factor_selected_names&#125;</span><br><span class="line">    pickle.dump(dummy_info, open(os.path.expanduser(pickle_file), &apos;wb&apos;))</span><br><span class="line">    print(&quot;dummy_info saved in:\t&quot; + pickle_file)</span><br><span class="line">    return dummy_info #返回了一个包含处理信息的字典</span><br><span class="line"></span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">pickle提供了一个简单的持久化功能。可以将对象以文件的形式存放在磁盘上</span><br><span class="line">pickle.dump(obj, file[, protocol])</span><br><span class="line">　　序列化对象，并将结果数据流写入到文件对象中。参数protocol是序列化模式，默认值为0，表示以文本的形式序列化。protocol的值还可以是1或2，表示以二进制的形式序列化。</span><br><span class="line">　　pickle.load(file)</span><br><span class="line">　　反序列化对象。将文件中的数据解析为一个Python对象。</span><br><span class="line"></span><br><span class="line">其中要注意的是，在load(file)的时候，要让python能够找到类的定义，否则会报错：</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def select_dummy_factors_from_file(file, header, dummy_columns, keep_top,</span><br><span class="line">                                   replace_with, pickle_file):</span><br><span class="line">    &apos;&apos;&apos;Memory constrained algorithm to select dummy factors from a large file</span><br><span class="line">    对大文件使用内存约束算法选择dummy，一个真正的分布式的算法</span><br><span class="line">    要输入文件路径、表头，要变成哑变量的列，保留的比例，</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    dummy_dict = &#123;&#125;</span><br><span class="line">    buffer_num = 0</span><br><span class="line">    with open(file) as f:</span><br><span class="line">        while True:</span><br><span class="line">            buffer = f.readlines(</span><br><span class="line">                1024000)  # Returns *at most* 1024000 bytes, maybe less</span><br><span class="line">            if len(buffer) == 0:</span><br><span class="line">                break</span><br><span class="line">            else:</span><br><span class="line">                buffer_list = [x.strip().split(&quot;,&quot;) for x in buffer]</span><br><span class="line">                buffer_num += 1</span><br><span class="line">                if ((buffer_num == 1) and (header is True)):</span><br><span class="line">                    buffer_header = buffer_list[0]</span><br><span class="line">                    buffer_starts = 1</span><br><span class="line">                else:</span><br><span class="line">                    buffer_starts = 0</span><br><span class="line">                buffer_pdf = pd.DataFrame(buffer_list[buffer_starts:])</span><br><span class="line">                if header is True:</span><br><span class="line">                    buffer_pdf.columns = buffer_header</span><br><span class="line">                dummy_dict_new = dummy_factors_counts(buffer_pdf,</span><br><span class="line">                                                      dummy_columns)</span><br><span class="line">                dummy_dict = cumsum_dicts(dummy_dict, dummy_dict_new)</span><br><span class="line">    dummy_info = select_dummy_factors(dummy_dict, keep_top, replace_with,</span><br><span class="line">                                      pickle_file)</span><br><span class="line">    return (dummy_info)</span><br><span class="line"></span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">#####看一下情况确定要不要＋others列</span><br><span class="line">air.groupby(&apos;Month&apos;).count().show() #没有比例差异</span><br><span class="line">air.groupby(&apos;DayofMonth&apos;).count().show(31) #没有比例差异</span><br><span class="line">air.groupby(&apos;DayofWeek&apos;).count().show()#没有比例差异</span><br><span class="line">air.groupby(&apos;Year&apos;).count().collect()#没有比例差异</span><br><span class="line">air.groupby(&apos;UniqueCarrier&apos;).count().collect()#</span><br><span class="line">air.groupby(&apos;UniqueCarrier&apos;).count().orderBy(&apos;count&apos;).show(50)</span><br><span class="line">m=air.groupby(&apos;Origin&apos;).count()</span><br><span class="line">#air.groupby(&apos;UniqueCarrier&apos;).count().rdd.foreach(print) 为什么打印不出来？</span><br><span class="line">m.orderBy(-m(&apos;count&apos;)).collect()</span><br><span class="line">m.sort(desc(&apos;count&apos;)).collect()</span><br><span class="line">.collect()</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line"></span><br><span class="line">    # User settings</span><br><span class="line">    file = os.path.expanduser(&quot;/home/devel/data/airdelay_small.csv&quot;)</span><br><span class="line">    header = True</span><br><span class="line">    dummy_columns = [&apos;UniqueCarrier&apos;, &apos;Origin&apos;, &apos;Dest&apos;]</span><br><span class="line">    keep_top = [0.8, 0.8, 0.8]</span><br><span class="line">    replace_with = &apos;00_OTHERS&apos;</span><br><span class="line">    pickle_file = os.path.expanduser(&quot;/home/devel/students/2020211004chenxi/1112work/airdelay_dummy_info_latest.pkl&quot;)</span><br><span class="line">    dummy_info = select_dummy_factors_from_file(file, header, dummy_columns,keep_top, replace_with,pickle_file)</span><br><span class="line"></span><br><span class="line">#得到应该记为others的列名</span><br><span class="line">drop_uc=dummy_info[&apos;factor_dropped&apos;][&apos;UniqueCarrier&apos;]</span><br><span class="line">drop_o=dummy_info[&apos;factor_dropped&apos;][&apos;Origin&apos;]</span><br><span class="line">drop_d=dummy_info[&apos;factor_dropped&apos;][&apos;Dest&apos;]</span><br><span class="line">sle_uc=dummy_info[&apos;factor_selected&apos;][&apos;UniqueCarrier&apos;]</span><br><span class="line">sle_o=dummy_info[&apos;factor_selected&apos;][&apos;Origin&apos;]</span><br><span class="line">sle_d=dummy_info[&apos;factor_selected&apos;][&apos;Dest&apos;]</span><br><span class="line">########################使用字典把很小的类别更改成others</span><br><span class="line">#生成字典</span><br><span class="line">drop_all=drop_uc+drop_o+drop_d</span><br><span class="line">sle_all=sle_uc+sle_o+sle_d</span><br><span class="line">v=[&quot;others&quot;]*len(drop_all)</span><br><span class="line">dic=dict(zip(sle_all+drop_all,sle_all+v))</span><br><span class="line">air11=air.na.replace(dic,1,&apos;UniqueCarrier&apos;)</span><br><span class="line">air11=air11.na.replace(dic,1,&apos;Origin&apos;)</span><br><span class="line">air11=air11.na.replace(dic,1,&apos;Dest&apos;)</span><br><span class="line">print(&apos;替换others后的数据\n&apos;)</span><br><span class="line">air11.show(10)#更改后的结果</span><br><span class="line">#报错好像是内存太小？</span><br><span class="line">###########################################################独热编码################</span><br><span class="line">&apos;&apos;&apos;sample</span><br><span class="line">from pyspark.ml.feature import OneHotEncoder,StringIndexer</span><br><span class="line">indexer = StringIndexer(inputCol=&apos;Month&apos;, outputCol=&apos;MonthIndex&apos;)</span><br><span class="line">model = indexer.fit(air)</span><br><span class="line">indexed = model.transform(air)</span><br><span class="line">onehotencoder = OneHotEncoder(inputCol=&apos;MonthIndex&apos;, outputCol=&apos;MonthVec&apos;)</span><br><span class="line">oncoded = onehotencoder.transform(indexed)</span><br><span class="line">oncoded.show(5)</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">#https://github.com/spark-in-action/first-edition/blob/master/ch08/python/ch08-listings.py</span><br><span class="line">#先生成index</span><br><span class="line">def indexStringColumns(df, cols):</span><br><span class="line">    from pyspark.ml.feature import StringIndexer</span><br><span class="line">    #variable newdf will be updated several times</span><br><span class="line">    newdf = df</span><br><span class="line">    for c in cols:</span><br><span class="line">        si = StringIndexer(inputCol=c, outputCol=c+&quot;-num&quot;)</span><br><span class="line">        sm = si.fit(newdf)</span><br><span class="line">        newdf = sm.transform(newdf).drop(c)</span><br><span class="line">        newdf = newdf.withColumnRenamed(c+&quot;-num&quot;, c)</span><br><span class="line">    return newdf</span><br><span class="line"></span><br><span class="line">#根据index进行独热编码</span><br><span class="line">def oneHotEncodeColumns(df, cols):</span><br><span class="line">    from pyspark.ml.feature import OneHotEncoder</span><br><span class="line">    newdf = df</span><br><span class="line">    for c in cols:</span><br><span class="line">        onehotenc = OneHotEncoder(inputCol=c, outputCol=c+&quot;-onehot&quot;, dropLast=False)</span><br><span class="line">        newdf = onehotenc.transform(newdf).drop(c)</span><br><span class="line">        newdf = newdf.withColumnRenamed(c+&quot;-onehot&quot;, c)</span><br><span class="line">    return newdf</span><br><span class="line">cols=[&apos;Year&apos;,&apos;Month&apos;,&apos;DayofMonth&apos;,&apos;DayOfWeek&apos;,&apos;UniqueCarrier&apos;,&apos;Origin&apos;,&apos;Dest&apos;]</span><br><span class="line">dff=indexStringColumns(air11,[&apos;Year&apos;,&apos;Month&apos;,&apos;DayofMonth&apos;,&apos;DayOfWeek&apos;,&apos;UniqueCarrier&apos;,&apos;Origin&apos;,&apos;Dest&apos;])</span><br><span class="line">dfhot = oneHotEncodeColumns(dff, cols)</span><br><span class="line">print(&apos;编码后形式\n&apos;)</span><br><span class="line">dfhot.take(2)</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">py4j.protocol.Py4JJavaError: An error occurred while calling o1290.transform.</span><br><span class="line">: java.lang.IllegalArgumentException: Field &quot;DayofWeek&quot; does not exist</span><br><span class="line">Available fields: ArrDelay, DepTime, CRSDepTime, CRSArrTime, ActualElapsedTime, Distance, DayOfWeek, UniqueCarrier, Origin, Dest, Year, Month, DayofMonth</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">#转换成能使用的形式</span><br><span class="line">from pyspark.ml.feature import VectorAssembler#把所有字符型向量转换成数值型的后，可以合并,能直接在MLlib里用</span><br><span class="line">va = VectorAssembler(outputCol=&quot;features&quot;, inputCols=dfhot.columns[0:])#取除最后一列外的所有值</span><br><span class="line">lpoints = va.transform(dfhot).select(&quot;features&quot;)</span><br><span class="line">print(&apos;最终结果\n&apos;)</span><br><span class="line">lpoints.take(2)</span><br><span class="line"></span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">问题1：独热编码没有办法设定基准组，默认count中的最后一个是基准组，并不是数据最少的那个————如果替换了others，问题应该不是很大</span><br><span class="line">问题2：要求是矩阵形式怎么办？——可以尝试vector分列，有合适的写法，但是没能实现</span><br><span class="line">###尝试把一个vector分列，但是报错没有numpy？</span><br><span class="line">#vectors = lpoints.select(&quot;features&quot;).rdd.map(lambda row: row.features)#PipelinedRDD</span><br><span class="line">#疑问：退出后就没有以前的操作了，怎么办？ 有没有类似screen或者保存工作空间的操作？</span><br><span class="line">&apos;&apos;&apos;</span><br></pre></td></tr></table></figure><h3 id="三、稍微讲了点新课"><a href="#三、稍微讲了点新课" class="headerlink" title="三、稍微讲了点新课"></a>三、稍微讲了点新课</h3><h4 id="1-需求"><a href="#1-需求" class="headerlink" title="1.需求"></a>1.需求</h4><p>机器学习，可分成一些步骤：</p><p>Featurization-特征选取。</p><p>40个观测，并非特征越多，模型越好（要选，steplm之类）</p><p>下来变换清理数据。</p><p>0-1，降维……等等问题都涌现出来。</p><p>这些都叫“特征工程”，这个变量矩阵本身就是分布式的（spark）。</p><p>最后使用模型建模，得到想要的信息等等。</p><h4 id="2-Pipelines（管道）"><a href="#2-Pipelines（管道）" class="headerlink" title="2.Pipelines（管道）"></a>2.Pipelines（管道）</h4><p>spark通过管道把不同的流程结合起来。</p><p>pipline来自于python机器学习模块中scikit-learn。</p><p>persistence（工具性）模型存储，加载。</p><p>utilities：线性代数，统计学等等。</p><p>旧版本的mllib中，基于rdd形式。现在逐渐转化成df（好处是能和sql结合）。这是由于sql很难被直接用在rdd形式上。</p><p>不过，根据上面所说的，其实可以将df转化（Transformer、Estimator）</p><p>Pipeline 提供了一个能够完整工作流的链（Parameter）</p><p>比如有个文本数据：</p><blockquote><p>pipeline：</p><p>————1.Tokenizer————2.hashingTF———3.logistic regression</p><p>pipeline的流：</p><p>0.5Rawtext————1.5words————2.5feature vectors</p><p> （数字表示时间顺序）</p></blockquote><p>课件以逻辑回归为例，regparam是惩罚。fit结果，不用规定x和y，因为默认的需要标记y为label，x标记为features。（机器学习的默认规则，那些函数的默认参数都是features，头大）</p><p>（未完待续，下节课讲文本处理）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;讲解作业，炒鸡复杂（其实也罢了）的air-delay数据清洗。&lt;/p&gt;
&lt;p&gt;附带可以认识spark的强大之处。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式1112-Spark简单功能补充介绍</title>
    <link href="https://konelane.github.io/2020/11/12/201112hadoop/"/>
    <id>https://konelane.github.io/2020/11/12/201112hadoop/</id>
    <published>2020-11-11T16:00:00.000Z</published>
    <updated>2020-12-31T02:17:30.840Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>对spark进行一些补充介绍。</p><a id="more"></a><p>两个函数可以选定</p><blockquote><p>Cache()</p><p>Persist()</p></blockquote><p>主动将数据放到硬盘上-内存中</p><blockquote><p>Data.persist()</p></blockquote><p>旧数据放在内存里，新数据放硬盘，spark帮助中有persist 的水平（默认是全放进内存的cache，假设内存很大）</p><blockquote><p>lineLengths.unpersist()</p><p>persist的参数水平</p><p>Memory_only</p><p>Memory_AND_DISK</p><p>Memory_AND_DISK_SER</p><p>DISK_ONLY</p><p>MEMORY_ONLY_2</p></blockquote><p>内存不够则会报错</p><img src="/2020/11/12/201112hadoop/tu1.png" title="tu1"><h3 id="二、Spark的一些特别之处"><a href="#二、Spark的一些特别之处" class="headerlink" title="二、Spark的一些特别之处"></a>二、Spark的一些特别之处</h3><h4 id="1-广播"><a href="#1-广播" class="headerlink" title="1. 广播"></a>1. 广播</h4><p>分布式最重要的是“数据共享”使得不同节点之间能够用一个数据。</p><p>比如正态分布的概率密度函数，π就如此，共享，但不修改。</p><blockquote><p>broadcastVar = sc.broadcast([1, 2, 3])</p><p>broadcastVar</p><p>Sparkcontext.broadcast(v)</p></blockquote><p>广播出去的变量不能修改，否则会乱。</p><p>Broadcast.value可以查看广播出去的变量。</p><p>spark中accumulator可以用于累积，在MapReduce中：</p><blockquote><p>accum = sc.accumulator(0)</p><p>sc.parallelize([1, 2, 3, 4])<strong>.foreach</strong>(lambda x: accum.add(x)) # foreach有点像R的</p><p>accum.value</p></blockquote><h4 id="2-懒人模式"><a href="#2-懒人模式" class="headerlink" title="2. 懒人模式"></a>2. 懒人模式</h4><p>spark的懒人模式：</p><p>节约计算资源</p><p>x=3 , y = 4 , z = 5</p><p>提交任务</p><blockquote><p>1.2x = ? </p><p>2.4y = ? </p><p>3.2x +4y = ?</p></blockquote><p> 或许前两步根本不用算，于是节约了资源。</p><p>spark使用DAG有向无环图，控制最后的结果本质上要求哪些计算。实现懒人模式。</p><blockquote><p>分布式就是管理人和物的一种抽象。 </p><p>—— 李丰老师</p></blockquote><h4 id="3-线性代数"><a href="#3-线性代数" class="headerlink" title="3. 线性代数"></a>3. 线性代数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import scipy.sparse as sps</span><br><span class="line">from pyspark.mllib.linalg import Vectors</span><br><span class="line"></span><br><span class="line"># Use a NumPy array as a dense vector.</span><br><span class="line">dv1 = np.array([1.0, 0.0, 3.0])</span><br><span class="line"># Use a Python list as a dense vector.</span><br><span class="line">dv2 = [1.0, 0.0, 3.0]</span><br><span class="line"># Create a SparseVector.</span><br><span class="line">sv1 = Vectors.sparse(3, [0, 2], [1.0, 3.0])</span><br><span class="line"># Use a single-column SciPy csc_matrix as a sparse vector.</span><br><span class="line">sv2 = sps.csc_matrix((np.array([1.0, 3.0]),</span><br><span class="line">                      np.array([0, 2]),</span><br><span class="line">                      np.array([0, 2])), shape=(3, 1))</span><br></pre></td></tr></table></figure><p>spark的线性代数模块很强大： pyspark.mllib.linalg</p><p>spark专门提供的<strong>标签</strong>工具</p><p>做分类模型时就可以使用特有变量了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.mllib.linalg import SparseVector</span><br><span class="line">from pyspark.mllib.regression import LabeledPoint</span><br><span class="line"></span><br><span class="line"># Create a labeled point with a positive label and a dense feature vector.</span><br><span class="line">pos = LabeledPoint(1.0, [1.0, 0.0, 3.0])</span><br><span class="line"># Create a labeled point with a negative label and a sparse feature vector.</span><br><span class="line">neg = LabeledPoint(0.0, SparseVector(3, [0, 2], [1.0, 3.0]))</span><br></pre></td></tr></table></figure><p>允许导入各式各样的稀疏数据。有了local就有distributed。</p><p>如果要做个逻辑回归、线性回归，能否模拟一个线性回归的数据，将其存入矩阵。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>spark集成了很多hive的优秀理念。</p><p>对于常见的数据框的操作，归类成不同类型的函数。</p><p>依赖于sparkSQL，有别于传统的RDD形式，因为在RDD上可以更底层地操作数据（矩阵向量……）</p><p>sparkSQL与hive结合，可以把hive的sql查询直接应用在数据框上，也允许用户自己的函数。支持读取hdfs上的数据，是个通用的多接口的形式。</p><p>sparkRDD形式数据灵活，操作很琐碎。于是spark提供了自己的dataset集合。其实就是分布式数据的综合，通过java的jvm集成的（java虚拟机，用于快速计算的技术）</p><p><strong>dataset的api只支持scala和Java。</strong></p><p>故如果想在spark上处理数据集，需要自己学习Scala语言（最后一节有讲，敬请期待）。</p><p>spark上的dataframe是分布式的，其实就是表，不同列之间可以是不同的数据类型。</p><p>可以对dataframe做清洗和操作。可以通过hive的表来构建，可以通过现成的表来构建。</p><p>各种语言都支持。</p><h3 id="三、战斗案例"><a href="#三、战斗案例" class="headerlink" title="三、战斗案例"></a>三、战斗案例</h3><p>目标，处理分布式的DataFrame，首先启动SC。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">spark = SparkSession.builder.appName(&quot;Python Spark&quot;).getOrCreate()</span><br><span class="line">spark # test if Spark session is created or not</span><br><span class="line"></span><br><span class="line">sc = spark.sparkContext # make a spakr context for RDD</span><br><span class="line">sc</span><br></pre></td></tr></table></figure><img src="/2020/11/12/201112hadoop/tu2.png" title="tu2"><img src="/2020/11/12/201112hadoop/tu3.png" title="tu3"><p>spark有read函数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sdf = spark.read.csv(&quot;/opt/apps/ecm/service/spark/2.4.4/package/spark-2.4.4-bin-hadoop2.7/examples/src/main/resources/people.txt&quot;)</span><br><span class="line">sdf.show() # Displays the content of the DataFrame to stdout</span><br></pre></td></tr></table></figure><img src="/2020/11/12/201112hadoop/tu4.png" title="tu4"><p>这个就是分布式上的表。</p><p>json格式可以直接读取（spark.read.json）</p><h4 id="schema"><a href="#schema" class="headerlink" title="schema"></a>schema</h4><p>属于读取表格时的表头信息。名字，类型，缺失等等。</p><p>经常需要手写表头，因为自动容易出错。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># We specify the correct schema by hand</span><br><span class="line">schema_sdf = StructType([</span><br><span class="line">        StructField(&apos;Year&apos;, IntegerType(), True),</span><br><span class="line">        StructField(&apos;Month&apos;, IntegerType(), True),</span><br><span class="line">        StructField(&apos;DayofMonth&apos;, IntegerType(), True),</span><br><span class="line">        StructField(&apos;DayOfWeek&apos;, IntegerType(), True),</span><br><span class="line">        StructField(&apos;DepTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;CRSDepTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;ArrTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;CRSArrTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;UniqueCarrier&apos;, StringType(), True),</span><br><span class="line">        StructField(&apos;FlightNum&apos;, StringType(), True),</span><br><span class="line">        StructField(&apos;TailNum&apos;, StringType(), True),</span><br><span class="line">        StructField(&apos;ActualElapsedTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;CRSElapsedTime&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;AirTime&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;ArrDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;DepDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;Origin&apos;, StringType(), True),</span><br><span class="line">        StructField(&apos;Dest&apos;,  StringType(), True),</span><br><span class="line">        StructField(&apos;Distance&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;TaxiIn&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;TaxiOut&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;Cancelled&apos;,  IntegerType(), True),</span><br><span class="line">        StructField(&apos;CancellationCode&apos;,  StringType(), True),</span><br><span class="line">        StructField(&apos;Diverted&apos;,  IntegerType(), True),</span><br><span class="line">        StructField(&apos;CarrierDelay&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;WeatherDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;NASDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;SecurityDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;LateAircraftDelay&apos;,  DoubleType(), True)</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">oridat = spark.read.options(header=&apos;true&apos;).schema(schema_sdf).csv(&quot;/data/airdelay_small.csv&quot;) # spark dataframe</span><br></pre></td></tr></table></figure><p>air.describe().show()就相当于简单的描述统计</p><p>air.describe([‘ArrDelay’]).show() 看具体的列</p><p>Data.collect()可以避开懒人模式直接计算</p><h3 id="四、作业-air-delay数据清洗"><a href="#四、作业-air-delay数据清洗" class="headerlink" title="四、作业 air-delay数据清洗"></a>四、作业 air-delay数据清洗</h3><p>五百万 * 十九列</p><p>转化成新的df，一类是0、1，告诉大家有没有延误</p><p>arrivedelay设置成0-1变量。现有的列可以使用：里程，是不是US（0-1），是不是AA（0-1），诸如此类，相当于把原变量修改成哑变量了。</p><p>最后得到————&gt;五百万 * 一百八十列</p><p>不要超过这么多列。（在老师github上/dlsa/blob/master/projects/logistic…）</p><p>作业，整理好这个数据。</p><p>下节课对这个数据做逻辑回归。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对spark进行一些补充介绍。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式1102-Hi,Hive!Hi,Spark!</title>
    <link href="https://konelane.github.io/2020/11/02/201102hadoop/"/>
    <id>https://konelane.github.io/2020/11/02/201102hadoop/</id>
    <published>2020-11-01T16:00:00.000Z</published>
    <updated>2020-12-30T09:10:23.494Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>hadoop以及MapReduce暂告一段落！</p><p>这一节我们做个过渡，讲一讲Hive以及Spark。</p><a id="more"></a><h3 id="一、Hive介绍"><a href="#一、Hive介绍" class="headerlink" title="一、Hive介绍"></a>一、Hive介绍</h3><p>Hive是分布式的数据库。对于结构化数据存储、查询的高效工具。</p><p>查询特殊的行、列，数据库操作非常重要。</p><blockquote><p>数据库就像计算器一样。</p><p>——李丰老师</p></blockquote><p>不管什么类型的数据库，都有sql，数据库查询语言。能够对很大的表格进行类似excel的操作。</p><p>数据库面向不同的对象：</p><blockquote><p>计算机：设计高效数据库，快速存储海量数据。</p><p>使用者：快速得到想要的数据。</p></blockquote><p>大数据时代，数据库进入瓶颈，因为其不可扩展。轻量级的数据应用就不太喜欢数据库，转而使用hdfs。但hdfs没有数据库那样便利，不能select…from…</p><p>就诞生了基于hdfs的数据库工具。</p><p><strong>初衷</strong>：为了使企业能够快速部署使用结构化表格与操作。能将hdfs上的表格当做数据库的表格来使用（如csv）。</p><p>只要用sql语句就可以在hdfs上处理结构化数据。其实Hive是把sql解析成了MapReduce语句，最后传递回用户。</p><p>Hadoop（系统）hdfs（文件管理系统）</p><p>hive-SQL（可操作的客户端）complie+optimize+execute（很快啊！）</p><p>hive其实有小缓存，如果大量/经常查询同一条，就会被缓存下来，方便直接调用。</p><p>不会hadoop也可以用hive，只需要sql语句就行了。</p><p>hive可以做spark中dataframe的查询引擎。hive的功能就是能用sql的客户端。（氦核：这一点在之后的工作中显示了其强大与方便）</p><p>hive将sql解析成XML语句（标记位置）</p><p>hive完全是模拟了sql的写法，sql用的最广，python之流不适合这样的工作。</p><h3 id="二、启动一个Hive任务"><a href="#二、启动一个Hive任务" class="headerlink" title="二、启动一个Hive任务"></a>二、启动一个Hive任务</h3><p>Hive + 回车（进入交互界面）</p><p>Exit （退出）</p><p>hive允许执行很多命令同时推出</p><p>如：</p><blockquote><p>Hive -e “dfs -ls /;”</p></blockquote><p>e是执行。引号内是hive语句，分号是模仿sql的结束符号。</p><p>传递给hadoop就是hadoop fs -ls /</p><p>结果再传回hive</p><p>也可以写成文件：</p><blockquote><p>Hive -f /path/to/file/withqueries.hql</p></blockquote><p>hql（hive的文本文件，与sql区分）</p><img src="/2020/11/02/201102hadoop/tu1.png" title="tu1"><p>输入hive可以进入终端</p><img src="/2020/11/02/201102hadoop/tu2.png" title="tu2"><p>操作时，在终端中可以直接输入dfs -ls /;    （别忘了分号）</p><p>注：sql语言的特点——对大小写不敏感，语句中可以小写可以大写。但是对表的字段依然敏感。</p><blockquote><p>Show databases;</p></blockquote><p>可以看分布式集群上有什么数据库</p><blockquote><p>Show databases like ‘d*’;</p><p>Create database if not exists mydb;</p></blockquote><p> if not exists（是一个条件，如果有了就不会再创建，如果没有的话就创建）</p><img src="/2020/11/02/201102hadoop/tu3.png" title="tu3"><p>数据库下有表，mydb不指定文件夹，就在warehouse的文件夹下。</p><p>location参数可以指定创建的位置</p><blockquote><p>Create database if not exists fff location ‘user/lifeng/hive’</p></blockquote><p>创建一个指定位置的数据库fff</p><blockquote><p>Drop database fff;</p></blockquote><p>删库，跑路！（危）</p><p>hive里如何创建表<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS mydb.employees (</span><br><span class="line">    name</span><br><span class="line">        STRING COMMENT &apos;Employee name&apos;,</span><br><span class="line">    salary</span><br><span class="line">        FLOAT COMMENT &apos;Employee salary&apos;,</span><br><span class="line">    subordinates ARRAY&lt;STRING&gt; COMMENT &apos;Names of subordinates&apos;,</span><br><span class="line">    deductions MAP&lt;STRING, FLOAT&gt;</span><br><span class="line">        COMMENT &apos;Keys are deductions names, values are percentages&apos;,</span><br><span class="line">    address</span><br><span class="line">        STRUCT&lt;street:STRING, city:STRING, state:STRING, zip:INT&gt;</span><br><span class="line">        COMMENT &apos;Home address&apos;)</span><br><span class="line">COMMENT &apos;Description of the table&apos;</span><br><span class="line">TABLEPROPERTIES (&apos;creator&apos;=&apos;me&apos;, &apos;created_at&apos;=&apos;2012-01-02 10:00:00&apos;);</span><br></pre></td></tr></table></figure></p><p>列名，comment记录注释，最后一行只创建了表头、创建者、创建时间等</p><p>hive记录了表的信息</p><p>因为刚刚用了use wyh_db;现在Show tables;就能看有哪些表。</p><p>hive提供了专门工具，把外部的csv文件链接进数据库。</p><p>hive可以创建外部表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">create external table if not exists stocks (</span><br><span class="line">    symbol string, </span><br><span class="line">    ymd string, </span><br><span class="line">    price_open float, </span><br><span class="line">    price_high float, </span><br><span class="line">    price_low float, </span><br><span class="line">    price_close float, </span><br><span class="line">    volume int, </span><br><span class="line">    price_adj_close float )</span><br><span class="line">row format delimited fields terminated by &apos;,&apos; </span><br><span class="line">location &apos;/user/lifeng/data&apos;;</span><br></pre></td></tr></table></figure><p>逗号分隔，原来是csv文件，要加一个逗号分隔（倒数第二行）</p><p>linux里有个内置命令awk脚本工具，能够</p><p>Awk -f 5，4啥的，能够选择打印第5和第4列</p><p>主要是不想导入python中处理。</p><p>如可以使用pig工具，合并两个表或多个表（我们用的不多）</p><p>pig有自己的书写习惯，计算机架构的工程师经常用</p><p>hbase是对谷歌bigtable的开源实现</p><p>能够按行更新（如python的append）</p><p>能做基于内存的文件缓存，加快速度</p><p>不支持sql的查询，但是hive目前有工具可以与之通行。</p><p>（HIVE的简介到此结束，后面有任务再见）</p><h3 id="三、Spark"><a href="#三、Spark" class="headerlink" title="三、Spark"></a>三、Spark</h3><p><a href="http://spark.apache.org/" target="_blank" rel="noopener">spark</a>，</p><blockquote><p>Speed - Run workloads 100x faster.</p><p>Ease of Use - Write applications quickly in Java, Scala, Python, R, and SQL.</p><p>Generality - Combine SQL, streaming, and complex analytics.</p><p>Runs Everywhere - Spark runs on Hadoop, Apache Mesos, Kubernetes, standalone, or in the cloud. It can access diverse data sources.</p></blockquote><p>伯克利的博士生，针对hadoop的问题重新写成了spark（老师也希望我们做这样的博士生，扶额）</p><p>Databricks公司，官网上提供了简单交互学习的平台。</p><p>spark在计算过程中非常快，是hadoop速度的一百倍</p><p>可以使用python，r，java，还有spark自带的scala语言。Scala语言有java的特性，又像r一样好写。</p><p>可以将spark当做python的一个模块来使用。（氦核：事实证明，pyspark很强，还自带深度学习模块，不过没那么顺手。）用户只需要学一点点就能用起来。</p><p>sparkR可以启动r。r语言设计用于统计分析，但是spark需要计算机组件，但是r没有，python有。</p><h4 id="spark与hadoop的区别"><a href="#spark与hadoop的区别" class="headerlink" title="spark与hadoop的区别"></a>spark与hadoop的区别</h4><p>hadoop是分布式的框架，spark对MapReduce看的更少，结果算的很快。</p><p>还有，hadoop不能交互；spark可以交互式操作一个对象。可以创建分布式对象， 在不同的节点上都存在，同时保证应用性和速度</p><p>spark也有通用性和广泛性，可以把sql集成进spark。</p><p>spark也可以处理流数据。</p><p>spark甚至可以机器学习和深度学习。</p><p>spark可以看做是分布式系统上更方便操作的hadoop客户端。</p><p>可以运行在hadoop上，可以当做独立的分布式系统。</p><p>spark可以接受hdfs等来源的文件，也可以自己建立dataframe。</p><p>spark可以用数据框组织数据。</p><p>spark有内置机器学习库，叫ml_lib；图形处理GraphX；流数据处理Spark Streaming（企业常用）。 </p><p>spark也可以运行在其他分布式平台上，各种各样的平台上都有spark接口。易用性使其广泛普及。</p><p>spark提供了hive的集成。不过select不能写很复杂。但是通过spark可以先让spark执行select，再让hive执行。</p><p>快的原因：</p><img src="/2020/11/02/201102hadoop/tu4.png" title="tu4"><blockquote><p>1.很多worker节点，worker之间交互很快（通过交换机）<br>2.worker上可以运行很多任务（executor）<br>3.每个worker上都有一些存储最常用数据的内存</p></blockquote><p>劣势：</p><blockquote><p>需要很大的内存 — hadoop最不耗内存</p><p>spark的官方建议，需要原始数据2-5倍的内存才能保证平稳运行</p></blockquote><p>有名的spark错误：OOM错误</p><p>Out of memory（哈哈哈）</p><p>加内存，扩容，烧钱啊。</p><blockquote><p>尽可能让代码写快一些，用最少的资源得到最大的价值。</p><p>——李丰老师</p></blockquote><p>之后课程计划讲：数据类型、机器学习的库（老版本基于rdd，新版本基于数据框）、streaming </p><p>不讲：计算机视觉相关包</p><h3 id="四、启动spark"><a href="#四、启动spark" class="headerlink" title="四、启动spark"></a>四、启动spark</h3><p>启动：.py .r</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Spark-submit \</span><br><span class="line"> --class </span><br><span class="line"> --master #什么节点(yarn)</span><br><span class="line"> --deploy-mode</span><br><span class="line"> --executor-memory 20G \</span><br><span class="line"> --conf</span><br></pre></td></tr></table></figure><p><a href="http://spark.apache.org/examples.html" target="_blank" rel="noopener">Spark案例</a></p><p>使用spark-summit提交上去就能执行了。在spark运算前，要想想全部需要多少运算资源，给每个executor分多少内存。</p><p>Tiny fat 两种分配资源想法</p><blockquote><p>Tiny 模式给每个核分一个executor，32g给8核，只能拿到4g，加上系统消耗就会更少。这种情形适用于cpu负荷大，如迭代类型，更多时候是迭代的分布式要跑起来。</p><p>Fat 模式，要是对IO很多的时候，我们不一定需要很多executor，八核可能只用两个executor，每个executor就有4核、16g使用。</p></blockquote><p>python有个**x，即将列表展开按位置放入</p><p>x的长度不超过256，但是python3.8现在允许任意长度参数传入</p><p>X = [1,2,3,…,1000] </p><p>Sumfunc(**x)</p><p>登录服务器，输入spark-shell</p><img src="/2020/11/02/201102hadoop/tu5.png" title="tu5"><p>使用pyspark要输入神秘代码（就是python的版本，配置时一定要与spark版本对应起来，比如服务器只能用3.6版本的python）</p><img src="/2020/11/02/201102hadoop/tu6.png" title="tu6"><p>或者直接在python中import pyspark，有时候需要先import findspark。</p><h4 id="Spark的API"><a href="#Spark的API" class="headerlink" title="Spark的API"></a>Spark的API</h4><p>rdd是什么（resilient distributed dataset）RDD是Spark里最重要的一个概念。</p><p>任何一个spark都可以通过rdd对象连接起来，也允许用户部署任何计算。</p><p>通过rdd转化成驱动程序，放入计算节点上计算，如传统的数学计算都可以转化。</p><p>spark-rdd提供了数据上的一个抽象，提供了海量数据的拆分机制，也可以通过不同的方式创建。</p><p>如分布式hdfs上有个文件，可以直接转化（好比hive上有个表），它也能判断哪些数据应该放入内存、硬盘。来提高效率。</p><p>其次，rdd也监视了每个计算节点的数据完整性。复活的基本机理与hadoop相似。闲暇时间拷贝。</p><p>spark能进行机器学习的理由：spark允许变量进行共享，每个节点都有想同的变量。</p><blockquote><p>1.常量，都用得着，不需修改。通过广播（broadcast variables）来传递给每个节点</p><p>2.传递到节点后，还可能要修改（如迭代算法）会消耗资源（accumulators）</p></blockquote><h4 id="如何创建spark-context"><a href="#如何创建spark-context" class="headerlink" title="如何创建spark context"></a>如何创建spark context</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import findspark</span><br><span class="line">findspark.init(&quot;/usr/lib/spark-current&quot;)</span><br><span class="line">import pyspark</span><br><span class="line"></span><br><span class="line">sc.stop()</span><br><span class="line">sc = pyspark.SparkContext(&quot;local&quot;, &quot;My First Spark App&quot;)</span><br></pre></td></tr></table></figure><p>使用了<strong>sc.parallelize</strong>就会传上spark，是一个对象。如果数据在本地或hdfs，都可以上传。</p><h4 id="给一个自己的作业超简单案例"><a href="#给一个自己的作业超简单案例" class="headerlink" title="给一个自己的作业超简单案例"></a>给一个自己的作业超简单案例</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#! /usr/bin/env python3.6</span><br><span class="line">import pyspark</span><br><span class="line"></span><br><span class="line">conf = pyspark.SparkConf().setAppName(&quot;Hehe First Spark RDD APP&quot;).setMaster(&quot;local&quot;)  # “yarn”</span><br><span class="line">sc = pyspark.SparkContext(conf=conf)</span><br><span class="line">sc.stop()</span><br><span class="line">sc = pyspark.SparkContext.getOrCreate()</span><br><span class="line">licenseFile = sc.textFile(&quot;2020210995wangyuanhe/reg/stocks.txt&quot;)</span><br><span class="line">lineLengths = licenseFile.map(lambda s: len(s))</span><br><span class="line">totalLength = lineLengths.reduce(lambda a, b: a + b)</span><br><span class="line"></span><br><span class="line">print(totalLength)</span><br></pre></td></tr></table></figure><p>（未完待续，下次再细讲Spark，学吧，学无止境，太深了）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;hadoop以及MapReduce暂告一段落！&lt;/p&gt;
&lt;p&gt;这一节我们做个过渡，讲一讲Hive以及Spark。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式1015-1021-分布式回归分析</title>
    <link href="https://konelane.github.io/2020/10/21/201015hadoop/"/>
    <id>https://konelane.github.io/2020/10/21/201015hadoop/</id>
    <published>2020-10-20T16:00:00.000Z</published>
    <updated>2020-12-30T08:21:42.816Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="一、开始！今日信息量巨大"><a href="#一、开始！今日信息量巨大" class="headerlink" title="一、开始！今日信息量巨大"></a>一、开始！今日信息量巨大</h3><p>大佬们展示肌肉。</p><p>回归部分还需要些数学根底。</p><p>代码后面也有一丢丢正文。</p><a id="more"></a><p>先给一个linux服务器的方便功能。</p><p>Screen -DR 加个名字，可以开启永远运行的窗口。</p><p>Ctrl A + </p><blockquote><ol><li>C 创建新窗口</li><li>N 切换下一个窗口</li><li>D 回到主界面（并未关闭窗口）<br>Exit 命令退出</li></ol></blockquote><p>同学们的学习能力很强，可以打开vim编辑器并且退出了。（笑</p><p>不不，是有与数据对话的能力了。</p><p>希望脱颖而出，代码能力肯定比不上，但是我们有专业优势，即对<strong>数据分析</strong>的能力。我们懂模型，懂预测。</p><p>至于为什么要用hadoop，因为数据多了，非常大。</p><h4 id="给出一个场景"><a href="#给出一个场景" class="headerlink" title="给出一个场景"></a>给出一个场景</h4><p>场景：美国二手车，kaggle us-used-car。一共300w条记录，66个变量。</p><p>因变量：Price，最主要的任务就是探究price受谁的影响。</p><p>首先这么多变量中，存在很多数据缺失问题。去缺失。传到服务器上后，挑出一些缺失值少的变量。</p><p>今天作业：<br>用这个数据，清理出一份可以回归的变量来。r里面有很多现成的东西。</p><h3 id="二、分布式上的回归分析"><a href="#二、分布式上的回归分析" class="headerlink" title="二、分布式上的回归分析"></a>二、分布式上的回归分析</h3><p>如何在分布式上进行回归分析？区别在哪？（按行读取）</p><p>原来的数据n乘p维，n很小100，p很小10。</p><p>现在的数据n乘p维，n很大300w，p有66列，实际上会比这多得多，比如多个水平的哑变量就会占很多列。p很可能大于1k。</p><p>原始数据9gb，存成双精度需要60g的内存。需要双倍的空间才能执行任务，单机不可能。但是我们有分布式。</p><script type="math/tex; mode=display">Y = x \times \beta + \epsilon</script><p>beta不大，但是帽子阵根本求不了。要想解决这个问题，最难的在于计算：</p><script type="math/tex; mode=display">（X^{t}X）^{-1}，X^{t}</script><p>有了目标，剩下的就很简单了。</p><p><strong>第一个问题</strong>：如何构造把X^{t}Y求出来？</p><p>如果x仅有一列，相当于 $ 1<em>n $ 与 $ n</em>1 $相乘，代数运算即一一对应相乘求和，放在转置前看，即每行的元素相乘。如果x有两列，最终结果是2乘1的两个数，第一行为x第一列与y的对应乘积求和，第二行为x第二列与y的对应元素乘积求和。（内积）</p><p><strong>第二个问题</strong>：如何把X^{t}X构造出来？</p><p>最终得到的是p乘p维的矩阵，第xij位置的元素，为x第i列与x第j列对应元素的乘积（内积）。i可以等于j。</p><p>看到所有问题的答案，我们发现，所有的计算都是行内部的计算！那不是很舒服？分行计算就行啊！</p><h3 id="三、作业代码"><a href="#三、作业代码" class="headerlink" title="三、作业代码"></a>三、作业代码</h3><h4 id="1-简单线性回归"><a href="#1-简单线性回归" class="headerlink" title="1. 简单线性回归"></a>1. 简单线性回归</h4><p>生成回归数据的r文件就不贴了。来看看我写的又臭又长的估计法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">readme.txt</span><br><span class="line">先使用Rscript reg.r建立reg.csv（回归数据集）</span><br><span class="line">再使用MapReduce</span><br><span class="line">mapper与process文件都是分行操作，使用1个process（reducer）求和就行</span><br></pre></td></tr></table></figure><p>下面是生成数据用的R代码。代码中控制了beta的值，可以与最后结果比较。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#! /usr/bin/env Rscript</span><br><span class="line"></span><br><span class="line">n = 1000</span><br><span class="line">p = 10</span><br><span class="line">x = matrix(rnorm(n*p), n, p)</span><br><span class="line">e = rnorm(n)</span><br><span class="line">beta = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)</span><br><span class="line">y = x%*%beta+0.3*e</span><br><span class="line">mydata = cbind(x, y)</span><br><span class="line">dim(mydata)</span><br><span class="line">write.table(mydata, &quot;linear.csv&quot;, sep = &quot;,&quot; , row.names = FALSE,  col.names = FALSE)</span><br><span class="line">colnames(mydata) = c(&quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;, &quot;x4&quot;, &quot;x5&quot;, &quot;x6&quot;, &quot;x7&quot;, &quot;x8&quot;, &quot;x9&quot;, &quot;x10&quot;, &quot;y&quot;)</span><br><span class="line">mydata = data.frame(mydata)</span><br><span class="line">myfit &lt;- lm(y~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, mydata)</span><br><span class="line">myfit$coefficients</span><br></pre></td></tr></table></figure><p>这段代码是mapper。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#! usr/bin/env python3</span><br><span class="line"># 目标是做一些读取的工作，R做不了不同类型数据的存储</span><br><span class="line"></span><br><span class="line">import sys</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 先按“读取，把文件里字符型数据中的逗号替换成其他符号</span><br><span class="line">def commakiller(abc):</span><br><span class="line">    i = 1</span><br><span class="line">    while(i&lt;len(abc)):</span><br><span class="line">        abc[i] = abc[i].replace(&quot;,&quot;,&quot;***&quot;)</span><br><span class="line">        a = &apos;&quot;&apos;</span><br><span class="line">        abc[i] = a + abc[i] + a</span><br><span class="line">        i = i + 2</span><br><span class="line">    b = &quot;&quot;</span><br><span class="line">    qline = b.join(abc)</span><br><span class="line">    return(qline)</span><br><span class="line"></span><br><span class="line">#reader = csv.reader(sys.stdin)</span><br><span class="line">#next(reader)</span><br><span class="line">times = 1</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    abc = line.split(&apos;&quot;&apos;)</span><br><span class="line">    data = commakiller(abc).split(&quot;,&quot;)</span><br><span class="line">    p = len(data)</span><br><span class="line">    if p &lt;= 1: continue</span><br><span class="line">    #if times == 1 : names = data;times = times + 1;continue</span><br><span class="line">    if p &gt; 1 :</span><br><span class="line">        data[p-1] = data[p-1][:-1]  # 每行后的换行符</span><br><span class="line">        datak = list(map(float, data))</span><br><span class="line">        xty = []</span><br><span class="line">        for i in range(p-1):</span><br><span class="line">            xty.append(datak[i] * datak[p-1]) # 默认第p个是因变量</span><br><span class="line">        print(&quot;*&quot;,&quot;,&quot;.join(str(i) for i in xty)) </span><br><span class="line">        xtx = np.outer(datak[0:(p-1)],datak[0:(p-1)])  # 外积</span><br><span class="line">        print(&quot;,&quot;.join(&quot;,&quot;.join(str(k) for k in qq) for qq in xtx.tolist()))</span><br></pre></td></tr></table></figure><p>mapper把数据用逗号分隔，标准输出在屏幕上。<br>用管道将mapper的输出结果能够被吸入process.py（reducer，如下段代码）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#! usr/bin/env python3</span><br><span class="line">import sys</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">xtx = [];xty = [];temp = []</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    data = line.split(&apos;,&apos;)</span><br><span class="line">    #print(data)</span><br><span class="line">    p = len(data)</span><br><span class="line">    data[p-1] = data[p-1][:-1]</span><br><span class="line">    if line[0] == &quot;*&quot;:  # 说明是标记的xty</span><br><span class="line">        data[0] = data[0][2:]</span><br><span class="line">        p1 = len(data)</span><br><span class="line">        data = list(map(float, data))</span><br><span class="line">        if len(xty) == 0:</span><br><span class="line">            xty = data</span><br><span class="line">            continue</span><br><span class="line">        else:</span><br><span class="line">            xty = xty + np.array(data)</span><br><span class="line">            # 在新的xtx出现之前</span><br><span class="line">            if len(xtx) == 0:</span><br><span class="line">                xtx = temp</span><br><span class="line">            else:</span><br><span class="line">                xtx = np.array(xtx) + np.array(temp) # bug</span><br><span class="line">                len2 = len(temp)</span><br><span class="line">            temp = []  # 循环结束初始化</span><br><span class="line">    else:   # 其他都是xtx</span><br><span class="line">        data = list(map(float, data))</span><br><span class="line">        if len(temp) == 0:</span><br><span class="line">            temp = data</span><br><span class="line">        else:</span><br><span class="line">            temp = temp + data # 连接</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">xtx = np.asarray(xtx).reshape(int(p1),int(len2/p1))</span><br><span class="line">print(np.dot(np.linalg.inv(xtx),np.array(xty)))</span><br></pre></td></tr></table></figure><p>原理与之前讲的相似，先计算xtx与xty，求逆（生成的矩阵有时候会奇异，那就重新生成一波）</p><p>最后是我们的main主函数shell文件，这个没啥变化 (不要直接跑，我改了文件名)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">PWD=$(cd $(dirname $0); pwd)</span><br><span class="line">cd $PWD 1&gt; /dev/null 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line">hadoop fs -put linear.csv /user/devel/hehe/reg</span><br><span class="line"></span><br><span class="line">TASKNAME=linear-hehe</span><br><span class="line">HADOOP_INPUT_DIR=/user/devel/hehe/reg/linear.csv</span><br><span class="line">HADOOP_OUTPUT_DIR=/user/devel/hehe/output/1020output</span><br><span class="line"></span><br><span class="line">echo $HADOOP_HOME</span><br><span class="line">echo $HADOOP_INPUT_DIR</span><br><span class="line">echo $HADOOP_OUTPUT_DIR</span><br><span class="line"></span><br><span class="line">hadoop fs -rm -r $HADOOP_OUTPUT_DIR</span><br><span class="line"></span><br><span class="line">hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.1.3.jar \</span><br><span class="line">-D mapred.job.name=$TASKNAME \</span><br><span class="line">-D mapred.job.priority=HIGH \</span><br><span class="line">-D stream.memory.limit=1000 \</span><br><span class="line">-D mapred.reduce.tasks=1 \</span><br><span class="line">-D mapred.job.map.capacity=100 \</span><br><span class="line">-D mapred.job.map.capacity=100 \</span><br><span class="line">-input $&#123;HADOOP_INPUT_DIR&#125; \</span><br><span class="line">-output $&#123;HADOOP_OUTPUT_DIR&#125; \</span><br><span class="line">-mapper &quot;$PWD/mapper.py&quot; \</span><br><span class="line">-reducer &quot;$PWD/process.py&quot; \</span><br><span class="line">-file &quot;$PWD/mapper.py&quot; &quot;$PWD/process.py&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ $? -ne 0 ]; then</span><br><span class="line">    echo &apos;error&apos;</span><br><span class="line">    exit 1</span><br><span class="line">fi</span><br><span class="line">hadoop fs -touchz $&#123;HADOOP_OUTPUT_DIR&#125;/done</span><br><span class="line"></span><br><span class="line">hadoop fs -ls $HADOOP_OUTPUT_DIR | cat</span><br><span class="line"></span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><h4 id="2-清洗二手车数据"><a href="#2-清洗二手车数据" class="headerlink" title="2. 清洗二手车数据"></a>2. 清洗二手车数据</h4><p>二手车数据来自kaggle <a href="https://www.kaggle.com/ananaymital/us-used-cars-dataset" target="_blank" rel="noopener">给个链接</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">本文件仅适用于二手车数据</span><br><span class="line"></span><br><span class="line">仅进行了OLS回归，GLM需要在帽子阵计算中加权，未实现</span><br><span class="line"></span><br><span class="line">本地5w行数据计算成功，hadoop上还未测试</span><br><span class="line"></span><br><span class="line">na.py用于清洗数据，计算变量均值标准差，并给出适合的列。对300万原数据得到的结果存入vars.txt</span><br><span class="line"></span><br><span class="line">mapper.py用于简单正态插补，计算帽子矩阵</span><br><span class="line"></span><br><span class="line">reducer.py用于计算系数阵估计值betahat，得到的结果存入result1.txt中</span><br></pre></td></tr></table></figure><p>先看na.py，这个代码对数据na等情况做了处理，有点长，这个文件在处理时单独运行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line">#! usr/bin/env python3</span><br><span class="line">## 任务：计算每列的na、均值、方差、总量与内部情况</span><br><span class="line">times = 1</span><br><span class="line">import sys</span><br><span class="line">import re # 正则化</span><br><span class="line">import numpy as np</span><br><span class="line">import math</span><br><span class="line">from operator import itemgetter</span><br><span class="line"></span><br><span class="line"># 先按“读取，把文件里字符型数据中的逗号替换成其他符号</span><br><span class="line">def commakiller(abc):</span><br><span class="line">    i = 1</span><br><span class="line">    while(i&lt;len(abc)):</span><br><span class="line">        abc[i] = abc[i].replace(&quot;,&quot;,&quot;***&quot;)</span><br><span class="line">        a = &apos;&quot;&apos;</span><br><span class="line">        abc[i] = a + abc[i] + a</span><br><span class="line">        i = i + 2</span><br><span class="line">    b = &quot;&quot;</span><br><span class="line">    qline = b.join(abc)</span><br><span class="line">    return(qline)</span><br><span class="line"></span><br><span class="line">na_count = &#123;&#125;</span><br><span class="line">num_count = &#123;&#125;;var_count = &#123;&#125;</span><br><span class="line">strvalue = &#123;&#125;</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    data = line.split(&apos;&quot;&apos;)</span><br><span class="line">    items = commakiller(data).split(&apos;,&apos;)</span><br><span class="line">    #print(&quot;,&quot;.join(str(k) for k in items))</span><br><span class="line">    if(times == 1):</span><br><span class="line">        times += 1</span><br><span class="line">        names = items  # 后续遍历使用</span><br><span class="line">        continue</span><br><span class="line">    if(times &gt;= 2):</span><br><span class="line">        ## na的计算与插补需要把全数据遍历</span><br><span class="line">        for key, value in enumerate(items):</span><br><span class="line">            count = int((value == &apos;&apos;) | (value == &quot;--&quot;))</span><br><span class="line">            na_count[key] = na_count.get(key, 0) + count # 每行统计缺失值</span><br><span class="line">            # get函数，如果对应key是空值，则返回0（设置的默认值），有缺失会被上一行count记录下来</span><br><span class="line">            # 计算其他列属性，描述统计</span><br><span class="line">           </span><br><span class="line">            if ((value != &quot;&quot;) &amp; (value != &quot;--&quot;)):</span><br><span class="line">                #if len(value) &gt; 25:  # 超长取值一般都无法处理，删除</span><br><span class="line">                #    continue</span><br><span class="line">                try:</span><br><span class="line">                    val_num = float(value) # 如果是数值型变量</span><br><span class="line">                    num_count[key] = num_count.get(key,0) + val_num # 数值型直接求和</span><br><span class="line">                    var_count[key] = var_count.get(key,0) + val_num ** 2 # 平方求和</span><br><span class="line">                except(ValueError):</span><br><span class="line">                    try:</span><br><span class="line">                        # 数值型变量带单位的，如下处理</span><br><span class="line">                        if ((&quot;in&quot; in value[-5:])&amp;(re.findall(&apos;[a-z]in&apos;,value)==[])):</span><br><span class="line">                            val_num = float(re.sub(&apos;in&apos;,&apos;&apos;,value,1))</span><br><span class="line">                            num_count[key] = num_count.get(key,0) + val_num</span><br><span class="line">                            var_count[key] = var_count.get(key,0) + val_num ** 2</span><br><span class="line">                        elif ((&quot;seats&quot; in value[-8:])&amp;(re.findall(&apos;[a-z]seats&apos;,value)==[])):</span><br><span class="line">                            val_num = float(re.sub(&apos;seats&apos;,&apos;&apos;,value,1))</span><br><span class="line">                            num_count[key] = num_count.get(key,0) + val_num</span><br><span class="line">                            var_count[key] = var_count.get(key,0) + val_num ** 2</span><br><span class="line">                        elif ((&apos;gal&apos; in value[-6:])&amp;(re.findall(&apos;[a-z]gal&apos;,value)==[])):</span><br><span class="line">                            val_num = float(re.sub(&apos;gal&apos;,&apos;&apos;,value,1))</span><br><span class="line">                            num_count[key] = num_count.get(key,0) + val_num</span><br><span class="line">                            var_count[key] = var_count.get(key,0) + val_num ** 2</span><br><span class="line">                        #elif &apos;RPM&apos; in value[-3:]:</span><br><span class="line">                        #    val_num = float(re.sub(&apos;RPM&apos;,&apos;&apos;,value,1))</span><br><span class="line">                        #    num_count[key] = num_count.get(key,0) + val_num</span><br><span class="line">                        # 带单位的只有这几个，数值化后，全存进num_count的字典中 </span><br><span class="line">                        # 出了点问题，&apos;148 lb-ft @ 200 RPM&apos; 这什么意思（于是这列被删了）</span><br><span class="line">                        # 下面处理所有字符类型的变量，用字典存储元素，并计算种类和数量</span><br><span class="line">                        #print(num_count)</span><br><span class="line">                        else:</span><br><span class="line">                            strvalue.setdefault(key,&#123;&#125;)  # 设定每个变量默认字典初始值为空</span><br><span class="line">                            strvalue[key][value] = strvalue[key].get(value,0) + 1  # 每次更新对应元素的value，+1</span><br><span class="line">                    except(ValueError):</span><br><span class="line">                        #print(&apos;转换失败 第%s列\t%s&apos;%(key,names[key]))</span><br><span class="line">                        continue</span><br><span class="line">        times += 1</span><br><span class="line"></span><br><span class="line">### 1.处理 na</span><br><span class="line">abort = [];fix = [];perf = []</span><br><span class="line"></span><br><span class="line">print(&quot;,&quot;.join(str(k) for k in names))  # 变量名-1行</span><br><span class="line">sorted_na_count = sorted(na_count.items(), key=itemgetter(0))</span><br><span class="line">for num, count in sorted_na_count:</span><br><span class="line">    na01 = times - count - 1</span><br><span class="line">    print(&apos;%s\t%s\t%s&apos; % (num, count,times))  # 每列缺失值-66行</span><br><span class="line">    value = int(count)</span><br><span class="line">    key = int(num)</span><br><span class="line">    lendata = times - 1 # 数据长度</span><br><span class="line">    if key == 0:</span><br><span class="line">        abort.append(key)</span><br><span class="line">        continue # ID列直接加入废弃</span><br><span class="line">    if (value/lendata) &gt;= 0.3:</span><br><span class="line">        abort.append(key) # 把大于30% 的缺失列号加入废弃</span><br><span class="line">    elif ((value/lendata &gt; 0) &amp; (value/lendata &lt; 0.3)):</span><br><span class="line">        fix.append(key)</span><br><span class="line">    elif(value == 0):</span><br><span class="line">        perf.append(key)</span><br><span class="line"></span><br><span class="line">print(&quot;需要丢掉的列号：%s\n需要插补的列号：%s\n完美列号：%s&quot; % ((&quot;,&quot;.join(str(k) for k in abort)),(&quot;,&quot;.join(str(k) for k in fix)),(&quot;,&quot;.join(str(k) for k in perf))))</span><br><span class="line"></span><br><span class="line">### 2.数值型变量</span><br><span class="line">sorted_num_count = sorted(num_count.items(), key=itemgetter(0)) </span><br><span class="line">for num,count in sorted_num_count:</span><br><span class="line">    if int(num) in abort:</span><br><span class="line">        print(&apos;丢掉第%d列\t%s\t-是首列或因na过多&apos;%(num,names[num]))</span><br><span class="line">        continue</span><br><span class="line">    xbar = count/na01</span><br><span class="line">    if xbar &gt; 100000:</span><br><span class="line">        print(&apos;丢掉第%d列\t%s\t-xbar大于100000&apos;%(num,names[num]))</span><br><span class="line">        continue</span><br><span class="line">    sdlist = math.sqrt(var_count[num]/na01 - xbar**2) # EX2 - (EX)2</span><br><span class="line">    print(&apos;%s\t%s\t%s\t%s&apos; % (num, names[num], xbar, sdlist)) # num是列号，count是全元素和</span><br><span class="line">    ## 问题，会出现很多大均值的列，不清楚为什么，需要筛选</span><br><span class="line"></span><br><span class="line">### 3.字符型变量</span><br><span class="line">for key in strvalue.keys(): # 把所有字符型的key遍历一遍 (都是列号)</span><br><span class="line">    if int(key) in abort:</span><br><span class="line">        try:</span><br><span class="line">            print(&apos;丢掉第%d列\t%s\t-na过多&apos;%(key,names[key]))</span><br><span class="line">            continue</span><br><span class="line">        except(TypeError):</span><br><span class="line">            print(&apos;丢掉第%d列\t%s\t-数据出界&apos;%(key,names[key]))</span><br><span class="line">            continue </span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    if len(strvalue[key].keys()) &gt; 10 : # 字符型变量之内有个统计，也存成dict，现在要取值大于5类的变量都消灭掉</span><br><span class="line">        print(&apos;丢掉第%d列\t%s\t-类数大于10&apos;%(key,names[key]))</span><br><span class="line">        continue # 分行操作时，可能有些时候会保留一些取值本来很多的变量，不过没关系</span><br><span class="line">    sorted_str_count = sorted(strvalue[key].items(), key=itemgetter(0)) # 变量内部的字典-再计数，根据变量名这个key放回到names中找原位置</span><br><span class="line">    print(&apos;%s&apos;%(&apos;第%d列&apos;%(key))) </span><br><span class="line">    for num, count in sorted_str_count:</span><br><span class="line">        try:</span><br><span class="line">            print(&apos;%s\t%s\t%s&apos; % (num, names[key], count))</span><br><span class="line">        except(TypeError):</span><br><span class="line">            print(&apos;上一行的有问题，丢掉第%d列\t%s\t-type_error了&apos;%(key,names[key]))</span><br><span class="line">            continue</span><br></pre></td></tr></table></figure><p>上面处理时，其实要十分了解原数据的含义和数据初始形式。在数据处理之前，尽可能选择取样观察，或者利用信息提前计划。</p><p>na.py的处理中，会给出需要删除/不需删除，各列的均值与标准差等。结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br></pre></td><td class="code"><pre><span class="line">[devel@emr-header-1 1026]$ cat vars.txt</span><br><span class="line">vin,back_legroom,bed,bed_height,bed_length,body_type,cabin,city,city_fuel_economy,combine_fuel_economy,daysonmarket,dealer_zip,description,engine_cylinders,engine_displacement,engine_type,exterior_color,fleet,frame_damaged,franchise_dealer,franchise_make,front_legroom,fuel_tank_volume,fuel_type,has_accidents,height,highway_fuel_economy,horsepower,interior_color,isCab,is_certified,is_cpo,is_new,is_oemcpo,latitude,length,listed_date,listing_color,listing_id,longitude,main_picture_url,major_options,make_name,maximum_seating,mileage,model_name,owner_count,power,price,salvage,savings_amount,seller_rating,sp_id,sp_name,theft_title,torque,transmission,transmission_display,trimId,trim_name,vehicle_damage_category,wheel_system,wheel_system_display,wheelbase,width,year</span><br><span class="line"></span><br><span class="line">0       0       3000600</span><br><span class="line">1       242727  3000600</span><br><span class="line">2       2980472 3000600</span><br><span class="line">3       3000040 3000600</span><br><span class="line">4       2579859 3000600</span><br><span class="line">5       13543   3000600</span><br><span class="line">6       2936507 3000600</span><br><span class="line">7       0       3000600</span><br><span class="line">8       491285  3000600</span><br><span class="line">9       3000040 3000600</span><br><span class="line">10      0       3000600</span><br><span class="line">11      0       3000600</span><br><span class="line">12      77901   3000600</span><br><span class="line">13      100578  3000600</span><br><span class="line">14      172383  3000600</span><br><span class="line">15      100578  3000600</span><br><span class="line">16      0       3000600</span><br><span class="line">17      1426595 3000600</span><br><span class="line">18      1426595 3000600</span><br><span class="line">19      0       3000600</span><br><span class="line">20      572568  3000600</span><br><span class="line">21      175452  3000600</span><br><span class="line">22      160673  3000600</span><br><span class="line">23      82721   3000600</span><br><span class="line">24      1426595 3000600</span><br><span class="line">25      159733  3000600</span><br><span class="line">26      491266  3000600</span><br><span class="line">27      172383  3000600</span><br><span class="line">28      2       3000600</span><br><span class="line">29      1426595 3000600</span><br><span class="line">30      2999953 3000600</span><br><span class="line">31      2817055 3000600</span><br><span class="line">32      0       3000600</span><br><span class="line">33      2864591 3000600</span><br><span class="line">34      0       3000600</span><br><span class="line">35      159722  3000600</span><br><span class="line">36      0       3000600</span><br><span class="line">37      0       3000600</span><br><span class="line">38      0       3000600</span><br><span class="line">39      0       3000600</span><br><span class="line">40      369087  3000600</span><br><span class="line">41      200042  3000600</span><br><span class="line">42      0       3000600</span><br><span class="line">43      159766  3000600</span><br><span class="line">44      144387  3000600</span><br><span class="line">45      0       3000600</span><br><span class="line">46      1517012 3000600</span><br><span class="line">47      481415  3000600</span><br><span class="line">48      0       3000600</span><br><span class="line">49      1426595 3000600</span><br><span class="line">50      0       3000600</span><br><span class="line">51      40828   3000600</span><br><span class="line">52      52      3000600</span><br><span class="line">53      0       3000600</span><br><span class="line">54      1426595 3000600</span><br><span class="line">55      517782  3000600</span><br><span class="line">56      64166   3000600</span><br><span class="line">57      64166   3000600</span><br><span class="line">58      115826  3000600</span><br><span class="line">59      116293  3000600</span><br><span class="line">60      2999953 3000600</span><br><span class="line">61      146731  3000600</span><br><span class="line">62      146731  3000600</span><br><span class="line">63      159698  3000600</span><br><span class="line">64      159746  3000600</span><br><span class="line">65      0       3000600</span><br><span class="line">66      0       3000600</span><br><span class="line">67      0       3000600</span><br><span class="line">68      0       3000600</span><br><span class="line">69      0       3000600</span><br><span class="line">70      0       3000600</span><br><span class="line">71      0       3000600</span><br><span class="line">72      0       3000600</span><br><span class="line">73      0       3000600</span><br><span class="line">74      0       3000600</span><br><span class="line">75      0       3000600</span><br><span class="line">76      0       3000600</span><br><span class="line">77      0       3000600</span><br><span class="line">78      0       3000600</span><br><span class="line">79      0       3000600</span><br><span class="line">80      0       3000600</span><br><span class="line">81      0       3000600</span><br><span class="line">82      0       3000600</span><br><span class="line">83      0       3000600</span><br><span class="line">84      0       3000600</span><br><span class="line">85      0       3000600</span><br><span class="line">86      0       3000600</span><br><span class="line">87      0       3000600</span><br><span class="line">88      0       3000600</span><br><span class="line">89      0       3000600</span><br><span class="line">90      0       3000600</span><br><span class="line">91      0       3000600</span><br><span class="line">92      0       3000600</span><br><span class="line">93      0       3000600</span><br><span class="line">94      0       3000600</span><br><span class="line">95      0       3000600</span><br><span class="line">需要丢掉的列号：0,2,3,4,6,9,17,18,24,29,30,31,33,46,49,54,60</span><br><span class="line">需要插补的列号：1,5,8,12,13,14,15,20,21,22,23,25,26,27,28,35,40,41,43,44,47,51,52,55,56,57,58,59,61,62,63,64</span><br><span class="line">完美列号：7,10,11,16,19,32,34,36,37,38,39,42,45,48,50,53,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95</span><br><span class="line">丢掉第0列       vin     -是首列或因na过多</span><br><span class="line">1       back_legroom    34.88554152025584       10.803048024003107</span><br><span class="line">丢掉第4列       bed_length      -是首列或因na过多</span><br><span class="line">8       city_fuel_economy       18.973479961834286      11.637300445996951</span><br><span class="line">10      daysonmarket    76.0455595699392        108.87863896938518</span><br><span class="line">11      dealer_zip      50669.81150830218       27375.94715300726</span><br><span class="line">12      description     0.17846959890341893     255.2549902888531</span><br><span class="line">14      engine_displacement     2797.285075413276       1481.0219220754384</span><br><span class="line">16      exterior_color  2.260508282512925       442.6922512862191</span><br><span class="line">21      front_legroom   39.72592702320007       10.02756775400742</span><br><span class="line">22      fuel_tank_volume        17.608113546641402      6.7668815295322435</span><br><span class="line">25      height  62.35115022029862       16.541684822918757</span><br><span class="line">26      highway_fuel_economy    24.641676545249798      13.020379389747855</span><br><span class="line">27      horsepower      233.69342021376397      105.1379926203423</span><br><span class="line">28      interior_color  2.2194684128069095      559.1713000695153</span><br><span class="line">34      latitude        36.97614874552056       5.025653349279904</span><br><span class="line">35      length  183.34090699859522      47.80448637471194</span><br><span class="line">丢掉第38列      listing_id      -xbar大于100000</span><br><span class="line">39      longitude       -90.62260148008761      13.967765609990069</span><br><span class="line">43      maximum_seating 5.18447183379052        1.6826429709038224</span><br><span class="line">44      mileage 29640.29273455067       73067.93566116491</span><br><span class="line">45      model_name      58.31043968221012       333.09392240515734</span><br><span class="line">丢掉第46列      owner_count     -是首列或因na过多</span><br><span class="line">48      price   29926.953581444013      19568.717865222385</span><br><span class="line">50      savings_amount  550.8380996594346       1079.351149695568</span><br><span class="line">51      seller_rating   4.211379641169585       0.7130308234825646</span><br><span class="line">丢掉第52列      sp_id   -xbar大于100000</span><br><span class="line">59      trim_name       0.04460616030332584     10.331173669741302</span><br><span class="line">63      wheelbase       109.1642761329817       29.529077769800306</span><br><span class="line">64      width   74.1947137895581        19.1476096014168</span><br><span class="line">65      year</span><br><span class="line">        2017.2940512877597      29.89588340213624</span><br><span class="line">丢掉第0列       vin     -na过多</span><br><span class="line">丢掉第5列       body_type       -类数大于10</span><br><span class="line">丢掉第7列       city    -类数大于10</span><br><span class="line">丢掉第12列      description     -类数大于10</span><br><span class="line">丢掉第13列      engine_cylinders        -类数大于10</span><br><span class="line">丢掉第15列      engine_type     -类数大于10</span><br><span class="line">丢掉第16列      exterior_color  -类数大于10</span><br><span class="line">丢掉第19列      franchise_dealer        -类数大于10</span><br><span class="line">丢掉第20列      franchise_make  -类数大于10</span><br><span class="line">丢掉第23列      fuel_type       -类数大于10</span><br><span class="line">丢掉第28列      interior_color  -类数大于10</span><br><span class="line">丢掉第32列      is_new  -类数大于10</span><br><span class="line">丢掉第36列      listed_date     -类数大于10</span><br><span class="line">丢掉第37列      listing_color   -类数大于10</span><br><span class="line">丢掉第40列      main_picture_url        -类数大于10</span><br><span class="line">丢掉第41列      major_options   -类数大于10</span><br><span class="line">丢掉第42列      make_name       -类数大于10</span><br><span class="line">丢掉第45列      model_name      -类数大于10</span><br><span class="line">丢掉第47列      power   -类数大于10</span><br><span class="line">丢掉第53列      sp_name -类数大于10</span><br><span class="line">丢掉第55列      torque  -类数大于10</span><br><span class="line">丢掉第56列      transmission    -类数大于10</span><br><span class="line">丢掉第57列      transmission_display    -类数大于10</span><br><span class="line">丢掉第58列      trimId  -类数大于10</span><br><span class="line">丢掉第59列      trim_name       -类数大于10</span><br><span class="line">丢掉第61列      wheel_system    -类数大于10</span><br><span class="line">丢掉第62列      wheel_system_display    -类数大于10</span><br><span class="line">丢掉第17列      fleet   -na过多</span><br><span class="line">丢掉第18列      frame_damaged   -na过多</span><br><span class="line">丢掉第24列      has_accidents   -na过多</span><br><span class="line">丢掉第29列      isCab   -na过多</span><br><span class="line">丢掉第49列      salvage -na过多</span><br><span class="line">丢掉第54列      theft_title     -na过多</span><br><span class="line">丢掉第31列      is_cpo  -na过多</span><br><span class="line">丢掉第33列      is_oemcpo       -na过多</span><br><span class="line">丢掉第6列       cabin   -na过多</span><br><span class="line">丢掉第2列       bed     -na过多</span><br><span class="line">丢掉第1列       back_legroom    -类数大于10</span><br><span class="line">丢掉第3列       bed_height      -na过多</span><br><span class="line">丢掉第4列       bed_length      -na过多</span><br><span class="line">丢掉第8列       city_fuel_economy       -类数大于10</span><br><span class="line">丢掉第9列       combine_fuel_economy    -na过多</span><br><span class="line">丢掉第10列      daysonmarket    -类数大于10</span><br><span class="line">丢掉第11列      dealer_zip      -类数大于10</span><br><span class="line">丢掉第14列      engine_displacement     -类数大于10</span><br><span class="line">丢掉第21列      front_legroom   -类数大于10</span><br><span class="line">丢掉第25列      height  -类数大于10</span><br><span class="line">丢掉第26列      highway_fuel_economy    -类数大于10</span><br><span class="line">丢掉第27列      horsepower      -类数大于10</span><br><span class="line">丢掉第22列      fuel_tank_volume        -类数大于10</span><br><span class="line">丢掉第30列      is_certified    -na过多</span><br><span class="line">丢掉第34列      latitude        -类数大于10</span><br><span class="line">第35列</span><br><span class="line"> &apos;Backup Camera&apos;        length  1</span><br><span class="line"> 4-wheel antilock       length  1</span><br><span class="line"> Traction control - ABS and driveline   length  1</span><br><span class="line"> automatic high beam on/off|Glass       length  1</span><br><span class="line"> body-color (Not available on Double Cab models.)|Glass length  1</span><br><span class="line"> driver 8-way power|Seats       length  1</span><br><span class="line"> front passenger        length  1</span><br><span class="line"> heated driver and front passenger|Console front center with 2 cup holders and storage  length  1</span><br><span class="line"> includes rear storage drawer (Excludes storage drawer with (GAT) All Terrain with (ABD) 5-passenger seating.)|Power outlet       length  2</span><br><span class="line">第38列</span><br><span class="line"> 2 in front door panel  listing_id      1</span><br><span class="line"> 3-prong household style located on the rear of center console|Cup holders 2 in front center console    listing_id        1</span><br><span class="line"> Xenon headlights&quot;***V6***3600.0***V6***Silver***True***False***False******42.1 in***19 gal***Gasoline***False***59.1 in***28.0***304.0***Gray (Dark Grey)***True*********False******31.8552***202 in***2020-08-27***SILVER***280340040***-106.028***https://static.cargurus.com/images/forsale/2020/08/26/00/06/2016_cadillac_xts-pic-1844722391038826724-152x114.jpeg***&quot;[&apos;Leather Seats&apos;   listing_id      1</span><br><span class="line"> deep-tinted|Wipers     listing_id      1</span><br><span class="line"> folding|Dead pedal     listing_id      1</span><br><span class="line"> rear (Requires Crew Cab or Double Cab model. Deleted with (ZW9) pickup box delete.)|Bumper     listing_id1</span><br><span class="line"> tilt and telescopic|Display    listing_id      2</span><br><span class="line"> top|Tailgate   listing_id      1</span><br><span class="line">第39列</span><br><span class="line"> &apos;Navigation System&apos;    longitude       1</span><br><span class="line"> 2 bottle holders in front door panel   longitude       1</span><br><span class="line"> 2 in front door panel  longitude       1</span><br><span class="line"> EZ-Lift and Lower (Deleted when (ZW9) pickup box delete is ordered.)|Remote Locking Tailgate|Radio     longitude 1</span><br><span class="line"> driver instrument information enhanced longitude       2</span><br><span class="line"> driver|Steering wheel  longitude       1</span><br><span class="line"> front chrome|CornerStep        longitude       1</span><br><span class="line"> front intermittent     longitude       1</span><br><span class="line">第43列</span><br><span class="line"> &apos;Heated Seats&apos; maximum_seating 1</span><br><span class="line"> 3-channel programmable|Defogger        maximum_seating 2</span><br><span class="line"> 3-passenger (includes child seat top tether anchor)|Instrumentation    maximum_seating 1</span><br><span class="line"> HD|Floor covering      maximum_seating 1</span><br><span class="line"> chrome|4X4 chrome badge (Included and only available with 4X4 models.)|Grille surround maximum_seating 1</span><br><span class="line"> driver instrument information enhanced maximum_seating 1</span><br><span class="line"> miles/kilometers|Driver Information Center     maximum_seating 1</span><br><span class="line"> tilt and telescopic|Display    maximum_seating 1</span><br><span class="line">第44列</span><br><span class="line"> &apos;Android Auto&apos; mileage 1</span><br><span class="line"> 6-gauge cluster featuring speedometer  mileage 1</span><br><span class="line"> chrome|Headlamps       mileage 1</span><br><span class="line"> color-keyed carpeting|Driver Information Center        mileage 1</span><br><span class="line"> driver instrument information enhanced mileage 1</span><br><span class="line"> enhanced       mileage 1</span><br><span class="line"> one color|Sensor       mileage 1</span><br><span class="line"> rear-window electric|Cup holders 2 in front center console     mileage 2</span><br><span class="line">丢掉第46列      owner_count     -na过多</span><br><span class="line">第48列</span><br><span class="line"> &apos;Bluetooth&apos;    price   1</span><br><span class="line"> 10 total|Lighting      price   2</span><br><span class="line"> 3-channel programmable|Air conditioning        price   1</span><br><span class="line"> cargo box with switch on center switch bank (Deleted when (ZW9) pickup box delete is ordered.) (Deleted with (ZW9) pickup box delete.)|Fog lamps price   1</span><br><span class="line"> power  price   1</span><br><span class="line"> power with driver and passenger Express-Down/Up|Cruise control price   1</span><br><span class="line"> right front passenger and rear seat occupants|Defogger price   1</span><br><span class="line"> voltage and oil pressure|Driver Information Center     price   1</span><br><span class="line">第50列</span><br><span class="line"> &apos;Backup Camera&apos;        savings_amount  1</span><br><span class="line"> cargo compartment      savings_amount  2</span><br><span class="line"> halogen|Mirror caps    savings_amount  1</span><br><span class="line"> inside rearview manual day/night|Lighting      savings_amount  1</span><br><span class="line"> programmable|Pedals    savings_amount  1</span><br><span class="line"> right front passenger and rear seat occupants (Dual-zone climate control when (GAT) All Terrain is ordered. Tri-zone climate control on all other models.)|Defogger      savings_amount  1</span><br><span class="line"> steering wheel mounted|Mirror  savings_amount  1</span><br><span class="line"> warning messages and vehicle information|Windows       savings_amount  1</span><br><span class="line">第51列</span><br><span class="line"> &apos;Remote Start&apos;]&quot;***Cadillac***5 seats***64070.0***XTS***3.0***&quot;304 hp @ 6      seller_rating   1</span><br><span class="line"> body-color (Included and only available with (GAT) All Terrain HD Package.) (Included and only available with (GAT) All Terrain Package and mirror caps will be Black.)|Mirror caps      seller_rating   1</span><br><span class="line"> inside rearview manual day/night       seller_rating   1</span><br><span class="line"> interior with theater dimming  seller_rating   1</span><br><span class="line"> power with driver express up and down and express down on all other windows|Visors     seller_rating   1</span><br><span class="line"> power-adjustable for accelerator and brake|Climate control     seller_rating   1</span><br><span class="line"> rear-window electric|Mirror    seller_rating   1</span><br><span class="line">第52列</span><br><span class="line"> cargo compartment      sp_id   1</span><br><span class="line"> chrome|Glass   sp_id   1</span><br><span class="line"> driver and front passenger illuminated vanity mirrors|Assist handle    sp_id   1</span><br><span class="line"> frameless|Visors       sp_id   1</span><br><span class="line"> inside rearview auto-dimming|Lighting  sp_id   1</span><br><span class="line"> second row reading lamps integrated into dome light    sp_id   2</span><br><span class="line"> tri-zone automatic with individual climate settings for driver sp_id   1</span><br><span class="line">800 RPM&quot;***19950.0***False***65*********private seller***False***&quot;264 lb-ft @ 5 sp_id   1</span><br><span class="line">丢掉第60列      vehicle_damage_category -na过多</span><br><span class="line">第63列</span><br><span class="line"> &apos;Bluetooth&apos;    wheelbase       1</span><br><span class="line"> GMC Smart Driver       wheelbase       2</span><br><span class="line"> front reading lamps|Shift knob wheelbase       1</span><br><span class="line"> frontal and side impact for driver and front passenger driver inboard seat-mounted side-impact wheelbase1</span><br><span class="line"> interior with dome light       wheelbase       1</span><br><span class="line"> rear child security|Teen Driver mode a configurable feature that lets you activate customizable vehicle settings associated with a key fob       wheelbase       1</span><br><span class="line"> tachometer     wheelbase       1</span><br><span class="line">第64列</span><br><span class="line"> &apos;Backup Camera&apos;        width   1</span><br><span class="line"> Marketplace and more (Limitations apply. Not transferable. Standard connectivity available to original purchaser for ten years from the date of initial vehicle purchase for model year 2018 or newer GMC vehicles. See onstar.com for details and further plan limitations. Connected Access does not include emergency or security services. Availability and additional services enables by Connected Access are subject to change.)|Rear Vision Camera|Door locks  width   2</span><br><span class="line"> driver side knee and head curtain side-impact for all rows in outboard seating positions (Always use safety belts and the correct child restraints. Children are safer when properly secured in a rear seat in the appropriate child restraint. See the Owner&apos;s Manual for more information.)|Rear Vision Camera|Door locks width    1</span><br><span class="line"> driver- and passenger-side door switch with delayed entry feature      width   1</span><br><span class="line"> leather-wrapped|Brake  width   1</span><br><span class="line"> to encourage safe driving behavior. It can limit certain vehicle features      width   1</span><br><span class="line"> voltage and oil pressure|Driver Information Center     width   1</span><br><span class="line">第65列</span><br><span class="line"> &apos;CarPlay&apos;]&quot;***Chevrolet***6 seats***42921.0***Silverado 2500HD***1.0******56995.0***False***4549***4.814814814814815***285608***Platinum Auto Group***False******A***Automatic***t78815***LT Crew Cab 4WD******4WD***Four-Wheel Drive***153.7 in***80.5 in***2019</span><br><span class="line">&quot;       year</span><br><span class="line">        1</span><br><span class="line"> 4.2-inch diagonal color display includes driver personalization        year</span><br><span class="line">        1</span><br><span class="line"> and it prevents certain safety systems from being turned off. An in-vehicle report gives you information on your teen&apos;s driving habits and helps you to continue to coach your new driver|Tire pressure monitoring system|Horn     year</span><br><span class="line">        1</span><br><span class="line"> cargo lights   year</span><br><span class="line">        1</span><br><span class="line"> parking        year</span><br><span class="line">        1</span><br><span class="line"> rear child security|Rear seat reminder|Teen Driver configurable feature that lets you activate customizable vehicle settings associated with a key fob   year</span><br><span class="line">        2</span><br><span class="line"> rear child security|Teen Driver mode a configurable feature that lets you activate customizable vehicle settings associated with a key fob       year</span><br><span class="line">        1</span><br><span class="line">第66列</span><br></pre></td></tr></table></figure><p>上面的结果就是我们处理的标准。</p><p>下面看看mapper.py</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">#! usr/bin/env python3</span><br><span class="line"># 目标：插补na，并计算乘积 xtx与xty</span><br><span class="line"></span><br><span class="line">import sys</span><br><span class="line">import re</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 先按“读取，把文件里字符型数据中的逗号替换成其他符号</span><br><span class="line">def commakiller(abc):</span><br><span class="line">    i = 1</span><br><span class="line">    while(i&lt;len(abc)):</span><br><span class="line">        abc[i] = abc[i].replace(&quot;,&quot;,&quot;***&quot;)</span><br><span class="line">        a = &apos;&quot;&apos;</span><br><span class="line">        abc[i] = a + abc[i] + a</span><br><span class="line">        i = i + 2</span><br><span class="line">    b = &quot;&quot;</span><br><span class="line">    qline = b.join(abc)</span><br><span class="line">    return(qline)</span><br><span class="line"></span><br><span class="line">num_list = &#123;&apos;1&apos;:[34.886,10.803],&apos;8&apos;:[18.973,11.637],&apos;10&apos;:[76.046,108.879],&apos;11&apos;:[50669.812,27375.947],&apos;14&apos;:[2797.2851,1481.0219],&apos;21&apos;:[39.726,10.028],&apos;22&apos;:[17.608,6.767],&apos;25&apos;:[62.351,16.542],&apos;26&apos;:[24.642,13.020],&apos;27&apos;:[233.693,105.138],&apos;35&apos;:[183.341,47.804],&apos;43&apos;:[5.184,1.683],&apos;44&apos;:[29640.293,73067.936],&apos;64&apos;:[74.195,19.148],&apos;51&apos;:[4.211,0.713],&apos;63&apos;:[109.164,29.529],&apos;48&apos;:[29926.954,19568.718]&#125;</span><br><span class="line">nafixed = []</span><br><span class="line">times = 1</span><br><span class="line">for line in sys.stdin:    </span><br><span class="line">    abc = line.split(&apos;&quot;&apos;)</span><br><span class="line">    items = commakiller(abc).split(&quot;,&quot;)</span><br><span class="line">    if(times == 1):</span><br><span class="line">        times += 1</span><br><span class="line">        names = items  # 列名，后续遍历使用</span><br><span class="line">        continue</span><br><span class="line">    if(times &gt;= 2):</span><br><span class="line">        times += 1</span><br><span class="line">        p = len(num_list.keys()) # 变量长度</span><br><span class="line">        ## 1. na fix</span><br><span class="line">        for key, value in enumerate(items):</span><br><span class="line">            if str(key) in num_list.keys() :</span><br><span class="line">                if((value == &apos;&apos;) | (value == &quot;--&quot;)):</span><br><span class="line">                    # 每行统计缺失值</span><br><span class="line">                    mu = num_list[str(key)][0] #期望</span><br><span class="line">                    sigma = num_list[str(key)][1]   #标准差</span><br><span class="line">                    nafixed.append(np.random.normal(mu, sigma, 1))</span><br><span class="line">                else: </span><br><span class="line">                    nafixed.append(value)</span><br><span class="line">            else:</span><br><span class="line">                continue</span><br><span class="line">        # 对变量取值处理</span><br><span class="line">        if p &lt;= 1: continue</span><br><span class="line">        if p &gt; 1 :</span><br><span class="line">            # 全部数值变量转换为浮点型数据</span><br><span class="line">            flag = 0 # 每行从0开始算</span><br><span class="line">            for value in nafixed:</span><br><span class="line">                try:</span><br><span class="line">                    nafixed[flag] = float(value)</span><br><span class="line">                    flag += 1</span><br><span class="line">                except(ValueError):</span><br><span class="line">                    try:</span><br><span class="line">                        ## 1.数值型变量带单位的，如下处理</span><br><span class="line">                        if ((&quot;in&quot; in value[-5:])&amp;(re.findall(&apos;[a-z]in&apos;,value)==[])):</span><br><span class="line">                            nafixed[flag] = float(re.sub(&apos;in&apos;,&apos;&apos;,value,1));flag += 1</span><br><span class="line">                        elif ((&quot;seats&quot; in value[-8:])&amp;(re.findall(&apos;[a-z]seats&apos;,value)==[])):</span><br><span class="line">                            nafixed[flag] = float(re.sub(&apos;seats&apos;,&apos;&apos;,value,1));flag += 1</span><br><span class="line">                        elif ((&apos;gal&apos; in value[-6:])&amp;(re.findall(&apos;[a-z]gal&apos;,value)==[])):</span><br><span class="line">                            nafixed[flag] = float(re.sub(&apos;gal&apos;,&apos;&apos;,value,1));flag += 1</span><br><span class="line">                        else:</span><br><span class="line">                            nafixed[flag] = np.random.normal(list(num_list.values())[flag][0],list(num_list.values())[flag][1],1) </span><br><span class="line">                            flag += 1</span><br><span class="line">                    except(ValueError):</span><br><span class="line">                        nafixed[flag] = np.random.normal(list(num_list.values())[flag][0],list(num_list.values())[flag][1],1) # 未经或无法转换的值当na，插补处理</span><br><span class="line">                        flag += 1</span><br><span class="line">                        continue</span><br><span class="line">            ## 3. computing XTX &amp; XTY            </span><br><span class="line">            xty = []</span><br><span class="line">            for i in range(p-1):</span><br><span class="line">                xty.append(nafixed[i] * nafixed[p-1]) # 默认第p个是因变量price (事先设定)</span><br><span class="line">            print(&quot;*&quot;,&quot;,&quot;.join(str(i) for i in xty)) </span><br><span class="line">            xtx = np.outer(nafixed[0:(p-1)],nafixed[0:(p-1)])  # 外积</span><br><span class="line">            print(&quot;,&quot;.join(&quot;,&quot;.join(str(k) for k in qq) for qq in xtx.tolist()))</span><br></pre></td></tr></table></figure><p>mapper算出各行的xtx与xty，标准输出时以开头有无“*”来判定。</p><p>下面看看reducer</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">#! usr/bin/env python3</span><br><span class="line">import sys</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">xtx = [];xty = [];temp = []</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    data = line.split(&apos;,&apos;)</span><br><span class="line">    #print(data)</span><br><span class="line">    p = len(data)</span><br><span class="line">    data[p-1] = data[p-1][:-1]</span><br><span class="line">    if line[0] == &quot;*&quot;:  # 说明是标记的xty</span><br><span class="line">        data[0] = data[0][2:]</span><br><span class="line">        p1 = len(data)</span><br><span class="line">        data = list(map(float, data))</span><br><span class="line">        if len(xty) == 0:</span><br><span class="line">            xty = data</span><br><span class="line">            continue</span><br><span class="line">        else:</span><br><span class="line">            xty = xty + np.array(data)</span><br><span class="line">            # 在新的xtx出现之前</span><br><span class="line">            if len(xtx) == 0:</span><br><span class="line">                xtx = temp</span><br><span class="line">            else:</span><br><span class="line">                xtx = np.array(xtx) + np.array(temp) # bug</span><br><span class="line">                len2 = len(temp)</span><br><span class="line">            temp = []  # 循环结束初始化</span><br><span class="line">    else:   # 其他都是xtx</span><br><span class="line">        data = list(map(float, data))</span><br><span class="line">        if len(temp) == 0:</span><br><span class="line">            temp = data</span><br><span class="line">        else:</span><br><span class="line">            temp = temp + data # 连接</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">xtx = np.asarray(xtx).reshape(int(p1),int(len2/p1))</span><br><span class="line">print(xtx,&apos;\n&apos;)</span><br><span class="line">print(xty,&apos;\n&apos;)</span><br><span class="line">try:</span><br><span class="line">    print(np.dot(np.linalg.inv(xtx),np.array(xty)))</span><br><span class="line">except(LinAlgError):</span><br><span class="line">    continue</span><br></pre></td></tr></table></figure><p>由于某些原因，分布式没跑成（大家都去运行，系统拥堵了），只用了五万数据单机测试了一下。最终结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[devel@emr-header-1 1026]$ cat result1.txt</span><br><span class="line">[-1.37866211e+01 -3.97949219e+00  4.95000000e+01 -1.43750000e+01</span><br><span class="line"> -1.50000000e+01 -1.48950195e+00 -8.51562500e-01 -3.92000000e+02</span><br><span class="line"> -6.60400391e-01  5.33750000e+01  1.35742188e-01  7.20000000e+03</span><br><span class="line"> -9.96875000e+00 -4.97070312e-01  9.94726562e+00 -8.00781250e-02]</span><br></pre></td></tr></table></figure><p>最后附上main文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">PWD=$(cd $(dirname $0); pwd)</span><br><span class="line">cd $PWD 1&gt; /dev/null 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line">hadoop fs -put used_cars_5w.csv /user/devel/2020210995wangyuanhe/reg</span><br><span class="line"></span><br><span class="line">TASKNAME=lm-usedcars-hehe</span><br><span class="line">HADOOP_INPUT_DIR=/user/devel/2020210995wangyuanhe/reg/used_cars_5w.csv</span><br><span class="line">HADOOP_OUTPUT_DIR=/user/devel/2020210995wangyuanhe/output/1026output</span><br><span class="line"></span><br><span class="line">echo $HADOOP_HOME</span><br><span class="line">echo $HADOOP_INPUT_DIR</span><br><span class="line">echo $HADOOP_OUTPUT_DIR</span><br><span class="line"></span><br><span class="line">hadoop fs -rm -r $HADOOP_OUTPUT_DIR</span><br><span class="line"></span><br><span class="line">hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.1.3.jar \</span><br><span class="line">-D mapred.job.name=$TASKNAME \</span><br><span class="line">-D mapred.job.priority=NORMAL \</span><br><span class="line">-D mapred.reduce.tasks=1 \</span><br><span class="line">-file &quot;$PWD/mapper.py&quot; &quot;$PWD/reducer.py&quot; \</span><br><span class="line">-input $&#123;HADOOP_INPUT_DIR&#125; \</span><br><span class="line">-output $&#123;HADOOP_OUTPUT_DIR&#125; \</span><br><span class="line">-mapper &quot;$PWD/mapper.py&quot; \</span><br><span class="line">-reducer &quot;$PWD/reducer.py&quot; </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ $? -ne 0 ]; then</span><br><span class="line">    echo &apos;error&apos;</span><br><span class="line">    exit 1</span><br><span class="line">fi</span><br><span class="line">hadoop fs -touchz $&#123;HADOOP_OUTPUT_DIR&#125;/done</span><br><span class="line"></span><br><span class="line">hadoop fs -ls $HADOOP_OUTPUT_DIR | cat</span><br><span class="line"></span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><p>至此，分布式的运用基本结束了。</p><h3 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h3><p>先放一个系统卡住的样子</p><img src="/2020/10/21/201015hadoop/tu1.png" title="tu1"><p>同学的代码写的很糟，放上去跑不动，系统没资源……理由有很多，总之就是卡了。</p><p>上面代码漏说了一个技巧：</p><blockquote><p>Tail -n 99 used_cars_data.csv<br>就可以只取一部分行</p></blockquote><p>我们可以把大文件一条一条读，与stdin一样，这样就能对数据按行操作。</p><p>Slice 指每次读入多大的数据，如1024k，2000行。你想使用集成化工具时，可以这样做，当while循环跑到最后一行时停止。</p><p>但这样太慢了。因为每次都在找，不能存入内存</p><p>不过，SAS软件允许在很有限的内存中处理大量数据，每次只操作一行（有钱任性）</p><p>分布式系统上，最好是stdin的形式，标准输入输出。</p><p>处理中新的问题：<br>我现在有个很长的数据，其中有一列我知道是哑变量。</p><p>需要统计：有多少个哑变量，有多少种type，占比如何？如何自动识别呢（频数统计）</p><p>设置一个“其他”类，如果我要保证设定的“其他”类的占比大于20%，</p><h4 id="大家的问题："><a href="#大家的问题：" class="headerlink" title="大家的问题："></a>大家的问题：</h4><p><strong>1.面向python的编程，而非面向MapReduce的编程</strong></p><p>hadoop可以做到streaming，成为数据流。所有操作都应该在第一个循环下操作！这样才能完成对所有数据的处理，如果不能再这个缩进下操作，则代码不能面对分布式。</p><p><strong>2.介绍了python中的log模块，记录了一些信息。不要随便把过程打印出来。</strong></p><p>老师的程序：在大数据集上找到全部哑变量，并且把哑变量的top取出来</p><p><a href="https://github.com/feng-li/dlsa/blob/master/dlsa/dummies.py" target="_blank" rel="noopener">可以用这个</a></p><h4 id="MapReduce如何在分布式系统上呈现的"><a href="#MapReduce如何在分布式系统上呈现的" class="headerlink" title="MapReduce如何在分布式系统上呈现的"></a>MapReduce如何在分布式系统上呈现的</h4><p>最常听的：键值对。以标准输入输出来理解。key-value，将任何的行拆分成这两部分。必须尊重这两部分的对应关系。一般情况下，键值的对应有一个标准形式。</p><p><strong>Map(key,value) ——&gt; list(key2,value2)</strong></p><p>拿到了学号的姓名，现在要数一下名字有几画。拿到的是（学号-姓名），输出是（学号-笔画）。</p><p>如何体现键值对的影响呢？比如有个数据，记录了某个地区的温度，以及记录温度的设备。位置信息就作为了键，对应的温度就是值。（csv数据是碰巧有换行符作为间隔值）</p><p>如果我们把关心的数据拿出来（举个栗子：）</p><blockquote><p>1950，0<br>1950，22<br>1950，-11  </p></blockquote><p>这不是键值，这是一行中两个值，并非是键与值。但经过计算之后，就能得到新的键值对！</p><p>map过的key可能变了，不再是原来的key。csv其实是打印换行符对应的一行数据，平时的cat也是一行一换。如果数据是不换行的键值对，那么就需要自己识别key，写自己的map函数。</p><p>如果数据很大，那我们不能放进内存。  </p><p>比如放入：swap交换分区，缓存，页面文件……都在硬盘上。map出来的结果，需要做一定的排序（主要是打乱），打乱之后，数据均匀，负载平衡。</p><p>最后，代码的路径应该是：</p><p><strong>Input —-&gt; Map —-&gt; shuffle —-&gt; reduce &gt; output</strong>  </p><p>操作都以行为单位，都是以标准的键值对形式实施！map与reduce之间可以（且必要）加入排序，这个过程需要硬盘，或者需要很大内存的机器，读写频繁。</p><p>MapReduce可以拆分开来，只有map，没有reduce。</p><p>数据清洗时，这个很重要。只需要拆分，不需要合并。化整为零，所有资源就能一起打工（bushi）！</p><p>也可以很多mapper很多reduce，拆分成很多份，但每一份都一定有键值对应关系。也可以很多mapper，但只使用<strong>一个</strong>reduce，此时reduce任务不重，可以在这里合并。</p><p>（未完待续）</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;一、开始！今日信息量巨大&quot;&gt;&lt;a href=&quot;#一、开始！今日信息量巨大&quot; class=&quot;headerlink&quot; title=&quot;一、开始！今日信息量巨大&quot;&gt;&lt;/a&gt;一、开始！今日信息量巨大&lt;/h3&gt;&lt;p&gt;大佬们展示肌肉。&lt;/p&gt;
&lt;p&gt;回归部分还需要些数学根底。&lt;/p&gt;
&lt;p&gt;代码后面也有一丢丢正文。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>数据之学|交叉验证相关理论介绍</title>
    <link href="https://konelane.github.io/2020/10/13/201010CV/"/>
    <id>https://konelane.github.io/2020/10/13/201010CV/</id>
    <published>2020-10-12T16:00:00.000Z</published>
    <updated>2020-10-16T01:53:21.547Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="交叉验证相关理论介绍"><a href="#交叉验证相关理论介绍" class="headerlink" title="交叉验证相关理论介绍"></a>交叉验证相关理论介绍</h2><p>2020.10.13</p><h3 id="1-1-场景构建"><a href="#1-1-场景构建" class="headerlink" title="1.1 场景构建"></a>1.1 场景构建</h3><p>源禾同学和正阳同学在某次考试都考了100分，正阳同学实力强劲，学习踏实，掌握核心科技，考了100是实力的体现，因为卷子上只有100分。而源禾同学考100分，因为源禾使用了败者食尘，他课下做了这张卷子的所有题，背了题，考了100分是因为记性好。</p><p>谁才是老师喜爱的同学呢？</p><a id="more"></a><p>在对模型进行测试时，不可以照着“考卷”疯狂练习。尤其是在样本量小的时候，换一张卷子就会原形毕露。</p><p>那么不妨站在老师的角度想，如果题库只有这么多题，该怎么出题才能真正考察学生的实力呢？</p><h3 id="1-2-模型-算法的选择"><a href="#1-2-模型-算法的选择" class="headerlink" title="1.2 模型/算法的选择"></a>1.2 模型/算法的选择</h3><p>在建模时，可选用的模型很多，我们想选用何种模型，此时就需要对模型的<strong>“泛化误差”</strong>（generalization-error，指在独立测试样本上的期望预测误差，也称测试误差test-error或预测误差prediction-error）进行评估。</p><p>在实际建模中，很少能得到样本的精确分布，也无法直接计算泛化误差。基于训练样本得到的样本上平均损失的训练误差是它的一个直接估计，可训练误差会随着模型复杂度（光滑度，自由度）的增加而减小，直至减小到0。（训练均方误差 vs 测试均方误差）</p><p>如果训练均方误差很小但测试均方误差较大时，我们称该数据被过拟合。（模型开始背题了）</p><img src="/2020/10/13/201010CV/图1.png" title="图1"><blockquote><p>源禾：任何难处都可以靠增加数据量来解决。<br>（当然解决不了的除外）</p></blockquote><p>事实上，这里涉及到偏差方差权衡（bias-variance trade-off）的问题，如果一个统计模型被称为测试性能好，那么要去该模型具有较小的方差和较小的偏差。直觉上我们会选择有极小偏差可是有很大方差的方法（如画一条通过所有观测的曲线，下图的绿线）</p><img src="/2020/10/13/201010CV/图2.png" title="图2"><blockquote><p>源禾：虽然没有完美的模型，但是有完美模型的传说。</p></blockquote><p>为一个模型来选择何适的光滑度的过程即<strong>模型选择</strong>。这个问题在训练集较小时，被产生的过拟合现象加大了难度。</p><h3 id="1-3-出路-重抽样（resampling）"><a href="#1-3-出路-重抽样（resampling）" class="headerlink" title="1.3 出路 - 重抽样（resampling）"></a>1.3 出路 - 重抽样（resampling）</h3><p>应当找到一个方法解决过拟合，而唯一的限制是，没那么多数据。</p><p>于是人们想了个办法：让这个测试集来源于训练集。我反复从训练集中抽取样本，对每一个样本重新拟合一个模型，来获取关于拟合模型的附加信息。这就是<strong>重抽样</strong>方法。在拟合过程中，保留（holding out）训练观测的一个子集，然后对保留的观测运用统计学习方法，从而来估计其<strong>测试错误率</strong>（test error rate）。</p><img src="/2020/10/13/201010CV/图3.jpg" title="图3"><blockquote><p>源禾：预测集神圣不可侵犯。</p></blockquote><h3 id="2-1-验证集方法（validation-set-approach）"><a href="#2-1-验证集方法（validation-set-approach）" class="headerlink" title="2.1 验证集方法（validation set approach）"></a>2.1 验证集方法（validation set approach）</h3><p>首先随机地把观测集分成两部分：一个训练集（training set），一个验证集（validation set），或者叫保留集（hold-out set）。模型在训练集上拟合，然后用拟合的模型来预测验证集中观测的响应变量。最后得到的验证集错误率——通常用均方误差作为定量响应变量的误差度量——提供了对于测试错误率的一个估计。</p><p>附一个“上帝”的比例：70%的训练集，30%的测试集。</p><blockquote><p>验证集方法原理简单，易于执行，但它有两个潜在的<strong>缺陷</strong>：<br>1.测试错误率的验证法估计的波动很大，这取决于具体哪些观测被包括在训练集中，哪些观测被包括在验证集中。<br>2.在验证法中，只有一部分观测被用于拟合模型，由于被训练的观测越少，统计方法的表现越不好，意味着验证集错误率可能会<strong>高估</strong>在整个数据集上拟合模型的测试错误率。</p></blockquote><p>统计分析中通过多次重复试验来减小方差。</p><h3 id="2-2-留一交叉验证（leave-one-out-cross-validation）"><a href="#2-2-留一交叉验证（leave-one-out-cross-validation）" class="headerlink" title="2.2 留一交叉验证（leave-one-out cross-validation）"></a>2.2 留一交叉验证（leave-one-out cross-validation）</h3><p>留一交叉验证（LOOCV）与验证集方法很相似，但这种方法尝试解决验证集方法遗留的缺陷问题。</p><p>LOOCV将观测集分为两部分，但不同于把观测集分为两个大小相当的子集，留一交叉验证法将一个单独的观测$(x_1, y_1)$作为验证集，剩下的观测$\{(x_2, y_2),(x_3, y_3), … ,(x_n, y_n)\}$组成训练集。由于拟合中没有用到$(x_1, y_1)$，所以$MSE_1 = (y_1 - \hat{y_1})^2$ 提供了对于测试误差的一个渐进无偏估计。</p><p>能看出，由于$MSE_1$是基于一个单独的观测计算得出的，故具有很高的波动性。</p><p>重复上面计算$MSE_1$的步骤，计算出全部的$MSE_1, MSE_2, …, MSE_n$，对测试均方误差的LOOCV估计是这n个测试误差估计的均值：</p><script type="math/tex; mode=display">CV_{(n)} = \frac{1}{n} \sum^{n}_{i=1}MSE_i</script><p>相对于验证集方法，LOOCV方法更不容易高估测试错误率，也能彻底解决训练集和验证集分割时随机性导致的结果不同问题。</p><h3 id="2-3-K折交叉验证（K-fold-CV）"><a href="#2-3-K折交叉验证（K-fold-CV）" class="headerlink" title="2.3 K折交叉验证（K-fold CV）"></a>2.3 K折交叉验证（K-fold CV）</h3><p>k折交叉验证法是LOOCV的一个替代，这种方法将观测集随机地分成K个大小基本一致的组，或者说<strong>折（fold）</strong>。第一折作为验证集，然后在剩下的k-1折上拟合模型。均方误差$MSE_1$由保留的观测计算得出。</p><img src="/2020/10/13/201010CV/图4.png" title="图4"><p>重复这个步骤k次（注意一般k大于2），每一次把不同的观测组作为验证集（分组只是第一次分）。整个过程会得到k个测试误差的估计，$MSE_1, MSE_2, …, MSE_k$。k折CV估计由这些值求平均计算得到：</p><script type="math/tex; mode=display">CV_{(k)} = \frac{1}{k} \sum^{k}_{i=1}MSE_i</script><p>不难发现，<strong>k等于n时，LOOCV方法是k折交叉验证的一个特例</strong>。</p><p>k一般取5或10。不取n的原因果然还是因为<strong>好算啊</strong>。几乎对于任一种统计学习方法适用，都有更好的可行性。</p><blockquote><p>源禾：在计算简便和尽可能减少估计的波动面前，一个能“我全都要”的方法谁不喜欢呢？</p></blockquote><p>k折交叉验证的结果也会因观测分折的随机性产生一定波动。同时对$Err$估计时也会因训练集样本容量大小产生一定的高估。</p><img src="/2020/10/13/201010CV/图5.png" title="图5"><p>由上图可知，训练集在150+时，训练效果已经不再随着训练集样本量增加而增加。但训练集样本容量在0至50时，会明显低估$1-Err$。</p><h3 id="2-4-总结"><a href="#2-4-总结" class="headerlink" title="2.4 总结"></a>2.4 总结</h3><p>先画一张表在这：</p><div class="table-container"><table><thead><tr><th>方法</th><th>优点</th><th>缺点</th><th>计算复杂度</th></tr></thead><tbody><tr><td>验证集方法(validation set approach)</td><td>原理简单，易于执行</td><td>A.测试错误率的验证法估计的波动很大，与分组关系很大。B.验证集错误率可能会高估在整个数据集上拟合模型的测试错误率。</td><td>计算最简单，方便对比称一个<strong>计算单步</strong>（对数据进行多次重复划分时计算复杂度会相应高）</td></tr><tr><td>留一交叉验证法(Leave-one-out cross-validation)</td><td>A.偏差较小，不易高估错误率。训练模型最接近原始样本的分布。B.LOOCV方法能解决训练集和验证集分割的随机性。实验可复制。</td><td>A.模型需拟合n次，非常耗时。（<em>但是最小二乘法来拟合线性或多项式回归时只消耗一个计算单步</em>）B.方差较大。</td><td>除左栏提到的线性/多项式回归外，需要<strong>n个计算单步</strong>。大样本情况时，对于某些算法来说数据划分为n份也不可接受。svm和朴素贝叶斯分类器。</td></tr><tr><td>k折交叉验证(k-fold CV)</td><td>A.偏差问题不大,方差较小。有效避免过拟合和欠拟合情况发生。B.计算方便，计算开销小。</td><td>A.选择K折交叉验证的<strong>“K”</strong>时比较随机。B.会产生一定波动。偏差大小会随训练集样本容量变化而改变。</td><td><strong>k个计算单步</strong></td></tr></tbody></table></div><p>k折CV方法相对于LOOCV方法除了计算优势外，它对测试错误率的估计通常来说更加准确。</p><div class="table-container"><table><thead><tr><th></th><th>验证集方法</th><th>LOOCV方法</th><th>k折CV方法</th></tr></thead><tbody><tr><td>偏差角度</td><td>高估</td><td>近似无偏</td><td>中等程度偏差</td></tr><tr><td>方差角度</td><td></td><td>k&lt;n时方差大于k折CV方法</td><td>k&lt;n时方差小于LOOCV方法</td></tr></tbody></table></div><p>由上表可知，选择方法时，需要进行偏差-方差权衡。在选择k折CV的折数时，一般k=5或10使得测试错误率的估计不会有过大的偏差或方差。</p><h3 id="2-5-补充"><a href="#2-5-补充" class="headerlink" title="2.5 补充"></a>2.5 补充</h3><p>一、</p><p>之前提到交叉验证方法可以应用于多个场景，举个例子，交叉验证在分类器模型的应用：</p><p>其实只需要修改“泛化误差”为“损失函数”（$MSE$ to $Err$），比如k折CV错误率的形式：</p><script type="math/tex; mode=display">CV_{(k)} = \frac{1}{k} \sum^{k}_{i=1}Err_i</script><p>其中$Err_i = I(y_i \ne \hat{y_i}) $。LOOCV和验证集错误率也可类似定义。</p><p>二、</p><p>上文提到，在LOOCV方法中，最小二乘法来拟合线性或多项式回归时将只计算一次。</p><script type="math/tex; mode=display">CV_{(n)} = \frac{1}{n} \sum^{n}_{i=1}(\frac{y_i - \hat{y_i}}{1-h_i})^2</script><p>其中$\hat{y_i}$为用原始最小二乘拟合的第i个拟合值，$h_i$为杠杆统计量：</p><script type="math/tex; mode=display">h_i = \frac{1}{n} + \frac{(x_{i} - \bar{x})^2}{\sum^n_{i'}(x_{i'} - \bar{x})^2}</script><p>区别仅在于第i个残差除了一个系数$(1-h_i)$。杠杆值的大小在0到1之间，反映了一个观测对自己拟合值的影响大小。因此，该公式表明高杠杆值的残差根据它本身偏离数据的程度进行了等量的放大。</p><p>三、</p><p>若样本量非常小，非常非常小，我们还可以使用重抽样的另一种方法：<strong>自助法</strong>（bootstrap）。</p><p>比如我们有m个样本（m较小），每次在这m个样本中随机采集一个样本，放入训练集，采样完后把样本放回。这样重复采集m次，我们得到m个样本组成的训练集。当然，这m个样本中很有可能有<strong>重复</strong>的样本数据。同时，用原始的m个样本做测试集。这样接着进行交叉验证。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1]James G , Witten D , Hastie T , et al. An Introduction to Statistical Learning[M]. Springer New York, 2013.</p><p>[2]杨柳,王钰.泛化误差的各种交叉验证估计方法综述[J].计算机应用研究,2015,32(05):1287-1290+1297.</p><p>[3]范永东. 模型选择中的交叉验证方法综述[D].山西大学,2013.</p><p>[4]Hastie, Trevor J. The Elements of Statistical Learning[M]. 世界图书出版公司, 2015.</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;交叉验证相关理论介绍&quot;&gt;&lt;a href=&quot;#交叉验证相关理论介绍&quot; class=&quot;headerlink&quot; title=&quot;交叉验证相关理论介绍&quot;&gt;&lt;/a&gt;交叉验证相关理论介绍&lt;/h2&gt;&lt;p&gt;2020.10.13&lt;/p&gt;
&lt;h3 id=&quot;1-1-场景构建&quot;&gt;&lt;a href=&quot;#1-1-场景构建&quot; class=&quot;headerlink&quot; title=&quot;1.1 场景构建&quot;&gt;&lt;/a&gt;1.1 场景构建&lt;/h3&gt;&lt;p&gt;源禾同学和正阳同学在某次考试都考了100分，正阳同学实力强劲，学习踏实，掌握核心科技，考了100是实力的体现，因为卷子上只有100分。而源禾同学考100分，因为源禾使用了败者食尘，他课下做了这张卷子的所有题，背了题，考了100分是因为记性好。&lt;/p&gt;
&lt;p&gt;谁才是老师喜爱的同学呢？&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据分析" scheme="https://konelane.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>分布式1007-Map-Reduce的文字流</title>
    <link href="https://konelane.github.io/2020/10/07/201007hadoop/"/>
    <id>https://konelane.github.io/2020/10/07/201007hadoop/</id>
    <published>2020-10-06T16:00:00.000Z</published>
    <updated>2020-10-15T03:56:25.264Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最后编辑于：20.10.15</p><p>开门见山地来一段，就一段，不会有人这个都没搞懂吧，不会吧不会吧（拖走</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar \</span><br><span class="line"> $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.1.3.jar \</span><br><span class="line"> -input /user/devel/2020210995wangyuanhe/README.txt \</span><br><span class="line"> -output /user/devel/2020210995wangyuanhe/1007output \</span><br><span class="line"> -mapper &quot;/usr/bin/cat&quot; \</span><br><span class="line"> -reducer &quot;/usr/bin/wc&quot;</span><br></pre></td></tr></table></figure><p>开始前再插一句题外话，被强大而可爱的丰丰老师表（da）扬（shang）了，动力+10086，继续努力啊小禾禾！！</p><a id="more"></a><h2 id="分布式1007-Map-Reduce的文字流"><a href="#分布式1007-Map-Reduce的文字流" class="headerlink" title="分布式1007-Map-Reduce的文字流"></a>分布式1007-Map-Reduce的文字流</h2><h3 id="1-程序运行情况介绍"><a href="#1-程序运行情况介绍" class="headerlink" title="1.程序运行情况介绍"></a>1.程序运行情况介绍</h3><img src="/2020/10/07/201007hadoop/tu1.png" title="tu1"><p>这张运行图只是执行中间一部分，正常情况下无ERROR，map 100% reduce 100%（这里运行时看着最爽）。</p><img src="/2020/10/07/201007hadoop/tu2.png" title="tu2"><p>图2中第一行文件并无内容，后7个文件是本次运行开启的7个mapper的结果，reducer在这几个文件中运行，并把结果写入这7个文件中，所有的结果求和即真正结果。</p><p>下面看看运行的文件情况：</p><img src="/2020/10/07/201007hadoop/tu3.png" title="tu3"><img src="/2020/10/07/201007hadoop/tu4.png" title="tu4"><p>上图中，wc函数第一列的和就是16，即行数（验证正确），第二列为单词数（字符串连在一起算一个单词），第三列为字节数。</p><img src="/2020/10/07/201007hadoop/tu5.png" title="tu5"><p>单个mapper+单个reducer运行</p><blockquote><p>每次cat：<br>行数+1；单词+n；字节数+m</p></blockquote><p>服务器上有很多个mapper，本次有17个（见上图），每个程序都做了cat函数（打印），7个reducer一起运行wc（计算行数）。Hadoop jar 中有这样一个参数，num.tasks，控制任务的数量。</p><h3 id="2-运行的相关介绍"><a href="#2-运行的相关介绍" class="headerlink" title="2. 运行的相关介绍"></a>2. 运行的相关介绍</h3><p>reducer结束的很慢，原因是启动时要花资源，map过程非常快（程序运行时有体会）。听说均分文件时会用到哈希code，现在很多算法都是哈希函数的进阶，不知真伪，之后问问。</p><p>在传输中，隐含了打乱shuffle和整理sort的过程:  </p><script type="math/tex; mode=display">平摊</script><p>把数据随机打乱，$shuffle$，保证每个mapper接受的任务量相近。<br>打乱顺序的任务再排序，$sort$，使每个程序尽可能找到较近数据。  </p><p>由于，数据在HDFS上存储在分布式的硬盘上，必须主动从硬盘读到内存里，有I/O（input/output）的消耗。如果数据很多，读起来很慢。一般map很复杂，可能map的中间结果要写入硬盘，又产生I/O消耗，reduce也需要从硬盘中读取。</p><p>故HADOOP对<strong>硬件读写</strong>的要求很高，如此反过来也节约了内存资源（贵）。真正制约hadoop的大多是硬盘读写，因此很多服务器用SSD，但是SSD很容易坏，故需要做冗余（防止硬件坏掉）。</p><p>apply函数，groupby函数，都有map的感觉</p><h3 id="3-Hadoop-与-Spark"><a href="#3-Hadoop-与-Spark" class="headerlink" title="3. Hadoop 与 Spark"></a>3. Hadoop 与 Spark</h3><p>hadoop擅长进行批处理，但不能进行实时计算（比如无人驾驶）、股票高频交易（短时间的计算），这种实时运算需要使数据保持“热状态”不存入硬盘，在map-reduce后立刻传出，与硬盘无关。</p><p>hadoop不擅长，但是spark擅长。spark写入硬盘的操作很有限，因此速度快。当然，上文也提到了，内存比硬盘贵，所以hadoop更廉价，两个框架各有胜负。</p><p>同时，hadoop不能实现迭代计算（牛顿迭代，神经网络，梯度下降，反向传播），几乎涵盖所有机器学习算法。迭代时需要大量循环，不能经常读写硬盘。</p><h3 id="4-标准输入输出-STDin-amp-STDout"><a href="#4-标准输入输出-STDin-amp-STDout" class="headerlink" title="4. 标准输入输出 STDin &amp; STDout"></a>4. 标准输入输出 STDin &amp; STDout</h3><p>在计算机编程中，有一类输入输出只与屏幕有关：</p><h4 id="Stdout"><a href="#Stdout" class="headerlink" title="Stdout"></a>Stdout</h4><p>任何程序结果总是需要保存，但有一类输出直接打印在屏幕上。凡是能打印的都是stdout。举些例子：print函数(r,python)，cat函数(r,linux)，printf函数(c)等等等等。基本全部语言都能标准输出。</p><h4 id="Stdin"><a href="#Stdin" class="headerlink" title="Stdin"></a>Stdin</h4><p>计算机能够接受打印的“文字流”（这也是hadoop streaming中streaming的含义！），举些例子：如linux和r的管道函数，python里open函数，都是打开文件把每一行读进来。</p><p>linux中很方便地组织你的文件，只要文件是文本文件，都可以用管道<strong>“吸入”</strong>。很多linux的函数都以cat开头（猫猫头）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat txt | python wc.py 单机实验</span><br></pre></td></tr></table></figure><p>再用R语言举个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sink(&quot;想保存的文件名.txt&quot;,append = T, splt = T)</span><br><span class="line">abc = c(rnorm(100))</span><br><span class="line">abc</span><br><span class="line">sink()</span><br></pre></td></tr></table></figure><p>写进hdfs就是另外一幅模样了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#! /usr/bin/env Rscript</span><br><span class="line">options(warn=-1)</span><br><span class="line">sink(&quot;/dev/null&quot;)</span><br><span class="line"></span><br><span class="line">input &lt;- file(&quot;stdin&quot;, &quot;r&quot;) # 用input 吸入来自linux的STDin</span><br><span class="line">while(length(currentLine &lt;- readLines(input, n=1, warn=FALSE)) &gt; 0)</span><br><span class="line">&#123;</span><br><span class="line">    fields &lt;- unlist(strsplit(currentLine, &quot;,&quot;))</span><br><span class="line">    lowHigh &lt;- c(as.double(fields[3]), as.double(fields[6]))</span><br><span class="line">    stock_mean &lt;- mean(lowHigh)</span><br><span class="line">    sink()</span><br><span class="line">    cat(fields[1], fields[2], stock_mean, &quot;\n&quot;, sep=&quot;\t&quot;)</span><br><span class="line">    sink(&quot;/dev/null&quot;) # dev/null是linux的黑洞目录，扔进去就会消失呢！</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">close(input)</span><br></pre></td></tr></table></figure><p>运行时在linux中用rscript：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Rscript test.r</span><br></pre></td></tr></table></figure></p><p>其实做开发时，java语言很好用（类操作，大型项目架构，内存管理），适合创建非常巨大的项目，运行很久不停止，其他语言不行。hadoop也是java编成。但java并非所有人都会，hadoop面向数据处理，会java的人不多。</p><p>由此，先辈们做了个<strong>能让各种语言都能识别</strong>的框架：</p><p>hadoop做了很好玩的模块：streaming（标准输入输出的“文本流”）。提供了简单的接口，c，py，java，r……但凡能接受标准输入输出，就可以调用！使得map函数和reduce函数完全脱离了hadoop，只需要输入输出就能得到结果，影响速度的只有map和reduce的写法。</p><blockquote><p>Hadoop不是编程语言，是分布式计算架构。<br>    ——李丰老师</p></blockquote><h3 id="5-我们的函数，部署！"><a href="#5-我们的函数，部署！" class="headerlink" title="5. 我们的函数，部署！"></a>5. 我们的函数，部署！</h3><p><strong>教练，我也想调用hadoop接口跑我自己的程序！</strong></p><p>完全没问题！</p><p>很简单，首先要保证每个存储数据的节点上（worker节点）必须有函数cat、wc，我们自己写一个wchehe.py，然后放上服务器去就好啦。</p><p>如下，就是一个简单的读取行数的py程序，第一行一定要注明函数应该怎么找到运行的地方：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#! /usr/bin/env python3</span><br><span class="line">import sys</span><br><span class="line">linecount=0</span><br><span class="line">data = []</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">linecount += 1</span><br><span class="line">data.append(line)</span><br><span class="line">Print(linecount)</span><br></pre></td></tr></table></figure><p>可以用chmod +x wchehe.py 改一下运行权限。</p><p>下来，为了规范代码格式，我们用一个shell批处理文件作为我们的程序入口，也方便调整参数。</p><p>开头别忘了告诉sh函数这是个批处理。<em>看到这篇文章的同学不要用原代码直接跑啊（</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#! /usr/bin/bash</span><br><span class="line"></span><br><span class="line">PWD=$(cd $(dirname $0); pwd)</span><br><span class="line">cd $PWD</span><br><span class="line"></span><br><span class="line">HADOOP_inputdir=/user/devel/2020210995wangyuanhe/ordertxtfiles/test-edit.txt</span><br><span class="line">HADOOP_outputdir=/user/devel/2020210995wangyuanhe/output/1007out01</span><br><span class="line">HADOOP_home=/share/hadoop/tools/lib/hadoop-straming-3.1.3.jar</span><br><span class="line"></span><br><span class="line">echo $HADOOP_home</span><br><span class="line">echo $HADOOP_inputdir</span><br><span class="line">echo $HADOOP_outputdir</span><br><span class="line"></span><br><span class="line">hadoop fs -rm -r $HADOOP_outputdir</span><br><span class="line"></span><br><span class="line">hadoop jar \</span><br><span class="line"> $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.1.3.jar \</span><br><span class="line"> -files $PWD/wchehe.py \</span><br><span class="line"> -input $&#123;HADOOP_inputdir&#125; \</span><br><span class="line"> -output $&#123;HADOOP_outputdir&#125; \</span><br><span class="line"> -mapper &quot;/usr/bin/cat&quot; \</span><br><span class="line"> -reducer &quot;python wchehe.py&quot;</span><br></pre></td></tr></table></figure><p>-jobconf 被替代为-D，-file 被替换成 -files</p><p>附上本次课程老师的<a href="https://github.com/feng-li/Distributed-Statistical-Computing/tree/master/L02-MapReduce" target="_blank" rel="noopener">代码和讲义</a>，我还得好好研究一下，收获满满的一节课（虽然有点怀疑人生哈哈哈</p><p>附作业中可能用到的hadoop jar<a href="http://www.voidcn.com/article/p-nyinxrro-cn.html" target="_blank" rel="noopener">参数介绍</a>，hadoop fs <a href="https://www.cnblogs.com/zwgblog/p/6005061.html" target="_blank" rel="noopener">参数介绍</a></p><img src="/2020/10/07/201007hadoop/tu6.png" title="tu6"><p>（完）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最后编辑于：20.10.15&lt;/p&gt;
&lt;p&gt;开门见山地来一段，就一段，不会有人这个都没搞懂吧，不会吧不会吧（拖走&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;hadoop jar \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.1.3.jar \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; -input /user/devel/2020210995wangyuanhe/README.txt \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; -output /user/devel/2020210995wangyuanhe/1007output \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; -mapper &amp;quot;/usr/bin/cat&amp;quot; \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; -reducer &amp;quot;/usr/bin/wc&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;开始前再插一句题外话，被强大而可爱的丰丰老师表（da）扬（shang）了，动力+10086，继续努力啊小禾禾！！&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式0924-分布式服务器基础Linux中主机的远程交互(ssh)</title>
    <link href="https://konelane.github.io/2020/09/24/200924hadoop/"/>
    <id>https://konelane.github.io/2020/09/24/200924hadoop/</id>
    <published>2020-09-23T16:00:00.000Z</published>
    <updated>2020-09-25T08:57:43.824Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="大数据分布式计算-0924"><a href="#大数据分布式计算-0924" class="headerlink" title="大数据分布式计算 0924"></a>大数据分布式计算 0924</h2><p>本次课程以上次思考题入手：</p><blockquote><p>并行计算与分布式计算的区别？</p></blockquote><a id="more"></a><p>并行计算是一台计算机使用自身共享的内存和算力，用CPU的多核特点进行并行处理。</p><p>分布式计算是利用服务器的高算力，从远程交互终端中向服务器部署代码进行计算。</p><p>我的理解还是太片面，下面看看李丰老师的想法：</p><p>并行计算（parallel computing）是一个通常用于高性能计算（HPC）领域的术语。它具体指的是使用 多个处理器执行计算或模拟。超级计算机是为执行并行计算而设计的。这些系统不一定有共享内存。并 行系统使用MPI这样的工具将在超级计算机或者集群机器上的计算资源调度并实现多任务的同步计算。 并行计算在许多计算软件中都集成了一些基本的实现途径。比如R中的自带parallel包，Python标准 库中的multiprocessing是一个用与 threading 模块相似API的支持产生进程的包。这些程序模块允 许程序员充分利用机器上的多个核心。Unix 和 Windows 上都可以运行。结合OpenMP（Open Multi-Processing）等支持跨平台共享内存方式的多线程并发的编程API，使用现有编程语言可以在大 多数的处理器体系和操作系统中运行并行计算任务。具有并行计算能力的高性能计算平台往往被应用在 很多特定的科学领域，如超级计算机，密码破译，生物医学。</p><p>分布式计算（distributed computing）实际上是一个比并行计算更笼统的术语。人们可以将分布式计 算与并行计算的意义等同于并行计算，分布式特指的是将计算分布在许多不同的计算机之间。然而，分 布式计算处理的是并发性以外的其他方面。分布式计算具有并行计算所不具有的一些特性，包括计算一 致性、计算高可用性和高容错性能等。此外现在分布式计算平台的计算成本更低。像本书涉及到的 Hadoop或Spark这样的系统都是分布式计算系统，它们都有处理节点和网络故障的能力。不过，这两种 系统也都是为了执行并行计算而设计的。与MPI等HPC系统不同，这类新型系统即使其中一个计算节点出 现故障，也能继续进行海量计算。分布式计算主要应用在数据科学领域，如互联网、物联网、车联网、 数字金融。</p><p>在现代数据科学浪潮的冲击下，利用低成本硬件实现大规模分布式计算成为大数据应用的主流方向。世 界上各大数据科学公司都把分布式计算作为数据科学的核心技术与产品。最为大家熟知的有如亚马逊、 阿里巴巴各大云平台。在数据科学的应用中催生了大量分布式计算的优秀工具，如Hadoop, HDFS, Hive, Spark, Storm。</p><h2 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h2><p>分布式中，有不同的框架：</p><p>资源调度器（分布式文件系统HDFS） + 资源管理器（管理计算机资源哪一部分做什么，YARN） + 管理框架（zookeeper &amp; AMBARI）</p><p>不同的领域侧重的框架也不同。</p><blockquote><p>电商 - spark（计算）<br>图片处理 - Hadoop<br>存储数据财富 - hive<br>……</p></blockquote><h2 id="大数据分布式的特性"><a href="#大数据分布式的特性" class="headerlink" title="大数据分布式的特性"></a>大数据分布式的特性</h2><p>分布式服务器一般由很多同质的软件和硬件构成。</p><p>服务器为<strong>“刀片式服务器”</strong>（不同于塔式服务器），每一个计算节点都是一个刀片，通过网络连接，非核心的节点损坏不影响整体。可以在计算资源空闲时慢慢修复。</p><p>masternode<br>|——- workernode1…<br>|——- workernode2…<br>|——- workernode3…  </p><p>HDFS以来的两种逻辑组件，一个是起索引作用的namenode，一个是起存储作用的DataNode。二者数量和位置取决于worker节点的数量：worker很多时，要单独做成服务器，因为他们对算力要求很高；很少时可以置于masternode中。</p><p>优点：用廉价的硬件达到较高的存储性能。</p><p>缺点：随机存储，故不擅于做随机文件的搜索（会消耗大量算力查找索引），大文件被分成小份，存在不同的datanode中。</p><blockquote><p>根据文件大小切割为相似大小的block：<br>$/tmp/test.txt $<br>|——- blocka<br>|——- blockb</p></blockquote><p>&gt;<br>blocka<br>|——- datanode2<br>|——- datanode1<br>blockb<br>|——- datanode1<br>|——- datanode3  </p><p>注意到，DataNode1被复制了两份，这在分布式服务器中是很常见的。DataNode之间会根据是否空闲以及是否存储了相关数据而进行并行处理。只要namenode在，哪怕一块硬盘坏了，也能恢复。</p><h2 id="MapReduce组件"><a href="#MapReduce组件" class="headerlink" title="MapReduce组件"></a>MapReduce组件</h2><p>位置：Hadoop中</p><p>作用：处理大量数据，能用forloop处理的，可以通过分布式发给程序，代码对象应当各自独立。</p><p>对服务器？的I-O性能要求较高（input-output）</p><p>老师提示：分布式程序中应有容错空间（未领会，无经历）</p><p>分布式的MapReduce如下：</p><blockquote><p>JobTracker<br>|——- tasktracker1<br>|——- tasktracker2  （注意，ttk1和ttk2之间也互相连通）<br>ttk中容纳的是M-R两步的多个子程序  </p><p>activeJobs(位置JobTracker)：<br>joba<br>|——- map task1<br>|——- map task2<br>jobb<br>|——- reduce task1<br>|——- reduce task2  </p></blockquote><h2 id="服务器讲解"><a href="#服务器讲解" class="headerlink" title="服务器讲解"></a>服务器讲解</h2><p>远程操作终端：putty</p><p>账号密码和ip就略了（逃</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mkdir</span><br><span class="line">cd</span><br><span class="line">ls</span><br><span class="line">rm -rf /user/students</span><br><span class="line">touch lifeng.txt</span><br><span class="line">vim lifeng.txt</span><br><span class="line">emacs lifeng.txt</span><br><span class="line">cat lifeng.txt</span><br><span class="line"></span><br><span class="line">hadoop fs -ls /</span><br><span class="line">hadoop fs -put lifeng.txt /user/test </span><br><span class="line">hadoop fs -cat /user/test/lifeng.txt</span><br><span class="line">hadoop fs -get /user/test/lifeng.txt lifeng2.txt</span><br><span class="line">hadoop fs -ls /test &gt; hadoop-ls-return.txt</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;大数据分布式计算-0924&quot;&gt;&lt;a href=&quot;#大数据分布式计算-0924&quot; class=&quot;headerlink&quot; title=&quot;大数据分布式计算 0924&quot;&gt;&lt;/a&gt;大数据分布式计算 0924&lt;/h2&gt;&lt;p&gt;本次课程以上次思考题入手：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;并行计算与分布式计算的区别？&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式0917-遍历检索的多进程初试水</title>
    <link href="https://konelane.github.io/2020/09/17/200917hadoop/"/>
    <id>https://konelane.github.io/2020/09/17/200917hadoop/</id>
    <published>2020-09-16T16:00:00.000Z</published>
    <updated>2021-01-04T07:07:33.930Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="大数据分布式计算-0917"><a href="#大数据分布式计算-0917" class="headerlink" title="大数据分布式计算 0917"></a>大数据分布式计算 0917</h2><p>本次课程内容讲述的几个注意的有意思的东西：</p><h3 id="分布式是什么"><a href="#分布式是什么" class="headerlink" title="分布式是什么"></a>分布式是什么</h3><p>“数据向代码跑” / “代码向数据跑”</p><p>原本的流程：<script type="math/tex">数据 -> cpu(code) -> answer</script></p><p>新流程：<script type="math/tex">cpu -> 数据 <- cpu</script></p><p>俗话说：双拳难敌四手嘛。</p><a id="more"></a><h3 id="多进程-并非-多线程"><a href="#多进程-并非-多线程" class="headerlink" title="多进程 并非 多线程"></a>多进程 并非 多线程</h3><p>多进程即开很多程序，多线程是多路并行。</p><h3 id="map-reduce原理"><a href="#map-reduce原理" class="headerlink" title="map-reduce原理"></a>map-reduce原理</h3><blockquote><p>1+3+5+7+9+11+13+15+17<br>map<br>(1+3+5) + (7+9+11) + (13+15+17)<br>reduce<br>9 + 27+ 45<br>answer</p></blockquote><p>常用的框架已经封装了分布式运算的计算法，用户只写需求的逻辑，由此产生了MapReduce的框架和Yarn，并不做运算。</p><p>因为专门的“计算引擎”（基于计算系统）Hadoop，HDFS储存，spark（生于伯克利，号称分布式平台中流砥柱）</p><p>学习目标：非常熟悉，能够把自己写的东西放上去，不写，要会用。</p><h3 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h3><p>请用R或者Python自带的并行计算模块实现一个简单的单机文件查找代码，并与串行代码在效率上做比较。思考分布式与并行计算的区别。</p><p>我的答案，由于特殊需求无意义地加长了很多。同时就当初学python的任务驱动练习了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># coding:utf-8</span><br><span class="line"># 分布式计算1-多进程对比检索代码</span><br><span class="line">import os</span><br><span class="line">import time</span><br><span class="line">import multiprocessing as mp</span><br><span class="line">from time import sleep</span><br><span class="line"></span><br><span class="line">def get_all_file(path):</span><br><span class="line">    res = []</span><br><span class="line">    for root, dirs, files in os.walk(path):</span><br><span class="line">        for file in files:</span><br><span class="line">            res.append(os.path.join(root, file))</span><br><span class="line">    return (res)</span><br><span class="line"></span><br><span class="line">def checkdir(dir):</span><br><span class="line">    file = dir.split(&apos;\\&apos;)[-1]</span><br><span class="line">    (filename, extension) = os.path.splitext(file)</span><br><span class="line">    if (extension == &apos;.txt&apos;) and (&apos;win&apos; in filename):  # 检验文件后缀与事先设置的关键字</span><br><span class="line">        sleep(1)</span><br><span class="line">        return (dir)</span><br><span class="line"># 上一版作业是猜测，不过本次提交版本根据一段未写在作业中的代码可以得知，要把循环从函数剔除，非遍历的部分才能使用迭代加速</span><br><span class="line"># 同时为了实现更直观的对比，而不是对简单函数进行多进程（有时甚至会起反效果），加入了sleep函数</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # 设定参数</span><br><span class="line">    path0 = &quot;D:\\&quot;   # 设置一个路径，目标是这个路径下全部带有关键字‘win’的文本文档</span><br><span class="line"></span><br><span class="line">    # 顺序执行部分</span><br><span class="line">    print(&apos;顺序执行：&apos;)</span><br><span class="line">    start1 = time.time()</span><br><span class="line">    pathall2 = get_all_file(path0)</span><br><span class="line">    result = []</span><br><span class="line">    for path in pathall2:</span><br><span class="line">        result.append(checkdir(path))</span><br><span class="line">    for res2 in result:</span><br><span class="line">        if res2 != None:  # 为了对比效果，特意使用了和多进程代码相同的函数，徒增复杂度</span><br><span class="line">            print(res2)</span><br><span class="line">    end1 = time.time()</span><br><span class="line">    yongshi1 = end1 - start1</span><br><span class="line">    print(&quot;顺序耗时：%s&quot; % yongshi1)</span><br><span class="line">    print(&apos;==&apos;*20)</span><br><span class="line">    # 多进程执行部分</span><br><span class="line">    print(&quot;多进程执行:&quot;)</span><br><span class="line">    start2 = time.time()</span><br><span class="line">    pool = mp.Pool(4) # 设置4个进程同时运行，不过感觉没有必要，空缺时会根据系统设置最佳参数</span><br><span class="line">    pathall1 = pool.apply_async(get_all_file,args=(path0,)).get()</span><br><span class="line">    # 上一行根据结果来看，没有起作用，即for循环不能被多进程加速，必须按部就班</span><br><span class="line">    results1 = pool.map(checkdir, pathall1) # 此处pathall一定是一个可迭代变量(iter)</span><br><span class="line">    pool.close() #关闭池子，不能再加入进程</span><br><span class="line">    pool.join() # 等待进程结束</span><br><span class="line">    for res1 in results1:</span><br><span class="line">        if res1 != None:</span><br><span class="line">            print(res1)</span><br><span class="line">    end2 = time.time()</span><br><span class="line">    yongshi2 = end2 - start2</span><br><span class="line">    print(&quot;多进程耗时：%s&quot; % yongshi2)</span><br><span class="line"></span><br><span class="line"># 总结：其实本程序慢在os.walk()遍历文件，对后续&lt;比对筛选打印&gt;函数调用多进程反而可能降速</span><br><span class="line"># 核心函数只有pool四行，以及调用os.walk函数</span><br></pre></td></tr></table></figure><p>多进程也不见得很好用嘛，甚至不经过特意等待，比顺序运行还慢，哈哈。</p><p>（请多指教，完）</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;大数据分布式计算-0917&quot;&gt;&lt;a href=&quot;#大数据分布式计算-0917&quot; class=&quot;headerlink&quot; title=&quot;大数据分布式计算 0917&quot;&gt;&lt;/a&gt;大数据分布式计算 0917&lt;/h2&gt;&lt;p&gt;本次课程内容讲述的几个注意的有意思的东西：&lt;/p&gt;
&lt;h3 id=&quot;分布式是什么&quot;&gt;&lt;a href=&quot;#分布式是什么&quot; class=&quot;headerlink&quot; title=&quot;分布式是什么&quot;&gt;&lt;/a&gt;分布式是什么&lt;/h3&gt;&lt;p&gt;“数据向代码跑” / “代码向数据跑”&lt;/p&gt;
&lt;p&gt;原本的流程：&lt;script type=&quot;math/tex&quot;&gt;数据 -&gt; cpu(code) -&gt; answer&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;新流程：&lt;script type=&quot;math/tex&quot;&gt;cpu -&gt; 数据 &lt;- cpu&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;俗话说：双拳难敌四手嘛。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>遍历山河|贵州</title>
    <link href="https://konelane.github.io/2020/09/15/200915%E8%B4%B5%E5%B7%9E%E4%B9%8B%E8%A1%8C/"/>
    <id>https://konelane.github.io/2020/09/15/200915%E8%B4%B5%E5%B7%9E%E4%B9%8B%E8%A1%8C/</id>
    <published>2020-09-14T16:00:00.000Z</published>
    <updated>2020-09-16T13:02:00.926Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>第一次坐飞机。</p><p>夜航|氦核20.07.06</p><blockquote><p>芸芸灯火糅中盘，一子冲天战正酣。<br>班师星中我非客，翼稍挂月天外山。<br>明灯未知夜深浅，颠簸可猜云浓淡。<br>远电殷霞威颜厉，破雾勒马便坦然。</p></blockquote><a id="more"></a><h2 id="7日"><a href="#7日" class="headerlink" title="7日"></a>7日</h2><p>行程开始得急，昨夜飞机才至，今天清晨就踏上旅程。</p><p>第一次坐飞机的感觉很是神奇，以前总为自己在新时代还没能坐上飞机而感慨，全家也仅仅我一人没有乘坐过飞机出行。飞机这种交通工具于我总有某种遥不可及的神秘感，我也喜欢在文中用“飞”的意象，现在又少了一份能够为家人和我津津乐道的立场。飞机起飞时的加速让我猝不及防，高度变化时我也头晕目眩，甚至会因为身下无依无凭而突然感到害怕，但我依然震撼于夜航所见地面的万家灯火，震撼于穿云破雾时的一往无前，飞在天上的我觉得自己从星星中来，像极了将要下凡的天官。因为刚刚过十五，皎洁而饱满的月亮透过稀薄的云层高悬在机翼远端，注视着祝福着一飞机的旅人。如此种种感情纠缠在一起，甚至落地许久后也没能平复。</p><p>今天去了小七孔景区，一开始不明所以，后来才知是道光年间修起的七孔石桥，横跨响水河，天然去雕饰。这里的水泛着奇妙的青绿色，又不似别处清澈，更像翡翠和玉石，也带点“油”的感觉。水动处成涓流，水死处成碧潭，水高地飞落作瀑布，恰如一语“寒烟翠波”所言。飞瀑从山而下，如银龙攀附，面露凶光，口中喑嘶。</p><p>其实也没能仔细转完，走走停停拍照歇脚，转过卧龙潭，翠谷瀑布，石上森林，断桥飞瀑，再到拉雅瀑布，最后就见到小七孔了。小七孔没有介绍中那样“天然”，但经过了前面聒噪澎湃的飞瀑激流，此处的她更像无声胜有声，前面的澎湃被跋涉消磨将尽，到此这座饱经风雨的石桥张开怀抱，迎接这碧波末路，汇入大江。站在铜鼓桥上，面对滚滚江水，习习微风，我一时语塞，我消磨过的人事物太多太纷繁，也太匆匆，最终留下的还有什么呢？我总是不察得失，不知悔改。子在川上曰，逝者如斯夫。今日偶然得宽余，才能一览千山万水，于自然中体察得失。</p><p>其实旅行团也罢，自驾游也罢，但凡是省内打转的，免不了赶路的时间。今天在大巴车上度过了许久的时间，两小时才能换来二十分钟的放松，我们便会如囚鸟出笼，蜂拥而出。旅游分两种，一种看人文，另一种读山水，我这次出行，大抵属于第二种。可贵州山多，一山放过一山拦，眼前满溢的山光水色还是容易腻，此时我就不自觉地开始寻觅风景背后的些许生活与人味。</p><p>夜幕来临，我们总算赶到了千户苗寨。按理来说白天可以看这里勾心斗角的苗族建筑，但夜幕锁上了大部分文化。此处充满商业化的臭味，但总还是值得一看，十余座村寨合成的大寨灯火星点，我们趁着夜色还有时间登上山顶，眼前灯火宛如一盘迷局，十分壮观。</p><p>苗族竟是蚩尤氏部落后裔，也颇有来头，还有些奇妙的传说，诸如中元节的传说，苗药的神奇，以及用少女初潮制作的情蛊等等，都令我耳目一新，我还寻思着大概很多人今生盖也无机会制作情蛊，这番思索让我不得不感慨自己总是在这种稍显变态的地方好奇拉满。</p><p>不过，本地妹子也确实好看，尤其话语间轻柔的发音习惯让我听来很是舒服，我的语气也不禁缓和下来。当地人更是无比好客。虽然一路上扰我乱我的破烦事多，但听两首苗族祝酒歌，看一番高山流水情长酒，再多烦恼也便抛之脑后了。我还破例喝了几口米酒，或许有些醉，可他们说我没醉，我便也不知道我醉没醉了。</p><h2 id="8日"><a href="#8日" class="headerlink" title="8日"></a>8日</h2><p>旅行也总是混杂着一些愉快和不愉快，我们愉快了，导游不一定愉快，反之亦然。这世界不能人人都舒坦，你舒坦时总有人不舒坦。</p><p>其实来之前我以为的旅游，行到水穷处，坐看云起时，举匏樽以相属，寄蜉蝣于天地，渺沧海之一粟。结果现实的旅游团给了我对贪婪更加深刻的认识，早饭是永远不变的鸡蛋馒头咸菜条，午饭好一些，一桌添一口炖菜火锅，几道油盐意难平的家常菜，真不如家里吃的好。导游于是鼓吹苗族长寿皆源于口味清淡的饮食，我也无语。</p><p>今天驱车前往一处闻所未闻的非遗博物馆，前几层倒是货真价实的苗族文化，服饰，用品，家装，都有模有样。苗族的银饰着实多种多样，玩出了花，但同时作为民族争斗中的败者，他们也只能在此一些无关紧要的地方花心思。其余银品相关的奇怪传言，但凡是受过高中教育的，都会一笑了之。</p><p>可是闹剧才刚刚开始，来到最后的展厅，讲解做了个墨水变色的实验，银碗甚至能改变水质的酸碱性，又大肆宣扬银离子杀菌作用高强，紧接着带着全团走进了远超博物馆规格的银饰品商城。虽然讲解那番反智言论令一个“醒来”的人不适，但我也不想做断人财路的傻事，顺其自然才是此时的最优解。但独善其身者又何止我，饭后上车，导游问大家在有多少消费，结果自然是寥寥无几，直接导致导游对后面的景点毫无讲解的兴致，放任全车人无知中来无知中去了。</p><p>好在所到之处是有名的军事重镇镇远，古镇青石板长街，烟雨中行人稀疏，尽管留下的游览时间并不充裕，但节奏依然很慢很舒服。我们踏入古镇侧面的巷子，迈进一座座飞檐叠廊，那即是当地人住的地方，墙上的有年头的方砖有些翻新痕迹，但也有部分破损了，爬满潮湿的青苔。在巷子深处一口井，井中投鱼防毒，我们看了一圈正要离去，恰巧碰见一位当地人拎着绳子和桶去汲水，我第一次见人井中打水，饶有兴致问了问，原来井边那条放绳子的凹痕是世世代代打水人磨出的，并非刻意为之。其实整个打水也没什么特别之处，第一次觉得景点和生活糅合在一起，生活即风景，如此自然天成。</p><p>镇远的舞阳河因为小雨变得稍显浑浊，这里人酒足饭饱便躺卧在河边长廊中纳凉，但其实这里找不到几个真正凉爽的地方，更多的是潮湿与闷热，行走时还好，站定就会收获停不下来的汗水。我在路边奶茶店买了一杯并不中意的奶茶，但是惊喜之处在于奶茶店中温柔的老板姐姐和两面贴满便利贴的许愿墙。老板姐姐自不必说，更值得称道的是许愿墙上纯真可爱的文字与愿望，有本地人有外地人，有成年人有小孩子，有痛苦和忧虑的祈祷，也有满心欢喜的纪念和憧憬。这一面许愿墙，并没有满满地写着人的欲望，更多的竟然是祝福和期待未来，我对贵州人风土人情也大概摸清一二了。</p><p>结束了旅程，又进入赶赴下一个地点的大巴车程。路上又开始寂寞，翻照片，看到烟雨半掩的古镇和青石板街，突然想念起一位朋友，可惜因为种种原因，我再无问候的立场了。晚上烤鱼也无味了，可能是我以前吃过家门口的麻辣重口烤鱼，对于眼前这条平淡的存在实在无感了吧。</p><h2 id="9日"><a href="#9日" class="headerlink" title="9日"></a>9日</h2><p>贵州省会贵阳名副其实，今早起来果不其然又浓云密布。昨晚住的酒店旁边有条小溪，酒店也起了个恰如其分的名字叫“栖溪”，然而店家倒是惬意了，住客则要忍受经久不息的激流声，以及山中那无比潮湿的空气，早上起来诸位无一不是困意十足，料想昨晚一定默念了百遍“逝者如斯”。</p><p>昨晚经同学极力推荐，我们去吃了贵州的烤鱼，这算是几日来吃的最好的一次，虽然价格贵了点，可相当有滋味，配上小米酒冰红茶，很受用。独特的江口烤小豆腐脆皮软心，外表冷漠，内心却还是狂热的。虽然早有人给我打过预防针，贵州食物辣度非凡，可是我只觉得贵州人对于酸更加钟爱。本地甚至有“三日无酸，腿打捞酸”的警世名言，仅看遍地开花的酸汤鱼店以及逢菜必放的西红柿，可见一斑。昨晚烤鱼中剩下不少余料，土豆黄瓜锅巴粉什么的，正好也调剂了每日清晨的咸菜馒头。</p><p>其实昨晚睡得地方是梵净山山脚，离旅游区不过五分钟路。若说是仙境倒是夸大了，但梵净山确实不同于我以往去的任何地方。时间所限，摆渡车缆车把我们送上半山腰，刚开始谁都没有意识到，当缆车上看到远山刺透云层，而我们的缆绳也向着虚无的朦胧中无限延伸时，才恍然大悟周身大雾是高山云雾。云雾比通常所见大雾更加细腻，肉眼可见的小水滴浮在空中，不一会眼镜就全花掉了。</p><p>这么介绍下去，恐怕这篇文章也像受了潮气一样无趣。这两天最喜欢的两句诗，一句是林则徐的“风雨冥冥极漏天”，一句是毛主席的“胜似闲庭信步”，两句深得我心。在爬山过程中，我做先锋，一路高歌猛进，森林栈道拾级而上，没料到台阶太密太紧凑，让人疲惫不堪。蘑菇石这里奇石林立，那些方砖似的巨石层叠而起，如天外来客，危险诡妙地搭在山顶。视觉上无比险峻易碎，可真实情况是这里的地质无比稳定，经久不变。蘑菇石甚至目睹沧海桑田，区区人类文明不足道也。</p><p>孤独的旅途中，我攀上峰顶，突然想拍张照，可是一时间找不到人。四周没有深渊巨谷，只有逼人窄道和沾衣的云露，伴着早早来此工作的僧侣和清洁工，我发了会呆，这里大概不属于我，我亦不属于这里。我想求神拜佛让我忘记烦恼，可我不能求“无求”，而烦恼大多生于所求。我怎么能用欲望来战胜欲望，用烦恼来解决烦恼呢？然而事实只能如此，所以佛门离我还是太远，真希望有一天我也能找到属于我的答案。不过神奇的是，今天山上寺院中两位僧人师父看了我许久，可是欲言又止，不知是我犯了禁忌还是面露凶光，大家都喜欢对我欲言又止，这可苦坏了我这个蠢人。</p><p>路上，天气突然转晴，那是从未见过的蓝天白云，然而转瞬即逝了。</p><h2 id="10日"><a href="#10日" class="headerlink" title="10日"></a>10日</h2><p>和父母出去，总不如自己一人出行更加完整，至少体验上看，不论是突然对某些问题发问，亦或是对拍照的执着，父母常常打断我游览的思路。如果说满状态的体验可以到达80分，那么父母主导的旅行最多50分。不过看在贵州山水的份上，这趟旅行还算没有失去灵魂。</p><p>今天早上仍然是无聊的购物环节，导游来之前大谈国学风水，还将迷信说成信仰，结果今早全都泡了汤，我们并没有领情。商场中宝石确实超出了我们的理解，在我看来毫无价值的石头，在偏僻无人烟的犄角旮旯这样一座藏宝宫里，竟然成倍地涨价，以至于完全消费不起。找到知情人了解了产业链，才知道这小小宝石养活了导游导购匠人还有批发商这么一群人，谁不想从中抽点东西分一杯羹呢？不过导购也十分尽职，至少她盯着我们走了一早上，甚至当我找不到同伴时，她会告诉我们此人所在。讲解与推销双管齐下，还专门挑出可能对我们口味的商品挨个询问，只可惜定价着实太高，都是些明摆着“谁买谁是大傻子”的东西，不然以导购之勤奋没有功劳也有苦劳，定能成功。</p><p>抛开购物不谈，今天的早中两顿饭都是极好的，四星酒店待遇真不同，早餐一改往日馒头咸菜，变成了多姿多彩的自助餐，一句诗来说“萧瑟秋风今又是，换了人间”，爸妈胃口大开，我还是量力而为。中午饭也不错，不再从头酸到脚，下饭者下饭，充饥者充饥，竟然各司其职起来，让我大快朵颐。</p><p>黄果树瀑布是好的。看完有诗为证：</p><blockquote><p>白龙破水自巍吟，骤雨穿林渐希音。<br>银河玉碎比拟俗，七进七出战袍轻。<br>散落人间星满镜，厮磨耳鬓石衔青。<br>闲庭信步岿然立，云露拌作落汤鸡。</p></blockquote><p>其实一路上感慨良多，但思来想去都是些和人相关的复杂情感，在大自然面前我仍然只能乖乖做个孩子，除了敬畏以外也不剩太多痴心妄想。这些年人造之景愈发多了，本来无甚可看，但经过修修造造总算能凑齐一个景点，总的来说还是没必要，整体质量下降了不少。黄果树瀑布是中国第一大瀑布，至少是我贫瘠的旅游生涯中所见的最大的瀑布了，适逢汛期，瀑布水大，看完后水汽沾衣浑身湿透，却连连大呼震撼爽快。</p><p>晚上在贵阳市里闲逛，碰巧天晴，看到了夜晚的蓝天。这里仗着地质稳定，飞楼百米接二连三，高楼林立。甲秀楼南明河夜景倒是普普通通，不过南门口粉面不错，尤其是谐音常旺的肠旺面，肠与血配上油炸小肉丁别有风味，深得我心。到隔壁叫了一碗玫瑰绿豆冰粉，做冰粉的小姐姐和我攀谈，在我将别之时推荐了一些好吃好玩，可以说非常遗憾了。</p><p>这两天接触的东西太多太杂，导致我在记忆中筛选得不是特别仔细，加上每天烦恼多多，操心多多，倍感时间飞逝，天色已晚，不再赘述了。</p><p>（完）</p><p>9月15日整理时记：旅行的最后一天没有记述，行程紧张3点才到家。其实白天也看了不少风景。旱溶洞和水溶洞，还有多彩贵州城，都挺有见闻，可惜淡忘了。触景生情，朋友说只有恰当的时机和恰当的人才能碰撞出无与伦比的绝美感情，我想确实是这样的。至少现在的意义和旅游时的意义全然不同了。我曾经是个猛男，现在又一次变回了二五仔，哈哈。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;第一次坐飞机。&lt;/p&gt;
&lt;p&gt;夜航|氦核20.07.06&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;芸芸灯火糅中盘，一子冲天战正酣。&lt;br&gt;班师星中我非客，翼稍挂月天外山。&lt;br&gt;明灯未知夜深浅，颠簸可猜云浓淡。&lt;br&gt;远电殷霞威颜厉，破雾勒马便坦然。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="文章" scheme="https://konelane.github.io/tags/%E6%96%87%E7%AB%A0/"/>
    
  </entry>
  
  <entry>
    <title>python联萌|pandas（国宝库</title>
    <link href="https://konelane.github.io/2020/02/06/200206pandaslearning/"/>
    <id>https://konelane.github.io/2020/02/06/200206pandaslearning/</id>
    <published>2020-02-05T16:00:00.000Z</published>
    <updated>2020-02-06T09:59:14.619Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最后编辑于：2020.02.06 18:00</p><h2 id="Pandas库"><a href="#Pandas库" class="headerlink" title="Pandas库"></a>Pandas库</h2><p>Pandas是基于NumPy 的一种工具，其出现是为了解决数据分析任务。（氦核：个人觉得更像是探索工具，没有模型，简单分析。）<br>Pandas吸纳了大量库和一些标准的数据模型，提供了高效操作大型数据集所需的工具。<br>Pandas中的函数和方法能够使我们快速便捷地处理数据。<br>它是使Python成为强大而高效的数据分析环境的重要因素之一。</p><p><a href="http://pandas.pydata.org/pandas-docs/stable/api.html" target="_blank" rel="noopener">http://pandas.pydata.org/pandas-docs/stable/api.html</a></p><p>本文参考<a href="https://www.windquant.com/" target="_blank" rel="noopener">万旷网教程</a>。</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先导入pandas库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><p>numpy详见上一篇文章。</p><h2 id="一、序列Series"><a href="#一、序列Series" class="headerlink" title="一、序列Series"></a>一、序列Series</h2><p>序列Series是一个一维数组结构，可以存入任一种Python数据类型(integers, strings, floating point numbers, Python objects, 等等)</p><p>序列Series由两部分构成，一个是index，另一个是对应的值，注意两者的长度必须一样。序列Series和数组array很类似，大多数numpy的函数都可以直接应用于序列Series</p><p>序列Series也像一个固定大小的字典dict，可以通过index来赋值或者取值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'通过数组来生成序列Series'</span>)</span><br><span class="line">s_array = np.random.randn(<span class="number">5</span>)</span><br><span class="line">s = pd.Series(s_array, index = [<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>,<span class="string">'e'</span>])</span><br><span class="line">s</span><br></pre></td></tr></table></figure><pre><code>通过数组来生成序列Seriesa   -0.298058b   -1.095748c    1.333607d    1.119917e    1.595123dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'通过字典来生成序列Series'</span>)</span><br><span class="line">s_dict= &#123;<span class="string">'a'</span>:<span class="number">11</span>,<span class="string">'b'</span>:<span class="number">1000</span>,<span class="string">'c'</span>:<span class="number">123213</span>,<span class="string">'d'</span>:<span class="number">-1000</span>&#125;</span><br><span class="line">s = pd.Series(s_dict)</span><br><span class="line">s</span><br></pre></td></tr></table></figure><pre><code>通过字典来生成序列Seriesa        11b      1000c    123213d     -1000dtype: int64</code></pre><p>我们取一段金融时间序列给大家做更具体的分析：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> WindPy <span class="keyword">import</span> *</span><br><span class="line">w.start()</span><br><span class="line"></span><br><span class="line">list1 = w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"close"</span>, <span class="string">"2018-06-28"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>)</span><br><span class="line">list1</span><br></pre></td></tr></table></figure><pre><code>Welcome to use Wind Quant API for Python (WindPy)!COPYRIGHT (C) 2017 WIND INFORMATION CO., LTD. ALL RIGHTS RESERVED.IN NO CIRCUMSTANCE SHALL WIND BE RESPONSIBLE FOR ANY DAMAGES OR LOSSES CAUSED BY USING WIND QUANT API FOR Python..ErrorCode=0.Codes=[000001.SZ].Fields=[CLOSE].Times=[20180628,20180629,20180702,20180703,20180704,20180705,20180706,20180709,20180710,20180711].Data=[[8.92,9.09,8.61,8.67,8.61,8.6,8.66,9.03,8.98,8.78]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将收盘价转为</span></span><br><span class="line">ss = pd.Series(list1.Data[<span class="number">0</span>], index = list1.Times)</span><br><span class="line">ss</span><br></pre></td></tr></table></figure><pre><code>2018-06-28    8.922018-06-29    9.092018-07-02    8.612018-07-03    8.672018-07-04    8.612018-07-05    8.602018-07-06    8.662018-07-09    9.032018-07-10    8.982018-07-11    8.78dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以通过index来查看序列Series中的元素</span></span><br><span class="line">print(<span class="string">'查看序列中index为：'</span>,ss.index)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看序列中index为a的元素：'</span>,ss[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><pre><code>查看序列中index为： Index([2018-06-28, 2018-06-29, 2018-07-02, 2018-07-03, 2018-07-04, 2018-07-05,       2018-07-06, 2018-07-09, 2018-07-10, 2018-07-11],      dtype=&#39;object&#39;)查看序列中index为a的元素： 8.92</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于index 可以修改序列s中的元素</span></span><br><span class="line">print(<span class="string">'原序列：\n'</span>,ss)</span><br><span class="line">print()</span><br><span class="line">ss[<span class="number">0</span>] = <span class="number">11.4</span></span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'修改后的序列：\n'</span>,ss)</span><br></pre></td></tr></table></figure><pre><code>原序列： 2018-06-28    8.922018-06-29    9.092018-07-02    8.612018-07-03    8.672018-07-04    8.612018-07-05    8.602018-07-06    8.662018-07-09    9.032018-07-10    8.982018-07-11    8.78dtype: float64修改后的序列：2018-06-28    11.402018-06-29     9.092018-07-02     8.612018-07-03     8.672018-07-04     8.612018-07-05     8.602018-07-06     8.662018-07-09     9.032018-07-10     8.982018-07-11     8.78dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ss1 = pd.Series(np.random.randn(<span class="number">10</span>))</span><br><span class="line">print(<span class="string">'原序列：\n'</span>,ss)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'新序列：\n'</span>,ss1)</span><br><span class="line">print()</span><br><span class="line"><span class="comment"># 大多数numpy的函数可以直接应用于 序列 Series</span></span><br><span class="line">print(<span class="string">'序列相加：\n'</span>,pd.Series(ss.values+ss1.values,index=ss.index))</span><br></pre></td></tr></table></figure><pre><code>原序列： 2018-06-28    11.402018-06-29     9.092018-07-02     8.612018-07-03     8.672018-07-04     8.612018-07-05     8.602018-07-06     8.662018-07-09     9.032018-07-10     8.982018-07-11     8.78dtype: float64新序列： 0   -0.9557001    0.3915612    0.0024353   -0.1316214   -0.7913215    0.8412646   -0.0580347   -0.4866778    0.7088759    1.841834dtype: float64序列相加： 2018-06-28    10.4443002018-06-29     9.4815612018-07-02     8.6124352018-07-03     8.5383792018-07-04     7.8186792018-07-05     9.4412642018-07-06     8.6019662018-07-09     8.5433232018-07-10     9.6888752018-07-11    10.621834dtype: float64</code></pre><h2 id="二、DataFrame"><a href="#二、DataFrame" class="headerlink" title="二、DataFrame"></a>二、DataFrame</h2><p>DataFrame是一个二维数组结构，可以存入任一种Python数据类型(integers, strings, floating point numbers, Python objects, 等等)。<br>DataFrame由<strong>三部分</strong>构成，一个是行索引index，一个是列名，另一个则是取值。</p><h3 id="2-1-DataFrame的生成"><a href="#2-1-DataFrame的生成" class="headerlink" title="2.1 DataFrame的生成"></a>2.1 DataFrame的生成</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'由字典来产生数据框'</span>)</span><br><span class="line">data = &#123;<span class="string">'state'</span>: [<span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Nevada'</span>, <span class="string">'Nevada'</span>],</span><br><span class="line">        <span class="string">'year'</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>],</span><br><span class="line">        <span class="string">'pop'</span>: [<span class="number">1.5</span>, <span class="number">1.7</span>, <span class="number">3.6</span>, <span class="number">2.4</span>, <span class="number">2.9</span>]&#125;</span><br><span class="line">frame = pd.DataFrame(data)</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><pre><code>由字典来产生数据框</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>1.7</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>Nevada</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'由列表来产生数据框'</span>)</span><br><span class="line">data = [[<span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Nevada'</span>, <span class="string">'Nevada'</span>],</span><br><span class="line">        [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>],</span><br><span class="line">        [<span class="number">1.5</span>, <span class="number">1.7</span>, <span class="number">3.6</span>, <span class="number">2.4</span>, <span class="number">2.9</span>]]</span><br><span class="line">frame = pd.DataFrame(data,index=[<span class="string">'state'</span>,<span class="string">'year'</span>,<span class="string">'pop'</span>]).T</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><pre><code>由列表来产生数据框</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>1.7</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>Nevada</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><h3 id="2-2-DataFrame的基本性质"><a href="#2-2-DataFrame的基本性质" class="headerlink" title="2.2 DataFrame的基本性质"></a>2.2 DataFrame的基本性质</h3><p>我们取一段金融时间序列给大家做更具体的分析：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">list2 = w.wsd(<span class="string">"000300.SH"</span>, <span class="string">"open,high,low,close"</span>, <span class="string">"2018-06-28"</span>, <span class="string">"2018-07-10"</span>, <span class="string">""</span>)</span><br><span class="line">list2</span><br></pre></td></tr></table></figure><pre><code>.ErrorCode=0.Codes=[000300.SH].Fields=[OPEN,HIGH,LOW,CLOSE].Times=[20180628,20180629,20180702,20180703,20180704,20180705,20180706,20180709,20180710].Data=[[3434.9441,3431.9619,3504.4571,3410.4767,3398.7788,3365.5547,3347.0624,3378.9056,3464.9064],[3477.0565,3512.3834,3506.8996,3422.0398,3418.3311,3398.4852,3396.2458,3459.3153,3474.1396],[3416.9476,3425.2159,3383.5006,3319.2889,3359.0861,3330.7113,3295.7296,3378.9056,3437.2706],[3423.5255,3510.9845,3407.9638,3409.2801,3363.7473,3342.4379,3365.1227,3459.1837,3467.5155]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(list2.Data,columns=list2.Times,index=list2.Fields)</span><br><span class="line">df = df.T</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>    </tr>  </thead>  <tbody>    <tr>      <td>2018-06-28</td>      <td>3434.9441</td>      <td>3477.0565</td>      <td>3416.9476</td>      <td>3423.5255</td>    </tr>    <tr>      <td>2018-06-29</td>      <td>3431.9619</td>      <td>3512.3834</td>      <td>3425.2159</td>      <td>3510.9845</td>    </tr>    <tr>      <td>2018-07-02</td>      <td>3504.4571</td>      <td>3506.8996</td>      <td>3383.5006</td>      <td>3407.9638</td>    </tr>    <tr>      <td>2018-07-03</td>      <td>3410.4767</td>      <td>3422.0398</td>      <td>3319.2889</td>      <td>3409.2801</td>    </tr>    <tr>      <td>2018-07-04</td>      <td>3398.7788</td>      <td>3418.3311</td>      <td>3359.0861</td>      <td>3363.7473</td>    </tr>    <tr>      <td>2018-07-05</td>      <td>3365.5547</td>      <td>3398.4852</td>      <td>3330.7113</td>      <td>3342.4379</td>    </tr>    <tr>      <td>2018-07-06</td>      <td>3347.0624</td>      <td>3396.2458</td>      <td>3295.7296</td>      <td>3365.1227</td>    </tr>    <tr>      <td>2018-07-09</td>      <td>3378.9056</td>      <td>3459.3153</td>      <td>3378.9056</td>      <td>3459.1837</td>    </tr>    <tr>      <td>2018-07-10</td>      <td>3464.9064</td>      <td>3474.1396</td>      <td>3437.2706</td>      <td>3467.5155</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'首先查看数据框的形状'</span>,df.shape)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看数据框的头部：'</span>)</span><br><span class="line">print(df.head()) </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看数据框的尾部：'</span>)</span><br><span class="line">print(df.tail())</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看数据框的索引index'</span>)</span><br><span class="line">print(df.index)</span><br></pre></td></tr></table></figure><pre><code>首先查看数据框的形状 (9, 4)查看数据框的头部：                 OPEN       HIGH        LOW      CLOSE2018-06-28  3434.9441  3477.0565  3416.9476  3423.52552018-06-29  3431.9619  3512.3834  3425.2159  3510.98452018-07-02  3504.4571  3506.8996  3383.5006  3407.96382018-07-03  3410.4767  3422.0398  3319.2889  3409.28012018-07-04  3398.7788  3418.3311  3359.0861  3363.7473查看数据框的尾部：                 OPEN       HIGH        LOW      CLOSE2018-07-04  3398.7788  3418.3311  3359.0861  3363.74732018-07-05  3365.5547  3398.4852  3330.7113  3342.43792018-07-06  3347.0624  3396.2458  3295.7296  3365.12272018-07-09  3378.9056  3459.3153  3378.9056  3459.18372018-07-10  3464.9064  3474.1396  3437.2706  3467.5155查看数据框的索引indexIndex([2018-06-28, 2018-06-29, 2018-07-02, 2018-07-03, 2018-07-04, 2018-07-05,       2018-07-06, 2018-07-09, 2018-07-10],      dtype=&#39;object&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'查看数据框的列名'</span>)</span><br><span class="line">print(df.columns)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看数据框的值，其格式为数组array'</span>)</span><br><span class="line">print(df.values)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看数据框的基础描述性统计'</span>)</span><br><span class="line">print(df.describe())</span><br></pre></td></tr></table></figure><pre><code>查看数据框的列名Index([&#39;OPEN&#39;, &#39;HIGH&#39;, &#39;LOW&#39;, &#39;CLOSE&#39;], dtype=&#39;object&#39;)查看数据框的值，其格式为数组array[[3434.9441 3477.0565 3416.9476 3423.5255] [3431.9619 3512.3834 3425.2159 3510.9845] [3504.4571 3506.8996 3383.5006 3407.9638] [3410.4767 3422.0398 3319.2889 3409.2801] [3398.7788 3418.3311 3359.0861 3363.7473] [3365.5547 3398.4852 3330.7113 3342.4379] [3347.0624 3396.2458 3295.7296 3365.1227] [3378.9056 3459.3153 3378.9056 3459.1837] [3464.9064 3474.1396 3437.2706 3467.5155]]查看数据框的基础描述性统计              OPEN         HIGH          LOW        CLOSEcount     9.000000     9.000000     9.000000     9.000000mean   3415.227522  3451.655144  3371.850689  3416.640111std      49.780741    44.488942    49.698315    55.264867min    3347.062400  3396.245800  3295.729600  3342.43790025%    3378.905600  3418.331100  3330.711300  3365.12270050%    3410.476700  3459.315300  3378.905600  3409.28010075%    3434.944100  3477.056500  3416.947600  3459.183700max    3504.457100  3512.383400  3437.270600  3510.984500</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在原有的数据框中新加入一列</span></span><br><span class="line">df[<span class="string">'名称'</span>] = [<span class="string">'HS300'</span>] * len(df)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>      <th>名称</th>    </tr>  </thead>  <tbody>    <tr>      <td>2018-06-28</td>      <td>3434.9441</td>      <td>3477.0565</td>      <td>3416.9476</td>      <td>3423.5255</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-06-29</td>      <td>3431.9619</td>      <td>3512.3834</td>      <td>3425.2159</td>      <td>3510.9845</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-02</td>      <td>3504.4571</td>      <td>3506.8996</td>      <td>3383.5006</td>      <td>3407.9638</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-03</td>      <td>3410.4767</td>      <td>3422.0398</td>      <td>3319.2889</td>      <td>3409.2801</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-04</td>      <td>3398.7788</td>      <td>3418.3311</td>      <td>3359.0861</td>      <td>3363.7473</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-05</td>      <td>3365.5547</td>      <td>3398.4852</td>      <td>3330.7113</td>      <td>3342.4379</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-06</td>      <td>3347.0624</td>      <td>3396.2458</td>      <td>3295.7296</td>      <td>3365.1227</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-09</td>      <td>3378.9056</td>      <td>3459.3153</td>      <td>3378.9056</td>      <td>3459.1837</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-10</td>      <td>3464.9064</td>      <td>3474.1396</td>      <td>3437.2706</td>      <td>3467.5155</td>      <td>HS300</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据框的转置</span></span><br><span class="line">df.T</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>2018-06-28</th>      <th>2018-06-29</th>      <th>2018-07-02</th>      <th>2018-07-03</th>      <th>2018-07-04</th>      <th>2018-07-05</th>      <th>2018-07-06</th>      <th>2018-07-09</th>      <th>2018-07-10</th>    </tr>  </thead>  <tbody>    <tr>      <td>OPEN</td>      <td>3434.94</td>      <td>3431.96</td>      <td>3504.46</td>      <td>3410.48</td>      <td>3398.78</td>      <td>3365.55</td>      <td>3347.06</td>      <td>3378.91</td>      <td>3464.91</td>    </tr>    <tr>      <td>HIGH</td>      <td>3477.06</td>      <td>3512.38</td>      <td>3506.9</td>      <td>3422.04</td>      <td>3418.33</td>      <td>3398.49</td>      <td>3396.25</td>      <td>3459.32</td>      <td>3474.14</td>    </tr>    <tr>      <td>LOW</td>      <td>3416.95</td>      <td>3425.22</td>      <td>3383.5</td>      <td>3319.29</td>      <td>3359.09</td>      <td>3330.71</td>      <td>3295.73</td>      <td>3378.91</td>      <td>3437.27</td>    </tr>    <tr>      <td>CLOSE</td>      <td>3423.53</td>      <td>3510.98</td>      <td>3407.96</td>      <td>3409.28</td>      <td>3363.75</td>      <td>3342.44</td>      <td>3365.12</td>      <td>3459.18</td>      <td>3467.52</td>    </tr>    <tr>      <td>名称</td>      <td>HS300</td>      <td>HS300</td>      <td>HS300</td>      <td>HS300</td>      <td>HS300</td>      <td>HS300</td>      <td>HS300</td>      <td>HS300</td>      <td>HS300</td>    </tr>  </tbody></table></div><h3 id="2-3-DataFrame截取"><a href="#2-3-DataFrame截取" class="headerlink" title="2.3 DataFrame截取"></a>2.3 DataFrame截取</h3><h4 id="2-3-1-行截取"><a href="#2-3-1-行截取" class="headerlink" title="2.3.1 行截取"></a>2.3.1 行截取</h4><p>氦核：不推荐使用ix进行截取，因为ix既可以对名称截取，又可以索引截取。如果index是整数，会很迷惑。一般使用loc和iloc函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'查看df索引为1的行——方法一'</span>)</span><br><span class="line">print(df.ix[<span class="number">1</span>])   <span class="comment"># print(df.iloc[1]) 推荐使用</span></span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看df前3行'</span>)</span><br><span class="line">print(df[:<span class="number">3</span>])</span><br></pre></td></tr></table></figure><pre><code>查看df索引为1的行——方法一OPEN     3431.96HIGH     3512.38LOW      3425.22CLOSE    3510.98名称         HS300Name: 2018-06-29, dtype: object查看df前3行                 OPEN       HIGH        LOW      CLOSE     名称2018-06-28  3434.9441  3477.0565  3416.9476  3423.5255  HS3002018-06-29  3431.9619  3512.3834  3425.2159  3510.9845  HS3002018-07-02  3504.4571  3506.8996  3383.5006  3407.9638  HS300D:\anaconda\lib\site-packages\ipykernel_launcher.py:2: FutureWarning: .ix is deprecated. Please use.loc for label based indexing or.iloc for positional indexingSee the documentation here:http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated</code></pre><h4 id="2-3-2-列截取"><a href="#2-3-2-列截取" class="headerlink" title="2.3.2 列截取"></a>2.3.2 列截取</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'df的一列选取'</span>)</span><br><span class="line">print(df[<span class="string">'OPEN'</span>])</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'df的两列同时选取'</span>)</span><br><span class="line">print(df[[<span class="string">'OPEN'</span>,<span class="string">'LOW'</span>]])</span><br></pre></td></tr></table></figure><pre><code>df的一列选取2018-06-28    3434.94412018-06-29    3431.96192018-07-02    3504.45712018-07-03    3410.47672018-07-04    3398.77882018-07-05    3365.55472018-07-06    3347.06242018-07-09    3378.90562018-07-10    3464.9064Name: OPEN, dtype: float64df的两列同时选取                 OPEN        LOW2018-06-28  3434.9441  3416.94762018-06-29  3431.9619  3425.21592018-07-02  3504.4571  3383.50062018-07-03  3410.4767  3319.28892018-07-04  3398.7788  3359.08612018-07-05  3365.5547  3330.71132018-07-06  3347.0624  3295.72962018-07-09  3378.9056  3378.90562018-07-10  3464.9064  3437.2706</code></pre><h4 id="2-3-3-DataFrame行列同时截取"><a href="#2-3-3-DataFrame行列同时截取" class="headerlink" title="2.3.3 DataFrame行列同时截取"></a>2.3.3 DataFrame行列同时截取</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'截取df的前4行的close和low列'</span>)</span><br><span class="line">df.ix[:<span class="number">4</span>,[<span class="string">'CLOSE'</span>,<span class="string">'LOW'</span>]]</span><br></pre></td></tr></table></figure><pre><code>截取df的前4行的close和low列D:\anaconda\lib\site-packages\ipykernel_launcher.py:2: FutureWarning: .ix is deprecated. Please use.loc for label based indexing or.iloc for positional indexingSee the documentation here:http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated</code></pre><p>​    </p><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>CLOSE</th>      <th>LOW</th>    </tr>  </thead>  <tbody>    <tr>      <td>2018-06-28</td>      <td>3423.5255</td>      <td>3416.9476</td>    </tr>    <tr>      <td>2018-06-29</td>      <td>3510.9845</td>      <td>3425.2159</td>    </tr>    <tr>      <td>2018-07-02</td>      <td>3407.9638</td>      <td>3383.5006</td>    </tr>    <tr>      <td>2018-07-03</td>      <td>3409.2801</td>      <td>3319.2889</td>    </tr>  </tbody></table></div><h4 id="2-3-4-DataFrame条件截取"><a href="#2-3-4-DataFrame条件截取" class="headerlink" title="2.3.4 DataFrame条件截取"></a>2.3.4 DataFrame条件截取</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'截取df CLOSE大于等于3500的记录'</span>)</span><br><span class="line">print(df[df[<span class="string">'CLOSE'</span>]&gt;=<span class="number">3500</span>])  </span><br><span class="line">print(<span class="string">''</span>)</span><br><span class="line">print(<span class="string">'截取df CLOSE大于3300且LOW小于3400的记录'</span>)</span><br><span class="line">print(df[(df[<span class="string">'CLOSE'</span>]&gt;<span class="number">3300</span>)&amp;(df[<span class="string">'LOW'</span>]&lt;<span class="number">3400</span>)])   </span><br><span class="line">print(<span class="string">''</span>)</span><br></pre></td></tr></table></figure><pre><code>截取df CLOSE大于等于3500的记录                 OPEN       HIGH        LOW      CLOSE     名称2018-06-29  3431.9619  3512.3834  3425.2159  3510.9845  HS300截取df CLOSE大于3300且LOW小于3400的记录                 OPEN       HIGH        LOW      CLOSE     名称2018-07-02  3504.4571  3506.8996  3383.5006  3407.9638  HS3002018-07-03  3410.4767  3422.0398  3319.2889  3409.2801  HS3002018-07-04  3398.7788  3418.3311  3359.0861  3363.7473  HS3002018-07-05  3365.5547  3398.4852  3330.7113  3342.4379  HS3002018-07-06  3347.0624  3396.2458  3295.7296  3365.1227  HS3002018-07-09  3378.9056  3459.3153  3378.9056  3459.1837  HS300</code></pre><p>​    </p><h3 id="2-4-DataFrame缺失值处理"><a href="#2-4-DataFrame缺失值处理" class="headerlink" title="2.4 DataFrame缺失值处理"></a>2.4 DataFrame缺失值处理</h3><p>例如下面这个数据框data，其中就存在缺失值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = &#123;<span class="string">'state'</span>: [<span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Nevada'</span>, <span class="string">'Nevada'</span>],</span><br><span class="line">        <span class="string">'year'</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>],</span><br><span class="line">        <span class="string">'pop'</span>: [<span class="number">1.5</span>, <span class="number">1.7</span>, <span class="number">3.6</span>, <span class="number">2.4</span>, <span class="number">2.9</span>]&#125;</span><br><span class="line">data = pd.DataFrame(data)</span><br><span class="line">data.loc[<span class="number">1</span>,<span class="string">'pop'</span>] = np.NaN</span><br><span class="line">data.loc[<span class="number">3</span>,<span class="string">'state'</span>] = <span class="keyword">None</span></span><br><span class="line">data</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>NaN</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>None</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#删除含有缺失的行</span></span><br><span class="line">data.dropna()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#表示该行都为缺失的行才删除 注意是这一行中的每一个元素都为缺失才删除这一行</span></span><br><span class="line">data.dropna(how=<span class="string">"all"</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>NaN</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>None</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#表示该列若都为缺失的列则删除,注意是这一列的每个元素都为缺失才会删除这一列</span></span><br><span class="line">data.dropna(how=<span class="string">"all"</span>, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>NaN</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>None</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#表示保留至少存在3个非NaN的行，即如果某一行的非缺失值个数小于3个，则会被删除</span></span><br><span class="line">data.dropna(thresh=<span class="number">3</span>, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#表示保留至少存在3个非NaN的列，即如果某一列的非缺失值个数小于3个，则会被删除</span></span><br><span class="line">data.dropna(thresh=<span class="number">3</span>, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>NaN</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>None</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>NaN</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>None</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'用0填充数据框中的缺失值,0是可选参数之一'</span>)</span><br><span class="line">data.fillna(value=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><pre><code>用0填充数据框中的缺失值,0是可选参数之一</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>0.0</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>0</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#填充缺失值 用缺失值所在列的前一个非NaN值来进行填充  </span></span><br><span class="line">data.fillna(method=<span class="string">'ffill'</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>1.5</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>Ohio</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#用缺失值所在列的后一个非NaN来填充</span></span><br><span class="line">data.fillna(method=<span class="string">"bfill"</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>3.6</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>Nevada</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><p>氦核：这些填补都是什么鬼方法，无语。</p><h3 id="2-5-DataFrame排序"><a href="#2-5-DataFrame排序" class="headerlink" title="2.5 DataFrame排序"></a>2.5 DataFrame排序</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>      <th>名称</th>    </tr>  </thead>  <tbody>    <tr>      <td>2018-06-28</td>      <td>3434.9441</td>      <td>3477.0565</td>      <td>3416.9476</td>      <td>3423.5255</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-06-29</td>      <td>3431.9619</td>      <td>3512.3834</td>      <td>3425.2159</td>      <td>3510.9845</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-02</td>      <td>3504.4571</td>      <td>3506.8996</td>      <td>3383.5006</td>      <td>3407.9638</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-03</td>      <td>3410.4767</td>      <td>3422.0398</td>      <td>3319.2889</td>      <td>3409.2801</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-04</td>      <td>3398.7788</td>      <td>3418.3311</td>      <td>3359.0861</td>      <td>3363.7473</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-05</td>      <td>3365.5547</td>      <td>3398.4852</td>      <td>3330.7113</td>      <td>3342.4379</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-06</td>      <td>3347.0624</td>      <td>3396.2458</td>      <td>3295.7296</td>      <td>3365.1227</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-09</td>      <td>3378.9056</td>      <td>3459.3153</td>      <td>3378.9056</td>      <td>3459.1837</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-10</td>      <td>3464.9064</td>      <td>3474.1396</td>      <td>3437.2706</td>      <td>3467.5155</td>      <td>HS300</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'df按列OPEN降序排序'</span>)</span><br><span class="line">df.sort_values(<span class="string">'OPEN'</span>)</span><br></pre></td></tr></table></figure><pre><code>df按列OPEN降序排序</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>      <th>名称</th>    </tr>  </thead>  <tbody>    <tr>      <td>2018-07-06</td>      <td>3347.0624</td>      <td>3396.2458</td>      <td>3295.7296</td>      <td>3365.1227</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-05</td>      <td>3365.5547</td>      <td>3398.4852</td>      <td>3330.7113</td>      <td>3342.4379</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-09</td>      <td>3378.9056</td>      <td>3459.3153</td>      <td>3378.9056</td>      <td>3459.1837</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-04</td>      <td>3398.7788</td>      <td>3418.3311</td>      <td>3359.0861</td>      <td>3363.7473</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-03</td>      <td>3410.4767</td>      <td>3422.0398</td>      <td>3319.2889</td>      <td>3409.2801</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-06-29</td>      <td>3431.9619</td>      <td>3512.3834</td>      <td>3425.2159</td>      <td>3510.9845</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-06-28</td>      <td>3434.9441</td>      <td>3477.0565</td>      <td>3416.9476</td>      <td>3423.5255</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-10</td>      <td>3464.9064</td>      <td>3474.1396</td>      <td>3437.2706</td>      <td>3467.5155</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-02</td>      <td>3504.4571</td>      <td>3506.8996</td>      <td>3383.5006</td>      <td>3407.9638</td>      <td>HS300</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'df按列LOW升序排序'</span>)</span><br><span class="line">df.sort_values(<span class="string">'LOW'</span>,ascending=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><pre><code>df按列LOW升序排序</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>      <th>名称</th>    </tr>  </thead>  <tbody>    <tr>      <td>2018-07-06</td>      <td>3347.0624</td>      <td>3396.2458</td>      <td>3295.7296</td>      <td>3365.1227</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-03</td>      <td>3410.4767</td>      <td>3422.0398</td>      <td>3319.2889</td>      <td>3409.2801</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-05</td>      <td>3365.5547</td>      <td>3398.4852</td>      <td>3330.7113</td>      <td>3342.4379</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-04</td>      <td>3398.7788</td>      <td>3418.3311</td>      <td>3359.0861</td>      <td>3363.7473</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-09</td>      <td>3378.9056</td>      <td>3459.3153</td>      <td>3378.9056</td>      <td>3459.1837</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-02</td>      <td>3504.4571</td>      <td>3506.8996</td>      <td>3383.5006</td>      <td>3407.9638</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-06-28</td>      <td>3434.9441</td>      <td>3477.0565</td>      <td>3416.9476</td>      <td>3423.5255</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-06-29</td>      <td>3431.9619</td>      <td>3512.3834</td>      <td>3425.2159</td>      <td>3510.9845</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-10</td>      <td>3464.9064</td>      <td>3474.1396</td>      <td>3437.2706</td>      <td>3467.5155</td>      <td>HS300</td>    </tr>  </tbody></table></div><h3 id="2-6-DataFrame的基本函数"><a href="#2-6-DataFrame的基本函数" class="headerlink" title="2.6 DataFrame的基本函数"></a>2.6 DataFrame的基本函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'按列求均值'</span>)</span><br><span class="line">df.mean()</span><br></pre></td></tr></table></figure><pre><code>按列求均值OPEN     3415.227522HIGH     3451.655144LOW      3371.850689CLOSE    3416.640111dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'按行求均值'</span>)</span><br><span class="line">df.mean(axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><pre><code>按行求均值2018-06-28    3438.1184252018-06-29    3470.1364252018-07-02    3450.7052752018-07-03    3390.2713752018-07-04    3384.9858252018-07-05    3359.2972752018-07-06    3351.0401252018-07-09    3419.0775502018-07-10    3460.958025dtype: float64</code></pre><h4 id="函数汇总"><a href="#函数汇总" class="headerlink" title="函数汇总"></a>函数汇总</h4><p>下面的函数都是通过数据框.函数名(参数设置)来进行调用，一般的参数是axis=0/1，选择为0则是按行来实现函数，1则是按列来实现函数</p><div class="table-container"><table><thead><tr><th>序号</th><th>函数</th><th>函数含义</th></tr></thead><tbody><tr><td>1</td><td>count</td><td>计数非na值</td></tr><tr><td>2</td><td>describe</td><td>针对Series或个DataFrame列基本描述统计</td></tr><tr><td>3</td><td>min、max</td><td>计算最小值和最大值</td></tr><tr><td>4</td><td>argmin、argmax</td><td>获取到最大值和最小值的索引位置（整数）</td></tr><tr><td>5</td><td>idxmin、idxmax</td><td>计算能够获取到最大值和最小值得索引值</td></tr><tr><td>6</td><td>quantile</td><td>计算样本的分位数（0到1）</td></tr><tr><td>7</td><td>sum</td><td>求和</td></tr><tr><td>8</td><td>mean</td><td>求平均数</td></tr><tr><td>9</td><td>median</td><td>求中位数（50%分位数）</td></tr><tr><td>10</td><td>mad</td><td>计算平均绝对离差</td></tr><tr><td>11</td><td>var</td><td>样本方差</td></tr><tr><td>12</td><td>std</td><td>样本标准差</td></tr><tr><td>13</td><td>skew</td><td>样本偏度（三阶矩）</td></tr><tr><td>14</td><td>kurt</td><td>样本峰度（四阶矩）</td></tr><tr><td>15</td><td>cumsum</td><td>样本累计和</td></tr><tr><td>16</td><td>cummin，cummax</td><td>样本累计最大值和累计最小值</td></tr><tr><td>17</td><td>cumprod</td><td>样本累计积</td></tr><tr><td>18</td><td>diff</td><td>计算一阶差分</td></tr><tr><td>19</td><td>pct_change</td><td>计算百分数变化</td></tr><tr><td>20</td><td>corr</td><td>计数相关性</td></tr></tbody></table></div><h3 id="2-7-DataFrame拼接"><a href="#2-7-DataFrame拼接" class="headerlink" title="2.7 DataFrame拼接"></a>2.7 DataFrame拼接</h3><p>下面介绍了三个函数来实现 DataFrame的拼接功能——concat函数，merge函数和join函数</p><h4 id="2-7-1-DataFrame拼接—pd-concat"><a href="#2-7-1-DataFrame拼接—pd-concat" class="headerlink" title="2.7.1 DataFrame拼接—pd.concat"></a>2.7.1 DataFrame拼接—pd.concat</h4><p>通过Wind API可以获取到各种金融数据，可以使用代码生成器生成获取数据的函数代码。获取到数据后，可参考一下代码将数据转换为DataFrame格式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> WindPy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame </span><br><span class="line">w.start()</span><br><span class="line"></span><br><span class="line">wsd_data = w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"lastradeday_s,sec_name,open,high,low,close"</span>, <span class="string">"2017-11-01"</span>, <span class="string">"2017-11-05"</span>, <span class="string">""</span>)</span><br><span class="line">data_df = DataFrame(wsd_data.Data,columns=wsd_data.Times,index=wsd_data.Fields)</span><br><span class="line">data_df = data_df.T <span class="comment">#转置数据表</span></span><br><span class="line">data_df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME</th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>    </tr>  </thead>  <tbody>    <tr>      <td>2017-11-01</td>      <td>2017-11-01</td>      <td>平安银行</td>      <td>11.56</td>      <td>11.59</td>      <td>11.32</td>      <td>11.4</td>    </tr>    <tr>      <td>2017-11-02</td>      <td>2017-11-02</td>      <td>平安银行</td>      <td>11.36</td>      <td>11.58</td>      <td>11.26</td>      <td>11.54</td>    </tr>    <tr>      <td>2017-11-03</td>      <td>2017-11-03</td>      <td>平安银行</td>      <td>11.49</td>      <td>11.68</td>      <td>11.35</td>      <td>11.39</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wsd_data1 = w.wsd(<span class="string">"000002.SZ"</span>, <span class="string">"lastradeday_s,sec_name,open,high,low,close"</span>, <span class="string">"2017-11-01"</span>, <span class="string">"2017-11-05"</span>, <span class="string">""</span>)</span><br><span class="line">data_df1 = DataFrame(wsd_data1.Data,columns=wsd_data.Times,index=wsd_data.Fields)</span><br><span class="line">data_df1 = data_df1.T <span class="comment">#转置数据表</span></span><br><span class="line">data_df1</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME</th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>    </tr>  </thead>  <tbody>    <tr>      <td>2017-11-01</td>      <td>2017-11-01</td>      <td>万科A</td>      <td>28.96</td>      <td>30.54</td>      <td>28.73</td>      <td>29.15</td>    </tr>    <tr>      <td>2017-11-02</td>      <td>2017-11-02</td>      <td>万科A</td>      <td>29.3</td>      <td>29.48</td>      <td>28.68</td>      <td>29.45</td>    </tr>    <tr>      <td>2017-11-03</td>      <td>2017-11-03</td>      <td>万科A</td>      <td>29.23</td>      <td>29.52</td>      <td>28.05</td>      <td>28.19</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'按行拼接'</span>)</span><br><span class="line">pd.concat([data_df,data_df1],axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><pre><code>按行拼接</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME</th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>    </tr>  </thead>  <tbody>    <tr>      <td>2017-11-01</td>      <td>2017-11-01</td>      <td>平安银行</td>      <td>11.56</td>      <td>11.59</td>      <td>11.32</td>      <td>11.4</td>    </tr>    <tr>      <td>2017-11-02</td>      <td>2017-11-02</td>      <td>平安银行</td>      <td>11.36</td>      <td>11.58</td>      <td>11.26</td>      <td>11.54</td>    </tr>    <tr>      <td>2017-11-03</td>      <td>2017-11-03</td>      <td>平安银行</td>      <td>11.49</td>      <td>11.68</td>      <td>11.35</td>      <td>11.39</td>    </tr>    <tr>      <td>2017-11-01</td>      <td>2017-11-01</td>      <td>万科A</td>      <td>28.96</td>      <td>30.54</td>      <td>28.73</td>      <td>29.15</td>    </tr>    <tr>      <td>2017-11-02</td>      <td>2017-11-02</td>      <td>万科A</td>      <td>29.3</td>      <td>29.48</td>      <td>28.68</td>      <td>29.45</td>    </tr>    <tr>      <td>2017-11-03</td>      <td>2017-11-03</td>      <td>万科A</td>      <td>29.23</td>      <td>29.52</td>      <td>28.05</td>      <td>28.19</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'按列拼接'</span>)</span><br><span class="line">pd.concat([data_df,data_df1],axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><pre><code>按列拼接</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME</th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME</th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>    </tr>  </thead>  <tbody>    <tr>      <td>2017-11-01</td>      <td>2017-11-01</td>      <td>平安银行</td>      <td>11.56</td>      <td>11.59</td>      <td>11.32</td>      <td>11.4</td>      <td>2017-11-01</td>      <td>万科A</td>      <td>28.96</td>      <td>30.54</td>      <td>28.73</td>      <td>29.15</td>    </tr>    <tr>      <td>2017-11-02</td>      <td>2017-11-02</td>      <td>平安银行</td>      <td>11.36</td>      <td>11.58</td>      <td>11.26</td>      <td>11.54</td>      <td>2017-11-02</td>      <td>万科A</td>      <td>29.3</td>      <td>29.48</td>      <td>28.68</td>      <td>29.45</td>    </tr>    <tr>      <td>2017-11-03</td>      <td>2017-11-03</td>      <td>平安银行</td>      <td>11.49</td>      <td>11.68</td>      <td>11.35</td>      <td>11.39</td>      <td>2017-11-03</td>      <td>万科A</td>      <td>29.23</td>      <td>29.52</td>      <td>28.05</td>      <td>28.19</td>    </tr>  </tbody></table></div><h3 id="2-7-3-DataFrame拼接—pd-merge"><a href="#2-7-3-DataFrame拼接—pd-merge" class="headerlink" title="2.7.3 DataFrame拼接—pd.merge"></a>2.7.3 DataFrame拼接—pd.merge</h3><p>pd.merge一般针对的是按列合并。</p><p>pd.merge(left, right, how=’inner’, on=None, left_on=None, right_on=None,<br>         left_index=False, right_index=False, sort=True,<br>         suffixes=(‘_x’, ‘_y’), copy=True, indicator=False)</p><p>left: 一个dataframe对象</p><p>right: 另一个dataframe对象</p><p>how: 可以是’left’, ‘right’, ‘outer’, ‘inner’. 默认为inner。</p><p>on: 列名，两个dataframe都有的列。如果不传参数，而且left_index和right_index也等于False，则默认把两者交叉/共有的列作为链接键（join keys）。可以是一个列名，也可以是包含多个列名的list。</p><p>left_on: 左边dataframe的列会用做keys。可以是列名，或者与dataframe长度相同的矩阵array。</p><p>right_on: 右边同上。</p><p>left_index: 如果为Ture，用左侧dataframe的index作为连接键。如果是多维索引，level数要跟右边相同才行。</p><p>right_index: 右边同上。</p><p>sort: 对合并后的数据框排序，以连接键。</p><p>suffixes: 一个tuple，包字符串后缀，用来加在重叠的列名后面。默认是(‘_x’,’_y’)。</p><p>copy: 默认Ture，复制数据。</p><p>indicator: 布尔型（True/FALSE），或是字符串。如果为True，合并之后会增加一列叫做_merge。是分类数据，用left_only, right_only, both来标记来自左边，右边和两边的数据。</p><p>参考：<a href="http://www.jianshu.com/p/dc8ba1c0eada" target="_blank" rel="noopener">http://www.jianshu.com/p/dc8ba1c0eada</a></p><p>希望将上面两个 DataFrame left_data和right_data拼接起来，但要求是按照时间来进行拼接</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'按LASTRADEDAY_S拼接，只保留共同的部分'</span>)</span><br><span class="line">pd.merge(data_df,data_df1,on=<span class="string">'LASTRADEDAY_S'</span>)</span><br></pre></td></tr></table></figure><pre><code>按LASTRADEDAY_S拼接，只保留共同的部分</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME_x</th>      <th>OPEN_x</th>      <th>HIGH_x</th>      <th>LOW_x</th>      <th>CLOSE_x</th>      <th>SEC_NAME_y</th>      <th>OPEN_y</th>      <th>HIGH_y</th>      <th>LOW_y</th>      <th>CLOSE_y</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>2017-11-01</td>      <td>平安银行</td>      <td>11.56</td>      <td>11.59</td>      <td>11.32</td>      <td>11.4</td>      <td>万科A</td>      <td>28.96</td>      <td>30.54</td>      <td>28.73</td>      <td>29.15</td>    </tr>    <tr>      <td>1</td>      <td>2017-11-02</td>      <td>平安银行</td>      <td>11.36</td>      <td>11.58</td>      <td>11.26</td>      <td>11.54</td>      <td>万科A</td>      <td>29.3</td>      <td>29.48</td>      <td>28.68</td>      <td>29.45</td>    </tr>    <tr>      <td>2</td>      <td>2017-11-03</td>      <td>平安银行</td>      <td>11.49</td>      <td>11.68</td>      <td>11.35</td>      <td>11.39</td>      <td>万科A</td>      <td>29.23</td>      <td>29.52</td>      <td>28.05</td>      <td>28.19</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'按LASTRADEDAY_S拼接，但所有的数据都保留下来'</span>)</span><br><span class="line">pd.merge(data_df,data_df1,on=<span class="string">'LASTRADEDAY_S'</span>,how=<span class="string">'outer'</span>)</span><br></pre></td></tr></table></figure><pre><code>按LASTRADEDAY_S拼接，但所有的数据都保留下来</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME_x</th>      <th>OPEN_x</th>      <th>HIGH_x</th>      <th>LOW_x</th>      <th>CLOSE_x</th>      <th>SEC_NAME_y</th>      <th>OPEN_y</th>      <th>HIGH_y</th>      <th>LOW_y</th>      <th>CLOSE_y</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>2017-11-01</td>      <td>平安银行</td>      <td>11.56</td>      <td>11.59</td>      <td>11.32</td>      <td>11.4</td>      <td>万科A</td>      <td>28.96</td>      <td>30.54</td>      <td>28.73</td>      <td>29.15</td>    </tr>    <tr>      <td>1</td>      <td>2017-11-02</td>      <td>平安银行</td>      <td>11.36</td>      <td>11.58</td>      <td>11.26</td>      <td>11.54</td>      <td>万科A</td>      <td>29.3</td>      <td>29.48</td>      <td>28.68</td>      <td>29.45</td>    </tr>    <tr>      <td>2</td>      <td>2017-11-03</td>      <td>平安银行</td>      <td>11.49</td>      <td>11.68</td>      <td>11.35</td>      <td>11.39</td>      <td>万科A</td>      <td>29.23</td>      <td>29.52</td>      <td>28.05</td>      <td>28.19</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'LASTRADEDAY_S，但所有的数据都保留下来，且生成一列来表示数据的来源'</span>)</span><br><span class="line">pd.merge(data_df,data_df1,on=<span class="string">'LASTRADEDAY_S'</span>,how=<span class="string">'outer'</span>,indicator=<span class="string">'数据来源'</span>)</span><br></pre></td></tr></table></figure><pre><code>LASTRADEDAY_S，但所有的数据都保留下来，且生成一列来表示数据的来源</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME_x</th>      <th>OPEN_x</th>      <th>HIGH_x</th>      <th>LOW_x</th>      <th>CLOSE_x</th>      <th>SEC_NAME_y</th>      <th>OPEN_y</th>      <th>HIGH_y</th>      <th>LOW_y</th>      <th>CLOSE_y</th>      <th>数据来源</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>2017-11-01</td>      <td>平安银行</td>      <td>11.56</td>      <td>11.59</td>      <td>11.32</td>      <td>11.4</td>      <td>万科A</td>      <td>28.96</td>      <td>30.54</td>      <td>28.73</td>      <td>29.15</td>      <td>both</td>    </tr>    <tr>      <td>1</td>      <td>2017-11-02</td>      <td>平安银行</td>      <td>11.36</td>      <td>11.58</td>      <td>11.26</td>      <td>11.54</td>      <td>万科A</td>      <td>29.3</td>      <td>29.48</td>      <td>28.68</td>      <td>29.45</td>      <td>both</td>    </tr>    <tr>      <td>2</td>      <td>2017-11-03</td>      <td>平安银行</td>      <td>11.49</td>      <td>11.68</td>      <td>11.35</td>      <td>11.39</td>      <td>万科A</td>      <td>29.23</td>      <td>29.52</td>      <td>28.05</td>      <td>28.19</td>      <td>both</td>    </tr>  </tbody></table></div><h3 id="2-7-4-DataFrame拼接—-join"><a href="#2-7-4-DataFrame拼接—-join" class="headerlink" title="2.7.4 DataFrame拼接—.join"></a>2.7.4 DataFrame拼接—.join</h3><p>DataFrame.join(other, on=None, how=’left’, lsuffix=’’, rsuffix=’’, sort=False)</p><p>other：一个DataFrame、Series（要有命名），或者DataFrame组成的list。</p><p>on：列名，包含列名的list或tuple，或矩阵样子的列 （如果是多列，必须有MultiIndex）。 跟上面的几种方法一样，用来指明依据哪一列进行合并。 如果没有赋值，则依据两个数据框的index合并。</p><p>how：合并方式， {‘left’, ‘right’, ‘outer’, ‘inner’}, 默认‘left‘。</p><p>lsuffix：字符串。用于左侧数据框的重复列。 把重复列重新命名，原来的列名+字符串。 【如果有重复列，必须添加这个参数。】</p><p>rsuffix：同上。右侧。</p><p>sort：布尔型，默认False。如果为True，将链接键（on的那列）按字母排序。</p><p>参考：<a href="http://www.jianshu.com/p/dc8ba1c0eada" target="_blank" rel="noopener">http://www.jianshu.com/p/dc8ba1c0eada</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'注意到两个拼接的数据框，含有相同的列LASTRADEDAY_S，故重新命名了这两个列'</span>)</span><br><span class="line">data_df.join(data_df1,lsuffix=<span class="string">'_left'</span>,rsuffix=<span class="string">'_right'</span>)</span><br></pre></td></tr></table></figure><pre><code>注意到两个拼接的数据框，含有相同的列LASTRADEDAY_S，故重新命名了这两个列</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S_left</th>      <th>SEC_NAME_left</th>      <th>OPEN_left</th>      <th>HIGH_left</th>      <th>LOW_left</th>      <th>CLOSE_left</th>      <th>LASTRADEDAY_S_right</th>      <th>SEC_NAME_right</th>      <th>OPEN_right</th>      <th>HIGH_right</th>      <th>LOW_right</th>      <th>CLOSE_right</th>    </tr>  </thead>  <tbody>    <tr>      <td>2017-11-01</td>      <td>2017-11-01</td>      <td>平安银行</td>      <td>11.56</td>      <td>11.59</td>      <td>11.32</td>      <td>11.4</td>      <td>2017-11-01</td>      <td>万科A</td>      <td>28.96</td>      <td>30.54</td>      <td>28.73</td>      <td>29.15</td>    </tr>    <tr>      <td>2017-11-02</td>      <td>2017-11-02</td>      <td>平安银行</td>      <td>11.36</td>      <td>11.58</td>      <td>11.26</td>      <td>11.54</td>      <td>2017-11-02</td>      <td>万科A</td>      <td>29.3</td>      <td>29.48</td>      <td>28.68</td>      <td>29.45</td>    </tr>    <tr>      <td>2017-11-03</td>      <td>2017-11-03</td>      <td>平安银行</td>      <td>11.49</td>      <td>11.68</td>      <td>11.35</td>      <td>11.39</td>      <td>2017-11-03</td>      <td>万科A</td>      <td>29.23</td>      <td>29.52</td>      <td>28.05</td>      <td>28.19</td>    </tr>  </tbody></table></div><h3 id="2-8-DataFrame重复值剔除"><a href="#2-8-DataFrame重复值剔除" class="headerlink" title="2.8 DataFrame重复值剔除"></a>2.8 DataFrame重复值剔除</h3><p>有时候，希望能够剔除掉DataFrame中的重复记录。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每股基本收益指标</span></span><br><span class="line">error_code,df3 = w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"fa_eps_basic"</span>, <span class="string">"2017-08-07"</span>, <span class="string">"2017-08-15"</span>, <span class="string">"Days=Alldays;currencyType="</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">df3</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>FA_EPS_BASIC</th>    </tr>  </thead>  <tbody>    <tr>      <td>2017-08-07</td>      <td>0.31</td>    </tr>    <tr>      <td>2017-08-08</td>      <td>0.31</td>    </tr>    <tr>      <td>2017-08-09</td>      <td>0.31</td>    </tr>    <tr>      <td>2017-08-10</td>      <td>0.31</td>    </tr>    <tr>      <td>2017-08-11</td>      <td>0.68</td>    </tr>    <tr>      <td>2017-08-12</td>      <td>0.68</td>    </tr>    <tr>      <td>2017-08-13</td>      <td>0.68</td>    </tr>    <tr>      <td>2017-08-14</td>      <td>0.68</td>    </tr>    <tr>      <td>2017-08-15</td>      <td>0.68</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'查看DataFrame中是否存在重复记录，标记为True的为重复记录'</span>)</span><br><span class="line">df3.duplicated()</span><br></pre></td></tr></table></figure><pre><code>查看DataFrame中是否存在重复记录，标记为True的为重复记录2017-08-07    False2017-08-08     True2017-08-09     True2017-08-10     True2017-08-11    False2017-08-12     True2017-08-13     True2017-08-14     True2017-08-15     Truedtype: bool</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'剔除数据框中的重复记录'</span>)</span><br><span class="line">df3.drop_duplicates()</span><br></pre></td></tr></table></figure><pre><code>剔除数据框中的重复记录</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>FA_EPS_BASIC</th>    </tr>  </thead>  <tbody>    <tr>      <td>2017-08-07</td>      <td>0.31</td>    </tr>    <tr>      <td>2017-08-11</td>      <td>0.68</td>    </tr>  </tbody></table></div><h3 id="2-9-DataFrame分组及透视表（groupby）"><a href="#2-9-DataFrame分组及透视表（groupby）" class="headerlink" title="2.9 DataFrame分组及透视表（groupby）"></a>2.9 DataFrame分组及透视表（groupby）</h3><h4 id="2-9-1-分组——groupby函数"><a href="#2-9-1-分组——groupby函数" class="headerlink" title="2.9.1 分组——groupby函数"></a>2.9.1 分组——groupby函数</h4><p>氦核：这个函数很厉害。下面列几个用法：</p><p>1.根据DataFrame本身的某一列或多列内容进行分组聚合。</p><p>2.还可以利用for循环，对分组进行迭代。（下面举了个小栗子）</p><pre><code>for name,group in df.groupby(&#39;key1&#39;):    print(name)     print(group)</code></pre><p>若仅使用一个变量name,会影响输出结果的索引层次表达方式，且结果为元组。</p><p>3.对聚合后的数据片段，进行格式类型转化</p><p>4.利用groupby，根据dtypes对列进行分组,此时，需指定<code>axis=1</code>，否则，groupby默认根据<code>axis=0</code>进行分组，而行数据由于类型不统一，故无法根据dtypes对列进行分组。</p><pre><code>*#将聚合后df转化为字典格式，后根据df的数据类型对列进行分组* grouped=df.groupby(df.dtypes,axis=1) dict(list(grouped))</code></pre><p>我们设定，如果当天收益率大于0，我们标记为up，反之为down。把收盘价大于11的标记为good，反之为bad。正式举例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> WindPy <span class="keyword">import</span> *</span><br><span class="line">w.start()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 先取一个金融时间序列，以DataFrame的形式</span></span><br><span class="line">error_code,df4 = w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"open,close,pct_chg"</span>, <span class="string">"2018-04-20"</span>, <span class="string">"2018-04-30"</span>, <span class="string">""</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">df4[<span class="string">'standard'</span>] = df4.PCT_CHG.apply(<span class="keyword">lambda</span> x: <span class="string">'up'</span> <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">'down'</span>)</span><br><span class="line">df4[<span class="string">'expression'</span>] = df4.CLOSE.apply(<span class="keyword">lambda</span> x: <span class="string">'good'</span> <span class="keyword">if</span> x &gt; <span class="number">11</span> <span class="keyword">else</span> <span class="string">'bad'</span>)</span><br><span class="line">df4</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>CLOSE</th>      <th>PCT_CHG</th>      <th>standard</th>      <th>expression</th>    </tr>  </thead>  <tbody>    <tr>      <td>2018-04-20</td>      <td>11.51</td>      <td>11.35</td>      <td>-1.046207</td>      <td>down</td>      <td>good</td>    </tr>    <tr>      <td>2018-04-23</td>      <td>11.30</td>      <td>11.57</td>      <td>1.938326</td>      <td>up</td>      <td>good</td>    </tr>    <tr>      <td>2018-04-24</td>      <td>11.63</td>      <td>11.86</td>      <td>2.506482</td>      <td>up</td>      <td>good</td>    </tr>    <tr>      <td>2018-04-25</td>      <td>11.76</td>      <td>11.68</td>      <td>-1.517707</td>      <td>down</td>      <td>good</td>    </tr>    <tr>      <td>2018-04-26</td>      <td>11.66</td>      <td>11.42</td>      <td>-2.226027</td>      <td>down</td>      <td>good</td>    </tr>    <tr>      <td>2018-04-27</td>      <td>11.49</td>      <td>10.85</td>      <td>-4.991243</td>      <td>down</td>      <td>bad</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grouped = df4[<span class="string">'CLOSE'</span>].groupby(df4[<span class="string">'standard'</span>])</span><br><span class="line">grouped</span><br></pre></td></tr></table></figure><pre><code>&lt;pandas.core.groupby.generic.SeriesGroupBy object at 0x0000020B26C63648&gt;</code></pre><p>氦核：上面这行是聚合后不适用配合函数的输出。</p><p>这是由于变量grouped是一个GroupBy对象，它实际上还没有进行任何计算，只是含有一些有关分组键<code>df[‘key1’]</code>的中间数据而已，然后我们可以调用配合函数（如：.mean()方法）来计算分组平均值等。<br>　　因此，一般为方便起见可直接在<strong>聚合之后+“配合函数”</strong>，默认情况下，所有数值列都将会被聚合，虽然有时可能会被过滤为一个子集。<br>　　一般，如果对df直接聚合时，<br><code>df.groupby([df[&#39;key1&#39;],df[&#39;key2&#39;]]).mean()</code>（分组键为：Series）与<code>df.groupby([&#39;key1&#39;,&#39;key2&#39;]).mean()</code>（分组键为：列名）是等价的，输出结果相同。<br>　　但是，如果对df的指定列进行聚合时，<br><code>df[&#39;data1&#39;].groupby(df[&#39;key1&#39;]).mean()</code>（分组键为：Series），唯一方式。<br>此时，直接使用“列名”作分组键，提示“Error Key”。<br>　　 注意：分组键中的任何缺失值都会被排除在结果之外。</p><p><a href="https://blog.csdn.net/weixin_42782150/article/details/90716533" target="_blank" rel="noopener">参考groupby用法博客链接</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grouped.mean()</span><br></pre></td></tr></table></figure><pre><code>standarddown    11.325up      11.715Name: CLOSE, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">means = df4[<span class="string">'CLOSE'</span>].groupby([df4[<span class="string">'standard'</span>],df4[<span class="string">'expression'</span>]]).mean()</span><br><span class="line">means</span><br></pre></td></tr></table></figure><pre><code>standard  expressiondown      bad           10.850000          good          11.483333up        good          11.715000Name: CLOSE, dtype: float64</code></pre><p>对两个键进行了分组，得到的Series具有一个层次化索引。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">means.unstack()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>expression</th>      <th>bad</th>      <th>good</th>    </tr>    <tr>      <th>standard</th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <td>down</td>      <td>10.85</td>      <td>11.483333</td>    </tr>    <tr>      <td>up</td>      <td>NaN</td>      <td>11.715000</td>    </tr>  </tbody></table></div><p>你还可以将列名用作分组键。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df4.groupby(<span class="string">'standard'</span>).mean()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>CLOSE</th>      <th>PCT_CHG</th>    </tr>    <tr>      <th>standard</th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <td>down</td>      <td>11.605</td>      <td>11.325</td>      <td>-2.445296</td>    </tr>    <tr>      <td>up</td>      <td>11.465</td>      <td>11.715</td>      <td>2.222404</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df4.groupby([df4[<span class="string">'standard'</span>],df4[<span class="string">'expression'</span>]]).mean()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th></th>      <th>OPEN</th>      <th>CLOSE</th>      <th>PCT_CHG</th>    </tr>    <tr>      <th>standard</th>      <th>expression</th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <td rowspan="2" valign="top">down</td>      <td>bad</td>      <td>11.490000</td>      <td>10.850000</td>      <td>-4.991243</td>    </tr>    <tr>      <td>good</td>      <td>11.643333</td>      <td>11.483333</td>      <td>-1.596647</td>    </tr>    <tr>      <td>up</td>      <td>good</td>      <td>11.465000</td>      <td>11.715000</td>      <td>2.222404</td>    </tr>  </tbody></table></div><p>我们还可以用size方法，返回一个含有分组大小的Series。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df4.groupby([<span class="string">'standard'</span>,<span class="string">'expression'</span>]).size()</span><br></pre></td></tr></table></figure><pre><code>standard  expressiondown      bad           1          good          3up        good          2dtype: int64</code></pre><h4 id="2-9-2-对分组进行迭代"><a href="#2-9-2-对分组进行迭代" class="headerlink" title="2.9.2 对分组进行迭代"></a>2.9.2 对分组进行迭代</h4><p>GroupBy对象支持迭代，可以产生一组二元元组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name,group <span class="keyword">in</span> df4.groupby(<span class="string">'standard'</span>):</span><br><span class="line">    print(name)</span><br><span class="line">    print(group)</span><br></pre></td></tr></table></figure><pre><code>down             OPEN  CLOSE   PCT_CHG standard expression2018-04-20  11.51  11.35 -1.046207     down       good2018-04-25  11.76  11.68 -1.517707     down       good2018-04-26  11.66  11.42 -2.226027     down       good2018-04-27  11.49  10.85 -4.991243     down        badup             OPEN  CLOSE   PCT_CHG standard expression2018-04-23  11.30  11.57  1.938326       up       good2018-04-24  11.63  11.86  2.506482       up       good</code></pre><p>对于<strong>多重组件</strong>的情况，元素的第一个元素将会是有键值组成的元组：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (k1,k2), group <span class="keyword">in</span> df4.groupby([<span class="string">'standard'</span>,<span class="string">'expression'</span>]):</span><br><span class="line">    print(k1,k2)</span><br><span class="line">    print(group)</span><br></pre></td></tr></table></figure><pre><code>down bad             OPEN  CLOSE   PCT_CHG standard expression2018-04-27  11.49  10.85 -4.991243     down        baddown good             OPEN  CLOSE   PCT_CHG standard expression2018-04-20  11.51  11.35 -1.046207     down       good2018-04-25  11.76  11.68 -1.517707     down       good2018-04-26  11.66  11.42 -2.226027     down       goodup good             OPEN  CLOSE   PCT_CHG standard expression2018-04-23  11.30  11.57  1.938326       up       good2018-04-24  11.63  11.86  2.506482       up       good</code></pre><p>当然，你可以对这些数据片段做任何操作。将这些数据片段做成一个字典：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pieces = dict(list(df4.groupby(<span class="string">'standard'</span>)))</span><br><span class="line">pieces</span><br></pre></td></tr></table></figure><pre><code>{&#39;down&#39;:              OPEN  CLOSE   PCT_CHG standard expression 2018-04-20  11.51  11.35 -1.046207     down       good 2018-04-25  11.76  11.68 -1.517707     down       good 2018-04-26  11.66  11.42 -2.226027     down       good 2018-04-27  11.49  10.85 -4.991243     down        bad, &#39;up&#39;:              OPEN  CLOSE   PCT_CHG standard expression 2018-04-23  11.30  11.57  1.938326       up       good 2018-04-24  11.63  11.86  2.506482       up       good}</code></pre><p>groupby默认是在<code>axis=0</code>上进行分组的。通过设置也可以对其他任何轴上进行分组。比如我们可以根据dtype对列进行分组：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df4.dtypes</span><br></pre></td></tr></table></figure><pre><code>OPEN          float64CLOSE         float64PCT_CHG       float64standard       objectexpression     objectdtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grouped = df4.groupby(df4.dtypes,axis=<span class="number">1</span>)</span><br><span class="line">dict(list(grouped))</span><br></pre></td></tr></table></figure><pre><code>{dtype(&#39;float64&#39;):              OPEN  CLOSE   PCT_CHG 2018-04-20  11.51  11.35 -1.046207 2018-04-23  11.30  11.57  1.938326 2018-04-24  11.63  11.86  2.506482 2018-04-25  11.76  11.68 -1.517707 2018-04-26  11.66  11.42 -2.226027 2018-04-27  11.49  10.85 -4.991243, dtype(&#39;O&#39;):            standard expression 2018-04-20     down       good 2018-04-23       up       good 2018-04-24       up       good 2018-04-25     down       good 2018-04-26     down       good 2018-04-27     down        bad}</code></pre><h4 id="2-9-3-选取一个或一组列"><a href="#2-9-3-选取一个或一组列" class="headerlink" title="2.9.3 选取一个或一组列"></a>2.9.3 选取一个或一组列</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df4.groupby([<span class="string">'standard'</span>,<span class="string">'expression'</span>])[[<span class="string">'CLOSE'</span>]].mean() <span class="comment"># 在['CLOSE']前后再多加一组[]即可</span></span><br></pre></td></tr></table></figure><p>氦核：再加一个中括号。</p><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th></th>      <th>CLOSE</th>    </tr>    <tr>      <th>standard</th>      <th>expression</th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <td rowspan="2" valign="top">down</td>      <td>bad</td>      <td>10.850000</td>    </tr>    <tr>      <td>good</td>      <td>11.483333</td>    </tr>    <tr>      <td>up</td>      <td>good</td>      <td>11.715000</td>    </tr>  </tbody></table></div><p>或者是以分组的Series:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s_grouped = df4.groupby([<span class="string">'standard'</span>,<span class="string">'expression'</span>])[<span class="string">'CLOSE'</span>]</span><br><span class="line">s_grouped.mean()</span><br></pre></td></tr></table></figure><pre><code>standard  expressiondown      bad           10.850000          good          11.483333up        good          11.715000Name: CLOSE, dtype: float64</code></pre><h4 id="2-9-4-通过字典或者Series进行分组"><a href="#2-9-4-通过字典或者Series进行分组" class="headerlink" title="2.9.4 通过字典或者Series进行分组"></a>2.9.4 通过字典或者Series进行分组</h4><p>除数组以外，分组信息还可以以其他形式存在。我们新构建一个DataFrame。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">error_code,df_wss = w.wss(<span class="string">"000001.SZ,000088.SZ,002626.SZ,600021.SH,600036.SH"</span>, <span class="string">"open,high,low,volume,amt,pct_chg"</span>, <span class="string">"tradeDate=2018-05-29;priceAdj=1;cycle=1"</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">df_wss</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>VOLUME</th>      <th>AMT</th>      <th>PCT_CHG</th>    </tr>  </thead>  <tbody>    <tr>      <td>000001.SZ</td>      <td>10.58</td>      <td>10.63</td>      <td>10.35</td>      <td>88949497.0</td>      <td>9.303870e+08</td>      <td>-1.983003</td>    </tr>    <tr>      <td>000088.SZ</td>      <td>7.65</td>      <td>7.79</td>      <td>7.61</td>      <td>9731389.0</td>      <td>7.493758e+07</td>      <td>-0.260756</td>    </tr>    <tr>      <td>002626.SZ</td>      <td>19.13</td>      <td>19.72</td>      <td>18.97</td>      <td>7058799.0</td>      <td>1.367769e+08</td>      <td>-0.679561</td>    </tr>    <tr>      <td>600021.SH</td>      <td>8.15</td>      <td>8.20</td>      <td>8.10</td>      <td>2065681.0</td>      <td>1.685831e+07</td>      <td>-0.368098</td>    </tr>    <tr>      <td>600036.SH</td>      <td>28.65</td>      <td>28.98</td>      <td>28.41</td>      <td>48053415.0</td>      <td>1.376605e+09</td>      <td>0.486111</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加几个空值NAN</span></span><br><span class="line">df_wss.ix[<span class="number">2</span>:<span class="number">3</span>, [<span class="string">'OPEN'</span>,<span class="string">'HIGH'</span>]] = np.nan</span><br><span class="line">df_wss</span><br></pre></td></tr></table></figure><pre><code>D:\anaconda\lib\site-packages\ipykernel_launcher.py:2: FutureWarning: .ix is deprecated. Please use.loc for label based indexing or.iloc for positional indexingSee the documentation here:http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated</code></pre><p>​    </p><p>氦核：依然不建议使用ix。</p><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>VOLUME</th>      <th>AMT</th>      <th>PCT_CHG</th>    </tr>  </thead>  <tbody>    <tr>      <td>000001.SZ</td>      <td>10.58</td>      <td>10.63</td>      <td>10.35</td>      <td>88949497.0</td>      <td>9.303870e+08</td>      <td>-1.983003</td>    </tr>    <tr>      <td>000088.SZ</td>      <td>7.65</td>      <td>7.79</td>      <td>7.61</td>      <td>9731389.0</td>      <td>7.493758e+07</td>      <td>-0.260756</td>    </tr>    <tr>      <td>002626.SZ</td>      <td>NaN</td>      <td>NaN</td>      <td>18.97</td>      <td>7058799.0</td>      <td>1.367769e+08</td>      <td>-0.679561</td>    </tr>    <tr>      <td>600021.SH</td>      <td>8.15</td>      <td>8.20</td>      <td>8.10</td>      <td>2065681.0</td>      <td>1.685831e+07</td>      <td>-0.368098</td>    </tr>    <tr>      <td>600036.SH</td>      <td>28.65</td>      <td>28.98</td>      <td>28.41</td>      <td>48053415.0</td>      <td>1.376605e+09</td>      <td>0.486111</td>    </tr>  </tbody></table></div><p>假设已知列的分组关系，并希望根据分组计算列的总和：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mapping = &#123;<span class="string">'OPEN'</span>:<span class="string">'r'</span>,<span class="string">'HIGH'</span>:<span class="string">'r'</span>,<span class="string">'LOW'</span>:<span class="string">'b'</span>,<span class="string">'VOLUME'</span>:<span class="string">'b'</span>,<span class="string">'AMT'</span>:<span class="string">'b'</span>,<span class="string">'PCT_CHG'</span>:<span class="string">'o'</span>&#125;</span><br></pre></td></tr></table></figure><p>只需要将这个字典传给groupby即可：（行方向）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">by_colum = df_wss.groupby(mapping,axis=<span class="number">1</span>)</span><br><span class="line">by_colum.sum()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>b</th>      <th>o</th>      <th>r</th>    </tr>  </thead>  <tbody>    <tr>      <td>000001.SZ</td>      <td>1.019336e+09</td>      <td>-1.983003</td>      <td>21.21</td>    </tr>    <tr>      <td>000088.SZ</td>      <td>8.466897e+07</td>      <td>-0.260756</td>      <td>15.44</td>    </tr>    <tr>      <td>002626.SZ</td>      <td>1.438358e+08</td>      <td>-0.679561</td>      <td>0.00</td>    </tr>    <tr>      <td>600021.SH</td>      <td>1.892400e+07</td>      <td>-0.368098</td>      <td>16.35</td>    </tr>    <tr>      <td>600036.SH</td>      <td>1.424658e+09</td>      <td>0.486111</td>      <td>57.63</td>    </tr>  </tbody></table></div><p>Series也有这样的功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">map_series = pd.Series(mapping)</span><br><span class="line">map_series</span><br></pre></td></tr></table></figure><pre><code>OPEN       rHIGH       rLOW        bVOLUME     bAMT        bPCT_CHG    odtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_wss.groupby(map_series,axis=<span class="number">1</span>).count()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>b</th>      <th>o</th>      <th>r</th>    </tr>  </thead>  <tbody>    <tr>      <td>000001.SZ</td>      <td>3</td>      <td>1</td>      <td>2</td>    </tr>    <tr>      <td>000088.SZ</td>      <td>3</td>      <td>1</td>      <td>2</td>    </tr>    <tr>      <td>002626.SZ</td>      <td>3</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <td>600021.SH</td>      <td>3</td>      <td>1</td>      <td>2</td>    </tr>    <tr>      <td>600036.SH</td>      <td>3</td>      <td>1</td>      <td>2</td>    </tr>  </tbody></table></div><h4 id="2-9-5-根据索引级别分组"><a href="#2-9-5-根据索引级别分组" class="headerlink" title="2.9.5 根据索引级别分组"></a>2.9.5 根据索引级别分组</h4><p>层次化索引数据最方便的地方就是在于它能够根据索引级别进行聚合。要实现该目的，通过level关键字传入级别编号或名称即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_wss</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>VOLUME</th>      <th>AMT</th>      <th>PCT_CHG</th>    </tr>  </thead>  <tbody>    <tr>      <td>000001.SZ</td>      <td>10.58</td>      <td>10.63</td>      <td>10.35</td>      <td>88949497.0</td>      <td>9.303870e+08</td>      <td>-1.983003</td>    </tr>    <tr>      <td>000088.SZ</td>      <td>7.65</td>      <td>7.79</td>      <td>7.61</td>      <td>9731389.0</td>      <td>7.493758e+07</td>      <td>-0.260756</td>    </tr>    <tr>      <td>002626.SZ</td>      <td>NaN</td>      <td>NaN</td>      <td>18.97</td>      <td>7058799.0</td>      <td>1.367769e+08</td>      <td>-0.679561</td>    </tr>    <tr>      <td>600021.SH</td>      <td>8.15</td>      <td>8.20</td>      <td>8.10</td>      <td>2065681.0</td>      <td>1.685831e+07</td>      <td>-0.368098</td>    </tr>    <tr>      <td>600036.SH</td>      <td>28.65</td>      <td>28.98</td>      <td>28.41</td>      <td>48053415.0</td>      <td>1.376605e+09</td>      <td>0.486111</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">columns = pd.MultiIndex.from_arrays([[<span class="string">'行情'</span>,<span class="string">'行情'</span>,<span class="string">'行情'</span>,<span class="string">'量'</span>,<span class="string">'量'</span>,<span class="string">'幅度'</span>],</span><br><span class="line">                                     [<span class="string">'OPEN'</span>,<span class="string">'HIGH'</span>,<span class="string">'LOW'</span>,<span class="string">'VOLUME'</span>,<span class="string">'AMT'</span>,<span class="string">'PCT_CHG'</span>]],names=[<span class="string">'s1'</span>,<span class="string">'s2'</span>])</span><br><span class="line">hier_df = pd.DataFrame(df_wss.values, columns=columns,index=df_wss.index)</span><br><span class="line">hier_df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead tr th {        text-align: left;    }</style><table border="1" class="dataframe">  <thead>    <tr>      <th>s1</th>      <th colspan="3" halign="left">行情</th>      <th colspan="2" halign="left">量</th>      <th>幅度</th>    </tr>    <tr>      <th>s2</th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>VOLUME</th>      <th>AMT</th>      <th>PCT_CHG</th>    </tr>  </thead>  <tbody>    <tr>      <td>000001.SZ</td>      <td>10.58</td>      <td>10.63</td>      <td>10.35</td>      <td>88949497.0</td>      <td>9.303870e+08</td>      <td>-1.983003</td>    </tr>    <tr>      <td>000088.SZ</td>      <td>7.65</td>      <td>7.79</td>      <td>7.61</td>      <td>9731389.0</td>      <td>7.493758e+07</td>      <td>-0.260756</td>    </tr>    <tr>      <td>002626.SZ</td>      <td>NaN</td>      <td>NaN</td>      <td>18.97</td>      <td>7058799.0</td>      <td>1.367769e+08</td>      <td>-0.679561</td>    </tr>    <tr>      <td>600021.SH</td>      <td>8.15</td>      <td>8.20</td>      <td>8.10</td>      <td>2065681.0</td>      <td>1.685831e+07</td>      <td>-0.368098</td>    </tr>    <tr>      <td>600036.SH</td>      <td>28.65</td>      <td>28.98</td>      <td>28.41</td>      <td>48053415.0</td>      <td>1.376605e+09</td>      <td>0.486111</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hier_df.groupby(level=<span class="string">'s1'</span>,axis=<span class="number">1</span>).count()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>s1</th>      <th>幅度</th>      <th>行情</th>      <th>量</th>    </tr>  </thead>  <tbody>    <tr>      <td>000001.SZ</td>      <td>1</td>      <td>3</td>      <td>2</td>    </tr>    <tr>      <td>000088.SZ</td>      <td>1</td>      <td>3</td>      <td>2</td>    </tr>    <tr>      <td>002626.SZ</td>      <td>1</td>      <td>1</td>      <td>2</td>    </tr>    <tr>      <td>600021.SH</td>      <td>1</td>      <td>3</td>      <td>2</td>    </tr>    <tr>      <td>600036.SH</td>      <td>1</td>      <td>3</td>      <td>2</td>    </tr>  </tbody></table></div><p>（完）</p><p>依然鸣谢：某大哥假粉。愿四下空虚的灵魂皆能得以慰藉。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最后编辑于：2020.02.06 18:00&lt;/p&gt;
&lt;h2 id=&quot;Pandas库&quot;&gt;&lt;a href=&quot;#Pandas库&quot; class=&quot;headerlink&quot; title=&quot;Pandas库&quot;&gt;&lt;/a&gt;Pandas库&lt;/h2&gt;&lt;p&gt;Pandas是基于NumPy 的一种工具，其出现是为了解决数据分析任务。（氦核：个人觉得更像是探索工具，没有模型，简单分析。）&lt;br&gt;Pandas吸纳了大量库和一些标准的数据模型，提供了高效操作大型数据集所需的工具。&lt;br&gt;Pandas中的函数和方法能够使我们快速便捷地处理数据。&lt;br&gt;它是使Python成为强大而高效的数据分析环境的重要因素之一。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://pandas.pydata.org/pandas-docs/stable/api.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://pandas.pydata.org/pandas-docs/stable/api.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文参考&lt;a href=&quot;https://www.windquant.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;万旷网教程&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据分析" scheme="https://konelane.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>python联萌|今天康康numpy（怒骂朋友库</title>
    <link href="https://konelane.github.io/2020/02/05/200205numpy/"/>
    <id>https://konelane.github.io/2020/02/05/200205numpy/</id>
    <published>2020-02-04T16:00:00.000Z</published>
    <updated>2020-02-05T05:26:34.465Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最后编辑于：2020.02.05 12:30</p><h2 id="Numpy库"><a href="#Numpy库" class="headerlink" title="Numpy库"></a>Numpy库</h2><p>Numpy库是Python的一种开源的数值计算扩展。</p><p>Numpy可用来存储和处理大型矩阵，比Python自身的嵌套列表结构要高效很多。</p><p>据说Numpy将Pyhon变成了一种免费的更强大的Matlab系统。</p><p>本文介绍性文字转载自<a href="https://www.windquant.com/" target="_blank" rel="noopener">万旷网</a>。氦核感觉notebook形式更适合学习，有机会把丘比特文件给大家附上。</p><a id="more"></a><p>Numpy库包含了：</p><p>&gt;</p><blockquote><p>强大的N维数组对象<br>精密的函数<br>连接C/C++和Fortran代码的工具<br>常用的线性代数，傅里叶变换和随机数生成  </p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先导入 numpy 库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><p>氦核：惯用的导入法，最好延用。</p><h2 id="一、数组array"><a href="#一、数组array" class="headerlink" title="一、数组array"></a>一、数组array</h2><p>数组array和列表list类似，但是数据array可以定义维度，且适合做数学代数运算</p><h3 id="1-数组array生成"><a href="#1-数组array生成" class="headerlink" title="1.数组array生成"></a>1.数组array生成</h3><p>数据使用windapi提取。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> WindPy <span class="keyword">import</span> *</span><br><span class="line">w.start()</span><br><span class="line">a = w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"close"</span>, <span class="string">"2018-07-05"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>)</span><br><span class="line">b = w.wsd(<span class="string">"000002.SZ"</span>, <span class="string">"close,open"</span>, <span class="string">"2018-07-05"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>)</span><br><span class="line">b</span><br></pre></td></tr></table></figure><p>氦核：取的是收盘价和开盘价。</p><pre><code>.ErrorCode=0.Codes=[000002.SZ].Fields=[CLOSE,OPEN].Times=[20180705,20180706,20180709,20180710,20180711].Data=[[23.05,23.21,24.01,24.15,23.46],[23.02,23.34,23.37,24.2,23.48]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a1 = np.array(a.Data[<span class="number">0</span>])</span><br><span class="line">a2 = np.array(b.Data)</span><br><span class="line">print(<span class="string">'这是一个一维数组：\n'</span>,a1)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'这是一个二维数组：\n'</span>,a2)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看a1的长度：\n'</span>,len(a1))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看a2的长度：\n'</span>,len(a2))</span><br></pre></td></tr></table></figure><p>氦核：len可以求数组长度，指数组里有几个list。</p><pre><code>这是一个一维数组： [8.6  8.66 9.03 8.98 8.78]这是一个二维数组： [[23.05 23.21 24.01 24.15 23.46] [23.02 23.34 23.37 24.2  23.48]]查看a1的长度： 5查看a2的长度： 2</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a2</span><br></pre></td></tr></table></figure><pre><code>array([[23.05, 23.21, 24.01, 24.15, 23.46],       [23.02, 23.34, 23.37, 24.2 , 23.48]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a2[<span class="number">0</span>,<span class="number">1</span>]</span><br></pre></td></tr></table></figure><pre><code>23.21</code></pre><h3 id="1-2-数组array性质"><a href="#1-2-数组array性质" class="headerlink" title="1.2 数组array性质"></a>1.2 数组array性质</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''数组元素整数转化为浮点数'''</span></span><br><span class="line">print(<span class="string">'数组类型：'</span>,a1.dtype)</span><br><span class="line">float_arr = a1.astype(np.int)</span><br><span class="line">print(<span class="string">'改变数组类型后：'</span>,float_arr.dtype)</span><br></pre></td></tr></table></figure><p>氦核：dtype可以查看类型，astype可以转换类型。不同类型变换后会产生不同结果。</p><pre><code>数组类型： float64改变数组类型后： int32</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''字符串数字转化为浮点数'''</span></span><br><span class="line">numeric_string = np.array([<span class="string">'1.11'</span>,<span class="string">'2.22'</span>,<span class="string">'3.33'</span>])</span><br><span class="line">print(numeric_string, numeric_string.dtype)</span><br><span class="line">print(numeric_string.astype(np.float),numeric_string.astype(np.float).dtype)</span><br></pre></td></tr></table></figure><pre><code>[&#39;1.11&#39; &#39;2.22&#39; &#39;3.33&#39;] &lt;U4[1.11 2.22 3.33] float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''字符串数字转化为浮点数'''</span></span><br><span class="line">numeric_string = np.array([<span class="string">'1.11'</span>,<span class="string">'2.22'</span>,<span class="string">'3.33'</span>])</span><br><span class="line">print(numeric_string, numeric_string.dtype)</span><br><span class="line">print(numeric_string.astype(np.float),numeric_string.astype(np.float).dtype)</span><br></pre></td></tr></table></figure><pre><code>[&#39;1.11&#39; &#39;2.22&#39; &#39;3.33&#39;] &lt;U4[1.11 2.22 3.33] float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">print(a2)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'第二行第三列元素(第二行索引为1，第三列索引为2)：\n'</span>,a2[<span class="number">1</span>,<span class="number">2</span>]) </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'倒数第一行(注意索引为-1)：\n'</span>,a2[<span class="number">-1</span>,:]) </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'第三列(索引为2)：\n'</span>,a2[:,<span class="number">2</span>])</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'a2形状：\n'</span>,a2.shape)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'a2形状重构：\n'</span>,a2.reshape(<span class="number">5</span>,<span class="number">2</span>))</span><br></pre></td></tr></table></figure><pre><code>[[23.05 23.21 24.01 24.15 23.46] [23.02 23.34 23.37 24.2  23.48]]第二行第三列元素(第二行索引为1，第三列索引为2)： 23.37倒数第一行(注意索引为-1)： [23.02 23.34 23.37 24.2  23.48]第三列(索引为2)： [24.01 23.37]a2形状： (2, 5)a2形状重构： [[23.05 23.21] [24.01 24.15] [23.46 23.02] [23.34 23.37] [24.2  23.48]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'维度解锁：'</span>,a2.ravel())  <span class="comment">#  ravel()函数可以将高维数组转化为一维数组</span></span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按列求和：'</span>,a2.sum(axis=<span class="number">0</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按列求积：'</span>,a2.prod(axis=<span class="number">0</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'全局最大值：'</span>,a2.max(),<span class="string">'全局最小值：'</span>,a2.min())</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按行求最大值：'</span>,a2.max(axis=<span class="number">0</span>),<span class="string">'按列求最小值：'</span>,a2.min(axis=<span class="number">1</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按列求均值：'</span>,a2.mean(axis=<span class="number">0</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按行求标准差：'</span>,a2.std(axis=<span class="number">0</span>))</span><br></pre></td></tr></table></figure><pre><code>维度解锁： [23.05 23.21 24.01 24.15 23.46 23.02 23.34 23.37 24.2  23.48]按列求和： [46.07 46.55 47.38 48.35 46.94]按列求积： [530.611  541.7214 561.1137 584.43   550.8408]全局最大值： 24.2 全局最小值： 23.02按行求最大值： [23.05 23.34 24.01 24.2  23.48] 按列求最小值： [23.05 23.02]按列求均值： [23.035 23.275 23.69  24.175 23.47 ]按行求标准差： [0.015 0.065 0.32  0.025 0.01 ]</code></pre><p>氦核：这些计算都是可以接受方向的。按列或按行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'原矩阵：\n'</span>,a2)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按列求和：\n'</span>,a2.sum(axis=<span class="number">0</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按行求均值：\n'</span>,a2.mean(axis=<span class="number">1</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按行累加：\n'</span>,a2.cumsum(axis=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><pre><code>原矩阵： [[23.05 23.21 24.01 24.15 23.46] [23.02 23.34 23.37 24.2  23.48]]按列求和： [46.07 46.55 47.38 48.35 46.94]按行求均值： [23.576 23.482]按行累加： [[ 23.05  46.26  70.27  94.42 117.88] [ 23.02  46.36  69.73  93.93 117.41]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'矩阵所有元素求指数：\n'</span>,np.exp(a2))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵所有元素求根号：\n'</span>,np.sqrt(a2))</span><br></pre></td></tr></table></figure><p>氦核：np.exp功能是“求e的幂次方”。</p><pre><code>矩阵所有元素求指数： [[1.02444302e+10 1.20219502e+10 2.67553422e+10 3.07759692e+10  1.54364896e+10] [9.94166153e+09 1.36909381e+10 1.41078893e+10 3.23538868e+10  1.57483274e+10]]矩阵所有元素求根号： [[4.80104155 4.81767579 4.9        4.91426495 4.84355242] [4.79791621 4.83114893 4.83425279 4.91934955 4.84561658]]</code></pre><p>小数位数控制和取整</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'小数位数：\n'</span>,a1.round(decimals=<span class="number">2</span>)) <span class="comment">#控制小数位数</span></span><br></pre></td></tr></table></figure><pre><code>小数位数： [8.6  8.66 9.03 8.98 8.78]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'原数组：\n'</span>,a1)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'向上取整：\n'</span>,np.floor(a1))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'向下取整：\n'</span>,np.ceil(a1))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'四舍五入(控制小数为2位)：\n'</span>,np.round(a1,<span class="number">2</span>))</span><br></pre></td></tr></table></figure><pre><code>原数组： [8.6  8.66 9.03 8.98 8.78]向上取整： [8. 8. 9. 8. 8.]向下取整： [ 9.  9. 10.  9.  9.]四舍五入(控制小数为2位)： [8.6  8.66 9.03 8.98 8.78]</code></pre><h4 id="数组——一元函数"><a href="#数组——一元函数" class="headerlink" title="数组——一元函数"></a>数组——一元函数</h4><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>abs、fabs</td><td>计算整数、浮点数或复数的绝对值。对于非复数，使用fabs更快</td></tr><tr><td>sqrt、square、exp</td><td>计算各元素的平方根、平方、指数𝑒𝑥</td></tr><tr><td>log、log10、log2、log1p</td><td>自然对数、底数10的对数、底数2的对数、𝑙𝑛(1+𝑥)</td></tr><tr><td>sign</td><td>计算各元素的正负号：正1,零0,负-1</td></tr><tr><td>ceil</td><td>计算各元素的取整：大于等于该数的最小整数</td></tr><tr><td>floor</td><td>计算各元素的取整：小于等于该数的最大整数</td></tr><tr><td>rint</td><td>各元素四舍五入最接近的整数，dtype不变</td></tr><tr><td>modf</td><td>将数组各元素的小数和整数部分以两个独立数组的形式返回</td></tr><tr><td>isnan、isfinite、isinf</td><td>判断各元素是否为NaN、是否有穷、是否为无穷</td></tr><tr><td>cos、cosh、sin、sinh、tan、tanh</td><td>一般和双曲型的三角函数</td></tr><tr><td>arccos、arccosh、arcsin、arcsinh、arctan、arctanh</td><td>反三角函数</td></tr><tr><td>sum、mean</td><td>数组全部或者按某个轴的方向进行求和、求均值</td></tr><tr><td>std、var</td><td>标准差、方差，自由度可以调整</td></tr><tr><td>min、max、argmin、argmax</td><td>最小和最大值、最小和最大元素的索引</td></tr><tr><td>cumsum、cumprod</td><td>数组全部或者按某个轴的方向进行累计和、累计积</td></tr></tbody></table></div><h3 id="1-3-数组array间运算"><a href="#1-3-数组array间运算" class="headerlink" title="1.3 数组array间运算"></a>1.3 数组array间运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">c, r = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]), np.array([<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">print(c)</span><br><span class="line">print(r)</span><br></pre></td></tr></table></figure><pre><code>[1 2 3 4][2 3 4 5]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'数组相加：'</span>,c + r)</span><br><span class="line">print(<span class="string">'数组相乘：'</span>,c * r)</span><br><span class="line">print(<span class="string">'数组乘方：'</span>,c **r)</span><br><span class="line">print(<span class="string">'数组判断：'</span>,c &gt;= <span class="number">2</span>)</span><br><span class="line">print(<span class="string">'向量内积：'</span>,c.dot(r.T))</span><br></pre></td></tr></table></figure><pre><code>数组相加： [3 5 7 9]数组相乘： [ 2  6 12 20]数组乘方： [   1    8   81 1024]数组判断： [False  True  True  True]向量内积： 40</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'取两个数组中的较大值组成新的数组：'</span>,np.maximum(c,r))</span><br><span class="line">print(<span class="string">'取两个数组中的较小者组成新的数组：'</span>,np.minimum(c,r))</span><br></pre></td></tr></table></figure><pre><code>取两个数组中的较大值组成新的数组： [2 3 4 5]取两个数组中的较小者组成新的数组： [1 2 3 4]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x1 = np.array([<span class="keyword">True</span>,<span class="keyword">False</span>,<span class="keyword">True</span>])</span><br><span class="line">x2 = np.array([<span class="keyword">False</span>,<span class="keyword">False</span>,<span class="keyword">True</span>])</span><br><span class="line">print(x1)</span><br><span class="line">print(x2)</span><br><span class="line">print(np.logical_and(x1,x2))</span><br><span class="line">print(np.logical_or(x1,x2))</span><br><span class="line">print(np.logical_xor(x1,x2))</span><br></pre></td></tr></table></figure><p>氦核：逻辑运算一样很简单，logical_xor是异或运算。一般逻辑函数用于检验数组内容，筛选出需要的元素（通常得到的是位置）。可以完成“检查a中元素是否存在于b中”这样的问题。简便操作详细见下面集合运算。</p><pre><code>[ True False  True][False False  True][False False  True][ True False  True][ True False False]</code></pre><h4 id="数组——二元函数"><a href="#数组——二元函数" class="headerlink" title="数组——二元函数"></a>数组——二元函数</h4><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>add、multiply</td><td>数组中对应的元素相加、相乘</td></tr><tr><td>substract</td><td>第一个数组减去第二个数组中的元素</td></tr><tr><td>divide、floor_divide</td><td>除法、向下圆整除法(余数直接舍弃)</td></tr><tr><td>power</td><td>对于第一个数组中的元素，根据第二个数组中的对应元素，进行幂运算</td></tr><tr><td>maximum、fmax</td><td>元素级的最大值、fmax功能相同只是忽略NaN</td></tr><tr><td>minimum、fmin</td><td>元素级的最小值、fmin功能相同只是忽略NaN</td></tr><tr><td>mod</td><td>元素级的求余</td></tr><tr><td>copysign</td><td>将第二个数组中的值的符号复制给第一个数组中的值</td></tr><tr><td>greater、greater_equal、less、less_equal、equal、not_equal</td><td>元素级的比较运算，产生True或者False为元素的数组</td></tr><tr><td>logical_and、logical_or、logical_xor</td><td>元素级的逻辑判断(且、或者、不等于)</td></tr></tbody></table></div><h3 id="1-4-数组array集合运算"><a href="#1-4-数组array集合运算" class="headerlink" title="1.4 数组array集合运算"></a>1.4 数组array集合运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>])</span><br><span class="line">y = np.array([<span class="number">100</span>,<span class="number">20</span>,<span class="number">40</span>,<span class="number">10</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">print(<span class="string">'数组x中的唯一元素：\n'</span>,np.unique(x))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'数组x和y的公共元素：\n'</span>,np.intersect1d(x,y))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'数组x和y的并集：\n'</span>,np.union1d(x,y))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'数组x中的元素是否包含于y：\n'</span>,np.in1d(x,y))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'集合差_在x中而不在y中的元素：\n'</span>,np.setdiff1d(x,y))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'只存在某个数组中，而不同时存在于两个数组中：\n'</span>,np.setxor1d(x,y))</span><br></pre></td></tr></table></figure><pre><code>数组x中的唯一元素： [ 1  2  3  4  5 10 20 30]数组x和y的公共元素： [ 1  2  3 10 20]数组x和y的并集： [  1   2   3   4   5  10  20  30  40 100]数组x中的元素是否包含于y： [ True  True  True  True  True  True False False  True  True  True False]集合差_在x中而不在y中的元素： [ 4  5 30]只存在某个数组中，而不同时存在于两个数组中： [  4   5  30  40 100]</code></pre><h3 id="1-5-数组array切片进阶"><a href="#1-5-数组array切片进阶" class="headerlink" title="1.5 数组array切片进阶"></a>1.5 数组array切片进阶</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#还是以000001收盘价为例</span></span><br><span class="line">a1</span><br></pre></td></tr></table></figure><pre><code>array([8.6 , 8.66, 9.03, 8.98, 8.78])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果我们想 按偶数来选取 即选择数组中的0,2,4,6,8</span></span><br><span class="line">print(a1[::<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果想 按奇数来选择呢</span></span><br><span class="line">print(a1[<span class="number">1</span>::<span class="number">2</span>]) <span class="comment">#这里的1表示从索引1开始截取</span></span><br></pre></td></tr></table></figure><p>氦核：上面片段中的2代表步长。</p><pre><code>[8.6  9.03 8.78][8.66 8.98]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#我们取多个指标看一下</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#五粮液</span></span><br><span class="line"><span class="keyword">from</span> WindPy <span class="keyword">import</span> *</span><br><span class="line">w.start()</span><br><span class="line">w = w.wsd(<span class="string">"000858.SZ"</span>, <span class="string">"open,high,low,close,pct_chg"</span>, <span class="string">"2018-07-05"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>)</span><br><span class="line">w</span><br></pre></td></tr></table></figure><p>氦核：开，高，低，收。</p><pre><code>.ErrorCode=0.Codes=[000858.SZ].Fields=[OPEN,HIGH,LOW,CLOSE,PCT_CHG].Times=[20180705,20180706,20180709,20180710,20180711].Data=[[71.69,69.9,71.58,73.57,71.2],[72.71,71.98,73.55,74.13,72.64],[69.7,68.88,70.4,72.08,70.93],[70.82,70.62,73.54,73.37,72.08],[0.16973125884014886,1.5822798147378172,4.134806003964902,-0.23116671199347652,-1.7582118031893383]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w1 = np.array(w.Data)</span><br><span class="line">w1</span><br></pre></td></tr></table></figure><pre><code>array([[71.69      , 69.9       , 71.58      , 73.57      , 71.2       ],       [72.71      , 71.98      , 73.55      , 74.13      , 72.64      ],       [69.7       , 68.88      , 70.4       , 72.08      , 70.93      ],       [70.82      , 70.62      , 73.54      , 73.37      , 72.08      ],       [ 0.16973126,  1.58227981,  4.134806  , -0.23116671, -1.7582118 ]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'截取第1行第4,5个元素：\n'</span>,w1[<span class="number">0</span>, <span class="number">3</span>:<span class="number">5</span>])</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'截取第5行至最后，第5列至最后的元素：\n'</span>,w1[<span class="number">4</span>:, <span class="number">4</span>:])</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'截取第3，5行，第1,3,5列\n'</span>,w1[<span class="number">2</span>::<span class="number">2</span>, ::<span class="number">2</span>])</span><br></pre></td></tr></table></figure><pre><code>截取第1行第4,5个元素： [73.57 71.2 ]截取第5行至最后，第5列至最后的元素： [[-1.7582118]]截取第3，5行，第1,3,5列 [[69.7        70.4        70.93      ] [ 0.16973126  4.134806   -1.7582118 ]]</code></pre><h3 id="1-6-数组排序"><a href="#1-6-数组排序" class="headerlink" title="1.6 数组排序"></a>1.6 数组排序</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> WindPy <span class="keyword">import</span> *</span><br><span class="line">w.start()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 000001.SZ收益率为例</span></span><br><span class="line">sy = w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"pct_chg"</span>, <span class="string">"2018-07-05"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>)</span><br><span class="line">sy</span><br></pre></td></tr></table></figure><pre><code>.ErrorCode=0.Codes=[000001.SZ].Fields=[PCT_CHG].Times=[20180705,20180706,20180709,20180710,20180711].Data=[[-0.11614401858303243,0.6976744186046501,4.272517321016162,-0.5537098560354228,-2.2271714922049117]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sy2 = np.array(sy.Data[<span class="number">0</span>])</span><br><span class="line">sy2</span><br></pre></td></tr></table></figure><pre><code>array([-0.11614402,  0.69767442,  4.27251732, -0.55370986, -2.22717149])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对一个数组array，想找到其中大于0的数所在的索引位置 可以用where函数</span></span><br><span class="line">print(<span class="string">'大于0元素所在的索引：\n'</span>,np.where(sy2&gt;<span class="number">0</span>))</span><br></pre></td></tr></table></figure><pre><code>大于0元素所在的索引： (array([1, 2], dtype=int64),)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于exp这个数组，希望对其按元素大小进行排序</span></span><br><span class="line">print(<span class="string">'从小到大排序：\n'</span>,np.sort(sy2))</span><br></pre></td></tr></table></figure><pre><code>从小到大排序： [-2.22717149 -0.55370986 -0.11614402  0.69767442  4.27251732]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'排序后元素所在的原索引位置'</span>,np.argsort(sy2))</span><br></pre></td></tr></table></figure><pre><code>排序后元素所在的原索引位置 [4 3 0 1 2]</code></pre><h3 id="1-7-数组拼接"><a href="#1-7-数组拼接" class="headerlink" title="1.7 数组拼接"></a>1.7 数组拼接</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a1</span><br></pre></td></tr></table></figure><pre><code>array([8.6 , 8.66, 9.03, 8.98, 8.78])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a3 = np.array(w.wsd(<span class="string">"000858.SZ"</span>, <span class="string">"close"</span>, <span class="string">"2018-07-05"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>).Data)[<span class="number">0</span>]</span><br><span class="line">a3</span><br></pre></td></tr></table></figure><pre><code>array([70.82, 70.62, 73.54, 73.37, 72.08])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'纵向拼接:\n'</span>,np.vstack((a1,a3)))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'横向拼接:\n'</span>,np.hstack((a1,a3)))</span><br></pre></td></tr></table></figure><pre><code>纵向拼接: [[ 8.6   8.66  9.03  8.98  8.78] [70.82 70.62 73.54 73.37 72.08]]横向拼接: [ 8.6   8.66  9.03  8.98  8.78 70.82 70.62 73.54 73.37 72.08]</code></pre><p>使用np.r_和np.c_也可以实现拼接的功能</p><p>注意纵向拼接的时候，np.c_产生的结果是5∗2，而np.r_产生的结果是2∗5</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'横向拼接：\n'</span>,np.r_[a1,a3])</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'纵向拼接：\n'</span>,np.c_[a1,a3])</span><br></pre></td></tr></table></figure><pre><code>横向拼接： [ 8.6   8.66  9.03  8.98  8.78 70.82 70.62 73.54 73.37 72.08]纵向拼接： [[ 8.6  70.82] [ 8.66 70.62] [ 9.03 73.54] [ 8.98 73.37] [ 8.78 72.08]]</code></pre><h3 id="1-8-数组分解"><a href="#1-8-数组分解" class="headerlink" title="1.8 数组分解"></a>1.8 数组分解</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a4 = np.array(w.wsd(<span class="string">"000858.SZ"</span>, <span class="string">"close,open,low"</span>, <span class="string">"2018-07-05"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>).Data)</span><br><span class="line">a4</span><br></pre></td></tr></table></figure><pre><code>array([[70.82, 70.62, 73.54, 73.37, 72.08],       [71.69, 69.9 , 71.58, 73.57, 71.2 ],       [69.7 , 68.88, 70.4 , 72.08, 70.93]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'横向分解为5个数组：\n'</span>,np.hsplit(a4,<span class="number">5</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'纵向分解为3个数组：\n'</span>,np.vsplit(a4,<span class="number">3</span>))</span><br></pre></td></tr></table></figure><pre><code>横向分解为5个数组： [array([[70.82],       [71.69],       [69.7 ]]), array([[70.62],       [69.9 ],       [68.88]]), array([[73.54],       [71.58],       [70.4 ]]), array([[73.37],       [73.57],       [72.08]]), array([[72.08],       [71.2 ],       [70.93]])]纵向分解为3个数组： [array([[70.82, 70.62, 73.54, 73.37, 72.08]]), array([[71.69, 69.9 , 71.58, 73.57, 71.2 ]]), array([[69.7 , 68.88, 70.4 , 72.08, 70.93]])]</code></pre><h2 id="二、常用数组"><a href="#二、常用数组" class="headerlink" title="二、常用数组"></a>二、常用数组</h2><p>在工作或者学习中，有些数组是我们常用的，利用numpy中的函数可以容易地产生这些数组。</p><h3 id="2-1-np-arange-起始数，终止数，间隔"><a href="#2-1-np-arange-起始数，终止数，间隔" class="headerlink" title="2.1 np.arange(起始数，终止数，间隔)"></a>2.1 np.arange(起始数，终止数，间隔)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># np.arange()函数 终止数并不产生 </span></span><br><span class="line">print(np.arange(<span class="number">1</span>,<span class="number">10</span>,<span class="number">1</span>)) </span><br><span class="line">print()</span><br><span class="line">print(np.arange(<span class="number">1</span>,<span class="number">10</span>,<span class="number">0.1</span>))</span><br></pre></td></tr></table></figure><pre><code>[1 2 3 4 5 6 7 8 9][1.  1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.  2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 3.  3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9 4.  4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9 5.  5.1 5.2 5.3 5.4 5.5 5.6 5.7 5.8 5.9 6.  6.1 6.2 6.3 6.4 6.5 6.6 6.7 6.8 6.9 7.  7.1 7.2 7.3 7.4 7.5 7.6 7.7 7.8 7.9 8.  8.1 8.2 8.3 8.4 8.5 8.6 8.7 8.8 8.9 9.  9.1 9.2 9.3 9.4 9.5 9.6 9.7 9.8 9.9]</code></pre><h3 id="2-2-np-linspace-起始数-终止数-产生数的个数"><a href="#2-2-np-linspace-起始数-终止数-产生数的个数" class="headerlink" title="2.2 np.linspace(起始数,终止数,产生数的个数)"></a>2.2 np.linspace(起始数,终止数,产生数的个数)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在指定区间返回均匀间隔的数字</span></span><br><span class="line">print(np.linspace(<span class="number">1</span>,<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">print()</span><br><span class="line">print(np.linspace(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">20</span>))</span><br><span class="line"><span class="comment"># np.linspace()函数 终止数是产生的</span></span><br></pre></td></tr></table></figure><pre><code>[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.][-1.         -0.89473684 -0.78947368 -0.68421053 -0.57894737 -0.47368421 -0.36842105 -0.26315789 -0.15789474 -0.05263158  0.05263158  0.15789474  0.26315789  0.36842105  0.47368421  0.57894737  0.68421053  0.78947368  0.89473684  1.        ]</code></pre><h3 id="2-3-常用矩阵"><a href="#2-3-常用矩阵" class="headerlink" title="2.3 常用矩阵"></a>2.3 常用矩阵</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'元素都为1的方阵：\n'</span>,np.ones((<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'元素都为0的方阵：\n'</span>,np.zeros((<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'单位阵：\n'</span>,np.eye(<span class="number">3</span>))</span><br></pre></td></tr></table></figure><pre><code>元素都为1的方阵： [[1. 1. 1.] [1. 1. 1.] [1. 1. 1.]]元素都为0的方阵： [[0. 0. 0.] [0. 0. 0.] [0. 0. 0.]]单位阵： [[1. 0. 0.] [0. 1. 0.] [0. 0. 1.]]</code></pre><h3 id="2-4-np-tile-函数"><a href="#2-4-np-tile-函数" class="headerlink" title="2.4 np.tile()函数"></a>2.4 np.tile()函数</h3><p>该函数的作用是重复某个对象为一定的结构</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">short = np.arange(<span class="number">1</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line">print(short)</span><br><span class="line">long = np.tile(short,<span class="number">3</span>)</span><br><span class="line">print(long)</span><br></pre></td></tr></table></figure><pre><code>[1 2 3][1 2 3 1 2 3 1 2 3]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">small = np.eye(<span class="number">2</span>)</span><br><span class="line">print(small)</span><br><span class="line">big = np.tile(small, (<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">print(big)</span><br></pre></td></tr></table></figure><pre><code>[[1. 0.] [0. 1.]][[1. 0. 1. 0.] [0. 1. 0. 1.] [1. 0. 1. 0.] [0. 1. 0. 1.]]</code></pre><h2 id="三、Numpy常用常量"><a href="#三、Numpy常用常量" class="headerlink" title="三、Numpy常用常量"></a>三、Numpy常用常量</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'自然底数：'</span>,np.e)</span><br><span class="line">print(<span class="string">'缺失值：'</span>,np.NaN)</span><br><span class="line">print(<span class="string">'无穷大：'</span>,np.inf)</span><br><span class="line">print(<span class="string">'圆周率：'</span>,np.pi)</span><br></pre></td></tr></table></figure><pre><code>自然底数： 2.718281828459045缺失值： nan无穷大： inf圆周率： 3.141592653589793</code></pre><h2 id="四、Numpy随机数产生"><a href="#四、Numpy随机数产生" class="headerlink" title="四、Numpy随机数产生"></a>四、Numpy随机数产生</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'一维正态随机数：\n'</span>,np.random.randn(<span class="number">5</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'二维正态随机数：\n'</span>,np.random.randn(<span class="number">2</span>,<span class="number">2</span>)) </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'二维0-1均匀分布随机数：\n'</span>,np.random.rand(<span class="number">2</span>,<span class="number">2</span>))   </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'5个10-20的均匀随机整数：'</span>,np.random.randint(<span class="number">10</span>,<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'二维均匀随机整数：\n'</span>,np.random.randint(<span class="number">10</span>,<span class="number">50</span>,(<span class="number">2</span>,<span class="number">2</span>)))</span><br></pre></td></tr></table></figure><pre><code>一维正态随机数： [-0.65240628  1.07426523 -0.86730208 -0.91339241  1.20066541]二维正态随机数： [[ 0.9663628  -1.32891237] [-0.54264665 -1.29035995]]二维0-1均匀分布随机数： [[0.52527192 0.17719291] [0.10103986 0.41623399]]5个10-20的均匀随机整数： [17 18 14 12 11]二维均匀随机整数： [[38 24] [24 38]]</code></pre><p><strong>numpy.random函数</strong></p><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>seed</td><td>随机数生成器的种子</td></tr><tr><td>permutation</td><td>序列的随机排列或者随机排列的范围，不改变原数组</td></tr><tr><td>shuffle</td><td>序列就地随机排列，改变原数组</td></tr><tr><td>rand</td><td>均匀分布样本值</td></tr><tr><td>randint</td><td>给定上下限随机产生整数</td></tr><tr><td>randn</td><td>正态分布样本值</td></tr><tr><td>binomial</td><td>二项分布样本值</td></tr><tr><td>normal</td><td>正态分布样本值</td></tr><tr><td>beta</td><td>beta分布样本值</td></tr><tr><td>chisquare</td><td>卡方分布样本值</td></tr><tr><td>gamma</td><td>Gamma分布样本值</td></tr><tr><td>uniform</td><td>[0,1)均匀分布样本值</td></tr><tr><td>choice</td><td>从数组中随机选择若干个元素</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">1</span>,<span class="number">11</span>,<span class="number">1</span>)</span><br><span class="line">print(a)</span><br><span class="line">np.random.shuffle(a)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'随机打乱a中的元素顺序：\n'</span>,a)</span><br></pre></td></tr></table></figure><pre><code>[ 1  2  3  4  5  6  7  8  9 10]随机打乱a中的元素顺序： [10  3  2  6  1  9  8  7  4  5]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(a)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'随机从a中选取5个元素：\n'</span>,np.random.choice(a,<span class="number">5</span>))</span><br></pre></td></tr></table></figure><pre><code>[10  3  2  6  1  9  8  7  4  5]随机从a中选取5个元素： [5 3 8 9 4]</code></pre><h2 id="五、Numpy矩阵性质"><a href="#五、Numpy矩阵性质" class="headerlink" title="五、Numpy矩阵性质"></a>五、Numpy矩阵性质</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">print(<span class="string">'原矩阵：\n'</span>,x)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵对角线：\n'</span>,np.diag(x))  </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵上三角：\n'</span>,np.triu(x))  </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵下三角：\n'</span>,np.tril(x))  </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵的迹：\n'</span>,np.trace(x))  </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵的转置：\n'</span>,x.T)</span><br></pre></td></tr></table></figure><pre><code>原矩阵： [[4 3 6] [2 7 1] [2 3 8]]矩阵对角线： [4 7 8]矩阵上三角： [[4 3 6] [0 7 1] [0 0 8]]矩阵下三角： [[4 0 0] [2 7 0] [2 3 8]]矩阵的迹： 19矩阵的转置： [[4 2 2] [3 7 3] [6 1 8]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">print(<span class="string">'原矩阵：\n'</span>,x)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵元素向右循环移动2位：\n'</span>,np.roll(x,<span class="number">2</span>))</span><br></pre></td></tr></table></figure><pre><code>原矩阵： [[1 1 6] [7 3 3] [7 6 5]]矩阵元素向右循环移动2位： [[6 5 1] [1 6 7] [3 3 7]]</code></pre><h2 id="六、Numpy矩阵运算"><a href="#六、Numpy矩阵运算" class="headerlink" title="六、Numpy矩阵运算"></a>六、Numpy矩阵运算</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># numpy下的子模块linalg是一个线性代数运算库，关于矩阵运算主要使用该库来完成</span></span><br><span class="line"><span class="keyword">import</span> numpy.linalg <span class="keyword">as</span> la</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以000001行情数据为例</span></span><br><span class="line">a5 = np.array(w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"close,open,low"</span>, <span class="string">"2018-07-08"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>).Data)</span><br><span class="line">a5</span><br></pre></td></tr></table></figure><pre><code>array([[9.03, 8.98, 8.78],       [8.69, 9.02, 8.76],       [8.68, 8.89, 8.68]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'原矩阵：\n'</span>,a5)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵的行列式：\n'</span>,la.det(a5)) </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵的逆：\n'</span>,la.inv(a5)) </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵的特征值分解：\n'</span>,la.eig(a5))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵的奇异值分解：\n'</span>,la.svd(a5))</span><br></pre></td></tr></table></figure><pre><code>原矩阵： [[9.03 8.98 8.78] [8.69 9.02 8.76] [8.68 8.89 8.68]]矩阵的行列式： 0.0967539999999976矩阵的逆： [[  4.31196643   1.11416582  -5.48607809] [  6.27984373  22.42801331 -28.98691527] [-10.74374186 -24.08479236  35.28949708]]矩阵的特征值分解： (array([2.65036938e+01, 2.08824580e-01, 1.74815890e-02]), array([[-0.58362007, -0.78625042, -0.09211654],       [-0.57657184,  0.5886538 , -0.64732544],       [-0.57179763,  0.18787491,  0.75662693]]))矩阵的奇异值分解： (array([[-0.58355077,  0.78217367, -0.21834112],       [-0.5766266 , -0.58842029, -0.56680096],       [-0.57181314, -0.20485584,  0.79439526]]), array([2.65057682e+01, 2.11310491e-01, 1.72745790e-02]), array([[-0.57510827, -0.58571691, -0.57112711],       [ 0.81163598, -0.49595222, -0.30867203],       [-0.10245733, -0.64106715,  0.76061515]]))</code></pre><p><strong>numpy.linalg函数</strong></p><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>diag</td><td>以一维数组的形式返回方阵的对角线元素或将一维数组转化为方阵</td></tr><tr><td>dot、trace、det</td><td>矩阵乘法、矩阵的迹运算、矩阵行列式</td></tr><tr><td>eig、inv、pinv</td><td>方阵的特征值和特征向量、方阵的逆、矩阵的Moore-Penrose伪逆</td></tr><tr><td>qr、svd</td><td>矩阵的QR分解、奇异值分解</td></tr><tr><td>solve</td><td>解线性方程组 $𝑋\beta = 𝑦$，其中$𝑋$为方阵</td></tr><tr><td>lstsq</td><td>计算$𝑋\beta = 𝑦$的最小二乘解</td></tr></tbody></table></div><h2 id="七、多项式曲线拟合"><a href="#七、多项式曲线拟合" class="headerlink" title="七、多项式曲线拟合"></a>七、多项式曲线拟合</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt   <span class="comment"># 导入作图库  为了更好展示曲线拟合的结果</span></span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br></pre></td></tr></table></figure><p>例如，对于下面的这些散点进行多项式拟合。观察散点的形态，采用直线取拟合</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(<span class="number">-10</span>,<span class="number">10</span>,<span class="number">100</span>)</span><br><span class="line">y = <span class="number">2</span>*x + <span class="number">1</span> + np.random.randn(<span class="number">100</span>)*<span class="number">2</span></span><br><span class="line">fig = plt.subplots(figsize=(<span class="number">14</span>,<span class="number">8</span>))</span><br><span class="line">plt.plot(x, y, <span class="string">'rx'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="/2020/02/05/200205numpy/tu1.png" title="图1"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> polyfit,poly1d</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">coef_fit = polyfit(x, y, <span class="number">1</span>)  <span class="comment">#进行线性拟合 1代表的是多项式拟合的多项式的阶数  这里指的是线性拟合</span></span><br><span class="line">coef_fit    <span class="comment">#查看拟合的系数</span></span><br></pre></td></tr></table></figure><pre><code>array([1.96386726, 1.11375232])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.subplots(figsize=(<span class="number">14</span>,<span class="number">8</span>))</span><br><span class="line">plt.plot(x, y, <span class="string">'rx'</span>,label=<span class="string">'真实散点'</span>)</span><br><span class="line">plt.plot(x, coef_fit[<span class="number">0</span>] * x + coef_fit[<span class="number">1</span>], <span class="string">'k-'</span>,label=<span class="string">'拟合直线'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 30495 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 23454 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 25955 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 28857 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 25311 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 21512 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 30452 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 32447 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 30495 missing from current font.  font.set_text(s, 0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 23454 missing from current font.  font.set_text(s, 0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 25955 missing from current font.  font.set_text(s, 0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 28857 missing from current font.  font.set_text(s, 0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 25311 missing from current font.  font.set_text(s, 0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 21512 missing from current font.  font.set_text(s, 0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 30452 missing from current font.  font.set_text(s, 0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 32447 missing from current font.  font.set_text(s, 0, flags=flags)</code></pre><img src="/2020/02/05/200205numpy/tu2.png" title="图2"><p>从上图可以看到，直线拟合的结果还是比较好的（报错可能是汉字bug</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">f = poly1d(coef_fit)   <span class="comment">#也可以直接产生拟合的函数解析式</span></span><br><span class="line">print(<span class="string">'拟合函数：'</span>,f)</span><br></pre></td></tr></table></figure><pre><code>拟合函数：  1.964 x + 1.114</code></pre><p>氦核：numpy库很有“大计算器”的味道了，其实不会用的时候再去查也可以，主要是应该了解有什么基础功能，否则就会出现“自己实现某些基础算法”的乌龙（某种意义上也是好事，笑）。一起加油吧。</p><p>（完）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最后编辑于：2020.02.05 12:30&lt;/p&gt;
&lt;h2 id=&quot;Numpy库&quot;&gt;&lt;a href=&quot;#Numpy库&quot; class=&quot;headerlink&quot; title=&quot;Numpy库&quot;&gt;&lt;/a&gt;Numpy库&lt;/h2&gt;&lt;p&gt;Numpy库是Python的一种开源的数值计算扩展。&lt;/p&gt;
&lt;p&gt;Numpy可用来存储和处理大型矩阵，比Python自身的嵌套列表结构要高效很多。&lt;/p&gt;
&lt;p&gt;据说Numpy将Pyhon变成了一种免费的更强大的Matlab系统。&lt;/p&gt;
&lt;p&gt;本文介绍性文字转载自&lt;a href=&quot;https://www.windquant.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;万旷网&lt;/a&gt;。氦核感觉notebook形式更适合学习，有机会把丘比特文件给大家附上。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据分析" scheme="https://konelane.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>python联萌|初探WindAPI</title>
    <link href="https://konelane.github.io/2020/02/01/20200201WindAPI/"/>
    <id>https://konelane.github.io/2020/02/01/20200201WindAPI/</id>
    <published>2020-01-31T16:00:00.000Z</published>
    <updated>2020-02-05T04:31:48.447Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最后编辑于：2020.02.05 12:30</p><h2 id="Wind-API使用说明"><a href="#Wind-API使用说明" class="headerlink" title="Wind API使用说明"></a>Wind API使用说明</h2><p>windAPI是一个很好的工具，可以不通过客户端获取数据（不过前提是要有土豪的账号加持，笑）本文大部分介绍性文字转载自<a href="https://www.windquant.com/" target="_blank" rel="noopener">万旷网</a>。本文的分析全部通过python完成。配置安装略过不表，请致电客服经理小哥哥（声音奶声奶气有点温柔！</p><a id="more"></a><h2 id="0-综述"><a href="#0-综述" class="headerlink" title="0. 综述"></a>0. 综述</h2><p>目前万矿网支持的API函数有：</p><p>1、WSD日期序列函数：支持股票、债券、基金、期货、指数等多种证券的基本资料、股东信息、市场行情、证券分析、预测评级、财务数据等各种数据。WSD可以支持取 <code>多品种单指标</code> 或者 <code>单品种多指标</code> 的时间序列数据。（氦核：可以说是最重要的函数）</p><p>2、WSS多维函数：同样支持股票、债券、基金、期货、指数等多种证券的基本资料、股东信息、市场行情、证券分析、预测评级、财务数据等各种数据。但是WSS支持取多品种多指标某个时间点的截面数据。</p><p>3、WSQ行情数据函数：支持股票、债券、基金、期货、指数等多种证券品种的实时行情数据，既可以选择获取一次性的快照数据，也可以选择订阅数据（即交易所有新的行情就推送）。</p><p>4、WSET数据集：支持股票、债券、基金、期货、指数等多种证券品种板块成分、指数历史成分股以及权重，以及各种市场常用报表的获取。</p><p>5、TDays 日期函数：日期函数包含日期序列函数（TDays)、日期偏移函数(TDaysOffset) 以及日期区间统计函数（TDaysCount）。</p><p>下面为大家介绍各个函数的详细用法。</p><p>注： 建议用户在使用取数函数时<strong>直接借助API函数</strong>生成相应的取数代码，然后修改其中的参数使其满足自己的取数需求。(氦核注：这个很好使，点点点就能拿到代码。)</p><h2 id="1-WSD日期序列函数"><a href="#1-WSD日期序列函数" class="headerlink" title="1. WSD日期序列函数"></a>1. WSD日期序列函数</h2><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>该命令用来获取选定证券品种的历史序列数据，包括日间的行情数据、基本面数据以及技术数据指标。（氦核注：有些数据被限制获取的数量了，有些是最多五十个，这倒是很不方便。如果看实盘还好，但是做分析就不舒服了。）</p><h4 id="函数输入"><a href="#函数输入" class="headerlink" title="函数输入"></a>函数输入</h4><p>WSD函数结构 w.wsd（security,fields,startdate,enddate,option）</p><div class="table-container"><table><thead><tr><th></th><th>Element</th><th>Type</th><th>Description</th><th></th></tr></thead><tbody><tr><td><strong>证券（必选）</strong></td><td>Security</td><td>String</td><td>获取数据的证券列表</td><td>范例1：’600030.SH’说明：证券列表支持Wind代码及证券转换类工具函数输出的Wind代码结果</td></tr><tr><td><strong>指标（必选）</strong></td><td>Fields</td><td>String</td><td>获取数据的指标列表</td><td>范例1：’CLOSE,HIGH,LOW,OPEN’</td></tr><tr><td><strong>起始日期（必选）</strong></td><td>StartDate</td><td></td><td>时间序列的起始日期</td><td>范例1：’2017-01-01’,’-5w’说明：支持日期类工具函数输出的标准日期结果，支持相对日期宏表达方式，日期宏具体使用方式参考’日期宏’部分内容</td></tr><tr><td><strong>截止日期（必选）</strong></td><td>EndDate</td><td></td><td>时间序列的截止日期，若为空默认为系统当前日期</td><td>范例1：’2017-05-30’，Sys.Date()，支持相对日期，比如’0w’; 不输入的话为当前时间说明：支持日期类工具函数输出的标准日期结果，支持相对日期宏表达方式</td></tr><tr><td>指标参数（可选）</td><td>Parameter/Value</td><td>String</td><td>提取指标时使用的参数名/指定参数的值</td><td>范例：’TRADE_DATE=20110301;FUND_DATE=20101231’说明：多指标参数支持在不同引号内分开取值</td></tr><tr><td>变频参数（可选）</td><td>Period</td><td>String</td><td>每天一值:D/每周一值:W/每月一值:M/每季度一值:Q/每半年一值:S/每年一值:Y</td><td>范例：’Period=D’ ，默认Period=D</td></tr><tr><td>输出日期（可选）</td><td>Days</td><td>String</td><td>所有工作日:Weekdays/所有日历日:Alldays/排除所有非交易日:Trading</td><td>范例：’Days=Trading’，默认Days=Trading</td></tr><tr><td>填充方式（可选）</td><td>Fill</td><td>String</td><td>沿用之前数据:Previous/返回空值:Blank</td><td>范例：’Fill=Previous’，默认Fill=Blank</td></tr><tr><td>日期排序（可选）</td><td>Order</td><td>String</td><td>升序:A/ 降序:D，最近日期在先</td></tr><tr><td>交易日历（可选）</td><td>TradingCalendar</td><td>String</td><td>选择不同交易所所在国家地区日历</td><td>范例1：’ TradingCalendar =SSE’，默认TradingCalendar =SSE;SSE表示上交所，SZSE表示深圳证券交易所，CFFE表示中金所……</td></tr><tr><td>输出币种（可选）</td><td>Currency</td><td>String</td><td>使用货币设置： ORIGINAL:原始货币/HKD：港币/USD：美元/CNY：人民币</td><td>范例1：’Currency =Original’，默认Currency =Original</td></tr></tbody></table></div><p>关于指标参数的详细说明见 <strong>7.指标常见参数说明</strong></p><h4 id="函数输出"><a href="#函数输出" class="headerlink" title="函数输出"></a>函数输出</h4><div class="table-container"><table><thead><tr><th></th><th>输出内容</th><th>说明</th></tr></thead><tbody><tr><td>错误ID</td><td>ErrorCode</td><td>返回值为0 ，则表示代码运行正常。若为其他则需查找原因</td></tr><tr><td>数据列表</td><td>Data</td><td>函数读取的数据存到此列表中，比如：读取000592.SZ 的close,open指标从’2017-05-08’到’2017-05-18’区间的数据.Data=[[5.12,5.16,5.02,4.9,4.91,5.13,5.35,5.42,5.32],[5.3,5.12,5.17,4.98,4.94,4.93,5.1,5.4,5.4]]</td></tr><tr><td>证券代码列表</td><td>Codes</td><td>输入的证券代码列表 .Codes=[000592.SZ]</td></tr><tr><td>字段列表</td><td>Field</td><td>函数输入中请求的字段列表 .Fields=[CLOSE,OPEN]</td></tr><tr><td>时间列表</td><td>Times</td><td>输出时间序列.Times=[20170508,20170509,20170510,20170511,20170512,20170515,20170516,20170517,20170518]</td></tr></tbody></table></div><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载相关的包</span></span><br><span class="line"><span class="keyword">from</span> WindPy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">w.start()</span><br></pre></td></tr></table></figure><p>w.start是启动函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例1、 取富士康概念股近七个交易日的每天机构资金流入额</span></span><br><span class="line">date=time.strftime(<span class="string">"%Y-%m-%d"</span>, time.localtime()) </span><br><span class="line">stock=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date="</span>+date+<span class="string">";sectorid=1000011346000000"</span>).Data[<span class="number">1</span>]  <span class="comment">#富士康概念股最新板块成分</span></span><br><span class="line">buyamt=w.wsd(stock, <span class="string">"mfd_buyamt_d"</span>, <span class="string">"ED-7TD"</span>, date, <span class="string">"unit=1;traderType=1"</span>) <span class="comment">#traderType表示类型，如机构、大户、中户、散户，具体参数设置可以借助API函数了解</span></span><br><span class="line">buyamt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(buyamt.Data,index=stock,columns=buyamt.Times).T</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例2、 任取一只国债010107.SH六月份以来的净值历史行情数据</span></span><br><span class="line">history_data=w.wsd(<span class="string">"010107.SH"</span>, <span class="string">"sec_name,ytm_b,volume,duration,convexity,open,high,low,close,vwap"</span>, <span class="string">"2018-06-01"</span>, <span class="string">"2018-06-11"</span>, <span class="string">"returnType=1;PriceAdj=CP"</span>) <span class="comment"># returnType表示到期收益率计算方法，PriceAdj表示债券价格类型‘</span></span><br><span class="line"><span class="comment">#pd.DataFrame(history_data.Data,index=history_data.Fields,columns=history_data.Times).T</span></span><br><span class="line">pd.DataFrame(history_data.Data,index=[<span class="string">"中文简称"</span>,<span class="string">"YTM"</span>,<span class="string">"成交量"</span>,<span class="string">"久期"</span>,<span class="string">"凸性"</span>,<span class="string">"开盘价"</span>,<span class="string">"最高价"</span>,<span class="string">"最低价"</span>,<span class="string">"收盘价"</span>,<span class="string">"均价"</span>],columns=history_data.Times).T</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例3、 取国内所有农产品主力合约不同日期所对应的具体合约</span></span><br><span class="line">future=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date="</span>+date+<span class="string">";sectorid=1000009337000000"</span>) <span class="comment">#农产品主力合约板块</span></span><br><span class="line">tradecode=w.wsd(future.Data[<span class="number">1</span>], <span class="string">"trade_hiscode"</span>, <span class="string">"2018-01-01"</span>, <span class="string">"2018-06-11"</span>, <span class="string">""</span>)</span><br><span class="line">pd.DataFrame(tradecode.Data,index=future.Data[<span class="number">2</span>],columns=tradecode.Times).T</span><br></pre></td></tr></table></figure><h2 id="2-WSS多维数据函数"><a href="#2-WSS多维数据函数" class="headerlink" title="2. WSS多维数据函数"></a>2. WSS多维数据函数</h2><h4 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h4><p>命令用来获取选定证券品种的历史截面数据</p><p>命令原型为：data= w.wss(品种代码,指标,可选参数)</p><h4 id="函数输入-1"><a href="#函数输入-1" class="headerlink" title="函数输入"></a>函数输入</h4><p>WSS函数输入 w.wss（security,fields, option）</p><div class="table-container"><table><thead><tr><th></th><th>Element</th><th>Type</th><th>Description</th><th></th></tr></thead><tbody><tr><td>证券（必选）</td><td>Security</td><td>String</td><td>获取数据的证券列表</td><td>范例：’600030.SH,600031.SH 说明：证券列表支持Wind代码及证券转换类工具函数输出的Wind代码结果</td></tr><tr><td>指标（必选）</td><td>Fields</td><td>String</td><td>获取数据的指标列表</td><td>范例1：’CLOSE,HIGH,LOW,OPEN’ 范例2：[‘CLOSE’,’HIGH’,’LOW’,’OPEN’]</td></tr><tr><td>指标参数（可选）</td><td>Parameter/Value</td><td>String</td><td>提取指标时使用的参数名/指定参数的值</td><td>范例：’TRADE_DATE=20170601;FUND_DATE=’20161231’ 说明：多指标参数支持在不同引号内分开取值</td></tr><tr><td>输出币种（可选）</td><td>Currency</td><td>String</td><td>使用什么货币 ORIGINAL/HKD/USD/CNY</td><td>范例：’Currency =Original’，默认Currency =Original</td></tr></tbody></table></div><p>关于指标参数的详细说明见 7.指标常见参数说明</p><h4 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例4、 取A股纳入MSCI各成分股的基本资料信息</span></span><br><span class="line">MSCI_stock=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date="</span>+date+<span class="string">";sectorid=1000027970000000"</span>)</span><br><span class="line">infor=w.wss(MSCI_stock.Data[<span class="number">1</span>] , <span class="string">"sec_name,ipo_date,mkt,stockclass,industry_sw,indexcode_sw,SHSC,SHSC2"</span>,<span class="string">"tradeDate="</span>+date+<span class="string">";industryType=1"</span>)</span><br><span class="line">pd.DataFrame(infor.Data,index=infor.Fields,columns=MSCI_stock.Data[<span class="number">1</span>]).T</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例5、 取截止日期 上海证券交易所 发行的国债 基本资料</span></span><br><span class="line">bond=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date=2018-06-11;sectorid=a101010201000000"</span>).Data[<span class="number">1</span>]</span><br><span class="line">error_code,bond_data=w.wss(bond, <span class="string">"sec_name,issueamount,term,issue_issueprice,couponrate,coupon,interesttype,interestfrequency,carrydate,maturitydate,ptmyear,trade_status"</span>,<span class="string">"unit=1;tradeDate=20180611"</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">bond_data.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例6、 取被动指数型基金最新业绩排名</span></span><br><span class="line">fund=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date=2018-06-11;sectorid=2001010102000000"</span>).Data[<span class="number">1</span>]</span><br><span class="line">error_code,returns=w.wss(fund, <span class="string">"sec_name,return_1w,return_1m,return_3m,return_6m,return_1y,return_ytd,fund_fundmanager"</span>,<span class="string">"annualized=0;tradeDate=20180611"</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">returns.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按今年以来总回报排序</span></span><br><span class="line">returns_sort=returns.sort_values(by = <span class="string">'RETURN_YTD'</span>,ascending=<span class="keyword">False</span>) </span><br><span class="line">returns_sort.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">first_fund=list(returns_sort.index.values)</span><br><span class="line">first_fund[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> WindCharts <span class="keyword">import</span> *</span><br><span class="line">error_code,nav=w.wsd(first_fund[<span class="number">0</span>], <span class="string">"NAV_adj"</span>, <span class="string">'2017-01-01'</span>, <span class="string">"2018-06-11"</span>, usedf=<span class="keyword">True</span>)</span><br><span class="line">chart=WLine(title=<span class="string">"复权单位净值走势图"</span>,subtitle=first_fund[<span class="number">0</span>],data=nav)</span><br><span class="line">chart.plot()</span><br></pre></td></tr></table></figure><h2 id="3-WSQ行情数据函数"><a href="#3-WSQ行情数据函数" class="headerlink" title="3. WSQ行情数据函数"></a>3. WSQ行情数据函数</h2><h3 id="3-1-实时行情取数函数说明"><a href="#3-1-实时行情取数函数说明" class="headerlink" title="3.1 实时行情取数函数说明"></a>3.1 实时行情取数函数说明</h3><h4 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h4><p>命令用来获取选定证券品种的当天实时指标数据，数据可以一次性请求，也可以通过订阅的方式获取</p><p>命令原型为： data=w.wsq(品种代码,指标,可选参数,回调函数)</p><h4 id="函数输入-2"><a href="#函数输入-2" class="headerlink" title="函数输入"></a>函数输入</h4><p>函数名: w.wsq（security,fields,func = None)</p><div class="table-container"><table><thead><tr><th></th><th>Element</th><th>Type</th><th>Description</th><th></th></tr></thead><tbody><tr><td>证券（必选）</td><td>Security</td><td>String</td><td>获取数据的证券列表</td><td>范例：’600030.SH’说明：实时行情所支持品种较多，基本上终端中有的行情接口中皆可取得</td></tr><tr><td>指标（必选）</td><td>Fields</td><td>String</td><td>获取数据的指标列表</td><td>范例：’rt_open,rt_high,rt_last’</td></tr><tr><td>回调函数（可选）</td><td>Func</td><td>指定回测函数</td><td>范例：’ func=w.demoCallback’</td></tr></tbody></table></div><p>返回选定品种的实时数据，支持一次请求和订阅两种方式。</p><h4 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例7. 获取沪股通最新一笔的行情数据</span></span><br><span class="line">hksh=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date=2018-06-12;sectorid=1000014938000000"</span>).Data[<span class="number">1</span>]</span><br><span class="line">mk_data=w.wsq(hksh,<span class="string">"rt_last,rt_vol,rt_amt,rt_chg,rt_pct_chg,rt_swing,rt_vwap,rt_upward_vol,rt_downward_vol,rt_ask1,rt_ask2,rt_ask3,rt_ask4,rt_ask5,rt_bid1,rt_bid2,rt_bid3,rt_bid4,rt_bid5"</span>)</span><br><span class="line"><span class="comment">#pd.DataFrame(tradecode.Data,index=future.Data[2],columns=tradecode.Times).T</span></span><br><span class="line">pd.DataFrame(data.Data,index=data.Fields,columns=data.Codes).T</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#任意订阅一只股票的最新行情</span></span><br><span class="line">w.wsq(<span class="string">"000001.SZ"</span>, <span class="string">"rt_last"</span>, func=DemoWSQCallback)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#订阅行情后当交易所发送新的行情数据时，这里就会推送</span></span><br><span class="line"><span class="comment"># 上面订阅后会返回一个RequestID，此ID作为后面取消订阅函数的传入参数</span></span><br><span class="line"><span class="comment">#当传入ID为0时表示取消所有订阅 </span></span><br><span class="line">w.cancelRequest(<span class="number">3</span>)</span><br></pre></td></tr></table></figure><h2 id="4-WSET数据集函数"><a href="#4-WSET数据集函数" class="headerlink" title="4. WSET数据集函数"></a>4. WSET数据集函数</h2><h4 id="定义-3"><a href="#定义-3" class="headerlink" title="定义"></a>定义</h4><p>命令用来获取数据集信息，包括板块成分、指数成分、ETF申赎成分信息、分级基金明细、融资标的、融券标的、融资融券担保品、回购担保品、停牌股票、复牌股票、分红送转等</p><p>参数设置为起止日期、板块名称等，不同的报表有不同的参数设置</p><p>命令原型为： data=w.wset(数据集名称,可选参数)</p><h4 id="函数输入-3"><a href="#函数输入-3" class="headerlink" title="函数输入"></a>函数输入</h4><p>函数名: w.wset（view，options），返回股票，基金，债券，商品等专题统计报表的数据。</p><div class="table-container"><table><thead><tr><th></th><th>Element</th><th>Type</th><th>Description</th><th></th></tr></thead><tbody><tr><td>数据集（必选）</td><td>view</td><td>String</td><td>提取数据集的VIEW名</td><td>范例1：’SectorConstituent’</td></tr><tr><td>View参数（可选）</td><td>Parameter/Value</td><td>String</td><td>提取指标时使用的参数名/指定参数的值</td><td>范例1：’date=20130531’;</td></tr><tr><td>板块列表（可选）</td><td>sectorid</td><td>String</td><td>获取数据的板块ID</td><td>范例1： ‘sector=全部A股’ 范例2：’sectorid=a001010100000000’</td></tr><tr><td>字段列表（可选）</td><td>Field</td><td>String</td><td>获取字段列表的数据</td><td>范例1：’field=wind_code,i_weight’</td></tr></tbody></table></div><p>基本获取某些板块的数据方法在上面的函数介绍中已经涉及了，这里就不再赘述</p><h4 id="示例-3"><a href="#示例-3" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例8、 获取申万一级行业的成分股</span></span><br><span class="line">sw_index=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date=2018-06-12;sectorid=a39901011g000000"</span>) <span class="comment">#申万一级行业指数代码</span></span><br><span class="line">sw_index</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面分别取各行业指数的成分股</span></span><br><span class="line">result=pd.DataFrame()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(sw_index.Data[<span class="number">0</span>])):</span><br><span class="line">    x=pd.DataFrame(w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date=2018-06-12;windcode="</span>+sw_index.Data[<span class="number">1</span>][i]+<span class="string">""</span>).Data[<span class="number">1</span>],columns=[sw_index.Data[<span class="number">1</span>][i]])</span><br><span class="line">    result=pd.concat([result,x], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例9、 获取A股纳入MSCI成分股的2017年报的股票分红实施情况</span></span><br><span class="line"><span class="comment"># MSCI_stock=w.wset("sectorconstituent","date="+date+";sectorid=1000027970000000") MSCI股票代码上文已经取出</span></span><br><span class="line">error_code,bonus=w.wset(<span class="string">"bonus"</span>,<span class="string">"orderby=报告期;year=2017;period=y1;sectorid=1000027970000000"</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">bonus.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例10、 沪深交易所期权列表</span></span><br><span class="line">error_code,option=w.wset(<span class="string">"optioncontractbasicinfo"</span>,<span class="string">"exchange=sse;windcode=510050.SH;status=trading"</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">option.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><h2 id="5-TDays-日期函数"><a href="#5-TDays-日期函数" class="headerlink" title="5. TDays 日期函数"></a>5. TDays 日期函数</h2><h3 id="5-1-返回区间内的日期序列w-tdays"><a href="#5-1-返回区间内的日期序列w-tdays" class="headerlink" title="5.1 返回区间内的日期序列w.tdays"></a>5.1 返回区间内的日期序列w.tdays</h3><h4 id="定义-4"><a href="#定义-4" class="headerlink" title="定义"></a>定义</h4><p>命令用来获取一个时间区间内的某种规则下的日期序列。</p><h4 id="函数输入-4"><a href="#函数输入-4" class="headerlink" title="函数输入"></a>函数输入</h4><p>函数名：TDays(startDate,endDate,[Optional argument])</p><div class="table-container"><table><thead><tr><th></th><th>Element</th><th>Type</th><th>Description</th><th></th></tr></thead><tbody><tr><td>起始日期（必选）</td><td>StartDate</td><td>String</td><td>时间序列的起始日期</td><td>范例1：”2015-01-01”，支持日期宏</td></tr><tr><td>截止日期（必选）</td><td>EndDate</td><td>String</td><td>时间序列的截止日期，置空取当前最新日期</td><td>范例1：”2015-06-30”，支持日期宏</td></tr><tr><td>日期类型（可选）</td><td>Days</td><td>String</td><td>所有工作日：Weekdays，所有日历日：Alldays，排除所有非交易日：Trading</td><td>范例：’Days=Trading’，默认Days=Trading</td></tr><tr><td>变频参数（可选）</td><td>Period</td><td>String</td><td>每天一值：D， 每周一值：W，每月一值M：，每季度一值：Q ，每半年一值：S ，每年一值：Y</td><td>范例：’Period=D’</td></tr><tr><td>交易日历（可选）</td><td>TradingCalendar</td><td>String</td><td></td><td>TradingCalendar默认为上海证券交易所，当DAYS为日历日的时候，这个参数不起作用,只有当DAYS为交易日的时候，这个参数才起作用,默认“TradingCalendar=SSE”(上海证券交易所)</td></tr></tbody></table></div><h4 id="示例-4"><a href="#示例-4" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例11 取上交所2018年以来的交易日期序列，交易所为空默认为上交所</span></span><br><span class="line">date_list=w.tdays(<span class="string">"2018-05-13"</span>, <span class="string">"2018-06-13"</span>,<span class="string">" "</span>)</span><br><span class="line">date_list</span><br></pre></td></tr></table></figure><h3 id="5-2-返回某个偏移值对应的日期w-tdaysoffset"><a href="#5-2-返回某个偏移值对应的日期w-tdaysoffset" class="headerlink" title="5.2 返回某个偏移值对应的日期w.tdaysoffset"></a>5.2 返回某个偏移值对应的日期w.tdaysoffset</h3><h4 id="定义-5"><a href="#定义-5" class="headerlink" title="定义"></a>定义</h4><p>命令用来获取基于某个基准时间前推(<0) 或者后推(="">0)指定天数的日期。</0)></p><p>命令原型为：data=w.tdaysoffset(偏移值，基准时间,可选参数)</p><h4 id="函数输入-5"><a href="#函数输入-5" class="headerlink" title="函数输入"></a>函数输入</h4><p>函数名:TDaysOffset(offset, refDate, [Optional argument])</p><div class="table-container"><table><thead><tr><th></th><th>Element</th><th>Type</th><th>Description</th><th></th></tr></thead><tbody><tr><td>参考日期</td><td>refDate</td><td>String</td><td>参照日期</td><td>范例1：”2015-01-01”，支持日期宏</td></tr><tr><td>日期类型（可选）</td><td>Days</td><td>String</td><td>所有工作日：Weekdays，所有日历日：Alldays，排除所有非交易日：Trading</td><td>范例：’Days=Trading’，默认Days=Trading</td></tr><tr><td>变频参数（可选）</td><td>Period</td><td>String</td><td>每天一值：D， 每周一值：W，每月一值M：，每季度一值：Q ，每半年一值：S ，每年一值：Y</td><td>范例：’Period=D’，默认Period=D</td></tr><tr><td>交易日历（可选）</td><td>TradingCalendar</td><td>String</td><td></td><td>TradingCalendar默认为上海证券交易所，当DAYS为日历日的时候，这个参数不起作用,只有当DAYS为交易日的时候，这个参数才起作用。默认“TradingCalendar=SSE”(上海证券交易所)</td></tr><tr><td>偏移量（可选）</td><td>Offset</td><td></td><td>偏移参数</td><td>偏移参数，为整数，&gt;0后推，&lt;0前推，默认为0</td></tr></tbody></table></div><h4 id="示例-5"><a href="#示例-5" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例12 取从今天往前推10个月的日历日</span></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line">today = datetime.date.today() </span><br><span class="line">w.tdaysoffset(<span class="number">-10</span>, today.isoformat(), <span class="string">"Period=M;Days=Alldays"</span>)</span><br></pre></td></tr></table></figure><h3 id="5-3-返回某个区间内日期数量w-tdayscount"><a href="#5-3-返回某个区间内日期数量w-tdayscount" class="headerlink" title="5.3 返回某个区间内日期数量w.tdayscount"></a>5.3 返回某个区间内日期数量w.tdayscount</h3><h4 id="定义-6"><a href="#定义-6" class="headerlink" title="定义"></a>定义</h4><p>命令用来获取两个时间区间内的某种规则下的日期序列个数</p><p>命令原型为：data= w.tdayscount(开始时间，结束时间,可选参数)</p><h4 id="函数输入-6"><a href="#函数输入-6" class="headerlink" title="函数输入"></a>函数输入</h4><p>函数名：TDaysCount(startDate,endDate, [Optional argument])</p><div class="table-container"><table><thead><tr><th></th><th>Element</th><th>Type</th><th>Description</th><th></th></tr></thead><tbody><tr><td>起始日期（必选）</td><td>StartDate</td><td>String</td><td>时间序列的起始日期</td><td>范例1：”2017-01-01”，支持日期宏</td></tr><tr><td>截止日期</td><td>EndDate</td><td>String</td><td>时间序列的截止日期，置空取当前最新日期</td><td>范例1：”2017-06-30”，支持日期宏</td></tr><tr><td>日期类型（可选）</td><td>Days</td><td>String</td><td>所有工作日:Weekdays，所有日历日：Alldays，排除所有非交易日：Trading</td><td>范例：’Days=Trading’，默认Days=Trading</td></tr><tr><td>交易日历（可选）</td><td>TradingCalendar</td><td>String</td><td></td><td>TradingCalendar默认为上海证券交易所，当DAYS为日历日的时候，这个参数不起作用,只有当DAYS为交易日的时候，这个参数才起作用，默认“TradingCalendar=SSE”(上海证券交易所)</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例13 统计2017年交易日天数</span></span><br><span class="line">days=w.tdayscount(<span class="string">"2017-01-01"</span>, <span class="string">"2017-12-31"</span>, <span class="string">""</span>).Data[<span class="number">0</span>]</span><br><span class="line">days</span><br></pre></td></tr></table></figure><h2 id="6-日期宏的说明"><a href="#6-日期宏的说明" class="headerlink" title="6. 日期宏的说明"></a>6. 日期宏的说明</h2><h3 id="6-1-通用日期"><a href="#6-1-通用日期" class="headerlink" title="6.1 通用日期"></a>6.1 通用日期</h3><p>支持相对日期表达方式，相对日期周期包括:交易日TD、日历日：D、日历周：W、日历月：M、日历季：Q、日历半年：S、日历年：Y。</p><p>相关说明：<br>1、以’-’代表前推，数字代表N个周期，只支持整数；后推没有负号，比如’-5D’表示从当前最新日期前推5个日历日；<br>2、截止日期若为’’空值，取系统当前日期；<br>3、可对日期宏进行加减运算，比如’ED-10d’。</p><p>举例：<br>1、起始日期为1个月前，截至日期为最新 StartDate=’-1M’,EndDate=’’<br>2、起始日期为前推10个交易日，截至日期为前推5个交易日 StartDate=’-10TD’,EndDate=’-5TD’</p><h3 id="6-2-特殊日期宏"><a href="#6-2-特殊日期宏" class="headerlink" title="6.2 特殊日期宏"></a>6.2 特殊日期宏</h3><div class="table-container"><table><thead><tr><th>宏名称</th><th>截止日期</th><th>开始日期</th><th>去年一季</th><th>去年二季</th><th>去年三季</th><th>去年年报</th><th>今年一季</th><th>今年二季</th><th>今年三季</th><th>最新一期</th><th>本年初</th><th>下半年初</th><th>本月初</th><th>本周一</th><th>上周末</th><th>上月末</th><th>上半年末</th><th>上年末</th><th>上市首日</th></tr></thead><tbody><tr><td>宏助记符</td><td>ED</td><td>SD</td><td>LQ1</td><td>LQ2</td><td>LQ3</td><td>LYR</td><td>RQ1</td><td>RQ2</td><td>RQ3</td><td>MRQ</td><td>RYF</td><td>RHYF</td><td>RMF</td><td>RWF</td><td>LWE</td><td>LME</td><td>LHYE</td><td>LYE</td><td>IPO</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例14 用日期宏IPO的示例</span></span><br><span class="line">error_code,data=w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"close"</span>, <span class="string">'IPO'</span>, <span class="string">"2018-06-11"</span>, usedf=<span class="keyword">True</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><h2 id="7-指标参数的说明"><a href="#7-指标参数的说明" class="headerlink" title="7. 指标参数的说明"></a>7. 指标参数的说明</h2><p>关于WSD/WSS中常见指标参数的举例说明</p><div class="table-container"><table><thead><tr><th>element</th><th>description</th><th>value</th><th>Indicator examples</th><th>demo</th></tr></thead><tbody><tr><td>tradeDate</td><td>交易日期</td><td>自填</td><td>开盘价</td><td>‘tradeDate=20180618’</td></tr><tr><td>startDate</td><td>开始日期</td><td>自填</td><td>区间开盘价</td><td>‘startDate=20180618’</td></tr><tr><td>endDate</td><td>截止日期</td><td>自填</td><td>区间开盘价</td><td>‘endDate=20180618’</td></tr><tr><td>adjDate</td><td>复权基期</td><td>自填</td><td>收盘价(支持定点复权)</td><td>‘adjDate=20180618’</td></tr><tr><td>rptDate</td><td>报告期</td><td>自填</td><td>净利润</td><td>‘rptDate=20171231’</td></tr><tr><td>priceAdj</td><td>复权方式</td><td>不复权/前复权/后复权/定点复权</td><td>收盘价</td><td>‘priceAdj=U’</td></tr><tr><td>cycle</td><td>周期</td><td>日/月/……</td><td>成交量</td><td>‘cycle=D’</td></tr><tr><td>bondPriceType</td><td>债券价格类型</td><td>全价/净价/收益率/市价</td><td>涨跌幅(债券)</td><td>‘bondPriceType=2’</td></tr><tr><td>currencyType</td><td>币种</td><td>原始币种/人民币/美元……</td><td>未平仓卖空金额</td><td>‘currencyType=Cur=CNY’</td></tr><tr><td>ndays</td><td>天数(用负号表示前推)</td><td>自填</td><td>N日涨跌幅</td><td>‘ndays=-5’</td></tr><tr><td>rptType</td><td>报表类型</td><td>合并报表/母公司报表……</td><td>杠杆率</td><td>‘rptType=1’</td></tr><tr><td>dataType</td><td>数据类型</td><td>本外币/本币/……</td><td>贷款利息收入-短期</td><td>‘dataType=2’</td></tr><tr><td>traderType</td><td>类型</td><td>机构/大户/散户……</td><td>流入单数</td><td>‘traderType=1’</td></tr><tr><td>exchangeType</td><td>交易所</td><td>上海/深圳/银行间……</td><td>跨市场代码</td><td>‘exchangeType=SSE’</td></tr><tr><td>index</td><td>所属指数</td><td>上证50指数/上证180指数/沪深300指数……</td><td>是否属于重要指数成份</td><td>‘index=1’</td></tr><tr><td>unit</td><td>单位</td><td>元、股、份、张、户</td><td>总市值、注册资本、持有人持有数量、单一投资者报告期末持有份额合计、股东户数……</td><td>‘unit=1’</td></tr><tr><td>industryType/category/industryStandard</td><td>行业级别/行业标准</td><td>一级行业/二级行业……</td><td>全部明细、中信行业/申万行业……</td><td>所属行业名称(支持历史)、所属恒生行业名称</td><td>‘industryType=1’，’category=1’,’industryStandard=3’</td></tr><tr><td>adminType</td><td>行政区划级别</td><td>省级/地级/县级</td><td>所属行政区划</td><td>‘adminType=1’</td></tr><tr><td>year</td><td>年度</td><td>2018/2017/2016……</td><td>管理层年度薪酬总额</td><td>‘year=2017’</td></tr><tr><td>month</td><td>月份</td><td>1月/2月/……</td><td>五星基金占比</td><td>‘month=2’</td></tr><tr><td>order</td><td>大股东排名、名次</td><td>第一名/第二名/……</td><td>持有人持有数量、基金经理年限</td><td>‘order=1’</td></tr><tr><td>instituteType</td><td>机构类别    基金公司/证券公司/……</td><td>配售对象名称</td><td>‘instituteType=1’</td></tr><tr><td>topNum</td><td>名次</td><td>第1名/第2名……</td><td>离职日期</td><td>‘topNum=1’</td></tr><tr><td>shareType</td><td>股本类型</td><td>流通股本/总股本</td><td>户均持股比例</td><td></td><td>‘shareType=1’</td></tr><tr><td>reportDateType</td><td>报告期</td><td>第一季度(1-3月)/第二季度(4-6月)……</td><td>单一投资者报告期末持有份额合计</td><td>‘reportDateType=1’</td></tr><tr><td>Type</td><td>资产池资产级别</td><td>次级/优先级/次优级</td><td>各级发行总额</td><td>‘reportDateType=1’</td></tr><tr><td>type</td><td>选择权类型、评级对象类型</td><td>赎回/回售/……、主体信用评级/不限……</td><td>行权资金到帐日</td><td>‘type=Pr’、’type=3’</td></tr><tr><td>serial</td><td>第N次提前偿还</td><td>手动输入数字</td><td>提前还本比例</td><td>‘serial=1’</td></tr><tr><td>ratingAgency</td><td>评级机构</td><td>标普/穆迪……</td><td>债项评级</td><td>‘ratingAgency=16’</td></tr><tr><td>bondTypeIndex</td><td>债券类型</td><td>短期融资券/中期票据/……</td><td>历史累计注册额度</td><td>‘bondTypeIndex=2’</td></tr><tr><td>bondType</td><td>债券类型</td><td>金融债/同业存单……</td><td>存量债券余额</td><td>‘bondType=1’</td></tr><tr><td>termType</td><td>期限类型</td><td>1年期内/1-3年期内……</td><td>存量债券余额(按期限)</td><td>termType=2</td></tr><tr><td>credibility</td><td>估值类型</td><td>推荐/不推荐/行权……</td><td>日终估价全价</td><td>‘credibility=2’</td></tr><tr><td>fundType</td><td>基金分类</td><td>投资类型(一级分类)/投资类型(二级分类)</td><td>同类基金数量</td><td>‘fundType=1’</td></tr><tr><td>fundRatingAgency</td><td>评级机构</td><td>1/2……</td><td>四星基金占比</td><td>‘fundRatingAgency=2’</td></tr><tr><td>chargesType</td><td>收费类型</td><td>前端/后端</td><td>认购费率</td><td>‘chargesType=1’</td></tr><tr><td>returnType</td><td>收益率计算方法</td><td>普通收益率/对数收益率</td><td>几何平均年化收益率</td><td>‘returnType=1’</td></tr><tr><td>annualized</td><td>是否年化</td><td>是/否</td><td>近1周回报</td><td>‘annualized=0’</td></tr><tr><td>netType</td><td>报告期净值数据项</td><td>过去1个月/过去3个月/……</td><td>报告期净值增长率</td><td>‘netType=1’</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">例<span class="number">16</span> 指标参数说明案例</span><br><span class="line">w.wss(<span class="string">"510010.SH"</span>, <span class="string">"fund_fullname,fund_similarfundno,fund_purchasefee,fund_redemptionfee,fund_dq_status,fund_pchredm_largepchmaxamt,fund_manager_totalnetasset,fund_manager_arithmeticannualizedyield,fund_manager_totalreturnoverbenchmark,fund_corp_fivestarfundsprop,fund_corp_fourstarfundsprop,fund_corp_teamstability,issue_etfdealshareonmarket,fund_etfpr_estcash,fund_etfpr_cashratio"</span>, <span class="string">"fundType=1;chargesType=0;tradeDate=20180619;unit=1;order=2;returnType=1;year=2018;month=1;fundRatingAgency=2;startDate=20180520;endDate=20180620"</span>)</span><br></pre></td></tr></table></figure><h2 id="8-财务数据的说明"><a href="#8-财务数据的说明" class="headerlink" title="8.财务数据的说明"></a>8.财务数据的说明</h2><p>Python如图，万矿的财务数据都是传入报告期，然后返回相应报告期的财务数据；在参数设置中可以直接设置报表类型为合并报表/母公司报表/合并报表（调整）/母公司报表（调整）。</p><p>万矿是取每个季度最后一天作为报告期,如取2017年的四个定期报告数据，那报告期设置分别为 ：一季报：2017-03-31，半年报：2017-06-30，三季报：2017-09-30，年报:2017-12-31</p><p>如果要用wsd取多个报告期的公告数据，则需要将周期设置为季，日期类型设置为日历日(因为有的季度最后一天不是交易日)</p><p>财务数据回填说明：<br>1、比如说某公司A在2018年3月22日公布2017年年报，那在2018年3月22以前取2017年年报数据则为空，A公司公布年报数据后，我们会将公布的数据回填到2017-12-31，用户传入相应的报告期参数即可取出对应的年报数据；<br>2、如果用户直接取出年报数据做回测则会引入未来数据，所以如果要用财报数据做回测要先按照定期报告披露日期拉平至时间序列再做回测。</p><p>下面举例说明如何获取各个报告期的财务数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例 17 用wsd函数取000001.SZ[平安银行]近十年的利润表(合并报表)数据</span></span><br><span class="line">error_code,finance_data=w.wsd(<span class="string">"000001.SZ"</span>,<span class="string">"tot_oper_rev,oper_rev,int_inc,insur_prem_unearned,handling_chrg_comm_inc,tot_prem_inc,reinsur_inc,prem_ceded,unearned_prem_rsrv_withdraw,net_inc_agencybusiness,net_inc_underwriting-business,net_inc_customerasset-managementbusiness,other_oper_inc,net_int_inc,net_fee_and_commission_inc,net_other_oper_inc,tot_oper_cost,oper_cost,int_exp,handling_chrg_comm_exp,oper_exp,taxes_surcharges_ops,selling_dist_exp,gerl_admin_exp,fin_exp_is,impair_loss_assets,prepay_surr,net_claim_exp,net_insur_cont_rsrv,dvd_exp_insured,reinsurance_exp,claim_exp_recoverable,Insur_rsrv_recoverable,reinsur_exp_recoverable,other_oper_exp,net_inc_other_ops,net_gain_chg_fv,net_invest_inc,inc_invest_assoc_jv_entp,net_gain_fx_trans,opprofit,non_oper_rev,non_oper_exp,net_loss_disp_noncur_asset,tot_profit,tax,unconfirmed_invest_loss_is"</span>, <span class="string">"2007-01-01"</span>, <span class="string">"2017-12-31"</span>, <span class="string">"unit=1;rptType=1;Period=Q;Days=Alldays"</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">finance_data</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例18 用wss取上证50的常见财务指标的2017年年报数据</span></span><br><span class="line">sh_50=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date=2018-06-20;sectorid=1000000087000000"</span>).Data[<span class="number">1</span>]</span><br><span class="line">error_code,Y_finance_data=w.wss(sh_50, <span class="string">"tot_oper_rev,tot_oper_cost,opprofit,tot_profit,net_profit_is,np_belongto_parcomsh,extraordinary,wgsd_deductedprofit,researchanddevelopmentexpenses,ebit,ebitda,tot_cur_assets,fix_assets,long_term_eqy_invest,tot_assets,tot_cur_liab,tot_non_cur_liab,tot_liab,cap_rsrv,surplus_rsrv,undistributed_profit,cash_recp_sg_and_rs,cash_pay_acq_const_fiolta"</span>,<span class="string">"unit=1;rptDate=20171231;rptType=1;currencyType="</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">Y_finance_data</span><br></pre></td></tr></table></figure><p>（完）<br>特别鸣谢：我家松鼠</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最后编辑于：2020.02.05 12:30&lt;/p&gt;
&lt;h2 id=&quot;Wind-API使用说明&quot;&gt;&lt;a href=&quot;#Wind-API使用说明&quot; class=&quot;headerlink&quot; title=&quot;Wind API使用说明&quot;&gt;&lt;/a&gt;Wind API使用说明&lt;/h2&gt;&lt;p&gt;windAPI是一个很好的工具，可以不通过客户端获取数据（不过前提是要有土豪的账号加持，笑）本文大部分介绍性文字转载自&lt;a href=&quot;https://www.windquant.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;万旷网&lt;/a&gt;。本文的分析全部通过python完成。配置安装略过不表，请致电客服经理小哥哥（声音奶声奶气有点温柔！&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据分析" scheme="https://konelane.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>遍历山河|南京</title>
    <link href="https://konelane.github.io/2020/01/22/20200122%E5%8D%97%E4%BA%AC%E6%97%85%E8%A1%8C%E6%97%A5%E5%BF%97/"/>
    <id>https://konelane.github.io/2020/01/22/20200122%E5%8D%97%E4%BA%AC%E6%97%85%E8%A1%8C%E6%97%A5%E5%BF%97/</id>
    <published>2020-01-21T16:00:00.000Z</published>
    <updated>2020-01-21T16:44:39.439Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>旅行结束，慢慢添加我的心绪啦。有人说旅行是痛并快乐着，我觉得没错。偶尔快乐多，偶尔痛苦多。但是南京不太一样，在这里，我几乎没有痛苦，只有一些遗憾和无穷快乐。</p><a id="more"></a><h2 id="14日-旅行日志"><a href="#14日-旅行日志" class="headerlink" title="14日 旅行日志"></a>14日 旅行日志</h2><p>告别我纯白如仙的松鼠，我独自拎着箱子，踏上了这次期待不算太久，但我绝对足够向往的旅行。</p><p>直达车不直达，特快车不特快，临客不会真的零客，只有高铁和动车还没有辱没名号。或许正是因为他们的出现，其他的客车才相形见绌，铁路系统从此认知失调。车上从各处来的人，混着不同的口音乱杂开放。我很少坐长时间的硬座，今晚恐怕会是个令人记忆深刻的不眠夜。</p><p>我初次独自远行去陌生的城市旅游，但也不算完全陌生，还好有认识的长辈在那里，还有松鼠一起，热心地帮我打点安排，让我才能安心地踏上旅途。看着满满当当的旅途安排，我心中说不上来的复杂。自己曾经标榜“读万卷书，行万里路”，然而真正做到还得靠自己一时冲动，当然也归功于周围人们的帮助。虽然很想细细品味，可是走得地方实在太多，眼花缭乱免不了落入走马观花之流，不知所向，只能到现场慢慢品味，再做取舍了。</p><p>听说哥哥做打算往往提前两个月，安排行程，预订酒店，这应该很清醒的旅行状态。很期待父母能策划一场出行，但是他们也碍于时间空间的距离，没法随心所欲。松鼠也在帝都寻了一份差事做，于是只留我一个孤独上路。我首次尝试独自出行，我期待一场奇妙的旅行，但是也在不断为之准备着。我着实向往着南京，以至于定下了行程才察觉天气不如意的问题，但冷暖或许已经无妨，我偶尔意决，今天算一次。</p><p>有一件值得在意的事：在火车上，教室里，坐着的时候，感觉自己的位置很清晰。但一站起来就瞬间失去方向感，不知自己身处何方。究其原因，或许是同一个视角看的太久，在升维瞬间失了格吧。</p><h2 id="15日-旅行日志"><a href="#15日-旅行日志" class="headerlink" title="15日 旅行日志"></a>15日 旅行日志</h2><p>冬雨不寒马蹄疾，一日看尽金陵花。<br>湿身方嫌寡情雨，酩酊难解太浮夸。</p><p>突然吟诗，说明开心。作为一个本意独行这个城市的旅人，没想到获得了异常热情的款待，在一个伯伯的帮助下，我今天辗转了无数景点，尝遍了千万小吃，大饱眼福的同时也大快朵颐，精神和肉体皆是满载而归。</p><p>白天刚到南京，漆黑混杂着大雾混沌成一片，南京像个封存老窖中的佳酿，像黑暗中待开启的宝箱，像迎进屋子但披着盖头的新娘，待人一探究竟。逐渐习惯了那些随心所欲的道路规则和巨大显示屏展示的宜人的红绿灯倒计时灯，其实这座城市没有我一开始想象的那么井然，但是在我眼中这般混乱之下，竟也有可以寻找的规则和有序。人人在这里都可以大摇大摆地做天王老子，享受每一刻在路上的时光。我也很享受在这里大街小巷行走的快乐。</p><p>我行程飞快。从长江大桥江底隧道，路过狮子山阅江楼，草草翻过毗芦寺，梅园新村，六朝博物馆，再到小九华山，鸡鸣寺和玄武湖，雨中闯入大钟亭，鼓楼和南京大学，夜里的狮子市，夫子庙，穿街走巷雨中狂奔才赶到的1912，没有哪一处突兀多余。这些或自然或历史或现代的风光景色，都已和南京融为一体，俨然成了南京现代生活的一部分。在意想不到的地方，总会突如其来杀出一座山，一座楼，一道水，一院佛。这里充满了人文和自然气息，物华天宝、人杰地灵。这里据说寸土寸金，跨过三五步一条马路突然就是一个崭新的迥然不同的世界，每一步都可能产生新的邂逅，这种未知的刺激令我着迷。南京也多美女，平日里原子弹炸不到一个，南京一颗手榴弹能炸一片，松鼠还嫉妒。</p><p>城市的诗情画意，还有它不为人知的小心思，我都有所理解。不仅仅是小面包车上与伯伯一字一句的对谈和学习，更多的是一种气质：城市的气质、人的气质、全部自然总体总和的气质。我听到了地道的南京话，插科打诨，无比惬意，虽然不习惯其中个中洒脱粗鄙，但是想到儒雅如我这个三秦猛男也常常口吐芬芳当街骂娘的事实，我也笑着理解了这种调侃性质的口癖。南京话总有种火药味，还是不要太较真的好。</p><p>明天还要早起，今天走着玩几万步，像是玩着走。白天五点到站还没睡够觉，实在困累之至，加上本应该成为东道主的松鼠也沉迷游戏，不搭理我，夜里雨中骑车狂奔尽兴而归才发觉丢了伞，浑身湿透地回了宾馆。大欢喜背后总是一个个小失落。松鼠也质疑我、嗔责我，虽然看起来像是口是心非，有了些南京人互怼的味道，但依然令我十分难受，可是又不想反驳什么，坏了我的期待和焦渴就算了，让松鼠批评一下舒服舒服也无妨。且熄一熄我这团让我膨胀到无所适从的火焰吧。</p><p>明天还有明天的旅途，眼皮打架，不说了。</p><h2 id="16日-旅行日志"><a href="#16日-旅行日志" class="headerlink" title="16日 旅行日志"></a>16日 旅行日志</h2><p>早起我就感受到了南京别样的一面，至少在没有暖气这一点上，就宣告了它是一座冰冷的城市。融入和接受恐怕很难，我想只有熬得住寒冷、耐得住性子，才能和这座城市打成一片，才更加接近这座城市的灵魂所在。我还是在寻找神奇的路上，从未停止。我也住过很久没有暖气的房子，全靠电暖气续命，每天起床前一定要把冰凉的衣服在暖气上烤一下，起床才不至于那么煎熬。</p><p>今天的目标颇多，本来只与昨天持平，结果今天伯伯突然有事，无力再送我。我已经心怀感激，哪敢多做要求，于是今天的路成全了昨日口中奢望的“独行”。就结果来看，我还是奢望有车接车送只管参观的旅途。不过今天去的景点都是需要用双脚踏踏实实丈量的，倒也完全没有投机取巧的空间，要车也无用。于是就诞生了这近乎4万的超越极限的旅程，从表面看来有车的旅行效率可以提高一倍。</p><p>气度雍容的美龄宫开启了这段钟山之旅，皇气浩瀚的明孝陵，排衙端庄的颜真卿碑林，肃穆清白中山陵，绝景入云的灵谷塔，还有一些情趣无限的小地方：三绝碑、音乐台、无梁殿、四方城。虽然走马观花，对历史由来也一知半解，但我总算是将那奇人奇景刻进脑海，待之后再品味。没顾上吃饭，斩了根烤肠，又转头向环环相扣的瞻园，途经深街老巷的老门东，又仰止中华门，行止雨花台。这么多还不够我体验，晚上又补足了第一天遗憾的玄武湖，还去了夜幕下的三山街熙南里，新街口商圈，论充实，这一天的容量比起考研的长途作战有过之无不及，我也好久没有来过这样的高强度旅行了，导致我写文章这会儿只能像一张煎饼一样在旅店中摊开来任人宰割，甚至因为太累了，害怕泡澡堂子散了紧绷的神，最后没去。</p><p>一路上都是人文景观，而绝美的风景并非很多，触动内心的更少。南京还在雨中，紫金山烟雾蒸腾。雨让天地模糊了界限，这混沌让我有些烦躁，可是微雨再不增添更多烦恼之上，把凝重和游人从景区一同抹去，留给我肆意想象和发挥的空间。在过年前的下雨的工作日游览南京，或许这体验只有现在才可能得到。这个季节的钟山树林红褐色与深绿色交融，错综的枝桠遮天蔽日，只有登高临台才有如此疏朗的开阔视野。但真正居高的时刻，我又没了高屋建瓴的气势，变得不知所向，无所适从。年轻时候，爱登高楼，待我再成熟一些，怕是就失去登楼心劲了。现在总觉得高楼如家乡这般，珍惜之处想去可是又不敢去，顺心和忧愁总是相伴而生，这就是爱吧。</p><p>颜真卿的碑林和刘勰文心雕龙纪念馆在钟山一角，本就与帝王伟人陵寝格格不入，但更出格的是一座无人的小园子还夹在两个建筑物之间，毫无征兆地撞出来，园虽小，但阁廊水木应有尽有，明明修在一个平面上，竟也有小曲折和错落的层次感，可能南京的园子有难名且优雅的修葺之道吧。我很喜欢这个没有名字的园子，更多是情景之喜，先前的凝重的地气在此行不通，进去出来竟然变成一园的清淡芳香，有如解油化腻的饭后小汤，沁人心脾。</p><p>其实我对园林毫无体验，来之前甚至只有一些北方园子的印象。观赏中若觉得某处入眼甚是契合我美感，凭空而爱，毫无理由，因此不好意思多说。看了瞻园，层层叠叠，钦佩和沉浸感无以复加，惬意凉亭。只是零落季节的园子，竟都有此等魅力，引得我反复穿行，寻找角度，左看右看，去留频繁。园子的窗门给出无限空间、亭廊自如穿梭带给人想置身其中的欲望、山水花草有情有据铺陈摆放十分讲究，惊为天作。雕梁画栋、星星灯火，与这季节的残花败柳，相映成趣，爱至深，盖我已成园内人。但这种“同化”有例外，我在园中发现了一只猫，在雨中漫步，愁眉苦脸，仿佛并不开心。我笨拙地学了几声猫叫，企图诱骗，反倒逼它使出浑身解数，飞檐走壁消失在楼台间。或许我不会骗人，更不会骗猫。我的体会就连我自己都不能完全把握，异想天开地企图把喜悦传递给猫猫，简直是乐昏了头。不过有趣的是，察觉到自己似乎“很快乐”的我自己，就接着认真地快乐起来。</p><p>猫猫是有灵气的，每一只猫都有，于是我喜欢看猫。人不一定，但也有灵气。昨天在小九华山的一条幽径中，一直黑猫欣然路过，丝毫不在意一旁赶路的我，瞬间隐匿，留我略略遗憾。今天晚上玄武湖的湖中小洲上也遇见了小黑猫，自顾自躲雨，看我几眼，又故作高冷，转身翻窗离去，似乎还被窗子卡了几秒钟。我本来想帮它，但觉得猫猫灵性至此，我一介庸人又能改变什么呢，或许不论它能不能穿过那条窗缝，我都不该出手才是。</p><p>可是，猫猫不改本性，我的认知上限却是容易被改变的。神道漫长，上山路上遇见一位高人，内力颇深，一曲《青藏高原》响彻整条路，我们身形交错瞬间，竟有种被浩然之气浇透打穿的感觉。我很少为了看人而回头，但这次如同一定要确认什么似的回了头。我也趁没人唱了两句，除了遭了报应绊了一跤差点滑倒，好像没有什么场地的加成。我猜想可能有两个原因：一是我不该放浪形骸，陕西人有时邪，说曹操曹操就到，陵寝高歌还是不好；二是我的唱歌内力太稀薄，遇见高手甚至会反噬自己，平时多是献丑。</p><p>其实，这一趟转悠下来，我也不知自己真正喜欢上了南京的什么，也不知道自己不喜欢什么。心中也像下了一场雨，界线模糊了。但明显的一点是，原本我不喜欢或者丝毫不感兴趣的东西，我开始尝试了，甚至会用心找它的特点。就比如我把主打甜味的梅花糕，形容为嬉笑怒骂，我自以为完全合理。粘和脆，苦和甜，硬和软，彩和白，一对对矛盾交织，共同构成了这一口梅花糕。或许真应该用“嬉笑怒骂”来形容，着实难忘。松鼠觉得不该把外壳做糊掉，糊掉生出多余苦味，可是那样的甜可能也单调，而且恐怕也只有高明的店家才能做到，并非是人们常常吃到的那种，少了一种地气吧。</p><p>吃的事之后专门写一篇。很晚了，休息。明天还要拼一拼，不过早上可以慢悠悠吃个早茶。人总是忙碌的，就拿我来说，担心的事有很多，我还悬着一颗梦想抢改签票的心，现在还担心松鼠的身体，坏的发展都是受罪。我不想松鼠受罪，我也不想受罪，可是有时候确实得为了所爱的什么拼一把。人是成长的，有些人走不了那么多路，可是热情驱使着，就会毫无征兆地焕发出超越身体机能的力量。</p><h2 id="17日-旅行日志"><a href="#17日-旅行日志" class="headerlink" title="17日 旅行日志"></a>17日 旅行日志</h2><p>今天去总统府，天下文枢坊，莫愁湖，奥体公园，还有大屠杀纪念馆，为南京之游收了官。每一处都有独特的感官体验。吃得好，玩得好，虽然走马观花，但也算肤浅到极致，极尽三天之能事，算是不虚此行。每每看到它新的面貌，有时是市井平常，有时是青春自由，有时是工作辛劳，不管什么样子，当我更加了解南京时，就又多几分喜爱。</p><p>从来没有高强度这么拼命地走过路，我很少如此用痛感苦感来强记某些旅程，但若旅途中带着一些苦痛和不顺利，那此行也会愈加刻骨。整条路也多亏只有我一人，我可以随心所欲走南闯北，当然也因为计划不周耽误了很多时间。所幸，南京是个交通便利的城市，用不着我在路上费劲，就能轻松地兜转访寻。限制自己的只有昨天透支的腿，让今天确实无力实现出格的想法，脑子都不灵光了许多。若说前两天在旅行，今天却像是一种修炼和补救错误。</p><p>这次出游，没做什么攻略，没写什么太长的安排，每次游览景点，也只是按照一个深度随心逛下去。也不知道有什么美食和根源，只好误打误撞，有时现场搜索，或蹭蹭别团的导游。狼狈不堪。今天也萌发了一种无力感，起因于我偶然听到总统府中的一位导游讲起府门前八字台阶和某“森”楼奥秘，我才察觉自己的充实只是肤浅的充实，有些事有些来由根本不是我一个人能查到或者体会到的。除了对先前的自满自惭形秽，我也更加喜爱南京这座城。</p><p>其实和松鼠聊过，但是免不了再提一嘴。在我眼里，南京无疑是一座“城”，有声有色，有古有今。但我不曾了解南京的那部分，却在我心底呼之欲出，而那一部分更像是一座“市”。人们日出而作日落而息，每个人都寻着一份事儿做。我独潇洒，逆流而动，这些天还真无人与我争，可能是因为天寒又下雨，还赶上年前大家都忙碌，基本都是独享美景，宛如包场。吃东西也一样，我作为半个吃货，常苦于选择困难，很少能搏得最好吃的头彩。但尽管这样，我还是被南京本地美食所征服，足见南京美食同文化一样博大精深。</p><p>其实，我总在渴望从不同的角度认识南京，渴望从最真实又最深刻的一面认识人事物。这次走马观花，我抱着能触碰这座城市除了历史以外的全部表象的另类的渴望，我想融入这里早上的忙碌生活，想度过不眠的灯火秦淮，体会拥堵和顺畅，看遍美食与美人，我喜欢更平常的南京，而非更“南京”的南京。或许这些微妙的差别只有等我再咀嚼时，才会体会。不过我想，这次快速游览，大概并非毫无意义，对我来说这算是已经铺好纸笔，只待我闲暇时再去看两眼，便能描画挥洒了。</p><p>说了许多大话空话客套话，可是没学会最想了解的南京话。当然，就算学会，我也不敢在老南京们面前班门弄斧，最多调侃一下松鼠。但是一点可以肯定，南京人的普通话不怎么好，至少这一路我时刻注意着，和我对话的人，讲普通话的不超过一手之数，大多数普通市民都会带着点南京的口音。通常，本地人对本地方言都有些特别的情节，我听了几天，虽然有些难名的词根和语缀记了几个，南京话虽然听着像北方话，却抛去了很多太刚坚的词，剩下一些令我摸不着头脑的婉转语调，以及一种鞭辟入里的直爽，和一种说完就抛的洒脱。出口成脏是常事，有人确实喜欢拿腔拿调还吹胡子瞪眼，只是听者不必钻牛角尖，应该用脏字还一口回去才是正解。看他们聊得火热，我感叹语言排外的严重，初来乍到完全假装不了本地人，可能也因此没能混进想看的学校。不管如何，南京话稍稍让我有些羡慕。</p><p>想到今天又去夫子庙，这次奔着几个文化展馆去的，个中展馆确实值得玩味。再回味前两次来这里，总觉得看到的秦淮灯火只是一种虚假的繁华。有趣的小玩意琳琅满目，可我不屑一顾；当地独特的美食飘香穿巷，可我吃过后便无心驻足。然而我偏爱这里的砖瓷碑匾，飞檐叠壁，亭台廊阁，我深醉这里的兵戈祸中，天下文枢，古都气韵。这一城氤氲于书香食色，融化于绵山长水，烙刻于时代纵横，这样的城，只南京一座。</p><p>你们又要说，去过南京就开始吹南京，是不是收了钱奉了旨，屁颠屁颠地傻乐呵。南京是个普通城市，也有着普通的一面，那是每个城市都有的市井市侩的一面。主干道上还在修建便民交通，拥堵是不可避免的，这座城市还在发展之中，还在成长之中，还好相见不晚，未来可期。</p><p>我眼中的平凡事也多，有取纸巾铲屎的路人老奶奶，有骂骂咧咧却又热心的公交司机，有高唱分手快乐的醉酒小情侣当街大戏，有书包加身的名校学子匆忙赶路尽显惫色，有早点摊、总统府、瞻园、玄武湖和小九华数不清的悠闲猫猫，有不喜欢戴手表手机的晨练大爷和急着下班地铁引导员，有追出五十米把落下东西送还的餐厅服务员，有无心逛街还等在商场门口的寂寞小男友，有快下班了还特意为我重启设施的景点管理员，有好心过问冷暖的酒店前台，有不给好脸色的公事公办学校门卫，有飞行在街巷的电动车手，有遛狗带娃不栓绳的小阿姨，有酒吧街用生命力高谈阔论的落魄青年，有串摊指点附近美食攻略的温柔小哥……明明只有三天，我遇见的人们比我想象中的要更多更丰富。不管事由如何，这一切的人一起组成了我眼中的南京市民，正是他们生活在这片城市中，带给这座城市无限生命力。刷新了我对南方人和南京人的认识。</p><p>你若问他们怎么看我，我觉得像是在看一只外地来的金丝猴：操着听不出籍贯的口音和生得一副独特的面貌身材，带着目中无人怼天怼地的气魄，三步并一步飞快穿行的孤独旅人。外地人来南京，南京人都无比自豪，开始话六朝古都，十洲云水。作为半个西安人，我对历史有莫名的感情，可惜这次没去成最为推崇的南京博物院，是最大的遗憾了，但也不算遗憾，反正走马观花看博物馆，那才是真的浪费时间。</p><p>之后再专门写点美食吧，在此不做赘述。我喜欢南京。</p><p>（未完待续，还有春运和美食没写qwq）</p><h2 id="附录：美食记录"><a href="#附录：美食记录" class="headerlink" title="附录：美食记录"></a>附录：美食记录</h2><p>15晨<br>桂花糖芋苗<br>赤豆元宵<br>鸡汁汤包<br>鸡汁回卤干</p><p>15午<br>慈悲素鹅面<br>沉鱼落雁（松鼠素鱼）<br>煮干丝</p><p>15晚<br>清炖狮子头<br>江南水乡一桶仙<br>蟹黄汤包<br>香干马兰头<br>清炒芦蒿<br>肥肠臭豆腐砂锅<br>千层油糕<br>桂花拉糕<br>糯米糖藕</p><p>16日晨<br>油条<br>烧麦<br>南瓜红枣粥</p><p>16晚<br>张三生煎+垃圾锅贴<br>梅花糕</p><p>17早<br>酥饼<br>鸭血粉丝汤</p><p>17午<br>喜妞炸串 鸭肠<br>晨祥记牛肉锅贴<br>桂花双皮奶<br>酱汁鸭肉卷<br>奇异果青麦汁<br>芋圆bobo鲜奶茶</p><p>17晚<br>香辣牛肉锅盔<br>酱汁烤鸭</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;旅行结束，慢慢添加我的心绪啦。有人说旅行是痛并快乐着，我觉得没错。偶尔快乐多，偶尔痛苦多。但是南京不太一样，在这里，我几乎没有痛苦，只有一些遗憾和无穷快乐。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="文章" scheme="https://konelane.github.io/tags/%E6%96%87%E7%AB%A0/"/>
    
  </entry>
  
  <entry>
    <title>软件初探|matlab之空间计量</title>
    <link href="https://konelane.github.io/2019/12/30/191230%E7%A9%BA%E9%97%B4%E8%AE%A1%E9%87%8F/"/>
    <id>https://konelane.github.io/2019/12/30/191230%E7%A9%BA%E9%97%B4%E8%AE%A1%E9%87%8F/</id>
    <published>2019-12-29T16:00:00.000Z</published>
    <updated>2020-10-29T01:08:04.888Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最后修改日期：191231，18:31</p><h4 id="事由"><a href="#事由" class="headerlink" title="事由"></a>事由</h4><p>松鼠有难，正派学长自然要拿出一点正派学长的样子。从零开始自学matlab，写写作业，不过如此。好啦，话不多说爱不多示，进入正题吧。</p><a id="more"></a><h2 id="一、介绍说明"><a href="#一、介绍说明" class="headerlink" title="一、介绍说明"></a>一、介绍说明</h2><p>数据为1978年-2011年华东<strong>七城市</strong>（上海、山东、安徽、江苏、浙江、江西、福建）各省区的<strong>GDP（GDP）、人口（RENKOU）、财政收入（GSH）、财政支出（GZH）、投资（TZ）、消费（XF）、进口（JK）</strong>。（氦核：别问我为什么起这些low爆的变量名，某松鼠的老师起的</p><p>以GDP为因变量，其他六个变量为解释变量，详细情况见表1。</p><p><strong>表1  变量介绍表</strong>  </p><div class="table-container"><table><thead><tr><th>变量名</th><th>含义</th><th>变量水平</th><th>单位</th></tr></thead><tbody><tr><td>GDP</td><td>地区生产总值</td><td>连续型</td><td>亿元</td></tr><tr><td>RENKOU</td><td>人口</td><td>连续型</td><td>万人</td></tr><tr><td>GSH</td><td>财政收入</td><td>连续型</td><td>亿元</td></tr><tr><td>GZH</td><td>财政支出</td><td>连续型</td><td>亿元</td></tr><tr><td>TZ</td><td>投资</td><td>连续型</td><td>亿元</td></tr><tr><td>XF</td><td>消费</td><td>连续型</td><td>亿元</td></tr><tr><td>JK</td><td>进出口</td><td>连续型</td><td>亿元</td></tr></tbody></table></div><p>利用matlab软件构造<strong>空间自回归模型、空间误差模型、空间杜宾模型和空间面板数据模型</strong>。其中空间自回归模型、空间误差模型、空间杜宾模型均使用2017年数据，空间面板数据模型使用40年全部数据构造。（氦核：切莫手滑一上来就panel函数。。。空间面板数据模型和空间xx模型有微妙的区别。血的教训</p><p>基于邻域关系的空间权重矩阵weight1由<em>“华东省区公路邻域.xlsx”</em>得出，基于距离关系的空间权重矩阵weight1由<em>“华东各省会城市的距离”</em>得出，基于GDP差距的经济距离关系的空间权重矩阵由<em>“华东2014年GDP计算的经济距离”</em>得出。综合权重矩阵取<strong>a=b=c=1/3</strong>（毫无梦想和灵魂的取值）。最后利用matlab构造出模型并进行检验。（氦核：文件在文末附件，你们看看我多好</p><blockquote><p>注1：<br>（1）空间自回归模型：<script type="math/tex">y=ρWy+βX+μ</script><br>（2）空间误差模型：<script type="math/tex">y=βX+μ     μ=ρWμ+ε</script><br>（3）空间杜宾模型：<script type="math/tex">y=ρW_1 y+Xβ_1+W_2 Xβ_2+μ</script><br>（4）空间面板数据模型：<script type="math/tex">y_it=ρWy_it+βX_it+μ_it</script></p><p>注2：<br>空间权重矩阵的选择，要有基于邻域关系的空间权重矩阵，基于距离关系的空间权重矩阵，基于某个经济指标的经济距离关系的空间权重矩阵。提倡构建组合空间权重矩阵<script type="math/tex">W=aW_1+(1-a)W_2（0＜a＜1）</script>；或 <script type="math/tex">W=aW_1+bW_2+ cW_3（a+b+c=1）</script>。</p></blockquote><h2 id="二、代码"><a href="#二、代码" class="headerlink" title="二、代码"></a>二、代码</h2><p>贴代码之前，先说几个坑。</p><p>sar函数，sem函数，sdm函数，一定不能做多年的数据，只能使用一年数据，否则报错。（氦核：不知道谁没搞清楚原理就开始写代码了呢。。。</p><p>松鼠的老师还是有意思，自己派人写了个有趣的包：fanzhuan（将上/下三角矩阵变成对称矩阵），里面还有几个对空间权重矩阵做标准化的函数，不想找的话<strong>normw()</strong>也可以，具体内容实在不想看了。</p><p>这次用到的方法，是空间计量，对于我来说很新奇，同时觉得很有趣。matlab空间计量需要最关键的<strong>jplv7</strong>工具包，下载安装这里也略过。</p><p>准备结束，下来就要开工了。这次代码注释写的很详细，原因不表，读者心领神会即可。</p><h3 id="工作开始"><a href="#工作开始" class="headerlink" title="工作开始"></a>工作开始</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">clear all;</span><br><span class="line"></span><br><span class="line">% 工作路径</span><br><span class="line">userpath(&apos;C:\Users\Surface\Desktop&apos;); </span><br><span class="line">% 读取数据</span><br><span class="line">[data,name] = xlsread(&apos;data&apos;,1); % 原数据为原始面板数据，需要转化为空间面板数据</span><br><span class="line"></span><br><span class="line">% 读取几个权重矩阵</span><br><span class="line">weight1 = xlsread(&apos;华东各省会城市距离&apos;,1);            % 基于距离关系的空间权重矩阵</span><br><span class="line">weight2 = xlsread(&apos;华东省区公路邻域&apos;,1);              % 基于邻域关系的空间权重矩阵</span><br><span class="line">weight3t = xlsread(&apos;华东2014GDP计算的经济距离&apos;,1);    % 基于GDP的经济距离关系的空间权重矩阵</span><br><span class="line">weight3 = fanzhuan(weight3t);                        % 将上三角矩阵反转为实对称矩阵，需要fanzhuan包</span><br><span class="line">% 空间权重标准化,函数需要fanzhuan包</span><br><span class="line">W1 = hbzh(weight1);</span><br><span class="line">W2 = lyhbzh(weight2);</span><br><span class="line">W3 = hbzh(weight3);</span><br><span class="line">W = 1/3*W1+1/3*W2+1/3*W3    % 加权构建复合矩阵</span><br><span class="line"></span><br><span class="line">% 问题的维度</span><br><span class="line">T = 40; % 时期数量 </span><br><span class="line">N = 7; % 地区数量</span><br></pre></td></tr></table></figure><p>最最重要的一个地方来了，要使用空间计量分析函数，就要明白其数据结构。</p><h3 id="调整数据结构"><a href="#调整数据结构" class="headerlink" title="调整数据结构"></a>调整数据结构</h3><p>空间面板数据结构<br>时间1 个体1  x1 x2 x3<br>时间1 个体2  x1 x2 x3<br>时间1 个体3  x1 x2 x3<br>……<br>时间2 个体1  x1 x2 x3<br>时间2 个体2  x1 x2 x3<br>时间2 个体3  x1 x2 x3<br>……<br>时间T 个体1  x1 x2 x3<br>时间T 个体2  x1 x2 x3<br>时间T 个体3  x1 x2 x3  </p><p>原始的面板结构如下，需要变换调整：</p><div class="table-container"><table><thead><tr><th></th><th>个体1</th><th>个体2</th><th>个体3</th><th>个体4</th></tr></thead><tbody><tr><td>时间1</td><td><script type="math/tex">x_{11}^{(1)},…… x_{1k}^{(1)}</script></td><td><script type="math/tex">x_{11}^{(2)},…… x_{1k}^{(2)}</script></td><td><script type="math/tex">x_{11}^{(3)},…… x_{1k}^{(3)}</script></td><td><script type="math/tex">x_{11}^{(4)},…… x_{1k}^{(4)}</script></td></tr><tr><td><script type="math/tex">时间2</script></td><td><script type="math/tex">x_{21}^{(1)},…… x_{2k}^{(1)}</script></td><td><script type="math/tex">x_{21}^{(2)},…… x_{2k}^{(2)}</script></td><td><script type="math/tex">x_{21}^{(3)},…… x_{2k}^{(3)}</script></td><td><script type="math/tex">x_{21}^{(4)},…… x_{2k}^{(4)}</script></td></tr><tr><td><script type="math/tex">时间3</script></td><td><script type="math/tex">x_{31}^{(1)},…… x_{3k}^{(1)}</script></td><td><script type="math/tex">x_{31}^{(2)},…… x_{3k}^{(2)}</script></td><td><script type="math/tex">x_{31}^{(3)},…… x_{3k}^{(3)}</script></td><td><script type="math/tex">x_{31}^{(4)},…… x_{3k}^{(4)}</script></td></tr><tr><td><script type="math/tex">时间4</script></td><td><script type="math/tex">x_{41}^{(1)},…… x_{4k}^{(1)}</script></td><td><script type="math/tex">x_{41}^{(2)},…… x_{4k}^{(2)}</script></td><td><script type="math/tex">x_{41}^{(3)},…… x_{4k}^{(3)}</script></td><td><script type="math/tex">x_{41}^{(4)},…… x_{4k}^{(4)}</script></td></tr><tr><td><script type="math/tex">……</script></td><td><script type="math/tex">……</script></td><td><script type="math/tex">……</script></td><td><script type="math/tex">……</script></td><td><script type="math/tex">……</script></td></tr></tbody></table></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">% 调整数据结构,从原始数据转化为空间面板数据</span><br><span class="line">temp =  zeros(T,7);  % 构建存储面板数据的0矩阵</span><br><span class="line">for i = 1:T         % 第i年至第40年</span><br><span class="line">    </span><br><span class="line">    shh = data(i,[2:8]);  % SHH上海当年的全部数据</span><br><span class="line">    shd = data(i,[9:15]); % SHD山东当年的全部数据</span><br><span class="line">    ah = data(i,[16:22]);  % AH 安徽当年的全部数据</span><br><span class="line">    js = data(i,[23:29]);  % JS 江苏当年的全部数据</span><br><span class="line">    zhj = data(i,[30:36]); % ZHJ浙江当年的全部数据</span><br><span class="line">    jx = data(i,[37:43]);  % JX 江西当年的全部数据</span><br><span class="line">    fj = data(i,[44:50]);  % FJ 福建当年的全部数据</span><br><span class="line">    temp&#123;(7*i-6):(7*i),:) = vertcat(shh,shd,ah,js,zhj,jx,fj);  % 将每一年的数据贴进准备好的0矩阵</span><br><span class="line">    </span><br><span class="line">    if i&gt;40</span><br><span class="line">        break</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>完事了，建模。先做个简单最小二乘法的回归对比一哈。</p><h3 id="OLS回归"><a href="#OLS回归" class="headerlink" title="OLS回归"></a>OLS回归</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">% 0 OLS模型</span><br><span class="line">% 提取变量</span><br><span class="line">y = temp(:,[1]);           % 华东各地区GDP</span><br><span class="line">x_ols = temp(:,[2:7]); </span><br><span class="line">% 变量名</span><br><span class="line">vnames=strvcat(&apos;gdp&apos;,&apos;renkou&apos;,&apos;gsh&apos;,&apos;gzh&apos;,&apos;tz&apos;,&apos;xf&apos;,&apos;jk&apos;); </span><br><span class="line">% 因变量：GDP（亿元），自变量：人口(万人)，财政收入（亿元），财政支出（亿元），投资（亿元），消费（亿元），进出口（亿元）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">% 建模</span><br><span class="line">results_ols = ols(y,x_ols); % 进行最小二乘法回归</span><br><span class="line">prt_reg(results_ols,vnames,1); </span><br><span class="line"></span><br><span class="line">I = eye(T);W1 = kron(I,W);</span><br><span class="line">res = moran(y,x_ols,W1); % moran 检验</span><br><span class="line">prt(res); %moran值较大，在0.01显著性水平下，依据空间分布的特征显著</span><br></pre></td></tr></table></figure><p>做完空间相关性检验后，一切才刚刚开始。空间相关性检验一般就moran和LR、LM检验。都有现成的函数，适合新手。</p><h3 id="空间计量模型SAR-SEM-SDM"><a href="#空间计量模型SAR-SEM-SDM" class="headerlink" title="空间计量模型SAR,SEM,SDM"></a>空间计量模型SAR,SEM,SDM</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">% ---------------------------------------------------------------------</span><br><span class="line">% 1 SAR模型</span><br><span class="line">% 提取变量：2017年数据</span><br><span class="line">y = temp(274:280,[1]);         </span><br><span class="line">x_sar = temp(274:280,[2,3,4,5,6,7]);      </span><br><span class="line">% 因变量：GDP（亿元），自变量：人口(万人)，财政收入（亿元），财政支出（亿元），投资（亿元），消费（亿元），进出口（亿元）</span><br><span class="line"></span><br><span class="line">% 建模</span><br><span class="line">results_sar = sar(y,x_sar,W);</span><br><span class="line">prt(results_sar,vnames);</span><br><span class="line"></span><br><span class="line">results_sar.tstat        % t检验统计量的值</span><br><span class="line">results_sar.rho          % 空间自回归系数rho</span><br><span class="line">results_sar.beta         % 模型估计的beta值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">% ---------------------------------------------------------------------</span><br><span class="line">% 2 SEM模型</span><br><span class="line">% y = beta*x + mu ; mu = rho*W*mu + e </span><br><span class="line">% 选择变量：2017年数据</span><br><span class="line">y = temp(274:280,[1]); </span><br><span class="line">x_sem = temp(274:280,[2:7]); </span><br><span class="line"></span><br><span class="line">results_sem = sem(y,x_sem,W);</span><br><span class="line">prt(results_sem,vnames);</span><br><span class="line"></span><br><span class="line">results_sem.tstat    % 渐进t检验统计量的值(最后输入为rho空间自回归系数)</span><br><span class="line">results_sem.rho      % (p above)</span><br><span class="line">results_sem.beta     % 模型估计的beta值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">% ---------------------------------------------------------------------</span><br><span class="line">% 3 SDM空间杜宾模型</span><br><span class="line">% y = XB + u (optional) + v (optional) + s,  s = p*W*s + e</span><br><span class="line">% 选择变量:2017年数据</span><br><span class="line">y = temp(274:280,[1]);  </span><br><span class="line">x_sdm = temp(274:280,[2:4]); % 空间相关性影响变量</span><br><span class="line">vnames1=strvcat(&apos;gdp&apos;,&apos;renkou&apos;,&apos;gsh&apos;,&apos;gzh&apos;); </span><br><span class="line"></span><br><span class="line">% 建模</span><br><span class="line">results_sdm = sdm(y,x_sdm,W); </span><br><span class="line">prt(results_sdm,vnames1);</span><br><span class="line"></span><br><span class="line">results_sdm.tstat        % t检验统计量的值</span><br><span class="line">results_sdm.rho          % 最后输入为rho空间自回归系数</span><br><span class="line">results_sdm.beta         % 模型估计的beta值</span><br></pre></td></tr></table></figure><p>以上是三个一年数据的结果，下面是面板数据模型，平时网上搜到的基本都是面板数据模型。</p><p>工具箱目录jplv7→spatial→panel下有一个演示程序：demopanelscompare好像是随机效应与混合模型的选择，使用的方法是LR检验。</p><h3 id="空间面板数据模型"><a href="#空间面板数据模型" class="headerlink" title="空间面板数据模型"></a>空间面板数据模型</h3><p>真没什么好说的。要说的话只能怪罪LMsarsem_panel函数太猛了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">% 4 空间面板数据模型</span><br><span class="line"></span><br><span class="line">% 4.1 空间相关性检验</span><br><span class="line">%LM检验，大于6.635拒绝原假设（不存在空间自相关），即存在误差项空间自相关</span><br><span class="line">LMsarsem_panel(results_sar,W,y,x_sar) </span><br><span class="line">% 结果表明0.1显著性水平下，空间固定效应LR检验通过，空间固定效应的空间滞后的LM检验通过</span><br><span class="line">% 时间固定效应的的空间误差的LM检验不通过,时间固定效应的LR检验不通过</span><br><span class="line">% 故选择时间效应固定模型info.model=2</span><br><span class="line">info.model=2;</span><br><span class="line"></span><br><span class="line">% 4.2 提取变量：30年数据</span><br><span class="line">y = temp(:,[1]);         </span><br><span class="line">x_sar = temp(:,[2,3,4,5,6,7]);      </span><br><span class="line">% 因变量：GDP（亿元），自变量：人口(万人)，财政收入（亿元），财政支出（亿元），投资（亿元），消费（亿元），进出口（亿元）</span><br><span class="line"></span><br><span class="line">% 4.3 建模</span><br><span class="line">results_general = sar_panel_FE(y,x_sar,W,T,info); </span><br><span class="line">prt_spnew(results_general,vnames);</span><br><span class="line"></span><br><span class="line">results_general.corr2     % 模型的拟合优度调整的r方</span><br><span class="line">results_general.tstat     % t检验统计量的值</span><br><span class="line">results_general.rho       % 最后输入为rho空间自回归系数</span><br><span class="line">results_general.beta      % 模型估计的beta值</span><br></pre></td></tr></table></figure><p>info.model参数是设定模型是某种固定效应：<br>info.model=0：表示此模型为混合模型，即没有固定效应；<br>info.model=1：表示此模型为地区固定效应模型；<br>info.model=2：表示时间固定效应模型；<br>info.model=3：表示双向固定效应模型。  </p><h2 id="经验小总结"><a href="#经验小总结" class="headerlink" title="经验小总结"></a>经验小总结</h2><p><strong>help+函数名</strong>这个指令太有用了，任何软件的帮助文档都是学软件的最好老师。</p><p>matlab有个现象，你不加句末的分号，就会输出在下面。我一开始循环没有加分号，每次运行都很慢。</p><p>不知道为什么，他们读“马特拉布”，难道是北美口音？不得而知。</p><p>虽然没有系统学习过matlab，但是这次借着任务也算好好认识了这款传说中的软件，点一下，玩一年，help不花一分钱。真心感觉全部的语言都有相通之处。不过matlab在做统计的问题时，我总是觉得用着不趁手，不如真正的统计软件，输出结果也乱糟糟的。或许这就是没有把好钢用在刀刃上吧。</p><p>结果不贴了，有兴趣的人们可以跑跑看。<a href="https://github.com/konelane/konelane.github.io/blob/master/upload/data%26weight.rar" target="_blank" rel="noopener">数据传送门</a></p><p>松鼠作业一定很优秀了（老父亲笑容）</p><p>（后补，松鼠观罢：烦死了！）</p><p>（完）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最后修改日期：191231，18:31&lt;/p&gt;
&lt;h4 id=&quot;事由&quot;&gt;&lt;a href=&quot;#事由&quot; class=&quot;headerlink&quot; title=&quot;事由&quot;&gt;&lt;/a&gt;事由&lt;/h4&gt;&lt;p&gt;松鼠有难，正派学长自然要拿出一点正派学长的样子。从零开始自学matlab，写写作业，不过如此。好啦，话不多说爱不多示，进入正题吧。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据分析" scheme="https://konelane.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>寻找神奇|名字</title>
    <link href="https://konelane.github.io/2019/09/18/190918%E5%90%8D%E5%AD%97/"/>
    <id>https://konelane.github.io/2019/09/18/190918%E5%90%8D%E5%AD%97/</id>
    <published>2019-09-17T16:00:00.000Z</published>
    <updated>2019-09-18T09:39:47.647Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="名字"><a href="#名字" class="headerlink" title="名字"></a>名字</h2><h4 id="氦核-190918"><a href="#氦核-190918" class="headerlink" title="氦核 190918"></a>氦核 190918</h4><p>名字对于人来说，是十分珍贵的东西。当我们喜欢上某人某事某物时，往往就会给他起上一个爱称。当然笔名也是如此。我也有过很多称呼，有时爱了叫禾禾，有时不爱了叫呵呵，以外观特点取我名的倒没多少，可能是名字比起外貌更加容易记，谁的名字还没有个谐音之梗呢？我倒是不在意，好记就行了。</p><a id="more"></a><p>我曾经称呼自己单行道子，乍看不是人名，但事出有因。当年看了一部对我废话能力影响无穷的动漫，深爱其中某位一流恶党的“彻底”作风，于是在注册贴吧之时就起下此名，希望自己在单行道上一路前行。那时愿望单纯，希望自己在人生路上要永远能够前进，不要后退。变强，那时单纯而由衷的心愿，藏在这个名字中伴随我走了三年。倒是现在，提起这个名字就会掩面而笑，好似回忆起一段不愿意认真审视的二货黑历史。</p><p>后来上高中，视野开阔，脑洞清奇，偏爱理科。听说冥冥之中有一种名为“氦核”的物质，在粒子中力大无比，电子板上轨迹粗壮，单纯而专一，会影响周围而不受电子太多干扰，能够冲击未知带来新发现，种种特性，颇合我心。加上谐音近似我的昵称，不假思索就把它当作了名字。每每有人问起笔名何意，我便莞尔。多年来也无人猜透其中深意，只是认为不过非主流个性，正反约等于氢弹或者核弹。现在也有以我祖母为首直呼我为王源的，我有时会觉得什么真实的东西被掩盖了，但是名字本就是他人用来称呼自己的，对大家来说好记就行。</p><p>说到“氦核”，就不得不提封笔之事，前些日子写歌词的时候又犯了曾经纠正过的毛病：笔下虚浮，空无一物。自觉填词生命耗尽，于是歇了笔耕，改完最后之作后不再写词。虽然看见好词仍会心头悸动，可我知道，不够努力是无法超越某些界限的，不够安静也看不见那些词。明明情感丰富，却摘不出一句能说出口，这也是由于我读书太少、想的太多、说的太多。</p><p>近日我突然想，有没有什么新名字更适合现在得我，毕竟成长了一些，不会把“我要变强”的字眼放在嘴边，待世界也更加温柔，原来那希望发光发热的名字貌似不太适合我现在佛系的心。便寻机求问《易经》，占得一卦泽天夬，夬者，决也。懂的朋友应该已经懂了，不懂的朋友现在肯定是不懂。其实改不改名字，答案我心里早都明白，只不过又让我坚定了一个目标，厚积薄发，该发就发。天不生氦核，屁话界万古如长夜。</p><p>关于名字还有一件有趣的事。起一个好记的名字真的挺重要，但碰巧会被大家都记住的那种，偶尔会产生奇妙的化学反应。母亲的朋友是个老师，在我小学时候经常去他的办公室玩耍。有一天去了，他正在批评一个大哥哥，应该是他的学生，但口中全都是“胡锦涛，你怎么没写作业……胡锦涛怎么又旷课……”我觉着疑惑，觉得像是模仿新闻联播。后来听他讲，原来受批评的学生名叫胡锦涛，那人自号“西北猛汉”，据说某次受罚还一口气做了两百个俯卧撑，属实猛男。他还说，每次教育那个学生时，都有一种奇妙的感觉，仿佛自己是为了某种巨大存在的命运而从事了教育。我当时听了觉得可笑，只是名字相仿罢了。后来我听说了一个词，叫人类命运共同体，我觉得来形容这个应该差不多，反正名字看去相似，而且好记，就行了。</p><p>（完，纯属虚构）</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;名字&quot;&gt;&lt;a href=&quot;#名字&quot; class=&quot;headerlink&quot; title=&quot;名字&quot;&gt;&lt;/a&gt;名字&lt;/h2&gt;&lt;h4 id=&quot;氦核-190918&quot;&gt;&lt;a href=&quot;#氦核-190918&quot; class=&quot;headerlink&quot; title=&quot;氦核 190918&quot;&gt;&lt;/a&gt;氦核 190918&lt;/h4&gt;&lt;p&gt;名字对于人来说，是十分珍贵的东西。当我们喜欢上某人某事某物时，往往就会给他起上一个爱称。当然笔名也是如此。我也有过很多称呼，有时爱了叫禾禾，有时不爱了叫呵呵，以外观特点取我名的倒没多少，可能是名字比起外貌更加容易记，谁的名字还没有个谐音之梗呢？我倒是不在意，好记就行了。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="文章" scheme="https://konelane.github.io/tags/%E6%96%87%E7%AB%A0/"/>
    
  </entry>
  
</feed>
