<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>KOneLane</title>
  
  <subtitle>一团代码，两行歌词，三篇文章</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://konelane.github.io/"/>
  <updated>2020-11-20T09:12:19.470Z</updated>
  <id>https://konelane.github.io/</id>
  
  <author>
    <name>Little Hehe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>大数据|分布式计算课程作业（持续更新）</title>
    <link href="https://konelane.github.io/2020/11/20/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%B1%87%E6%80%BB%E6%96%87%E4%BB%B6/"/>
    <id>https://konelane.github.io/2020/11/20/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%B1%87%E6%80%BB%E6%96%87%E4%BB%B6/</id>
    <published>2020-11-19T16:00:00.000Z</published>
    <updated>2020-11-20T09:12:19.470Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>还是熟悉的feng.li老师，还是熟悉的瓜皮禾禾，哈哈哈哈。</p><p>没想到研究生依然能听李丰老师的课。欢迎参观李丰老师<a href="feng.li">主页</a>，<a href="https://feng.li/teaching/distcomp/" target="_blank" rel="noopener">课程主页</a></p><p>李丰老师合著的<a href="https://feng.li/files/distcompbook/index.html" target="_blank" rel="noopener">参考书</a>依然在编</p><a id="more"></a><p>10.07记：被李丰老师表扬了！！甚至还被打赏了（笑</p><p>继续努力啊小禾禾</p><p><a href="https://konelane.github.io/2020/09/24/0917分布式计算">分布式0917-遍历检索的多进程初试水</a></p><p><a href="https://konelane.github.io/2020/09/24/0917分布式计算">分布式0924-分布式服务器基础Linux中主机的远程交互(ssh)</a></p><p><a href="https://konelane.github.io/2020/10/07/1007分布式计算">分布式1007-Map-Reduce的文字流</a></p><p><a href="https://konelane.github.io/2020/10/21/1015hadoop">分布式1015-1021-分布式回归分析</a></p><blockquote><p>Hadoop不是编程语言，是分布式计算架构。<br>——李丰老师</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;还是熟悉的feng.li老师，还是熟悉的瓜皮禾禾，哈哈哈哈。&lt;/p&gt;
&lt;p&gt;没想到研究生依然能听李丰老师的课。欢迎参观李丰老师&lt;a href=&quot;feng.li&quot;&gt;主页&lt;/a&gt;，&lt;a href=&quot;https://feng.li/teaching/distcomp/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;课程主页&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;李丰老师合著的&lt;a href=&quot;https://feng.li/files/distcompbook/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考书&lt;/a&gt;依然在编&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式1112-Spark简单功能补充介绍</title>
    <link href="https://konelane.github.io/2020/11/12/1112%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    <id>https://konelane.github.io/2020/11/12/1112%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/</id>
    <published>2020-11-11T16:00:00.000Z</published>
    <updated>2020-12-31T02:17:30.840Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>对spark进行一些补充介绍。</p><a id="more"></a><p>两个函数可以选定</p><blockquote><p>Cache()</p><p>Persist()</p></blockquote><p>主动将数据放到硬盘上-内存中</p><blockquote><p>Data.persist()</p></blockquote><p>旧数据放在内存里，新数据放硬盘，spark帮助中有persist 的水平（默认是全放进内存的cache，假设内存很大）</p><blockquote><p>lineLengths.unpersist()</p><p>persist的参数水平</p><p>Memory_only</p><p>Memory_AND_DISK</p><p>Memory_AND_DISK_SER</p><p>DISK_ONLY</p><p>MEMORY_ONLY_2</p></blockquote><p>内存不够则会报错</p><img src="/2020/11/12/1112分布式计算/11/12/1112分布式计算/tu1.png" title="tu1"><h3 id="二、Spark的一些特别之处"><a href="#二、Spark的一些特别之处" class="headerlink" title="二、Spark的一些特别之处"></a>二、Spark的一些特别之处</h3><h4 id="1-广播"><a href="#1-广播" class="headerlink" title="1. 广播"></a>1. 广播</h4><p>分布式最重要的是“数据共享”使得不同节点之间能够用一个数据。</p><p>比如正态分布的概率密度函数，π就如此，共享，但不修改。</p><blockquote><p>broadcastVar = sc.broadcast([1, 2, 3])</p><p>broadcastVar</p><p>Sparkcontext.broadcast(v)</p></blockquote><p>广播出去的变量不能修改，否则会乱。</p><p>Broadcast.value可以查看广播出去的变量。</p><p>spark中accumulator可以用于累积，在MapReduce中：</p><blockquote><p>accum = sc.accumulator(0)</p><p>sc.parallelize([1, 2, 3, 4])<strong>.foreach</strong>(lambda x: accum.add(x)) # foreach有点像R的</p><p>accum.value</p></blockquote><h4 id="2-懒人模式"><a href="#2-懒人模式" class="headerlink" title="2. 懒人模式"></a>2. 懒人模式</h4><p>spark的懒人模式：</p><p>节约计算资源</p><p>x=3 , y = 4 , z = 5</p><p>提交任务</p><blockquote><p>1.2x = ? </p><p>2.4y = ? </p><p>3.2x +4y = ?</p></blockquote><p> 或许前两步根本不用算，于是节约了资源。</p><p>spark使用DAG有向无环图，控制最后的结果本质上要求哪些计算。实现懒人模式。</p><blockquote><p>分布式就是管理人和物的一种抽象。 </p><p>—— 李丰老师</p></blockquote><h4 id="3-线性代数"><a href="#3-线性代数" class="headerlink" title="3. 线性代数"></a>3. 线性代数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import scipy.sparse as sps</span><br><span class="line">from pyspark.mllib.linalg import Vectors</span><br><span class="line"></span><br><span class="line"># Use a NumPy array as a dense vector.</span><br><span class="line">dv1 = np.array([1.0, 0.0, 3.0])</span><br><span class="line"># Use a Python list as a dense vector.</span><br><span class="line">dv2 = [1.0, 0.0, 3.0]</span><br><span class="line"># Create a SparseVector.</span><br><span class="line">sv1 = Vectors.sparse(3, [0, 2], [1.0, 3.0])</span><br><span class="line"># Use a single-column SciPy csc_matrix as a sparse vector.</span><br><span class="line">sv2 = sps.csc_matrix((np.array([1.0, 3.0]),</span><br><span class="line">                      np.array([0, 2]),</span><br><span class="line">                      np.array([0, 2])), shape=(3, 1))</span><br></pre></td></tr></table></figure><p>spark的线性代数模块很强大： pyspark.mllib.linalg</p><p>spark专门提供的<strong>标签</strong>工具</p><p>做分类模型时就可以使用特有变量了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.mllib.linalg import SparseVector</span><br><span class="line">from pyspark.mllib.regression import LabeledPoint</span><br><span class="line"></span><br><span class="line"># Create a labeled point with a positive label and a dense feature vector.</span><br><span class="line">pos = LabeledPoint(1.0, [1.0, 0.0, 3.0])</span><br><span class="line"># Create a labeled point with a negative label and a sparse feature vector.</span><br><span class="line">neg = LabeledPoint(0.0, SparseVector(3, [0, 2], [1.0, 3.0]))</span><br></pre></td></tr></table></figure><p>允许导入各式各样的稀疏数据。有了local就有distributed。</p><p>如果要做个逻辑回归、线性回归，能否模拟一个线性回归的数据，将其存入矩阵。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>spark集成了很多hive的优秀理念。</p><p>对于常见的数据框的操作，归类成不同类型的函数。</p><p>依赖于sparkSQL，有别于传统的RDD形式，因为在RDD上可以更底层地操作数据（矩阵向量……）</p><p>sparkSQL与hive结合，可以把hive的sql查询直接应用在数据框上，也允许用户自己的函数。支持读取hdfs上的数据，是个通用的多接口的形式。</p><p>sparkRDD形式数据灵活，操作很琐碎。于是spark提供了自己的dataset集合。其实就是分布式数据的综合，通过java的jvm集成的（java虚拟机，用于快速计算的技术）</p><p><strong>dataset的api只支持scala和Java。</strong></p><p>故如果想在spark上处理数据集，需要自己学习Scala语言（最后一节有讲，敬请期待）。</p><p>spark上的dataframe是分布式的，其实就是表，不同列之间可以是不同的数据类型。</p><p>可以对dataframe做清洗和操作。可以通过hive的表来构建，可以通过现成的表来构建。</p><p>各种语言都支持。</p><h3 id="三、战斗案例"><a href="#三、战斗案例" class="headerlink" title="三、战斗案例"></a>三、战斗案例</h3><p>目标，处理分布式的DataFrame，首先启动SC。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from pyspark.sql import SparkSession</span><br><span class="line">spark = SparkSession.builder.appName(&quot;Python Spark&quot;).getOrCreate()</span><br><span class="line">spark # test if Spark session is created or not</span><br><span class="line"></span><br><span class="line">sc = spark.sparkContext # make a spakr context for RDD</span><br><span class="line">sc</span><br></pre></td></tr></table></figure><img src="/2020/11/12/1112分布式计算/11/12/1112分布式计算/tu2.png" title="tu2"><img src="/2020/11/12/1112分布式计算/11/12/1112分布式计算/tu3.png" title="tu3"><p>spark有read函数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sdf = spark.read.csv(&quot;/opt/apps/ecm/service/spark/2.4.4/package/spark-2.4.4-bin-hadoop2.7/examples/src/main/resources/people.txt&quot;)</span><br><span class="line">sdf.show() # Displays the content of the DataFrame to stdout</span><br></pre></td></tr></table></figure><img src="/2020/11/12/1112分布式计算/11/12/1112分布式计算/tu4.png" title="tu4"><p>这个就是分布式上的表。</p><p>json格式可以直接读取（spark.read.json）</p><h4 id="schema"><a href="#schema" class="headerlink" title="schema"></a>schema</h4><p>属于读取表格时的表头信息。名字，类型，缺失等等。</p><p>经常需要手写表头，因为自动容易出错。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># We specify the correct schema by hand</span><br><span class="line">schema_sdf = StructType([</span><br><span class="line">        StructField(&apos;Year&apos;, IntegerType(), True),</span><br><span class="line">        StructField(&apos;Month&apos;, IntegerType(), True),</span><br><span class="line">        StructField(&apos;DayofMonth&apos;, IntegerType(), True),</span><br><span class="line">        StructField(&apos;DayOfWeek&apos;, IntegerType(), True),</span><br><span class="line">        StructField(&apos;DepTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;CRSDepTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;ArrTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;CRSArrTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;UniqueCarrier&apos;, StringType(), True),</span><br><span class="line">        StructField(&apos;FlightNum&apos;, StringType(), True),</span><br><span class="line">        StructField(&apos;TailNum&apos;, StringType(), True),</span><br><span class="line">        StructField(&apos;ActualElapsedTime&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;CRSElapsedTime&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;AirTime&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;ArrDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;DepDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;Origin&apos;, StringType(), True),</span><br><span class="line">        StructField(&apos;Dest&apos;,  StringType(), True),</span><br><span class="line">        StructField(&apos;Distance&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;TaxiIn&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;TaxiOut&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;Cancelled&apos;,  IntegerType(), True),</span><br><span class="line">        StructField(&apos;CancellationCode&apos;,  StringType(), True),</span><br><span class="line">        StructField(&apos;Diverted&apos;,  IntegerType(), True),</span><br><span class="line">        StructField(&apos;CarrierDelay&apos;, DoubleType(), True),</span><br><span class="line">        StructField(&apos;WeatherDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;NASDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;SecurityDelay&apos;,  DoubleType(), True),</span><br><span class="line">        StructField(&apos;LateAircraftDelay&apos;,  DoubleType(), True)</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">oridat = spark.read.options(header=&apos;true&apos;).schema(schema_sdf).csv(&quot;/data/airdelay_small.csv&quot;) # spark dataframe</span><br></pre></td></tr></table></figure><p>air.describe().show()就相当于简单的描述统计</p><p>air.describe([‘ArrDelay’]).show() 看具体的列</p><p>Data.collect()可以避开懒人模式直接计算</p><h3 id="四、作业-air-delay数据清洗"><a href="#四、作业-air-delay数据清洗" class="headerlink" title="四、作业 air-delay数据清洗"></a>四、作业 air-delay数据清洗</h3><p>五百万 * 十九列</p><p>转化成新的df，一类是0、1，告诉大家有没有延误</p><p>arrivedelay设置成0-1变量。现有的列可以使用：里程，是不是US（0-1），是不是AA（0-1），诸如此类，相当于把原变量修改成哑变量了。</p><p>最后得到————&gt;五百万 * 一百八十列</p><p>不要超过这么多列。（在老师github上/dlsa/blob/master/projects/logistic…）</p><p>作业，整理好这个数据。</p><p>下节课对这个数据做逻辑回归。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对spark进行一些补充介绍。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式1102-Hi,Hive!Hi,Spark!</title>
    <link href="https://konelane.github.io/2020/11/02/1102%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    <id>https://konelane.github.io/2020/11/02/1102%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/</id>
    <published>2020-11-01T16:00:00.000Z</published>
    <updated>2020-12-30T09:10:23.494Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>hadoop以及MapReduce暂告一段落！</p><p>这一节我们做个过渡，讲一讲Hive以及Spark。</p><a id="more"></a><h3 id="一、Hive介绍"><a href="#一、Hive介绍" class="headerlink" title="一、Hive介绍"></a>一、Hive介绍</h3><p>Hive是分布式的数据库。对于结构化数据存储、查询的高效工具。</p><p>查询特殊的行、列，数据库操作非常重要。</p><blockquote><p>数据库就像计算器一样。</p><p>——李丰老师</p></blockquote><p>不管什么类型的数据库，都有sql，数据库查询语言。能够对很大的表格进行类似excel的操作。</p><p>数据库面向不同的对象：</p><blockquote><p>计算机：设计高效数据库，快速存储海量数据。</p><p>使用者：快速得到想要的数据。</p></blockquote><p>大数据时代，数据库进入瓶颈，因为其不可扩展。轻量级的数据应用就不太喜欢数据库，转而使用hdfs。但hdfs没有数据库那样便利，不能select…from…</p><p>就诞生了基于hdfs的数据库工具。</p><p><strong>初衷</strong>：为了使企业能够快速部署使用结构化表格与操作。能将hdfs上的表格当做数据库的表格来使用（如csv）。</p><p>只要用sql语句就可以在hdfs上处理结构化数据。其实Hive是把sql解析成了MapReduce语句，最后传递回用户。</p><p>Hadoop（系统）hdfs（文件管理系统）</p><p>hive-SQL（可操作的客户端）complie+optimize+execute（很快啊！）</p><p>hive其实有小缓存，如果大量/经常查询同一条，就会被缓存下来，方便直接调用。</p><p>不会hadoop也可以用hive，只需要sql语句就行了。</p><p>hive可以做spark中dataframe的查询引擎。hive的功能就是能用sql的客户端。（氦核：这一点在之后的工作中显示了其强大与方便）</p><p>hive将sql解析成XML语句（标记位置）</p><p>hive完全是模拟了sql的写法，sql用的最广，python之流不适合这样的工作。</p><h3 id="二、启动一个Hive任务"><a href="#二、启动一个Hive任务" class="headerlink" title="二、启动一个Hive任务"></a>二、启动一个Hive任务</h3><p>Hive + 回车（进入交互界面）</p><p>Exit （退出）</p><p>hive允许执行很多命令同时推出</p><p>如：</p><blockquote><p>Hive -e “dfs -ls /;”</p></blockquote><p>e是执行。引号内是hive语句，分号是模仿sql的结束符号。</p><p>传递给hadoop就是hadoop fs -ls /</p><p>结果再传回hive</p><p>也可以写成文件：</p><blockquote><p>Hive -f /path/to/file/withqueries.hql</p></blockquote><p>hql（hive的文本文件，与sql区分）</p><img src="/2020/11/02/1102分布式计算/11/02/1102分布式计算/tu1.png" title="tu1"><p>输入hive可以进入终端</p><img src="/2020/11/02/1102分布式计算/11/02/1102分布式计算/tu2.png" title="tu2"><p>操作时，在终端中可以直接输入dfs -ls /;    （别忘了分号）</p><p>注：sql语言的特点——对大小写不敏感，语句中可以小写可以大写。但是对表的字段依然敏感。</p><blockquote><p>Show databases;</p></blockquote><p>可以看分布式集群上有什么数据库</p><blockquote><p>Show databases like ‘d*’;</p><p>Create database if not exists mydb;</p></blockquote><p> if not exists（是一个条件，如果有了就不会再创建，如果没有的话就创建）</p><img src="/2020/11/02/1102分布式计算/11/02/1102分布式计算/tu3.png" title="tu3"><p>数据库下有表，mydb不指定文件夹，就在warehouse的文件夹下。</p><p>location参数可以指定创建的位置</p><blockquote><p>Create database if not exists fff location ‘user/lifeng/hive’</p></blockquote><p>创建一个指定位置的数据库fff</p><blockquote><p>Drop database fff;</p></blockquote><p>删库，跑路！（危）</p><p>hive里如何创建表<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS mydb.employees (</span><br><span class="line">    name</span><br><span class="line">        STRING COMMENT &apos;Employee name&apos;,</span><br><span class="line">    salary</span><br><span class="line">        FLOAT COMMENT &apos;Employee salary&apos;,</span><br><span class="line">    subordinates ARRAY&lt;STRING&gt; COMMENT &apos;Names of subordinates&apos;,</span><br><span class="line">    deductions MAP&lt;STRING, FLOAT&gt;</span><br><span class="line">        COMMENT &apos;Keys are deductions names, values are percentages&apos;,</span><br><span class="line">    address</span><br><span class="line">        STRUCT&lt;street:STRING, city:STRING, state:STRING, zip:INT&gt;</span><br><span class="line">        COMMENT &apos;Home address&apos;)</span><br><span class="line">COMMENT &apos;Description of the table&apos;</span><br><span class="line">TABLEPROPERTIES (&apos;creator&apos;=&apos;me&apos;, &apos;created_at&apos;=&apos;2012-01-02 10:00:00&apos;);</span><br></pre></td></tr></table></figure></p><p>列名，comment记录注释，最后一行只创建了表头、创建者、创建时间等</p><p>hive记录了表的信息</p><p>因为刚刚用了use wyh_db;现在Show tables;就能看有哪些表。</p><p>hive提供了专门工具，把外部的csv文件链接进数据库。</p><p>hive可以创建外部表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">create external table if not exists stocks (</span><br><span class="line">    symbol string, </span><br><span class="line">    ymd string, </span><br><span class="line">    price_open float, </span><br><span class="line">    price_high float, </span><br><span class="line">    price_low float, </span><br><span class="line">    price_close float, </span><br><span class="line">    volume int, </span><br><span class="line">    price_adj_close float )</span><br><span class="line">row format delimited fields terminated by &apos;,&apos; </span><br><span class="line">location &apos;/user/lifeng/data&apos;;</span><br></pre></td></tr></table></figure><p>逗号分隔，原来是csv文件，要加一个逗号分隔（倒数第二行）</p><p>linux里有个内置命令awk脚本工具，能够</p><p>Awk -f 5，4啥的，能够选择打印第5和第4列</p><p>主要是不想导入python中处理。</p><p>如可以使用pig工具，合并两个表或多个表（我们用的不多）</p><p>pig有自己的书写习惯，计算机架构的工程师经常用</p><p>hbase是对谷歌bigtable的开源实现</p><p>能够按行更新（如python的append）</p><p>能做基于内存的文件缓存，加快速度</p><p>不支持sql的查询，但是hive目前有工具可以与之通行。</p><p>（HIVE的简介到此结束，后面有任务再见）</p><h3 id="三、Spark"><a href="#三、Spark" class="headerlink" title="三、Spark"></a>三、Spark</h3><p><a href="http://spark.apache.org/" target="_blank" rel="noopener">spark</a>，</p><blockquote><p>Speed - Run workloads 100x faster.</p><p>Ease of Use - Write applications quickly in Java, Scala, Python, R, and SQL.</p><p>Generality - Combine SQL, streaming, and complex analytics.</p><p>Runs Everywhere - Spark runs on Hadoop, Apache Mesos, Kubernetes, standalone, or in the cloud. It can access diverse data sources.</p></blockquote><p>伯克利的博士生，针对hadoop的问题重新写成了spark（老师也希望我们做这样的博士生，扶额）</p><p>Databricks公司，官网上提供了简单交互学习的平台。</p><p>spark在计算过程中非常快，是hadoop速度的一百倍</p><p>可以使用python，r，java，还有spark自带的scala语言。Scala语言有java的特性，又像r一样好写。</p><p>可以将spark当做python的一个模块来使用。（氦核：事实证明，pyspark很强，还自带深度学习模块，不过没那么顺手。）用户只需要学一点点就能用起来。</p><p>sparkR可以启动r。r语言设计用于统计分析，但是spark需要计算机组件，但是r没有，python有。</p><h4 id="spark与hadoop的区别"><a href="#spark与hadoop的区别" class="headerlink" title="spark与hadoop的区别"></a>spark与hadoop的区别</h4><p>hadoop是分布式的框架，spark对MapReduce看的更少，结果算的很快。</p><p>还有，hadoop不能交互；spark可以交互式操作一个对象。可以创建分布式对象， 在不同的节点上都存在，同时保证应用性和速度</p><p>spark也有通用性和广泛性，可以把sql集成进spark。</p><p>spark也可以处理流数据。</p><p>spark甚至可以机器学习和深度学习。</p><p>spark可以看做是分布式系统上更方便操作的hadoop客户端。</p><p>可以运行在hadoop上，可以当做独立的分布式系统。</p><p>spark可以接受hdfs等来源的文件，也可以自己建立dataframe。</p><p>spark可以用数据框组织数据。</p><p>spark有内置机器学习库，叫ml_lib；图形处理GraphX；流数据处理Spark Streaming（企业常用）。 </p><p>spark也可以运行在其他分布式平台上，各种各样的平台上都有spark接口。易用性使其广泛普及。</p><p>spark提供了hive的集成。不过select不能写很复杂。但是通过spark可以先让spark执行select，再让hive执行。</p><p>快的原因：</p><img src="/2020/11/02/1102分布式计算/11/02/1102分布式计算/tu4.png" title="tu4"><blockquote><p>1.很多worker节点，worker之间交互很快（通过交换机）<br>2.worker上可以运行很多任务（executor）<br>3.每个worker上都有一些存储最常用数据的内存</p></blockquote><p>劣势：</p><blockquote><p>需要很大的内存 — hadoop最不耗内存</p><p>spark的官方建议，需要原始数据2-5倍的内存才能保证平稳运行</p></blockquote><p>有名的spark错误：OOM错误</p><p>Out of memory（哈哈哈）</p><p>加内存，扩容，烧钱啊。</p><blockquote><p>尽可能让代码写快一些，用最少的资源得到最大的价值。</p><p>——李丰老师</p></blockquote><p>之后课程计划讲：数据类型、机器学习的库（老版本基于rdd，新版本基于数据框）、streaming </p><p>不讲：计算机视觉相关包</p><h3 id="四、启动spark"><a href="#四、启动spark" class="headerlink" title="四、启动spark"></a>四、启动spark</h3><p>启动：.py .r</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Spark-submit \</span><br><span class="line"> --class </span><br><span class="line"> --master #什么节点(yarn)</span><br><span class="line"> --deploy-mode</span><br><span class="line"> --executor-memory 20G \</span><br><span class="line"> --conf</span><br></pre></td></tr></table></figure><p><a href="http://spark.apache.org/examples.html" target="_blank" rel="noopener">Spark案例</a></p><p>使用spark-summit提交上去就能执行了。在spark运算前，要想想全部需要多少运算资源，给每个executor分多少内存。</p><p>Tiny fat 两种分配资源想法</p><blockquote><p>Tiny 模式给每个核分一个executor，32g给8核，只能拿到4g，加上系统消耗就会更少。这种情形适用于cpu负荷大，如迭代类型，更多时候是迭代的分布式要跑起来。</p><p>Fat 模式，要是对IO很多的时候，我们不一定需要很多executor，八核可能只用两个executor，每个executor就有4核、16g使用。</p></blockquote><p>python有个**x，即将列表展开按位置放入</p><p>x的长度不超过256，但是python3.8现在允许任意长度参数传入</p><p>X = [1,2,3,…,1000] </p><p>Sumfunc(**x)</p><p>登录服务器，输入spark-shell</p><img src="/2020/11/02/1102分布式计算/11/02/1102分布式计算/tu5.png" title="tu5"><p>使用pyspark要输入神秘代码（就是python的版本，配置时一定要与spark版本对应起来，比如服务器只能用3.6版本的python）</p><img src="/2020/11/02/1102分布式计算/11/02/1102分布式计算/tu6.png" title="tu6"><p>或者直接在python中import pyspark，有时候需要先import findspark。</p><h4 id="Spark的API"><a href="#Spark的API" class="headerlink" title="Spark的API"></a>Spark的API</h4><p>rdd是什么（resilient distributed dataset）RDD是Spark里最重要的一个概念。</p><p>任何一个spark都可以通过rdd对象连接起来，也允许用户部署任何计算。</p><p>通过rdd转化成驱动程序，放入计算节点上计算，如传统的数学计算都可以转化。</p><p>spark-rdd提供了数据上的一个抽象，提供了海量数据的拆分机制，也可以通过不同的方式创建。</p><p>如分布式hdfs上有个文件，可以直接转化（好比hive上有个表），它也能判断哪些数据应该放入内存、硬盘。来提高效率。</p><p>其次，rdd也监视了每个计算节点的数据完整性。复活的基本机理与hadoop相似。闲暇时间拷贝。</p><p>spark能进行机器学习的理由：spark允许变量进行共享，每个节点都有想同的变量。</p><blockquote><p>1.常量，都用得着，不需修改。通过广播（broadcast variables）来传递给每个节点</p><p>2.传递到节点后，还可能要修改（如迭代算法）会消耗资源（accumulators）</p></blockquote><h4 id="如何创建spark-context"><a href="#如何创建spark-context" class="headerlink" title="如何创建spark context"></a>如何创建spark context</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import findspark</span><br><span class="line">findspark.init(&quot;/usr/lib/spark-current&quot;)</span><br><span class="line">import pyspark</span><br><span class="line"></span><br><span class="line">sc.stop()</span><br><span class="line">sc = pyspark.SparkContext(&quot;local&quot;, &quot;My First Spark App&quot;)</span><br></pre></td></tr></table></figure><p>使用了<strong>sc.parallelize</strong>就会传上spark，是一个对象。如果数据在本地或hdfs，都可以上传。</p><h4 id="给一个自己的作业超简单案例"><a href="#给一个自己的作业超简单案例" class="headerlink" title="给一个自己的作业超简单案例"></a>给一个自己的作业超简单案例</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#! /usr/bin/env python3.6</span><br><span class="line">import pyspark</span><br><span class="line"></span><br><span class="line">conf = pyspark.SparkConf().setAppName(&quot;Hehe First Spark RDD APP&quot;).setMaster(&quot;local&quot;)  # “yarn”</span><br><span class="line">sc = pyspark.SparkContext(conf=conf)</span><br><span class="line">sc.stop()</span><br><span class="line">sc = pyspark.SparkContext.getOrCreate()</span><br><span class="line">licenseFile = sc.textFile(&quot;2020210995wangyuanhe/reg/stocks.txt&quot;)</span><br><span class="line">lineLengths = licenseFile.map(lambda s: len(s))</span><br><span class="line">totalLength = lineLengths.reduce(lambda a, b: a + b)</span><br><span class="line"></span><br><span class="line">print(totalLength)</span><br></pre></td></tr></table></figure><p>（未完待续，下次再细讲Spark，学吧，学无止境，太深了）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;hadoop以及MapReduce暂告一段落！&lt;/p&gt;
&lt;p&gt;这一节我们做个过渡，讲一讲Hive以及Spark。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式1015-1021-分布式回归分析</title>
    <link href="https://konelane.github.io/2020/10/21/1015hadoop/"/>
    <id>https://konelane.github.io/2020/10/21/1015hadoop/</id>
    <published>2020-10-20T16:00:00.000Z</published>
    <updated>2020-12-30T08:21:42.816Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="一、开始！今日信息量巨大"><a href="#一、开始！今日信息量巨大" class="headerlink" title="一、开始！今日信息量巨大"></a>一、开始！今日信息量巨大</h3><p>大佬们展示肌肉。</p><p>回归部分还需要些数学根底。</p><p>代码后面也有一丢丢正文。</p><a id="more"></a><p>先给一个linux服务器的方便功能。</p><p>Screen -DR 加个名字，可以开启永远运行的窗口。</p><p>Ctrl A + </p><blockquote><ol><li>C 创建新窗口</li><li>N 切换下一个窗口</li><li>D 回到主界面（并未关闭窗口）<br>Exit 命令退出</li></ol></blockquote><p>同学们的学习能力很强，可以打开vim编辑器并且退出了。（笑</p><p>不不，是有与数据对话的能力了。</p><p>希望脱颖而出，代码能力肯定比不上，但是我们有专业优势，即对<strong>数据分析</strong>的能力。我们懂模型，懂预测。</p><p>至于为什么要用hadoop，因为数据多了，非常大。</p><h4 id="给出一个场景"><a href="#给出一个场景" class="headerlink" title="给出一个场景"></a>给出一个场景</h4><p>场景：美国二手车，kaggle us-used-car。一共300w条记录，66个变量。</p><p>因变量：Price，最主要的任务就是探究price受谁的影响。</p><p>首先这么多变量中，存在很多数据缺失问题。去缺失。传到服务器上后，挑出一些缺失值少的变量。</p><p>今天作业：<br>用这个数据，清理出一份可以回归的变量来。r里面有很多现成的东西。</p><h3 id="二、分布式上的回归分析"><a href="#二、分布式上的回归分析" class="headerlink" title="二、分布式上的回归分析"></a>二、分布式上的回归分析</h3><p>如何在分布式上进行回归分析？区别在哪？（按行读取）</p><p>原来的数据n乘p维，n很小100，p很小10。</p><p>现在的数据n乘p维，n很大300w，p有66列，实际上会比这多得多，比如多个水平的哑变量就会占很多列。p很可能大于1k。</p><p>原始数据9gb，存成双精度需要60g的内存。需要双倍的空间才能执行任务，单机不可能。但是我们有分布式。</p><script type="math/tex; mode=display">Y = x \times \beta + \epsilon</script><p>beta不大，但是帽子阵根本求不了。要想解决这个问题，最难的在于计算：</p><script type="math/tex; mode=display">（X^{t}X）^{-1}，X^{t}</script><p>有了目标，剩下的就很简单了。</p><p><strong>第一个问题</strong>：如何构造把X^{t}Y求出来？</p><p>如果x仅有一列，相当于 $ 1<em>n $ 与 $ n</em>1 $相乘，代数运算即一一对应相乘求和，放在转置前看，即每行的元素相乘。如果x有两列，最终结果是2乘1的两个数，第一行为x第一列与y的对应乘积求和，第二行为x第二列与y的对应元素乘积求和。（内积）</p><p><strong>第二个问题</strong>：如何把X^{t}X构造出来？</p><p>最终得到的是p乘p维的矩阵，第xij位置的元素，为x第i列与x第j列对应元素的乘积（内积）。i可以等于j。</p><p>看到所有问题的答案，我们发现，所有的计算都是行内部的计算！那不是很舒服？分行计算就行啊！</p><h3 id="三、作业代码"><a href="#三、作业代码" class="headerlink" title="三、作业代码"></a>三、作业代码</h3><h4 id="1-简单线性回归"><a href="#1-简单线性回归" class="headerlink" title="1. 简单线性回归"></a>1. 简单线性回归</h4><p>生成回归数据的r文件就不贴了。来看看我写的又臭又长的估计法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">readme.txt</span><br><span class="line">先使用Rscript reg.r建立reg.csv（回归数据集）</span><br><span class="line">再使用MapReduce</span><br><span class="line">mapper与process文件都是分行操作，使用1个process（reducer）求和就行</span><br></pre></td></tr></table></figure><p>下面是生成数据用的R代码。代码中控制了beta的值，可以与最后结果比较。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#! /usr/bin/env Rscript</span><br><span class="line"></span><br><span class="line">n = 1000</span><br><span class="line">p = 10</span><br><span class="line">x = matrix(rnorm(n*p), n, p)</span><br><span class="line">e = rnorm(n)</span><br><span class="line">beta = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)</span><br><span class="line">y = x%*%beta+0.3*e</span><br><span class="line">mydata = cbind(x, y)</span><br><span class="line">dim(mydata)</span><br><span class="line">write.table(mydata, &quot;linear.csv&quot;, sep = &quot;,&quot; , row.names = FALSE,  col.names = FALSE)</span><br><span class="line">colnames(mydata) = c(&quot;x1&quot;, &quot;x2&quot;, &quot;x3&quot;, &quot;x4&quot;, &quot;x5&quot;, &quot;x6&quot;, &quot;x7&quot;, &quot;x8&quot;, &quot;x9&quot;, &quot;x10&quot;, &quot;y&quot;)</span><br><span class="line">mydata = data.frame(mydata)</span><br><span class="line">myfit &lt;- lm(y~x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, mydata)</span><br><span class="line">myfit$coefficients</span><br></pre></td></tr></table></figure><p>这段代码是mapper。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#! usr/bin/env python3</span><br><span class="line"># 目标是做一些读取的工作，R做不了不同类型数据的存储</span><br><span class="line"></span><br><span class="line">import sys</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 先按“读取，把文件里字符型数据中的逗号替换成其他符号</span><br><span class="line">def commakiller(abc):</span><br><span class="line">    i = 1</span><br><span class="line">    while(i&lt;len(abc)):</span><br><span class="line">        abc[i] = abc[i].replace(&quot;,&quot;,&quot;***&quot;)</span><br><span class="line">        a = &apos;&quot;&apos;</span><br><span class="line">        abc[i] = a + abc[i] + a</span><br><span class="line">        i = i + 2</span><br><span class="line">    b = &quot;&quot;</span><br><span class="line">    qline = b.join(abc)</span><br><span class="line">    return(qline)</span><br><span class="line"></span><br><span class="line">#reader = csv.reader(sys.stdin)</span><br><span class="line">#next(reader)</span><br><span class="line">times = 1</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    abc = line.split(&apos;&quot;&apos;)</span><br><span class="line">    data = commakiller(abc).split(&quot;,&quot;)</span><br><span class="line">    p = len(data)</span><br><span class="line">    if p &lt;= 1: continue</span><br><span class="line">    #if times == 1 : names = data;times = times + 1;continue</span><br><span class="line">    if p &gt; 1 :</span><br><span class="line">        data[p-1] = data[p-1][:-1]  # 每行后的换行符</span><br><span class="line">        datak = list(map(float, data))</span><br><span class="line">        xty = []</span><br><span class="line">        for i in range(p-1):</span><br><span class="line">            xty.append(datak[i] * datak[p-1]) # 默认第p个是因变量</span><br><span class="line">        print(&quot;*&quot;,&quot;,&quot;.join(str(i) for i in xty)) </span><br><span class="line">        xtx = np.outer(datak[0:(p-1)],datak[0:(p-1)])  # 外积</span><br><span class="line">        print(&quot;,&quot;.join(&quot;,&quot;.join(str(k) for k in qq) for qq in xtx.tolist()))</span><br></pre></td></tr></table></figure><p>mapper把数据用逗号分隔，标准输出在屏幕上。<br>用管道将mapper的输出结果能够被吸入process.py（reducer，如下段代码）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">#! usr/bin/env python3</span><br><span class="line">import sys</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">xtx = [];xty = [];temp = []</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    data = line.split(&apos;,&apos;)</span><br><span class="line">    #print(data)</span><br><span class="line">    p = len(data)</span><br><span class="line">    data[p-1] = data[p-1][:-1]</span><br><span class="line">    if line[0] == &quot;*&quot;:  # 说明是标记的xty</span><br><span class="line">        data[0] = data[0][2:]</span><br><span class="line">        p1 = len(data)</span><br><span class="line">        data = list(map(float, data))</span><br><span class="line">        if len(xty) == 0:</span><br><span class="line">            xty = data</span><br><span class="line">            continue</span><br><span class="line">        else:</span><br><span class="line">            xty = xty + np.array(data)</span><br><span class="line">            # 在新的xtx出现之前</span><br><span class="line">            if len(xtx) == 0:</span><br><span class="line">                xtx = temp</span><br><span class="line">            else:</span><br><span class="line">                xtx = np.array(xtx) + np.array(temp) # bug</span><br><span class="line">                len2 = len(temp)</span><br><span class="line">            temp = []  # 循环结束初始化</span><br><span class="line">    else:   # 其他都是xtx</span><br><span class="line">        data = list(map(float, data))</span><br><span class="line">        if len(temp) == 0:</span><br><span class="line">            temp = data</span><br><span class="line">        else:</span><br><span class="line">            temp = temp + data # 连接</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">xtx = np.asarray(xtx).reshape(int(p1),int(len2/p1))</span><br><span class="line">print(np.dot(np.linalg.inv(xtx),np.array(xty)))</span><br></pre></td></tr></table></figure><p>原理与之前讲的相似，先计算xtx与xty，求逆（生成的矩阵有时候会奇异，那就重新生成一波）</p><p>最后是我们的main主函数shell文件，这个没啥变化 (不要直接跑，我改了文件名)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">PWD=$(cd $(dirname $0); pwd)</span><br><span class="line">cd $PWD 1&gt; /dev/null 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line">hadoop fs -put linear.csv /user/devel/hehe/reg</span><br><span class="line"></span><br><span class="line">TASKNAME=linear-hehe</span><br><span class="line">HADOOP_INPUT_DIR=/user/devel/hehe/reg/linear.csv</span><br><span class="line">HADOOP_OUTPUT_DIR=/user/devel/hehe/output/1020output</span><br><span class="line"></span><br><span class="line">echo $HADOOP_HOME</span><br><span class="line">echo $HADOOP_INPUT_DIR</span><br><span class="line">echo $HADOOP_OUTPUT_DIR</span><br><span class="line"></span><br><span class="line">hadoop fs -rm -r $HADOOP_OUTPUT_DIR</span><br><span class="line"></span><br><span class="line">hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.1.3.jar \</span><br><span class="line">-D mapred.job.name=$TASKNAME \</span><br><span class="line">-D mapred.job.priority=HIGH \</span><br><span class="line">-D stream.memory.limit=1000 \</span><br><span class="line">-D mapred.reduce.tasks=1 \</span><br><span class="line">-D mapred.job.map.capacity=100 \</span><br><span class="line">-D mapred.job.map.capacity=100 \</span><br><span class="line">-input $&#123;HADOOP_INPUT_DIR&#125; \</span><br><span class="line">-output $&#123;HADOOP_OUTPUT_DIR&#125; \</span><br><span class="line">-mapper &quot;$PWD/mapper.py&quot; \</span><br><span class="line">-reducer &quot;$PWD/process.py&quot; \</span><br><span class="line">-file &quot;$PWD/mapper.py&quot; &quot;$PWD/process.py&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ $? -ne 0 ]; then</span><br><span class="line">    echo &apos;error&apos;</span><br><span class="line">    exit 1</span><br><span class="line">fi</span><br><span class="line">hadoop fs -touchz $&#123;HADOOP_OUTPUT_DIR&#125;/done</span><br><span class="line"></span><br><span class="line">hadoop fs -ls $HADOOP_OUTPUT_DIR | cat</span><br><span class="line"></span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><h4 id="2-清洗二手车数据"><a href="#2-清洗二手车数据" class="headerlink" title="2. 清洗二手车数据"></a>2. 清洗二手车数据</h4><p>二手车数据来自kaggle <a href="https://www.kaggle.com/ananaymital/us-used-cars-dataset" target="_blank" rel="noopener">给个链接</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">本文件仅适用于二手车数据</span><br><span class="line"></span><br><span class="line">仅进行了OLS回归，GLM需要在帽子阵计算中加权，未实现</span><br><span class="line"></span><br><span class="line">本地5w行数据计算成功，hadoop上还未测试</span><br><span class="line"></span><br><span class="line">na.py用于清洗数据，计算变量均值标准差，并给出适合的列。对300万原数据得到的结果存入vars.txt</span><br><span class="line"></span><br><span class="line">mapper.py用于简单正态插补，计算帽子矩阵</span><br><span class="line"></span><br><span class="line">reducer.py用于计算系数阵估计值betahat，得到的结果存入result1.txt中</span><br></pre></td></tr></table></figure><p>先看na.py，这个代码对数据na等情况做了处理，有点长，这个文件在处理时单独运行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line">#! usr/bin/env python3</span><br><span class="line">## 任务：计算每列的na、均值、方差、总量与内部情况</span><br><span class="line">times = 1</span><br><span class="line">import sys</span><br><span class="line">import re # 正则化</span><br><span class="line">import numpy as np</span><br><span class="line">import math</span><br><span class="line">from operator import itemgetter</span><br><span class="line"></span><br><span class="line"># 先按“读取，把文件里字符型数据中的逗号替换成其他符号</span><br><span class="line">def commakiller(abc):</span><br><span class="line">    i = 1</span><br><span class="line">    while(i&lt;len(abc)):</span><br><span class="line">        abc[i] = abc[i].replace(&quot;,&quot;,&quot;***&quot;)</span><br><span class="line">        a = &apos;&quot;&apos;</span><br><span class="line">        abc[i] = a + abc[i] + a</span><br><span class="line">        i = i + 2</span><br><span class="line">    b = &quot;&quot;</span><br><span class="line">    qline = b.join(abc)</span><br><span class="line">    return(qline)</span><br><span class="line"></span><br><span class="line">na_count = &#123;&#125;</span><br><span class="line">num_count = &#123;&#125;;var_count = &#123;&#125;</span><br><span class="line">strvalue = &#123;&#125;</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    data = line.split(&apos;&quot;&apos;)</span><br><span class="line">    items = commakiller(data).split(&apos;,&apos;)</span><br><span class="line">    #print(&quot;,&quot;.join(str(k) for k in items))</span><br><span class="line">    if(times == 1):</span><br><span class="line">        times += 1</span><br><span class="line">        names = items  # 后续遍历使用</span><br><span class="line">        continue</span><br><span class="line">    if(times &gt;= 2):</span><br><span class="line">        ## na的计算与插补需要把全数据遍历</span><br><span class="line">        for key, value in enumerate(items):</span><br><span class="line">            count = int((value == &apos;&apos;) | (value == &quot;--&quot;))</span><br><span class="line">            na_count[key] = na_count.get(key, 0) + count # 每行统计缺失值</span><br><span class="line">            # get函数，如果对应key是空值，则返回0（设置的默认值），有缺失会被上一行count记录下来</span><br><span class="line">            # 计算其他列属性，描述统计</span><br><span class="line">           </span><br><span class="line">            if ((value != &quot;&quot;) &amp; (value != &quot;--&quot;)):</span><br><span class="line">                #if len(value) &gt; 25:  # 超长取值一般都无法处理，删除</span><br><span class="line">                #    continue</span><br><span class="line">                try:</span><br><span class="line">                    val_num = float(value) # 如果是数值型变量</span><br><span class="line">                    num_count[key] = num_count.get(key,0) + val_num # 数值型直接求和</span><br><span class="line">                    var_count[key] = var_count.get(key,0) + val_num ** 2 # 平方求和</span><br><span class="line">                except(ValueError):</span><br><span class="line">                    try:</span><br><span class="line">                        # 数值型变量带单位的，如下处理</span><br><span class="line">                        if ((&quot;in&quot; in value[-5:])&amp;(re.findall(&apos;[a-z]in&apos;,value)==[])):</span><br><span class="line">                            val_num = float(re.sub(&apos;in&apos;,&apos;&apos;,value,1))</span><br><span class="line">                            num_count[key] = num_count.get(key,0) + val_num</span><br><span class="line">                            var_count[key] = var_count.get(key,0) + val_num ** 2</span><br><span class="line">                        elif ((&quot;seats&quot; in value[-8:])&amp;(re.findall(&apos;[a-z]seats&apos;,value)==[])):</span><br><span class="line">                            val_num = float(re.sub(&apos;seats&apos;,&apos;&apos;,value,1))</span><br><span class="line">                            num_count[key] = num_count.get(key,0) + val_num</span><br><span class="line">                            var_count[key] = var_count.get(key,0) + val_num ** 2</span><br><span class="line">                        elif ((&apos;gal&apos; in value[-6:])&amp;(re.findall(&apos;[a-z]gal&apos;,value)==[])):</span><br><span class="line">                            val_num = float(re.sub(&apos;gal&apos;,&apos;&apos;,value,1))</span><br><span class="line">                            num_count[key] = num_count.get(key,0) + val_num</span><br><span class="line">                            var_count[key] = var_count.get(key,0) + val_num ** 2</span><br><span class="line">                        #elif &apos;RPM&apos; in value[-3:]:</span><br><span class="line">                        #    val_num = float(re.sub(&apos;RPM&apos;,&apos;&apos;,value,1))</span><br><span class="line">                        #    num_count[key] = num_count.get(key,0) + val_num</span><br><span class="line">                        # 带单位的只有这几个，数值化后，全存进num_count的字典中 </span><br><span class="line">                        # 出了点问题，&apos;148 lb-ft @ 200 RPM&apos; 这什么意思（于是这列被删了）</span><br><span class="line">                        # 下面处理所有字符类型的变量，用字典存储元素，并计算种类和数量</span><br><span class="line">                        #print(num_count)</span><br><span class="line">                        else:</span><br><span class="line">                            strvalue.setdefault(key,&#123;&#125;)  # 设定每个变量默认字典初始值为空</span><br><span class="line">                            strvalue[key][value] = strvalue[key].get(value,0) + 1  # 每次更新对应元素的value，+1</span><br><span class="line">                    except(ValueError):</span><br><span class="line">                        #print(&apos;转换失败 第%s列\t%s&apos;%(key,names[key]))</span><br><span class="line">                        continue</span><br><span class="line">        times += 1</span><br><span class="line"></span><br><span class="line">### 1.处理 na</span><br><span class="line">abort = [];fix = [];perf = []</span><br><span class="line"></span><br><span class="line">print(&quot;,&quot;.join(str(k) for k in names))  # 变量名-1行</span><br><span class="line">sorted_na_count = sorted(na_count.items(), key=itemgetter(0))</span><br><span class="line">for num, count in sorted_na_count:</span><br><span class="line">    na01 = times - count - 1</span><br><span class="line">    print(&apos;%s\t%s\t%s&apos; % (num, count,times))  # 每列缺失值-66行</span><br><span class="line">    value = int(count)</span><br><span class="line">    key = int(num)</span><br><span class="line">    lendata = times - 1 # 数据长度</span><br><span class="line">    if key == 0:</span><br><span class="line">        abort.append(key)</span><br><span class="line">        continue # ID列直接加入废弃</span><br><span class="line">    if (value/lendata) &gt;= 0.3:</span><br><span class="line">        abort.append(key) # 把大于30% 的缺失列号加入废弃</span><br><span class="line">    elif ((value/lendata &gt; 0) &amp; (value/lendata &lt; 0.3)):</span><br><span class="line">        fix.append(key)</span><br><span class="line">    elif(value == 0):</span><br><span class="line">        perf.append(key)</span><br><span class="line"></span><br><span class="line">print(&quot;需要丢掉的列号：%s\n需要插补的列号：%s\n完美列号：%s&quot; % ((&quot;,&quot;.join(str(k) for k in abort)),(&quot;,&quot;.join(str(k) for k in fix)),(&quot;,&quot;.join(str(k) for k in perf))))</span><br><span class="line"></span><br><span class="line">### 2.数值型变量</span><br><span class="line">sorted_num_count = sorted(num_count.items(), key=itemgetter(0)) </span><br><span class="line">for num,count in sorted_num_count:</span><br><span class="line">    if int(num) in abort:</span><br><span class="line">        print(&apos;丢掉第%d列\t%s\t-是首列或因na过多&apos;%(num,names[num]))</span><br><span class="line">        continue</span><br><span class="line">    xbar = count/na01</span><br><span class="line">    if xbar &gt; 100000:</span><br><span class="line">        print(&apos;丢掉第%d列\t%s\t-xbar大于100000&apos;%(num,names[num]))</span><br><span class="line">        continue</span><br><span class="line">    sdlist = math.sqrt(var_count[num]/na01 - xbar**2) # EX2 - (EX)2</span><br><span class="line">    print(&apos;%s\t%s\t%s\t%s&apos; % (num, names[num], xbar, sdlist)) # num是列号，count是全元素和</span><br><span class="line">    ## 问题，会出现很多大均值的列，不清楚为什么，需要筛选</span><br><span class="line"></span><br><span class="line">### 3.字符型变量</span><br><span class="line">for key in strvalue.keys(): # 把所有字符型的key遍历一遍 (都是列号)</span><br><span class="line">    if int(key) in abort:</span><br><span class="line">        try:</span><br><span class="line">            print(&apos;丢掉第%d列\t%s\t-na过多&apos;%(key,names[key]))</span><br><span class="line">            continue</span><br><span class="line">        except(TypeError):</span><br><span class="line">            print(&apos;丢掉第%d列\t%s\t-数据出界&apos;%(key,names[key]))</span><br><span class="line">            continue </span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    if len(strvalue[key].keys()) &gt; 10 : # 字符型变量之内有个统计，也存成dict，现在要取值大于5类的变量都消灭掉</span><br><span class="line">        print(&apos;丢掉第%d列\t%s\t-类数大于10&apos;%(key,names[key]))</span><br><span class="line">        continue # 分行操作时，可能有些时候会保留一些取值本来很多的变量，不过没关系</span><br><span class="line">    sorted_str_count = sorted(strvalue[key].items(), key=itemgetter(0)) # 变量内部的字典-再计数，根据变量名这个key放回到names中找原位置</span><br><span class="line">    print(&apos;%s&apos;%(&apos;第%d列&apos;%(key))) </span><br><span class="line">    for num, count in sorted_str_count:</span><br><span class="line">        try:</span><br><span class="line">            print(&apos;%s\t%s\t%s&apos; % (num, names[key], count))</span><br><span class="line">        except(TypeError):</span><br><span class="line">            print(&apos;上一行的有问题，丢掉第%d列\t%s\t-type_error了&apos;%(key,names[key]))</span><br><span class="line">            continue</span><br></pre></td></tr></table></figure><p>上面处理时，其实要十分了解原数据的含义和数据初始形式。在数据处理之前，尽可能选择取样观察，或者利用信息提前计划。</p><p>na.py的处理中，会给出需要删除/不需删除，各列的均值与标准差等。结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br></pre></td><td class="code"><pre><span class="line">[devel@emr-header-1 1026]$ cat vars.txt</span><br><span class="line">vin,back_legroom,bed,bed_height,bed_length,body_type,cabin,city,city_fuel_economy,combine_fuel_economy,daysonmarket,dealer_zip,description,engine_cylinders,engine_displacement,engine_type,exterior_color,fleet,frame_damaged,franchise_dealer,franchise_make,front_legroom,fuel_tank_volume,fuel_type,has_accidents,height,highway_fuel_economy,horsepower,interior_color,isCab,is_certified,is_cpo,is_new,is_oemcpo,latitude,length,listed_date,listing_color,listing_id,longitude,main_picture_url,major_options,make_name,maximum_seating,mileage,model_name,owner_count,power,price,salvage,savings_amount,seller_rating,sp_id,sp_name,theft_title,torque,transmission,transmission_display,trimId,trim_name,vehicle_damage_category,wheel_system,wheel_system_display,wheelbase,width,year</span><br><span class="line"></span><br><span class="line">0       0       3000600</span><br><span class="line">1       242727  3000600</span><br><span class="line">2       2980472 3000600</span><br><span class="line">3       3000040 3000600</span><br><span class="line">4       2579859 3000600</span><br><span class="line">5       13543   3000600</span><br><span class="line">6       2936507 3000600</span><br><span class="line">7       0       3000600</span><br><span class="line">8       491285  3000600</span><br><span class="line">9       3000040 3000600</span><br><span class="line">10      0       3000600</span><br><span class="line">11      0       3000600</span><br><span class="line">12      77901   3000600</span><br><span class="line">13      100578  3000600</span><br><span class="line">14      172383  3000600</span><br><span class="line">15      100578  3000600</span><br><span class="line">16      0       3000600</span><br><span class="line">17      1426595 3000600</span><br><span class="line">18      1426595 3000600</span><br><span class="line">19      0       3000600</span><br><span class="line">20      572568  3000600</span><br><span class="line">21      175452  3000600</span><br><span class="line">22      160673  3000600</span><br><span class="line">23      82721   3000600</span><br><span class="line">24      1426595 3000600</span><br><span class="line">25      159733  3000600</span><br><span class="line">26      491266  3000600</span><br><span class="line">27      172383  3000600</span><br><span class="line">28      2       3000600</span><br><span class="line">29      1426595 3000600</span><br><span class="line">30      2999953 3000600</span><br><span class="line">31      2817055 3000600</span><br><span class="line">32      0       3000600</span><br><span class="line">33      2864591 3000600</span><br><span class="line">34      0       3000600</span><br><span class="line">35      159722  3000600</span><br><span class="line">36      0       3000600</span><br><span class="line">37      0       3000600</span><br><span class="line">38      0       3000600</span><br><span class="line">39      0       3000600</span><br><span class="line">40      369087  3000600</span><br><span class="line">41      200042  3000600</span><br><span class="line">42      0       3000600</span><br><span class="line">43      159766  3000600</span><br><span class="line">44      144387  3000600</span><br><span class="line">45      0       3000600</span><br><span class="line">46      1517012 3000600</span><br><span class="line">47      481415  3000600</span><br><span class="line">48      0       3000600</span><br><span class="line">49      1426595 3000600</span><br><span class="line">50      0       3000600</span><br><span class="line">51      40828   3000600</span><br><span class="line">52      52      3000600</span><br><span class="line">53      0       3000600</span><br><span class="line">54      1426595 3000600</span><br><span class="line">55      517782  3000600</span><br><span class="line">56      64166   3000600</span><br><span class="line">57      64166   3000600</span><br><span class="line">58      115826  3000600</span><br><span class="line">59      116293  3000600</span><br><span class="line">60      2999953 3000600</span><br><span class="line">61      146731  3000600</span><br><span class="line">62      146731  3000600</span><br><span class="line">63      159698  3000600</span><br><span class="line">64      159746  3000600</span><br><span class="line">65      0       3000600</span><br><span class="line">66      0       3000600</span><br><span class="line">67      0       3000600</span><br><span class="line">68      0       3000600</span><br><span class="line">69      0       3000600</span><br><span class="line">70      0       3000600</span><br><span class="line">71      0       3000600</span><br><span class="line">72      0       3000600</span><br><span class="line">73      0       3000600</span><br><span class="line">74      0       3000600</span><br><span class="line">75      0       3000600</span><br><span class="line">76      0       3000600</span><br><span class="line">77      0       3000600</span><br><span class="line">78      0       3000600</span><br><span class="line">79      0       3000600</span><br><span class="line">80      0       3000600</span><br><span class="line">81      0       3000600</span><br><span class="line">82      0       3000600</span><br><span class="line">83      0       3000600</span><br><span class="line">84      0       3000600</span><br><span class="line">85      0       3000600</span><br><span class="line">86      0       3000600</span><br><span class="line">87      0       3000600</span><br><span class="line">88      0       3000600</span><br><span class="line">89      0       3000600</span><br><span class="line">90      0       3000600</span><br><span class="line">91      0       3000600</span><br><span class="line">92      0       3000600</span><br><span class="line">93      0       3000600</span><br><span class="line">94      0       3000600</span><br><span class="line">95      0       3000600</span><br><span class="line">需要丢掉的列号：0,2,3,4,6,9,17,18,24,29,30,31,33,46,49,54,60</span><br><span class="line">需要插补的列号：1,5,8,12,13,14,15,20,21,22,23,25,26,27,28,35,40,41,43,44,47,51,52,55,56,57,58,59,61,62,63,64</span><br><span class="line">完美列号：7,10,11,16,19,32,34,36,37,38,39,42,45,48,50,53,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95</span><br><span class="line">丢掉第0列       vin     -是首列或因na过多</span><br><span class="line">1       back_legroom    34.88554152025584       10.803048024003107</span><br><span class="line">丢掉第4列       bed_length      -是首列或因na过多</span><br><span class="line">8       city_fuel_economy       18.973479961834286      11.637300445996951</span><br><span class="line">10      daysonmarket    76.0455595699392        108.87863896938518</span><br><span class="line">11      dealer_zip      50669.81150830218       27375.94715300726</span><br><span class="line">12      description     0.17846959890341893     255.2549902888531</span><br><span class="line">14      engine_displacement     2797.285075413276       1481.0219220754384</span><br><span class="line">16      exterior_color  2.260508282512925       442.6922512862191</span><br><span class="line">21      front_legroom   39.72592702320007       10.02756775400742</span><br><span class="line">22      fuel_tank_volume        17.608113546641402      6.7668815295322435</span><br><span class="line">25      height  62.35115022029862       16.541684822918757</span><br><span class="line">26      highway_fuel_economy    24.641676545249798      13.020379389747855</span><br><span class="line">27      horsepower      233.69342021376397      105.1379926203423</span><br><span class="line">28      interior_color  2.2194684128069095      559.1713000695153</span><br><span class="line">34      latitude        36.97614874552056       5.025653349279904</span><br><span class="line">35      length  183.34090699859522      47.80448637471194</span><br><span class="line">丢掉第38列      listing_id      -xbar大于100000</span><br><span class="line">39      longitude       -90.62260148008761      13.967765609990069</span><br><span class="line">43      maximum_seating 5.18447183379052        1.6826429709038224</span><br><span class="line">44      mileage 29640.29273455067       73067.93566116491</span><br><span class="line">45      model_name      58.31043968221012       333.09392240515734</span><br><span class="line">丢掉第46列      owner_count     -是首列或因na过多</span><br><span class="line">48      price   29926.953581444013      19568.717865222385</span><br><span class="line">50      savings_amount  550.8380996594346       1079.351149695568</span><br><span class="line">51      seller_rating   4.211379641169585       0.7130308234825646</span><br><span class="line">丢掉第52列      sp_id   -xbar大于100000</span><br><span class="line">59      trim_name       0.04460616030332584     10.331173669741302</span><br><span class="line">63      wheelbase       109.1642761329817       29.529077769800306</span><br><span class="line">64      width   74.1947137895581        19.1476096014168</span><br><span class="line">65      year</span><br><span class="line">        2017.2940512877597      29.89588340213624</span><br><span class="line">丢掉第0列       vin     -na过多</span><br><span class="line">丢掉第5列       body_type       -类数大于10</span><br><span class="line">丢掉第7列       city    -类数大于10</span><br><span class="line">丢掉第12列      description     -类数大于10</span><br><span class="line">丢掉第13列      engine_cylinders        -类数大于10</span><br><span class="line">丢掉第15列      engine_type     -类数大于10</span><br><span class="line">丢掉第16列      exterior_color  -类数大于10</span><br><span class="line">丢掉第19列      franchise_dealer        -类数大于10</span><br><span class="line">丢掉第20列      franchise_make  -类数大于10</span><br><span class="line">丢掉第23列      fuel_type       -类数大于10</span><br><span class="line">丢掉第28列      interior_color  -类数大于10</span><br><span class="line">丢掉第32列      is_new  -类数大于10</span><br><span class="line">丢掉第36列      listed_date     -类数大于10</span><br><span class="line">丢掉第37列      listing_color   -类数大于10</span><br><span class="line">丢掉第40列      main_picture_url        -类数大于10</span><br><span class="line">丢掉第41列      major_options   -类数大于10</span><br><span class="line">丢掉第42列      make_name       -类数大于10</span><br><span class="line">丢掉第45列      model_name      -类数大于10</span><br><span class="line">丢掉第47列      power   -类数大于10</span><br><span class="line">丢掉第53列      sp_name -类数大于10</span><br><span class="line">丢掉第55列      torque  -类数大于10</span><br><span class="line">丢掉第56列      transmission    -类数大于10</span><br><span class="line">丢掉第57列      transmission_display    -类数大于10</span><br><span class="line">丢掉第58列      trimId  -类数大于10</span><br><span class="line">丢掉第59列      trim_name       -类数大于10</span><br><span class="line">丢掉第61列      wheel_system    -类数大于10</span><br><span class="line">丢掉第62列      wheel_system_display    -类数大于10</span><br><span class="line">丢掉第17列      fleet   -na过多</span><br><span class="line">丢掉第18列      frame_damaged   -na过多</span><br><span class="line">丢掉第24列      has_accidents   -na过多</span><br><span class="line">丢掉第29列      isCab   -na过多</span><br><span class="line">丢掉第49列      salvage -na过多</span><br><span class="line">丢掉第54列      theft_title     -na过多</span><br><span class="line">丢掉第31列      is_cpo  -na过多</span><br><span class="line">丢掉第33列      is_oemcpo       -na过多</span><br><span class="line">丢掉第6列       cabin   -na过多</span><br><span class="line">丢掉第2列       bed     -na过多</span><br><span class="line">丢掉第1列       back_legroom    -类数大于10</span><br><span class="line">丢掉第3列       bed_height      -na过多</span><br><span class="line">丢掉第4列       bed_length      -na过多</span><br><span class="line">丢掉第8列       city_fuel_economy       -类数大于10</span><br><span class="line">丢掉第9列       combine_fuel_economy    -na过多</span><br><span class="line">丢掉第10列      daysonmarket    -类数大于10</span><br><span class="line">丢掉第11列      dealer_zip      -类数大于10</span><br><span class="line">丢掉第14列      engine_displacement     -类数大于10</span><br><span class="line">丢掉第21列      front_legroom   -类数大于10</span><br><span class="line">丢掉第25列      height  -类数大于10</span><br><span class="line">丢掉第26列      highway_fuel_economy    -类数大于10</span><br><span class="line">丢掉第27列      horsepower      -类数大于10</span><br><span class="line">丢掉第22列      fuel_tank_volume        -类数大于10</span><br><span class="line">丢掉第30列      is_certified    -na过多</span><br><span class="line">丢掉第34列      latitude        -类数大于10</span><br><span class="line">第35列</span><br><span class="line"> &apos;Backup Camera&apos;        length  1</span><br><span class="line"> 4-wheel antilock       length  1</span><br><span class="line"> Traction control - ABS and driveline   length  1</span><br><span class="line"> automatic high beam on/off|Glass       length  1</span><br><span class="line"> body-color (Not available on Double Cab models.)|Glass length  1</span><br><span class="line"> driver 8-way power|Seats       length  1</span><br><span class="line"> front passenger        length  1</span><br><span class="line"> heated driver and front passenger|Console front center with 2 cup holders and storage  length  1</span><br><span class="line"> includes rear storage drawer (Excludes storage drawer with (GAT) All Terrain with (ABD) 5-passenger seating.)|Power outlet       length  2</span><br><span class="line">第38列</span><br><span class="line"> 2 in front door panel  listing_id      1</span><br><span class="line"> 3-prong household style located on the rear of center console|Cup holders 2 in front center console    listing_id        1</span><br><span class="line"> Xenon headlights&quot;***V6***3600.0***V6***Silver***True***False***False******42.1 in***19 gal***Gasoline***False***59.1 in***28.0***304.0***Gray (Dark Grey)***True*********False******31.8552***202 in***2020-08-27***SILVER***280340040***-106.028***https://static.cargurus.com/images/forsale/2020/08/26/00/06/2016_cadillac_xts-pic-1844722391038826724-152x114.jpeg***&quot;[&apos;Leather Seats&apos;   listing_id      1</span><br><span class="line"> deep-tinted|Wipers     listing_id      1</span><br><span class="line"> folding|Dead pedal     listing_id      1</span><br><span class="line"> rear (Requires Crew Cab or Double Cab model. Deleted with (ZW9) pickup box delete.)|Bumper     listing_id1</span><br><span class="line"> tilt and telescopic|Display    listing_id      2</span><br><span class="line"> top|Tailgate   listing_id      1</span><br><span class="line">第39列</span><br><span class="line"> &apos;Navigation System&apos;    longitude       1</span><br><span class="line"> 2 bottle holders in front door panel   longitude       1</span><br><span class="line"> 2 in front door panel  longitude       1</span><br><span class="line"> EZ-Lift and Lower (Deleted when (ZW9) pickup box delete is ordered.)|Remote Locking Tailgate|Radio     longitude 1</span><br><span class="line"> driver instrument information enhanced longitude       2</span><br><span class="line"> driver|Steering wheel  longitude       1</span><br><span class="line"> front chrome|CornerStep        longitude       1</span><br><span class="line"> front intermittent     longitude       1</span><br><span class="line">第43列</span><br><span class="line"> &apos;Heated Seats&apos; maximum_seating 1</span><br><span class="line"> 3-channel programmable|Defogger        maximum_seating 2</span><br><span class="line"> 3-passenger (includes child seat top tether anchor)|Instrumentation    maximum_seating 1</span><br><span class="line"> HD|Floor covering      maximum_seating 1</span><br><span class="line"> chrome|4X4 chrome badge (Included and only available with 4X4 models.)|Grille surround maximum_seating 1</span><br><span class="line"> driver instrument information enhanced maximum_seating 1</span><br><span class="line"> miles/kilometers|Driver Information Center     maximum_seating 1</span><br><span class="line"> tilt and telescopic|Display    maximum_seating 1</span><br><span class="line">第44列</span><br><span class="line"> &apos;Android Auto&apos; mileage 1</span><br><span class="line"> 6-gauge cluster featuring speedometer  mileage 1</span><br><span class="line"> chrome|Headlamps       mileage 1</span><br><span class="line"> color-keyed carpeting|Driver Information Center        mileage 1</span><br><span class="line"> driver instrument information enhanced mileage 1</span><br><span class="line"> enhanced       mileage 1</span><br><span class="line"> one color|Sensor       mileage 1</span><br><span class="line"> rear-window electric|Cup holders 2 in front center console     mileage 2</span><br><span class="line">丢掉第46列      owner_count     -na过多</span><br><span class="line">第48列</span><br><span class="line"> &apos;Bluetooth&apos;    price   1</span><br><span class="line"> 10 total|Lighting      price   2</span><br><span class="line"> 3-channel programmable|Air conditioning        price   1</span><br><span class="line"> cargo box with switch on center switch bank (Deleted when (ZW9) pickup box delete is ordered.) (Deleted with (ZW9) pickup box delete.)|Fog lamps price   1</span><br><span class="line"> power  price   1</span><br><span class="line"> power with driver and passenger Express-Down/Up|Cruise control price   1</span><br><span class="line"> right front passenger and rear seat occupants|Defogger price   1</span><br><span class="line"> voltage and oil pressure|Driver Information Center     price   1</span><br><span class="line">第50列</span><br><span class="line"> &apos;Backup Camera&apos;        savings_amount  1</span><br><span class="line"> cargo compartment      savings_amount  2</span><br><span class="line"> halogen|Mirror caps    savings_amount  1</span><br><span class="line"> inside rearview manual day/night|Lighting      savings_amount  1</span><br><span class="line"> programmable|Pedals    savings_amount  1</span><br><span class="line"> right front passenger and rear seat occupants (Dual-zone climate control when (GAT) All Terrain is ordered. Tri-zone climate control on all other models.)|Defogger      savings_amount  1</span><br><span class="line"> steering wheel mounted|Mirror  savings_amount  1</span><br><span class="line"> warning messages and vehicle information|Windows       savings_amount  1</span><br><span class="line">第51列</span><br><span class="line"> &apos;Remote Start&apos;]&quot;***Cadillac***5 seats***64070.0***XTS***3.0***&quot;304 hp @ 6      seller_rating   1</span><br><span class="line"> body-color (Included and only available with (GAT) All Terrain HD Package.) (Included and only available with (GAT) All Terrain Package and mirror caps will be Black.)|Mirror caps      seller_rating   1</span><br><span class="line"> inside rearview manual day/night       seller_rating   1</span><br><span class="line"> interior with theater dimming  seller_rating   1</span><br><span class="line"> power with driver express up and down and express down on all other windows|Visors     seller_rating   1</span><br><span class="line"> power-adjustable for accelerator and brake|Climate control     seller_rating   1</span><br><span class="line"> rear-window electric|Mirror    seller_rating   1</span><br><span class="line">第52列</span><br><span class="line"> cargo compartment      sp_id   1</span><br><span class="line"> chrome|Glass   sp_id   1</span><br><span class="line"> driver and front passenger illuminated vanity mirrors|Assist handle    sp_id   1</span><br><span class="line"> frameless|Visors       sp_id   1</span><br><span class="line"> inside rearview auto-dimming|Lighting  sp_id   1</span><br><span class="line"> second row reading lamps integrated into dome light    sp_id   2</span><br><span class="line"> tri-zone automatic with individual climate settings for driver sp_id   1</span><br><span class="line">800 RPM&quot;***19950.0***False***65*********private seller***False***&quot;264 lb-ft @ 5 sp_id   1</span><br><span class="line">丢掉第60列      vehicle_damage_category -na过多</span><br><span class="line">第63列</span><br><span class="line"> &apos;Bluetooth&apos;    wheelbase       1</span><br><span class="line"> GMC Smart Driver       wheelbase       2</span><br><span class="line"> front reading lamps|Shift knob wheelbase       1</span><br><span class="line"> frontal and side impact for driver and front passenger driver inboard seat-mounted side-impact wheelbase1</span><br><span class="line"> interior with dome light       wheelbase       1</span><br><span class="line"> rear child security|Teen Driver mode a configurable feature that lets you activate customizable vehicle settings associated with a key fob       wheelbase       1</span><br><span class="line"> tachometer     wheelbase       1</span><br><span class="line">第64列</span><br><span class="line"> &apos;Backup Camera&apos;        width   1</span><br><span class="line"> Marketplace and more (Limitations apply. Not transferable. Standard connectivity available to original purchaser for ten years from the date of initial vehicle purchase for model year 2018 or newer GMC vehicles. See onstar.com for details and further plan limitations. Connected Access does not include emergency or security services. Availability and additional services enables by Connected Access are subject to change.)|Rear Vision Camera|Door locks  width   2</span><br><span class="line"> driver side knee and head curtain side-impact for all rows in outboard seating positions (Always use safety belts and the correct child restraints. Children are safer when properly secured in a rear seat in the appropriate child restraint. See the Owner&apos;s Manual for more information.)|Rear Vision Camera|Door locks width    1</span><br><span class="line"> driver- and passenger-side door switch with delayed entry feature      width   1</span><br><span class="line"> leather-wrapped|Brake  width   1</span><br><span class="line"> to encourage safe driving behavior. It can limit certain vehicle features      width   1</span><br><span class="line"> voltage and oil pressure|Driver Information Center     width   1</span><br><span class="line">第65列</span><br><span class="line"> &apos;CarPlay&apos;]&quot;***Chevrolet***6 seats***42921.0***Silverado 2500HD***1.0******56995.0***False***4549***4.814814814814815***285608***Platinum Auto Group***False******A***Automatic***t78815***LT Crew Cab 4WD******4WD***Four-Wheel Drive***153.7 in***80.5 in***2019</span><br><span class="line">&quot;       year</span><br><span class="line">        1</span><br><span class="line"> 4.2-inch diagonal color display includes driver personalization        year</span><br><span class="line">        1</span><br><span class="line"> and it prevents certain safety systems from being turned off. An in-vehicle report gives you information on your teen&apos;s driving habits and helps you to continue to coach your new driver|Tire pressure monitoring system|Horn     year</span><br><span class="line">        1</span><br><span class="line"> cargo lights   year</span><br><span class="line">        1</span><br><span class="line"> parking        year</span><br><span class="line">        1</span><br><span class="line"> rear child security|Rear seat reminder|Teen Driver configurable feature that lets you activate customizable vehicle settings associated with a key fob   year</span><br><span class="line">        2</span><br><span class="line"> rear child security|Teen Driver mode a configurable feature that lets you activate customizable vehicle settings associated with a key fob       year</span><br><span class="line">        1</span><br><span class="line">第66列</span><br></pre></td></tr></table></figure><p>上面的结果就是我们处理的标准。</p><p>下面看看mapper.py</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">#! usr/bin/env python3</span><br><span class="line"># 目标：插补na，并计算乘积 xtx与xty</span><br><span class="line"></span><br><span class="line">import sys</span><br><span class="line">import re</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 先按“读取，把文件里字符型数据中的逗号替换成其他符号</span><br><span class="line">def commakiller(abc):</span><br><span class="line">    i = 1</span><br><span class="line">    while(i&lt;len(abc)):</span><br><span class="line">        abc[i] = abc[i].replace(&quot;,&quot;,&quot;***&quot;)</span><br><span class="line">        a = &apos;&quot;&apos;</span><br><span class="line">        abc[i] = a + abc[i] + a</span><br><span class="line">        i = i + 2</span><br><span class="line">    b = &quot;&quot;</span><br><span class="line">    qline = b.join(abc)</span><br><span class="line">    return(qline)</span><br><span class="line"></span><br><span class="line">num_list = &#123;&apos;1&apos;:[34.886,10.803],&apos;8&apos;:[18.973,11.637],&apos;10&apos;:[76.046,108.879],&apos;11&apos;:[50669.812,27375.947],&apos;14&apos;:[2797.2851,1481.0219],&apos;21&apos;:[39.726,10.028],&apos;22&apos;:[17.608,6.767],&apos;25&apos;:[62.351,16.542],&apos;26&apos;:[24.642,13.020],&apos;27&apos;:[233.693,105.138],&apos;35&apos;:[183.341,47.804],&apos;43&apos;:[5.184,1.683],&apos;44&apos;:[29640.293,73067.936],&apos;64&apos;:[74.195,19.148],&apos;51&apos;:[4.211,0.713],&apos;63&apos;:[109.164,29.529],&apos;48&apos;:[29926.954,19568.718]&#125;</span><br><span class="line">nafixed = []</span><br><span class="line">times = 1</span><br><span class="line">for line in sys.stdin:    </span><br><span class="line">    abc = line.split(&apos;&quot;&apos;)</span><br><span class="line">    items = commakiller(abc).split(&quot;,&quot;)</span><br><span class="line">    if(times == 1):</span><br><span class="line">        times += 1</span><br><span class="line">        names = items  # 列名，后续遍历使用</span><br><span class="line">        continue</span><br><span class="line">    if(times &gt;= 2):</span><br><span class="line">        times += 1</span><br><span class="line">        p = len(num_list.keys()) # 变量长度</span><br><span class="line">        ## 1. na fix</span><br><span class="line">        for key, value in enumerate(items):</span><br><span class="line">            if str(key) in num_list.keys() :</span><br><span class="line">                if((value == &apos;&apos;) | (value == &quot;--&quot;)):</span><br><span class="line">                    # 每行统计缺失值</span><br><span class="line">                    mu = num_list[str(key)][0] #期望</span><br><span class="line">                    sigma = num_list[str(key)][1]   #标准差</span><br><span class="line">                    nafixed.append(np.random.normal(mu, sigma, 1))</span><br><span class="line">                else: </span><br><span class="line">                    nafixed.append(value)</span><br><span class="line">            else:</span><br><span class="line">                continue</span><br><span class="line">        # 对变量取值处理</span><br><span class="line">        if p &lt;= 1: continue</span><br><span class="line">        if p &gt; 1 :</span><br><span class="line">            # 全部数值变量转换为浮点型数据</span><br><span class="line">            flag = 0 # 每行从0开始算</span><br><span class="line">            for value in nafixed:</span><br><span class="line">                try:</span><br><span class="line">                    nafixed[flag] = float(value)</span><br><span class="line">                    flag += 1</span><br><span class="line">                except(ValueError):</span><br><span class="line">                    try:</span><br><span class="line">                        ## 1.数值型变量带单位的，如下处理</span><br><span class="line">                        if ((&quot;in&quot; in value[-5:])&amp;(re.findall(&apos;[a-z]in&apos;,value)==[])):</span><br><span class="line">                            nafixed[flag] = float(re.sub(&apos;in&apos;,&apos;&apos;,value,1));flag += 1</span><br><span class="line">                        elif ((&quot;seats&quot; in value[-8:])&amp;(re.findall(&apos;[a-z]seats&apos;,value)==[])):</span><br><span class="line">                            nafixed[flag] = float(re.sub(&apos;seats&apos;,&apos;&apos;,value,1));flag += 1</span><br><span class="line">                        elif ((&apos;gal&apos; in value[-6:])&amp;(re.findall(&apos;[a-z]gal&apos;,value)==[])):</span><br><span class="line">                            nafixed[flag] = float(re.sub(&apos;gal&apos;,&apos;&apos;,value,1));flag += 1</span><br><span class="line">                        else:</span><br><span class="line">                            nafixed[flag] = np.random.normal(list(num_list.values())[flag][0],list(num_list.values())[flag][1],1) </span><br><span class="line">                            flag += 1</span><br><span class="line">                    except(ValueError):</span><br><span class="line">                        nafixed[flag] = np.random.normal(list(num_list.values())[flag][0],list(num_list.values())[flag][1],1) # 未经或无法转换的值当na，插补处理</span><br><span class="line">                        flag += 1</span><br><span class="line">                        continue</span><br><span class="line">            ## 3. computing XTX &amp; XTY            </span><br><span class="line">            xty = []</span><br><span class="line">            for i in range(p-1):</span><br><span class="line">                xty.append(nafixed[i] * nafixed[p-1]) # 默认第p个是因变量price (事先设定)</span><br><span class="line">            print(&quot;*&quot;,&quot;,&quot;.join(str(i) for i in xty)) </span><br><span class="line">            xtx = np.outer(nafixed[0:(p-1)],nafixed[0:(p-1)])  # 外积</span><br><span class="line">            print(&quot;,&quot;.join(&quot;,&quot;.join(str(k) for k in qq) for qq in xtx.tolist()))</span><br></pre></td></tr></table></figure><p>mapper算出各行的xtx与xty，标准输出时以开头有无“*”来判定。</p><p>下面看看reducer</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">#! usr/bin/env python3</span><br><span class="line">import sys</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">xtx = [];xty = [];temp = []</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">    data = line.split(&apos;,&apos;)</span><br><span class="line">    #print(data)</span><br><span class="line">    p = len(data)</span><br><span class="line">    data[p-1] = data[p-1][:-1]</span><br><span class="line">    if line[0] == &quot;*&quot;:  # 说明是标记的xty</span><br><span class="line">        data[0] = data[0][2:]</span><br><span class="line">        p1 = len(data)</span><br><span class="line">        data = list(map(float, data))</span><br><span class="line">        if len(xty) == 0:</span><br><span class="line">            xty = data</span><br><span class="line">            continue</span><br><span class="line">        else:</span><br><span class="line">            xty = xty + np.array(data)</span><br><span class="line">            # 在新的xtx出现之前</span><br><span class="line">            if len(xtx) == 0:</span><br><span class="line">                xtx = temp</span><br><span class="line">            else:</span><br><span class="line">                xtx = np.array(xtx) + np.array(temp) # bug</span><br><span class="line">                len2 = len(temp)</span><br><span class="line">            temp = []  # 循环结束初始化</span><br><span class="line">    else:   # 其他都是xtx</span><br><span class="line">        data = list(map(float, data))</span><br><span class="line">        if len(temp) == 0:</span><br><span class="line">            temp = data</span><br><span class="line">        else:</span><br><span class="line">            temp = temp + data # 连接</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">xtx = np.asarray(xtx).reshape(int(p1),int(len2/p1))</span><br><span class="line">print(xtx,&apos;\n&apos;)</span><br><span class="line">print(xty,&apos;\n&apos;)</span><br><span class="line">try:</span><br><span class="line">    print(np.dot(np.linalg.inv(xtx),np.array(xty)))</span><br><span class="line">except(LinAlgError):</span><br><span class="line">    continue</span><br></pre></td></tr></table></figure><p>由于某些原因，分布式没跑成（大家都去运行，系统拥堵了），只用了五万数据单机测试了一下。最终结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[devel@emr-header-1 1026]$ cat result1.txt</span><br><span class="line">[-1.37866211e+01 -3.97949219e+00  4.95000000e+01 -1.43750000e+01</span><br><span class="line"> -1.50000000e+01 -1.48950195e+00 -8.51562500e-01 -3.92000000e+02</span><br><span class="line"> -6.60400391e-01  5.33750000e+01  1.35742188e-01  7.20000000e+03</span><br><span class="line"> -9.96875000e+00 -4.97070312e-01  9.94726562e+00 -8.00781250e-02]</span><br></pre></td></tr></table></figure><p>最后附上main文件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">PWD=$(cd $(dirname $0); pwd)</span><br><span class="line">cd $PWD 1&gt; /dev/null 2&gt;&amp;1</span><br><span class="line"></span><br><span class="line">hadoop fs -put used_cars_5w.csv /user/devel/2020210995wangyuanhe/reg</span><br><span class="line"></span><br><span class="line">TASKNAME=lm-usedcars-hehe</span><br><span class="line">HADOOP_INPUT_DIR=/user/devel/2020210995wangyuanhe/reg/used_cars_5w.csv</span><br><span class="line">HADOOP_OUTPUT_DIR=/user/devel/2020210995wangyuanhe/output/1026output</span><br><span class="line"></span><br><span class="line">echo $HADOOP_HOME</span><br><span class="line">echo $HADOOP_INPUT_DIR</span><br><span class="line">echo $HADOOP_OUTPUT_DIR</span><br><span class="line"></span><br><span class="line">hadoop fs -rm -r $HADOOP_OUTPUT_DIR</span><br><span class="line"></span><br><span class="line">hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.1.3.jar \</span><br><span class="line">-D mapred.job.name=$TASKNAME \</span><br><span class="line">-D mapred.job.priority=NORMAL \</span><br><span class="line">-D mapred.reduce.tasks=1 \</span><br><span class="line">-file &quot;$PWD/mapper.py&quot; &quot;$PWD/reducer.py&quot; \</span><br><span class="line">-input $&#123;HADOOP_INPUT_DIR&#125; \</span><br><span class="line">-output $&#123;HADOOP_OUTPUT_DIR&#125; \</span><br><span class="line">-mapper &quot;$PWD/mapper.py&quot; \</span><br><span class="line">-reducer &quot;$PWD/reducer.py&quot; </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ $? -ne 0 ]; then</span><br><span class="line">    echo &apos;error&apos;</span><br><span class="line">    exit 1</span><br><span class="line">fi</span><br><span class="line">hadoop fs -touchz $&#123;HADOOP_OUTPUT_DIR&#125;/done</span><br><span class="line"></span><br><span class="line">hadoop fs -ls $HADOOP_OUTPUT_DIR | cat</span><br><span class="line"></span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><p>至此，分布式的运用基本结束了。</p><h3 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h3><p>先放一个系统卡住的样子</p><img src="/2020/10/21/1015hadoop/10/21/1015hadoop/tu1.png" title="tu1"><p>同学的代码写的很糟，放上去跑不动，系统没资源……理由有很多，总之就是卡了。</p><p>上面代码漏说了一个技巧：</p><blockquote><p>Tail -n 99 used_cars_data.csv<br>就可以只取一部分行</p></blockquote><p>我们可以把大文件一条一条读，与stdin一样，这样就能对数据按行操作。</p><p>Slice 指每次读入多大的数据，如1024k，2000行。你想使用集成化工具时，可以这样做，当while循环跑到最后一行时停止。</p><p>但这样太慢了。因为每次都在找，不能存入内存</p><p>不过，SAS软件允许在很有限的内存中处理大量数据，每次只操作一行（有钱任性）</p><p>分布式系统上，最好是stdin的形式，标准输入输出。</p><p>处理中新的问题：<br>我现在有个很长的数据，其中有一列我知道是哑变量。</p><p>需要统计：有多少个哑变量，有多少种type，占比如何？如何自动识别呢（频数统计）</p><p>设置一个“其他”类，如果我要保证设定的“其他”类的占比大于20%，</p><h4 id="大家的问题："><a href="#大家的问题：" class="headerlink" title="大家的问题："></a>大家的问题：</h4><p><strong>1.面向python的编程，而非面向MapReduce的编程</strong></p><p>hadoop可以做到streaming，成为数据流。所有操作都应该在第一个循环下操作！这样才能完成对所有数据的处理，如果不能再这个缩进下操作，则代码不能面对分布式。</p><p><strong>2.介绍了python中的log模块，记录了一些信息。不要随便把过程打印出来。</strong></p><p>老师的程序：在大数据集上找到全部哑变量，并且把哑变量的top取出来</p><p><a href="https://github.com/feng-li/dlsa/blob/master/dlsa/dummies.py" target="_blank" rel="noopener">可以用这个</a></p><h4 id="MapReduce如何在分布式系统上呈现的"><a href="#MapReduce如何在分布式系统上呈现的" class="headerlink" title="MapReduce如何在分布式系统上呈现的"></a>MapReduce如何在分布式系统上呈现的</h4><p>最常听的：键值对。以标准输入输出来理解。key-value，将任何的行拆分成这两部分。必须尊重这两部分的对应关系。一般情况下，键值的对应有一个标准形式。</p><p><strong>Map(key,value) ——&gt; list(key2,value2)</strong></p><p>拿到了学号的姓名，现在要数一下名字有几画。拿到的是（学号-姓名），输出是（学号-笔画）。</p><p>如何体现键值对的影响呢？比如有个数据，记录了某个地区的温度，以及记录温度的设备。位置信息就作为了键，对应的温度就是值。（csv数据是碰巧有换行符作为间隔值）</p><p>如果我们把关心的数据拿出来（举个栗子：）</p><blockquote><p>1950，0<br>1950，22<br>1950，-11  </p></blockquote><p>这不是键值，这是一行中两个值，并非是键与值。但经过计算之后，就能得到新的键值对！</p><p>map过的key可能变了，不再是原来的key。csv其实是打印换行符对应的一行数据，平时的cat也是一行一换。如果数据是不换行的键值对，那么就需要自己识别key，写自己的map函数。</p><p>如果数据很大，那我们不能放进内存。  </p><p>比如放入：swap交换分区，缓存，页面文件……都在硬盘上。map出来的结果，需要做一定的排序（主要是打乱），打乱之后，数据均匀，负载平衡。</p><p>最后，代码的路径应该是：</p><p><strong>Input —-&gt; Map —-&gt; shuffle —-&gt; reduce &gt; output</strong>  </p><p>操作都以行为单位，都是以标准的键值对形式实施！map与reduce之间可以（且必要）加入排序，这个过程需要硬盘，或者需要很大内存的机器，读写频繁。</p><p>MapReduce可以拆分开来，只有map，没有reduce。</p><p>数据清洗时，这个很重要。只需要拆分，不需要合并。化整为零，所有资源就能一起打工（bushi）！</p><p>也可以很多mapper很多reduce，拆分成很多份，但每一份都一定有键值对应关系。也可以很多mapper，但只使用<strong>一个</strong>reduce，此时reduce任务不重，可以在这里合并。</p><p>（未完待续）</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;一、开始！今日信息量巨大&quot;&gt;&lt;a href=&quot;#一、开始！今日信息量巨大&quot; class=&quot;headerlink&quot; title=&quot;一、开始！今日信息量巨大&quot;&gt;&lt;/a&gt;一、开始！今日信息量巨大&lt;/h3&gt;&lt;p&gt;大佬们展示肌肉。&lt;/p&gt;
&lt;p&gt;回归部分还需要些数学根底。&lt;/p&gt;
&lt;p&gt;代码后面也有一丢丢正文。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>数据之学|交叉验证相关理论介绍</title>
    <link href="https://konelane.github.io/2020/10/13/1010CV/"/>
    <id>https://konelane.github.io/2020/10/13/1010CV/</id>
    <published>2020-10-12T16:00:00.000Z</published>
    <updated>2020-10-16T01:53:21.547Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="交叉验证相关理论介绍"><a href="#交叉验证相关理论介绍" class="headerlink" title="交叉验证相关理论介绍"></a>交叉验证相关理论介绍</h2><p>2020.10.13</p><h3 id="1-1-场景构建"><a href="#1-1-场景构建" class="headerlink" title="1.1 场景构建"></a>1.1 场景构建</h3><p>源禾同学和正阳同学在某次考试都考了100分，正阳同学实力强劲，学习踏实，掌握核心科技，考了100是实力的体现，因为卷子上只有100分。而源禾同学考100分，因为源禾使用了败者食尘，他课下做了这张卷子的所有题，背了题，考了100分是因为记性好。</p><p>谁才是老师喜爱的同学呢？</p><a id="more"></a><p>在对模型进行测试时，不可以照着“考卷”疯狂练习。尤其是在样本量小的时候，换一张卷子就会原形毕露。</p><p>那么不妨站在老师的角度想，如果题库只有这么多题，该怎么出题才能真正考察学生的实力呢？</p><h3 id="1-2-模型-算法的选择"><a href="#1-2-模型-算法的选择" class="headerlink" title="1.2 模型/算法的选择"></a>1.2 模型/算法的选择</h3><p>在建模时，可选用的模型很多，我们想选用何种模型，此时就需要对模型的<strong>“泛化误差”</strong>（generalization-error，指在独立测试样本上的期望预测误差，也称测试误差test-error或预测误差prediction-error）进行评估。</p><p>在实际建模中，很少能得到样本的精确分布，也无法直接计算泛化误差。基于训练样本得到的样本上平均损失的训练误差是它的一个直接估计，可训练误差会随着模型复杂度（光滑度，自由度）的增加而减小，直至减小到0。（训练均方误差 vs 测试均方误差）</p><p>如果训练均方误差很小但测试均方误差较大时，我们称该数据被过拟合。（模型开始背题了）</p><img src="/2020/10/13/1010CV/10/13/1010CV/图1.png" title="图1"><blockquote><p>源禾：任何难处都可以靠增加数据量来解决。<br>（当然解决不了的除外）</p></blockquote><p>事实上，这里涉及到偏差方差权衡（bias-variance trade-off）的问题，如果一个统计模型被称为测试性能好，那么要去该模型具有较小的方差和较小的偏差。直觉上我们会选择有极小偏差可是有很大方差的方法（如画一条通过所有观测的曲线，下图的绿线）</p><img src="/2020/10/13/1010CV/10/13/1010CV/图2.png" title="图2"><blockquote><p>源禾：虽然没有完美的模型，但是有完美模型的传说。</p></blockquote><p>为一个模型来选择何适的光滑度的过程即<strong>模型选择</strong>。这个问题在训练集较小时，被产生的过拟合现象加大了难度。</p><h3 id="1-3-出路-重抽样（resampling）"><a href="#1-3-出路-重抽样（resampling）" class="headerlink" title="1.3 出路 - 重抽样（resampling）"></a>1.3 出路 - 重抽样（resampling）</h3><p>应当找到一个方法解决过拟合，而唯一的限制是，没那么多数据。</p><p>于是人们想了个办法：让这个测试集来源于训练集。我反复从训练集中抽取样本，对每一个样本重新拟合一个模型，来获取关于拟合模型的附加信息。这就是<strong>重抽样</strong>方法。在拟合过程中，保留（holding out）训练观测的一个子集，然后对保留的观测运用统计学习方法，从而来估计其<strong>测试错误率</strong>（test error rate）。</p><img src="/2020/10/13/1010CV/10/13/1010CV/图3.jpg" title="图3"><blockquote><p>源禾：预测集神圣不可侵犯。</p></blockquote><h3 id="2-1-验证集方法（validation-set-approach）"><a href="#2-1-验证集方法（validation-set-approach）" class="headerlink" title="2.1 验证集方法（validation set approach）"></a>2.1 验证集方法（validation set approach）</h3><p>首先随机地把观测集分成两部分：一个训练集（training set），一个验证集（validation set），或者叫保留集（hold-out set）。模型在训练集上拟合，然后用拟合的模型来预测验证集中观测的响应变量。最后得到的验证集错误率——通常用均方误差作为定量响应变量的误差度量——提供了对于测试错误率的一个估计。</p><p>附一个“上帝”的比例：70%的训练集，30%的测试集。</p><blockquote><p>验证集方法原理简单，易于执行，但它有两个潜在的<strong>缺陷</strong>：<br>1.测试错误率的验证法估计的波动很大，这取决于具体哪些观测被包括在训练集中，哪些观测被包括在验证集中。<br>2.在验证法中，只有一部分观测被用于拟合模型，由于被训练的观测越少，统计方法的表现越不好，意味着验证集错误率可能会<strong>高估</strong>在整个数据集上拟合模型的测试错误率。</p></blockquote><p>统计分析中通过多次重复试验来减小方差。</p><h3 id="2-2-留一交叉验证（leave-one-out-cross-validation）"><a href="#2-2-留一交叉验证（leave-one-out-cross-validation）" class="headerlink" title="2.2 留一交叉验证（leave-one-out cross-validation）"></a>2.2 留一交叉验证（leave-one-out cross-validation）</h3><p>留一交叉验证（LOOCV）与验证集方法很相似，但这种方法尝试解决验证集方法遗留的缺陷问题。</p><p>LOOCV将观测集分为两部分，但不同于把观测集分为两个大小相当的子集，留一交叉验证法将一个单独的观测$(x_1, y_1)$作为验证集，剩下的观测$\{(x_2, y_2),(x_3, y_3), … ,(x_n, y_n)\}$组成训练集。由于拟合中没有用到$(x_1, y_1)$，所以$MSE_1 = (y_1 - \hat{y_1})^2$ 提供了对于测试误差的一个渐进无偏估计。</p><p>能看出，由于$MSE_1$是基于一个单独的观测计算得出的，故具有很高的波动性。</p><p>重复上面计算$MSE_1$的步骤，计算出全部的$MSE_1, MSE_2, …, MSE_n$，对测试均方误差的LOOCV估计是这n个测试误差估计的均值：</p><script type="math/tex; mode=display">CV_{(n)} = \frac{1}{n} \sum^{n}_{i=1}MSE_i</script><p>相对于验证集方法，LOOCV方法更不容易高估测试错误率，也能彻底解决训练集和验证集分割时随机性导致的结果不同问题。</p><h3 id="2-3-K折交叉验证（K-fold-CV）"><a href="#2-3-K折交叉验证（K-fold-CV）" class="headerlink" title="2.3 K折交叉验证（K-fold CV）"></a>2.3 K折交叉验证（K-fold CV）</h3><p>k折交叉验证法是LOOCV的一个替代，这种方法将观测集随机地分成K个大小基本一致的组，或者说<strong>折（fold）</strong>。第一折作为验证集，然后在剩下的k-1折上拟合模型。均方误差$MSE_1$由保留的观测计算得出。</p><img src="/2020/10/13/1010CV/10/13/1010CV/图4.png" title="图4"><p>重复这个步骤k次（注意一般k大于2），每一次把不同的观测组作为验证集（分组只是第一次分）。整个过程会得到k个测试误差的估计，$MSE_1, MSE_2, …, MSE_k$。k折CV估计由这些值求平均计算得到：</p><script type="math/tex; mode=display">CV_{(k)} = \frac{1}{k} \sum^{k}_{i=1}MSE_i</script><p>不难发现，<strong>k等于n时，LOOCV方法是k折交叉验证的一个特例</strong>。</p><p>k一般取5或10。不取n的原因果然还是因为<strong>好算啊</strong>。几乎对于任一种统计学习方法适用，都有更好的可行性。</p><blockquote><p>源禾：在计算简便和尽可能减少估计的波动面前，一个能“我全都要”的方法谁不喜欢呢？</p></blockquote><p>k折交叉验证的结果也会因观测分折的随机性产生一定波动。同时对$Err$估计时也会因训练集样本容量大小产生一定的高估。</p><img src="/2020/10/13/1010CV/10/13/1010CV/图5.png" title="图5"><p>由上图可知，训练集在150+时，训练效果已经不再随着训练集样本量增加而增加。但训练集样本容量在0至50时，会明显低估$1-Err$。</p><h3 id="2-4-总结"><a href="#2-4-总结" class="headerlink" title="2.4 总结"></a>2.4 总结</h3><p>先画一张表在这：</p><div class="table-container"><table><thead><tr><th>方法</th><th>优点</th><th>缺点</th><th>计算复杂度</th></tr></thead><tbody><tr><td>验证集方法(validation set approach)</td><td>原理简单，易于执行</td><td>A.测试错误率的验证法估计的波动很大，与分组关系很大。B.验证集错误率可能会高估在整个数据集上拟合模型的测试错误率。</td><td>计算最简单，方便对比称一个<strong>计算单步</strong>（对数据进行多次重复划分时计算复杂度会相应高）</td></tr><tr><td>留一交叉验证法(Leave-one-out cross-validation)</td><td>A.偏差较小，不易高估错误率。训练模型最接近原始样本的分布。B.LOOCV方法能解决训练集和验证集分割的随机性。实验可复制。</td><td>A.模型需拟合n次，非常耗时。（<em>但是最小二乘法来拟合线性或多项式回归时只消耗一个计算单步</em>）B.方差较大。</td><td>除左栏提到的线性/多项式回归外，需要<strong>n个计算单步</strong>。大样本情况时，对于某些算法来说数据划分为n份也不可接受。svm和朴素贝叶斯分类器。</td></tr><tr><td>k折交叉验证(k-fold CV)</td><td>A.偏差问题不大,方差较小。有效避免过拟合和欠拟合情况发生。B.计算方便，计算开销小。</td><td>A.选择K折交叉验证的<strong>“K”</strong>时比较随机。B.会产生一定波动。偏差大小会随训练集样本容量变化而改变。</td><td><strong>k个计算单步</strong></td></tr></tbody></table></div><p>k折CV方法相对于LOOCV方法除了计算优势外，它对测试错误率的估计通常来说更加准确。</p><div class="table-container"><table><thead><tr><th></th><th>验证集方法</th><th>LOOCV方法</th><th>k折CV方法</th></tr></thead><tbody><tr><td>偏差角度</td><td>高估</td><td>近似无偏</td><td>中等程度偏差</td></tr><tr><td>方差角度</td><td></td><td>k&lt;n时方差大于k折CV方法</td><td>k&lt;n时方差小于LOOCV方法</td></tr></tbody></table></div><p>由上表可知，选择方法时，需要进行偏差-方差权衡。在选择k折CV的折数时，一般k=5或10使得测试错误率的估计不会有过大的偏差或方差。</p><h3 id="2-5-补充"><a href="#2-5-补充" class="headerlink" title="2.5 补充"></a>2.5 补充</h3><p>一、</p><p>之前提到交叉验证方法可以应用于多个场景，举个例子，交叉验证在分类器模型的应用：</p><p>其实只需要修改“泛化误差”为“损失函数”（$MSE$ to $Err$），比如k折CV错误率的形式：</p><script type="math/tex; mode=display">CV_{(k)} = \frac{1}{k} \sum^{k}_{i=1}Err_i</script><p>其中$Err_i = I(y_i \ne \hat{y_i}) $。LOOCV和验证集错误率也可类似定义。</p><p>二、</p><p>上文提到，在LOOCV方法中，最小二乘法来拟合线性或多项式回归时将只计算一次。</p><script type="math/tex; mode=display">CV_{(n)} = \frac{1}{n} \sum^{n}_{i=1}(\frac{y_i - \hat{y_i}}{1-h_i})^2</script><p>其中$\hat{y_i}$为用原始最小二乘拟合的第i个拟合值，$h_i$为杠杆统计量：</p><script type="math/tex; mode=display">h_i = \frac{1}{n} + \frac{(x_{i} - \bar{x})^2}{\sum^n_{i'}(x_{i'} - \bar{x})^2}</script><p>区别仅在于第i个残差除了一个系数$(1-h_i)$。杠杆值的大小在0到1之间，反映了一个观测对自己拟合值的影响大小。因此，该公式表明高杠杆值的残差根据它本身偏离数据的程度进行了等量的放大。</p><p>三、</p><p>若样本量非常小，非常非常小，我们还可以使用重抽样的另一种方法：<strong>自助法</strong>（bootstrap）。</p><p>比如我们有m个样本（m较小），每次在这m个样本中随机采集一个样本，放入训练集，采样完后把样本放回。这样重复采集m次，我们得到m个样本组成的训练集。当然，这m个样本中很有可能有<strong>重复</strong>的样本数据。同时，用原始的m个样本做测试集。这样接着进行交叉验证。</p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1]James G , Witten D , Hastie T , et al. An Introduction to Statistical Learning[M]. Springer New York, 2013.</p><p>[2]杨柳,王钰.泛化误差的各种交叉验证估计方法综述[J].计算机应用研究,2015,32(05):1287-1290+1297.</p><p>[3]范永东. 模型选择中的交叉验证方法综述[D].山西大学,2013.</p><p>[4]Hastie, Trevor J. The Elements of Statistical Learning[M]. 世界图书出版公司, 2015.</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;交叉验证相关理论介绍&quot;&gt;&lt;a href=&quot;#交叉验证相关理论介绍&quot; class=&quot;headerlink&quot; title=&quot;交叉验证相关理论介绍&quot;&gt;&lt;/a&gt;交叉验证相关理论介绍&lt;/h2&gt;&lt;p&gt;2020.10.13&lt;/p&gt;
&lt;h3 id=&quot;1-1-场景构建&quot;&gt;&lt;a href=&quot;#1-1-场景构建&quot; class=&quot;headerlink&quot; title=&quot;1.1 场景构建&quot;&gt;&lt;/a&gt;1.1 场景构建&lt;/h3&gt;&lt;p&gt;源禾同学和正阳同学在某次考试都考了100分，正阳同学实力强劲，学习踏实，掌握核心科技，考了100是实力的体现，因为卷子上只有100分。而源禾同学考100分，因为源禾使用了败者食尘，他课下做了这张卷子的所有题，背了题，考了100分是因为记性好。&lt;/p&gt;
&lt;p&gt;谁才是老师喜爱的同学呢？&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据分析" scheme="https://konelane.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>分布式1007-Map-Reduce的文字流</title>
    <link href="https://konelane.github.io/2020/10/07/1007%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    <id>https://konelane.github.io/2020/10/07/1007%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/</id>
    <published>2020-10-06T16:00:00.000Z</published>
    <updated>2020-10-15T03:56:25.264Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最后编辑于：20.10.15</p><p>开门见山地来一段，就一段，不会有人这个都没搞懂吧，不会吧不会吧（拖走</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar \</span><br><span class="line"> $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.1.3.jar \</span><br><span class="line"> -input /user/devel/2020210995wangyuanhe/README.txt \</span><br><span class="line"> -output /user/devel/2020210995wangyuanhe/1007output \</span><br><span class="line"> -mapper &quot;/usr/bin/cat&quot; \</span><br><span class="line"> -reducer &quot;/usr/bin/wc&quot;</span><br></pre></td></tr></table></figure><p>开始前再插一句题外话，被强大而可爱的丰丰老师表（da）扬（shang）了，动力+10086，继续努力啊小禾禾！！</p><a id="more"></a><h2 id="分布式1007-Map-Reduce的文字流"><a href="#分布式1007-Map-Reduce的文字流" class="headerlink" title="分布式1007-Map-Reduce的文字流"></a>分布式1007-Map-Reduce的文字流</h2><h3 id="1-程序运行情况介绍"><a href="#1-程序运行情况介绍" class="headerlink" title="1.程序运行情况介绍"></a>1.程序运行情况介绍</h3><img src="/2020/10/07/1007分布式计算/10/07/1007分布式计算/tu1.png" title="tu1"><p>这张运行图只是执行中间一部分，正常情况下无ERROR，map 100% reduce 100%（这里运行时看着最爽）。</p><img src="/2020/10/07/1007分布式计算/10/07/1007分布式计算/tu2.png" title="tu2"><p>图2中第一行文件并无内容，后7个文件是本次运行开启的7个mapper的结果，reducer在这几个文件中运行，并把结果写入这7个文件中，所有的结果求和即真正结果。</p><p>下面看看运行的文件情况：</p><img src="/2020/10/07/1007分布式计算/10/07/1007分布式计算/tu3.png" title="tu3"><img src="/2020/10/07/1007分布式计算/10/07/1007分布式计算/tu4.png" title="tu4"><p>上图中，wc函数第一列的和就是16，即行数（验证正确），第二列为单词数（字符串连在一起算一个单词），第三列为字节数。</p><img src="/2020/10/07/1007分布式计算/10/07/1007分布式计算/tu5.png" title="tu5"><p>单个mapper+单个reducer运行</p><blockquote><p>每次cat：<br>行数+1；单词+n；字节数+m</p></blockquote><p>服务器上有很多个mapper，本次有17个（见上图），每个程序都做了cat函数（打印），7个reducer一起运行wc（计算行数）。Hadoop jar 中有这样一个参数，num.tasks，控制任务的数量。</p><h3 id="2-运行的相关介绍"><a href="#2-运行的相关介绍" class="headerlink" title="2. 运行的相关介绍"></a>2. 运行的相关介绍</h3><p>reducer结束的很慢，原因是启动时要花资源，map过程非常快（程序运行时有体会）。听说均分文件时会用到哈希code，现在很多算法都是哈希函数的进阶，不知真伪，之后问问。</p><p>在传输中，隐含了打乱shuffle和整理sort的过程:  </p><script type="math/tex; mode=display">平摊</script><p>把数据随机打乱，$shuffle$，保证每个mapper接受的任务量相近。<br>打乱顺序的任务再排序，$sort$，使每个程序尽可能找到较近数据。  </p><p>由于，数据在HDFS上存储在分布式的硬盘上，必须主动从硬盘读到内存里，有I/O（input/output）的消耗。如果数据很多，读起来很慢。一般map很复杂，可能map的中间结果要写入硬盘，又产生I/O消耗，reduce也需要从硬盘中读取。</p><p>故HADOOP对<strong>硬件读写</strong>的要求很高，如此反过来也节约了内存资源（贵）。真正制约hadoop的大多是硬盘读写，因此很多服务器用SSD，但是SSD很容易坏，故需要做冗余（防止硬件坏掉）。</p><p>apply函数，groupby函数，都有map的感觉</p><h3 id="3-Hadoop-与-Spark"><a href="#3-Hadoop-与-Spark" class="headerlink" title="3. Hadoop 与 Spark"></a>3. Hadoop 与 Spark</h3><p>hadoop擅长进行批处理，但不能进行实时计算（比如无人驾驶）、股票高频交易（短时间的计算），这种实时运算需要使数据保持“热状态”不存入硬盘，在map-reduce后立刻传出，与硬盘无关。</p><p>hadoop不擅长，但是spark擅长。spark写入硬盘的操作很有限，因此速度快。当然，上文也提到了，内存比硬盘贵，所以hadoop更廉价，两个框架各有胜负。</p><p>同时，hadoop不能实现迭代计算（牛顿迭代，神经网络，梯度下降，反向传播），几乎涵盖所有机器学习算法。迭代时需要大量循环，不能经常读写硬盘。</p><h3 id="4-标准输入输出-STDin-amp-STDout"><a href="#4-标准输入输出-STDin-amp-STDout" class="headerlink" title="4. 标准输入输出 STDin &amp; STDout"></a>4. 标准输入输出 STDin &amp; STDout</h3><p>在计算机编程中，有一类输入输出只与屏幕有关：</p><h4 id="Stdout"><a href="#Stdout" class="headerlink" title="Stdout"></a>Stdout</h4><p>任何程序结果总是需要保存，但有一类输出直接打印在屏幕上。凡是能打印的都是stdout。举些例子：print函数(r,python)，cat函数(r,linux)，printf函数(c)等等等等。基本全部语言都能标准输出。</p><h4 id="Stdin"><a href="#Stdin" class="headerlink" title="Stdin"></a>Stdin</h4><p>计算机能够接受打印的“文字流”（这也是hadoop streaming中streaming的含义！），举些例子：如linux和r的管道函数，python里open函数，都是打开文件把每一行读进来。</p><p>linux中很方便地组织你的文件，只要文件是文本文件，都可以用管道<strong>“吸入”</strong>。很多linux的函数都以cat开头（猫猫头）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat txt | python wc.py 单机实验</span><br></pre></td></tr></table></figure><p>再用R语言举个例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sink(&quot;想保存的文件名.txt&quot;,append = T, splt = T)</span><br><span class="line">abc = c(rnorm(100))</span><br><span class="line">abc</span><br><span class="line">sink()</span><br></pre></td></tr></table></figure><p>写进hdfs就是另外一幅模样了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#! /usr/bin/env Rscript</span><br><span class="line">options(warn=-1)</span><br><span class="line">sink(&quot;/dev/null&quot;)</span><br><span class="line"></span><br><span class="line">input &lt;- file(&quot;stdin&quot;, &quot;r&quot;) # 用input 吸入来自linux的STDin</span><br><span class="line">while(length(currentLine &lt;- readLines(input, n=1, warn=FALSE)) &gt; 0)</span><br><span class="line">&#123;</span><br><span class="line">    fields &lt;- unlist(strsplit(currentLine, &quot;,&quot;))</span><br><span class="line">    lowHigh &lt;- c(as.double(fields[3]), as.double(fields[6]))</span><br><span class="line">    stock_mean &lt;- mean(lowHigh)</span><br><span class="line">    sink()</span><br><span class="line">    cat(fields[1], fields[2], stock_mean, &quot;\n&quot;, sep=&quot;\t&quot;)</span><br><span class="line">    sink(&quot;/dev/null&quot;) # dev/null是linux的黑洞目录，扔进去就会消失呢！</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">close(input)</span><br></pre></td></tr></table></figure><p>运行时在linux中用rscript：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Rscript test.r</span><br></pre></td></tr></table></figure></p><p>其实做开发时，java语言很好用（类操作，大型项目架构，内存管理），适合创建非常巨大的项目，运行很久不停止，其他语言不行。hadoop也是java编成。但java并非所有人都会，hadoop面向数据处理，会java的人不多。</p><p>由此，先辈们做了个<strong>能让各种语言都能识别</strong>的框架：</p><p>hadoop做了很好玩的模块：streaming（标准输入输出的“文本流”）。提供了简单的接口，c，py，java，r……但凡能接受标准输入输出，就可以调用！使得map函数和reduce函数完全脱离了hadoop，只需要输入输出就能得到结果，影响速度的只有map和reduce的写法。</p><blockquote><p>Hadoop不是编程语言，是分布式计算架构。<br>    ——李丰老师</p></blockquote><h3 id="5-我们的函数，部署！"><a href="#5-我们的函数，部署！" class="headerlink" title="5. 我们的函数，部署！"></a>5. 我们的函数，部署！</h3><p><strong>教练，我也想调用hadoop接口跑我自己的程序！</strong></p><p>完全没问题！</p><p>很简单，首先要保证每个存储数据的节点上（worker节点）必须有函数cat、wc，我们自己写一个wchehe.py，然后放上服务器去就好啦。</p><p>如下，就是一个简单的读取行数的py程序，第一行一定要注明函数应该怎么找到运行的地方：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#! /usr/bin/env python3</span><br><span class="line">import sys</span><br><span class="line">linecount=0</span><br><span class="line">data = []</span><br><span class="line">for line in sys.stdin:</span><br><span class="line">linecount += 1</span><br><span class="line">data.append(line)</span><br><span class="line">Print(linecount)</span><br></pre></td></tr></table></figure><p>可以用chmod +x wchehe.py 改一下运行权限。</p><p>下来，为了规范代码格式，我们用一个shell批处理文件作为我们的程序入口，也方便调整参数。</p><p>开头别忘了告诉sh函数这是个批处理。<em>看到这篇文章的同学不要用原代码直接跑啊（</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#! /usr/bin/bash</span><br><span class="line"></span><br><span class="line">PWD=$(cd $(dirname $0); pwd)</span><br><span class="line">cd $PWD</span><br><span class="line"></span><br><span class="line">HADOOP_inputdir=/user/devel/2020210995wangyuanhe/ordertxtfiles/test-edit.txt</span><br><span class="line">HADOOP_outputdir=/user/devel/2020210995wangyuanhe/output/1007out01</span><br><span class="line">HADOOP_home=/share/hadoop/tools/lib/hadoop-straming-3.1.3.jar</span><br><span class="line"></span><br><span class="line">echo $HADOOP_home</span><br><span class="line">echo $HADOOP_inputdir</span><br><span class="line">echo $HADOOP_outputdir</span><br><span class="line"></span><br><span class="line">hadoop fs -rm -r $HADOOP_outputdir</span><br><span class="line"></span><br><span class="line">hadoop jar \</span><br><span class="line"> $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.1.3.jar \</span><br><span class="line"> -files $PWD/wchehe.py \</span><br><span class="line"> -input $&#123;HADOOP_inputdir&#125; \</span><br><span class="line"> -output $&#123;HADOOP_outputdir&#125; \</span><br><span class="line"> -mapper &quot;/usr/bin/cat&quot; \</span><br><span class="line"> -reducer &quot;python wchehe.py&quot;</span><br></pre></td></tr></table></figure><p>-jobconf 被替代为-D，-file 被替换成 -files</p><p>附上本次课程老师的<a href="https://github.com/feng-li/Distributed-Statistical-Computing/tree/master/L02-MapReduce" target="_blank" rel="noopener">代码和讲义</a>，我还得好好研究一下，收获满满的一节课（虽然有点怀疑人生哈哈哈</p><p>附作业中可能用到的hadoop jar<a href="http://www.voidcn.com/article/p-nyinxrro-cn.html" target="_blank" rel="noopener">参数介绍</a>，hadoop fs <a href="https://www.cnblogs.com/zwgblog/p/6005061.html" target="_blank" rel="noopener">参数介绍</a></p><img src="/2020/10/07/1007分布式计算/10/07/1007分布式计算/tu6.png" title="tu6"><p>（完）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最后编辑于：20.10.15&lt;/p&gt;
&lt;p&gt;开门见山地来一段，就一段，不会有人这个都没搞懂吧，不会吧不会吧（拖走&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;hadoop jar \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.1.3.jar \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; -input /user/devel/2020210995wangyuanhe/README.txt \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; -output /user/devel/2020210995wangyuanhe/1007output \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; -mapper &amp;quot;/usr/bin/cat&amp;quot; \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; -reducer &amp;quot;/usr/bin/wc&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;开始前再插一句题外话，被强大而可爱的丰丰老师表（da）扬（shang）了，动力+10086，继续努力啊小禾禾！！&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式0924-分布式服务器基础Linux中主机的远程交互(ssh)</title>
    <link href="https://konelane.github.io/2020/09/24/0924%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    <id>https://konelane.github.io/2020/09/24/0924%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/</id>
    <published>2020-09-23T16:00:00.000Z</published>
    <updated>2020-09-25T08:57:43.824Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="大数据分布式计算-0924"><a href="#大数据分布式计算-0924" class="headerlink" title="大数据分布式计算 0924"></a>大数据分布式计算 0924</h2><p>本次课程以上次思考题入手：</p><blockquote><p>并行计算与分布式计算的区别？</p></blockquote><a id="more"></a><p>并行计算是一台计算机使用自身共享的内存和算力，用CPU的多核特点进行并行处理。</p><p>分布式计算是利用服务器的高算力，从远程交互终端中向服务器部署代码进行计算。</p><p>我的理解还是太片面，下面看看李丰老师的想法：</p><p>并行计算（parallel computing）是一个通常用于高性能计算（HPC）领域的术语。它具体指的是使用 多个处理器执行计算或模拟。超级计算机是为执行并行计算而设计的。这些系统不一定有共享内存。并 行系统使用MPI这样的工具将在超级计算机或者集群机器上的计算资源调度并实现多任务的同步计算。 并行计算在许多计算软件中都集成了一些基本的实现途径。比如R中的自带parallel包，Python标准 库中的multiprocessing是一个用与 threading 模块相似API的支持产生进程的包。这些程序模块允 许程序员充分利用机器上的多个核心。Unix 和 Windows 上都可以运行。结合OpenMP（Open Multi-Processing）等支持跨平台共享内存方式的多线程并发的编程API，使用现有编程语言可以在大 多数的处理器体系和操作系统中运行并行计算任务。具有并行计算能力的高性能计算平台往往被应用在 很多特定的科学领域，如超级计算机，密码破译，生物医学。</p><p>分布式计算（distributed computing）实际上是一个比并行计算更笼统的术语。人们可以将分布式计 算与并行计算的意义等同于并行计算，分布式特指的是将计算分布在许多不同的计算机之间。然而，分 布式计算处理的是并发性以外的其他方面。分布式计算具有并行计算所不具有的一些特性，包括计算一 致性、计算高可用性和高容错性能等。此外现在分布式计算平台的计算成本更低。像本书涉及到的 Hadoop或Spark这样的系统都是分布式计算系统，它们都有处理节点和网络故障的能力。不过，这两种 系统也都是为了执行并行计算而设计的。与MPI等HPC系统不同，这类新型系统即使其中一个计算节点出 现故障，也能继续进行海量计算。分布式计算主要应用在数据科学领域，如互联网、物联网、车联网、 数字金融。</p><p>在现代数据科学浪潮的冲击下，利用低成本硬件实现大规模分布式计算成为大数据应用的主流方向。世 界上各大数据科学公司都把分布式计算作为数据科学的核心技术与产品。最为大家熟知的有如亚马逊、 阿里巴巴各大云平台。在数据科学的应用中催生了大量分布式计算的优秀工具，如Hadoop, HDFS, Hive, Spark, Storm。</p><h2 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h2><p>分布式中，有不同的框架：</p><p>资源调度器（分布式文件系统HDFS） + 资源管理器（管理计算机资源哪一部分做什么，YARN） + 管理框架（zookeeper &amp; AMBARI）</p><p>不同的领域侧重的框架也不同。</p><blockquote><p>电商 - spark（计算）<br>图片处理 - Hadoop<br>存储数据财富 - hive<br>……</p></blockquote><h2 id="大数据分布式的特性"><a href="#大数据分布式的特性" class="headerlink" title="大数据分布式的特性"></a>大数据分布式的特性</h2><p>分布式服务器一般由很多同质的软件和硬件构成。</p><p>服务器为<strong>“刀片式服务器”</strong>（不同于塔式服务器），每一个计算节点都是一个刀片，通过网络连接，非核心的节点损坏不影响整体。可以在计算资源空闲时慢慢修复。</p><p>masternode<br>|——- workernode1…<br>|——- workernode2…<br>|——- workernode3…  </p><p>HDFS以来的两种逻辑组件，一个是起索引作用的namenode，一个是起存储作用的DataNode。二者数量和位置取决于worker节点的数量：worker很多时，要单独做成服务器，因为他们对算力要求很高；很少时可以置于masternode中。</p><p>优点：用廉价的硬件达到较高的存储性能。</p><p>缺点：随机存储，故不擅于做随机文件的搜索（会消耗大量算力查找索引），大文件被分成小份，存在不同的datanode中。</p><blockquote><p>根据文件大小切割为相似大小的block：<br>$/tmp/test.txt $<br>|——- blocka<br>|——- blockb</p></blockquote><p>&gt;<br>blocka<br>|——- datanode2<br>|——- datanode1<br>blockb<br>|——- datanode1<br>|——- datanode3  </p><p>注意到，DataNode1被复制了两份，这在分布式服务器中是很常见的。DataNode之间会根据是否空闲以及是否存储了相关数据而进行并行处理。只要namenode在，哪怕一块硬盘坏了，也能恢复。</p><h2 id="MapReduce组件"><a href="#MapReduce组件" class="headerlink" title="MapReduce组件"></a>MapReduce组件</h2><p>位置：Hadoop中</p><p>作用：处理大量数据，能用forloop处理的，可以通过分布式发给程序，代码对象应当各自独立。</p><p>对服务器？的I-O性能要求较高（input-output）</p><p>老师提示：分布式程序中应有容错空间（未领会，无经历）</p><p>分布式的MapReduce如下：</p><blockquote><p>JobTracker<br>|——- tasktracker1<br>|——- tasktracker2  （注意，ttk1和ttk2之间也互相连通）<br>ttk中容纳的是M-R两步的多个子程序  </p><p>activeJobs(位置JobTracker)：<br>joba<br>|——- map task1<br>|——- map task2<br>jobb<br>|——- reduce task1<br>|——- reduce task2  </p></blockquote><h2 id="服务器讲解"><a href="#服务器讲解" class="headerlink" title="服务器讲解"></a>服务器讲解</h2><p>远程操作终端：putty</p><p>账号密码和ip就略了（逃</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mkdir</span><br><span class="line">cd</span><br><span class="line">ls</span><br><span class="line">rm -rf /user/students</span><br><span class="line">touch lifeng.txt</span><br><span class="line">vim lifeng.txt</span><br><span class="line">emacs lifeng.txt</span><br><span class="line">cat lifeng.txt</span><br><span class="line"></span><br><span class="line">hadoop fs -ls /</span><br><span class="line">hadoop fs -put lifeng.txt /user/test </span><br><span class="line">hadoop fs -cat /user/test/lifeng.txt</span><br><span class="line">hadoop fs -get /user/test/lifeng.txt lifeng2.txt</span><br><span class="line">hadoop fs -ls /test &gt; hadoop-ls-return.txt</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;大数据分布式计算-0924&quot;&gt;&lt;a href=&quot;#大数据分布式计算-0924&quot; class=&quot;headerlink&quot; title=&quot;大数据分布式计算 0924&quot;&gt;&lt;/a&gt;大数据分布式计算 0924&lt;/h2&gt;&lt;p&gt;本次课程以上次思考题入手：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;并行计算与分布式计算的区别？&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>分布式0917-遍历检索的多进程初试水</title>
    <link href="https://konelane.github.io/2020/09/24/0917%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    <id>https://konelane.github.io/2020/09/24/0917%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/</id>
    <published>2020-09-23T16:00:00.000Z</published>
    <updated>2020-09-24T03:04:11.439Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="大数据分布式计算-0917"><a href="#大数据分布式计算-0917" class="headerlink" title="大数据分布式计算 0917"></a>大数据分布式计算 0917</h2><p>本次课程内容讲述的几个注意的有意思的东西：</p><h3 id="分布式是什么"><a href="#分布式是什么" class="headerlink" title="分布式是什么"></a>分布式是什么</h3><p>“数据向代码跑” / “代码向数据跑”</p><p>原本的流程：<script type="math/tex">数据 -> cpu(code) -> answer</script></p><p>新流程：<script type="math/tex">cpu -> 数据 <- cpu</script></p><p>俗话说：双拳难敌四手嘛。</p><a id="more"></a><h3 id="多进程-并非-多线程"><a href="#多进程-并非-多线程" class="headerlink" title="多进程 并非 多线程"></a>多进程 并非 多线程</h3><p>多进程即开很多程序，多线程是多路并行。</p><h3 id="map-reduce原理"><a href="#map-reduce原理" class="headerlink" title="map-reduce原理"></a>map-reduce原理</h3><blockquote><p>1+3+5+7+9+11+13+15+17<br>map<br>(1+3+5) + (7+9+11) + (13+15+17)<br>reduce<br>9 + 27+ 45<br>answer</p></blockquote><p>常用的框架已经封装了分布式运算的计算法，用户只写需求的逻辑，由此产生了MapReduce的框架和Yarn，并不做运算。</p><p>因为专门的“计算引擎”（基于计算系统）Hadoop，HDFS储存，spark（生于伯克利，号称分布式平台中流砥柱）</p><p>学习目标：非常熟悉，能够把自己写的东西放上去，不写，要会用。</p><h3 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h3><p>请用R或者Python自带的并行计算模块实现一个简单的单机文件查找代码，并与串行代码在效率上做比较。思考分布式与并行计算的区别。</p><p>我的答案，由于特殊需求无意义地加长了很多。同时就当初学python的任务驱动练习了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># coding:utf-8</span><br><span class="line"># 分布式计算1-多进程对比检索代码</span><br><span class="line">import os</span><br><span class="line">import time</span><br><span class="line">import multiprocessing as mp</span><br><span class="line">from time import sleep</span><br><span class="line"></span><br><span class="line">def get_all_file(path):</span><br><span class="line">    res = []</span><br><span class="line">    for root, dirs, files in os.walk(path):</span><br><span class="line">        for file in files:</span><br><span class="line">            res.append(os.path.join(root, file))</span><br><span class="line">    return (res)</span><br><span class="line"></span><br><span class="line">def checkdir(dir):</span><br><span class="line">    file = dir.split(&apos;\\&apos;)[-1]</span><br><span class="line">    (filename, extension) = os.path.splitext(file)</span><br><span class="line">    if (extension == &apos;.txt&apos;) and (&apos;win&apos; in filename):  # 检验文件后缀与事先设置的关键字</span><br><span class="line">        sleep(1)</span><br><span class="line">        return (dir)</span><br><span class="line"># 上一版作业是猜测，不过本次提交版本根据一段未写在作业中的代码可以得知，要把循环从函数剔除，非遍历的部分才能使用迭代加速</span><br><span class="line"># 同时为了实现更直观的对比，而不是对简单函数进行多进程（有时甚至会起反效果），加入了sleep函数</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # 设定参数</span><br><span class="line">    path0 = &quot;D:\\&quot;   # 设置一个路径，目标是这个路径下全部带有关键字‘win’的文本文档</span><br><span class="line"></span><br><span class="line">    # 顺序执行部分</span><br><span class="line">    print(&apos;顺序执行：&apos;)</span><br><span class="line">    start1 = time.time()</span><br><span class="line">    pathall2 = get_all_file(path0)</span><br><span class="line">    result = []</span><br><span class="line">    for path in pathall2:</span><br><span class="line">        result.append(checkdir(path))</span><br><span class="line">    for res2 in result:</span><br><span class="line">        if res2 != None:  # 为了对比效果，特意使用了和多进程代码相同的函数，徒增复杂度</span><br><span class="line">            print(res2)</span><br><span class="line">    end1 = time.time()</span><br><span class="line">    yongshi1 = end1 - start1</span><br><span class="line">    print(&quot;顺序耗时：%s&quot; % yongshi1)</span><br><span class="line">    print(&apos;==&apos;*20)</span><br><span class="line">    # 多进程执行部分</span><br><span class="line">    print(&quot;多进程执行:&quot;)</span><br><span class="line">    start2 = time.time()</span><br><span class="line">    pool = mp.Pool(4) # 设置4个进程同时运行，不过感觉没有必要，空缺时会根据系统设置最佳参数</span><br><span class="line">    pathall1 = pool.apply_async(get_all_file,args=(path0,)).get()</span><br><span class="line">    # 上一行根据结果来看，没有起作用，即for循环不能被多进程加速，必须按部就班</span><br><span class="line">    results1 = pool.map(checkdir, pathall1) # 此处pathall一定是一个可迭代变量(iter)</span><br><span class="line">    pool.close() #关闭池子，不能再加入进程</span><br><span class="line">    pool.join() # 等待进程结束</span><br><span class="line">    for res1 in results1:</span><br><span class="line">        if res1 != None:</span><br><span class="line">            print(res1)</span><br><span class="line">    end2 = time.time()</span><br><span class="line">    yongshi2 = end2 - start2</span><br><span class="line">    print(&quot;多进程耗时：%s&quot; % yongshi2)</span><br><span class="line"></span><br><span class="line"># 总结：其实本程序慢在os.walk()遍历文件，对后续&lt;比对筛选打印&gt;函数调用多进程反而可能降速</span><br><span class="line"># 核心函数只有pool四行，以及调用os.walk函数</span><br></pre></td></tr></table></figure><p>多进程也不见得很好用嘛，甚至不经过特意等待，比顺序运行还慢，哈哈。</p><p>（请多指教，完）</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;大数据分布式计算-0917&quot;&gt;&lt;a href=&quot;#大数据分布式计算-0917&quot; class=&quot;headerlink&quot; title=&quot;大数据分布式计算 0917&quot;&gt;&lt;/a&gt;大数据分布式计算 0917&lt;/h2&gt;&lt;p&gt;本次课程内容讲述的几个注意的有意思的东西：&lt;/p&gt;
&lt;h3 id=&quot;分布式是什么&quot;&gt;&lt;a href=&quot;#分布式是什么&quot; class=&quot;headerlink&quot; title=&quot;分布式是什么&quot;&gt;&lt;/a&gt;分布式是什么&lt;/h3&gt;&lt;p&gt;“数据向代码跑” / “代码向数据跑”&lt;/p&gt;
&lt;p&gt;原本的流程：&lt;script type=&quot;math/tex&quot;&gt;数据 -&gt; cpu(code) -&gt; answer&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;新流程：&lt;script type=&quot;math/tex&quot;&gt;cpu -&gt; 数据 &lt;- cpu&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;俗话说：双拳难敌四手嘛。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="大数据" scheme="https://konelane.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>遍历山河|贵州</title>
    <link href="https://konelane.github.io/2020/09/15/200915%E8%B4%B5%E5%B7%9E%E4%B9%8B%E8%A1%8C/"/>
    <id>https://konelane.github.io/2020/09/15/200915%E8%B4%B5%E5%B7%9E%E4%B9%8B%E8%A1%8C/</id>
    <published>2020-09-14T16:00:00.000Z</published>
    <updated>2020-09-16T13:02:00.926Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>第一次坐飞机。</p><p>夜航|氦核20.07.06</p><blockquote><p>芸芸灯火糅中盘，一子冲天战正酣。<br>班师星中我非客，翼稍挂月天外山。<br>明灯未知夜深浅，颠簸可猜云浓淡。<br>远电殷霞威颜厉，破雾勒马便坦然。</p></blockquote><a id="more"></a><h2 id="7日"><a href="#7日" class="headerlink" title="7日"></a>7日</h2><p>行程开始得急，昨夜飞机才至，今天清晨就踏上旅程。</p><p>第一次坐飞机的感觉很是神奇，以前总为自己在新时代还没能坐上飞机而感慨，全家也仅仅我一人没有乘坐过飞机出行。飞机这种交通工具于我总有某种遥不可及的神秘感，我也喜欢在文中用“飞”的意象，现在又少了一份能够为家人和我津津乐道的立场。飞机起飞时的加速让我猝不及防，高度变化时我也头晕目眩，甚至会因为身下无依无凭而突然感到害怕，但我依然震撼于夜航所见地面的万家灯火，震撼于穿云破雾时的一往无前，飞在天上的我觉得自己从星星中来，像极了将要下凡的天官。因为刚刚过十五，皎洁而饱满的月亮透过稀薄的云层高悬在机翼远端，注视着祝福着一飞机的旅人。如此种种感情纠缠在一起，甚至落地许久后也没能平复。</p><p>今天去了小七孔景区，一开始不明所以，后来才知是道光年间修起的七孔石桥，横跨响水河，天然去雕饰。这里的水泛着奇妙的青绿色，又不似别处清澈，更像翡翠和玉石，也带点“油”的感觉。水动处成涓流，水死处成碧潭，水高地飞落作瀑布，恰如一语“寒烟翠波”所言。飞瀑从山而下，如银龙攀附，面露凶光，口中喑嘶。</p><p>其实也没能仔细转完，走走停停拍照歇脚，转过卧龙潭，翠谷瀑布，石上森林，断桥飞瀑，再到拉雅瀑布，最后就见到小七孔了。小七孔没有介绍中那样“天然”，但经过了前面聒噪澎湃的飞瀑激流，此处的她更像无声胜有声，前面的澎湃被跋涉消磨将尽，到此这座饱经风雨的石桥张开怀抱，迎接这碧波末路，汇入大江。站在铜鼓桥上，面对滚滚江水，习习微风，我一时语塞，我消磨过的人事物太多太纷繁，也太匆匆，最终留下的还有什么呢？我总是不察得失，不知悔改。子在川上曰，逝者如斯夫。今日偶然得宽余，才能一览千山万水，于自然中体察得失。</p><p>其实旅行团也罢，自驾游也罢，但凡是省内打转的，免不了赶路的时间。今天在大巴车上度过了许久的时间，两小时才能换来二十分钟的放松，我们便会如囚鸟出笼，蜂拥而出。旅游分两种，一种看人文，另一种读山水，我这次出行，大抵属于第二种。可贵州山多，一山放过一山拦，眼前满溢的山光水色还是容易腻，此时我就不自觉地开始寻觅风景背后的些许生活与人味。</p><p>夜幕来临，我们总算赶到了千户苗寨。按理来说白天可以看这里勾心斗角的苗族建筑，但夜幕锁上了大部分文化。此处充满商业化的臭味，但总还是值得一看，十余座村寨合成的大寨灯火星点，我们趁着夜色还有时间登上山顶，眼前灯火宛如一盘迷局，十分壮观。</p><p>苗族竟是蚩尤氏部落后裔，也颇有来头，还有些奇妙的传说，诸如中元节的传说，苗药的神奇，以及用少女初潮制作的情蛊等等，都令我耳目一新，我还寻思着大概很多人今生盖也无机会制作情蛊，这番思索让我不得不感慨自己总是在这种稍显变态的地方好奇拉满。</p><p>不过，本地妹子也确实好看，尤其话语间轻柔的发音习惯让我听来很是舒服，我的语气也不禁缓和下来。当地人更是无比好客。虽然一路上扰我乱我的破烦事多，但听两首苗族祝酒歌，看一番高山流水情长酒，再多烦恼也便抛之脑后了。我还破例喝了几口米酒，或许有些醉，可他们说我没醉，我便也不知道我醉没醉了。</p><h2 id="8日"><a href="#8日" class="headerlink" title="8日"></a>8日</h2><p>旅行也总是混杂着一些愉快和不愉快，我们愉快了，导游不一定愉快，反之亦然。这世界不能人人都舒坦，你舒坦时总有人不舒坦。</p><p>其实来之前我以为的旅游，行到水穷处，坐看云起时，举匏樽以相属，寄蜉蝣于天地，渺沧海之一粟。结果现实的旅游团给了我对贪婪更加深刻的认识，早饭是永远不变的鸡蛋馒头咸菜条，午饭好一些，一桌添一口炖菜火锅，几道油盐意难平的家常菜，真不如家里吃的好。导游于是鼓吹苗族长寿皆源于口味清淡的饮食，我也无语。</p><p>今天驱车前往一处闻所未闻的非遗博物馆，前几层倒是货真价实的苗族文化，服饰，用品，家装，都有模有样。苗族的银饰着实多种多样，玩出了花，但同时作为民族争斗中的败者，他们也只能在此一些无关紧要的地方花心思。其余银品相关的奇怪传言，但凡是受过高中教育的，都会一笑了之。</p><p>可是闹剧才刚刚开始，来到最后的展厅，讲解做了个墨水变色的实验，银碗甚至能改变水质的酸碱性，又大肆宣扬银离子杀菌作用高强，紧接着带着全团走进了远超博物馆规格的银饰品商城。虽然讲解那番反智言论令一个“醒来”的人不适，但我也不想做断人财路的傻事，顺其自然才是此时的最优解。但独善其身者又何止我，饭后上车，导游问大家在有多少消费，结果自然是寥寥无几，直接导致导游对后面的景点毫无讲解的兴致，放任全车人无知中来无知中去了。</p><p>好在所到之处是有名的军事重镇镇远，古镇青石板长街，烟雨中行人稀疏，尽管留下的游览时间并不充裕，但节奏依然很慢很舒服。我们踏入古镇侧面的巷子，迈进一座座飞檐叠廊，那即是当地人住的地方，墙上的有年头的方砖有些翻新痕迹，但也有部分破损了，爬满潮湿的青苔。在巷子深处一口井，井中投鱼防毒，我们看了一圈正要离去，恰巧碰见一位当地人拎着绳子和桶去汲水，我第一次见人井中打水，饶有兴致问了问，原来井边那条放绳子的凹痕是世世代代打水人磨出的，并非刻意为之。其实整个打水也没什么特别之处，第一次觉得景点和生活糅合在一起，生活即风景，如此自然天成。</p><p>镇远的舞阳河因为小雨变得稍显浑浊，这里人酒足饭饱便躺卧在河边长廊中纳凉，但其实这里找不到几个真正凉爽的地方，更多的是潮湿与闷热，行走时还好，站定就会收获停不下来的汗水。我在路边奶茶店买了一杯并不中意的奶茶，但是惊喜之处在于奶茶店中温柔的老板姐姐和两面贴满便利贴的许愿墙。老板姐姐自不必说，更值得称道的是许愿墙上纯真可爱的文字与愿望，有本地人有外地人，有成年人有小孩子，有痛苦和忧虑的祈祷，也有满心欢喜的纪念和憧憬。这一面许愿墙，并没有满满地写着人的欲望，更多的竟然是祝福和期待未来，我对贵州人风土人情也大概摸清一二了。</p><p>结束了旅程，又进入赶赴下一个地点的大巴车程。路上又开始寂寞，翻照片，看到烟雨半掩的古镇和青石板街，突然想念起一位朋友，可惜因为种种原因，我再无问候的立场了。晚上烤鱼也无味了，可能是我以前吃过家门口的麻辣重口烤鱼，对于眼前这条平淡的存在实在无感了吧。</p><h2 id="9日"><a href="#9日" class="headerlink" title="9日"></a>9日</h2><p>贵州省会贵阳名副其实，今早起来果不其然又浓云密布。昨晚住的酒店旁边有条小溪，酒店也起了个恰如其分的名字叫“栖溪”，然而店家倒是惬意了，住客则要忍受经久不息的激流声，以及山中那无比潮湿的空气，早上起来诸位无一不是困意十足，料想昨晚一定默念了百遍“逝者如斯”。</p><p>昨晚经同学极力推荐，我们去吃了贵州的烤鱼，这算是几日来吃的最好的一次，虽然价格贵了点，可相当有滋味，配上小米酒冰红茶，很受用。独特的江口烤小豆腐脆皮软心，外表冷漠，内心却还是狂热的。虽然早有人给我打过预防针，贵州食物辣度非凡，可是我只觉得贵州人对于酸更加钟爱。本地甚至有“三日无酸，腿打捞酸”的警世名言，仅看遍地开花的酸汤鱼店以及逢菜必放的西红柿，可见一斑。昨晚烤鱼中剩下不少余料，土豆黄瓜锅巴粉什么的，正好也调剂了每日清晨的咸菜馒头。</p><p>其实昨晚睡得地方是梵净山山脚，离旅游区不过五分钟路。若说是仙境倒是夸大了，但梵净山确实不同于我以往去的任何地方。时间所限，摆渡车缆车把我们送上半山腰，刚开始谁都没有意识到，当缆车上看到远山刺透云层，而我们的缆绳也向着虚无的朦胧中无限延伸时，才恍然大悟周身大雾是高山云雾。云雾比通常所见大雾更加细腻，肉眼可见的小水滴浮在空中，不一会眼镜就全花掉了。</p><p>这么介绍下去，恐怕这篇文章也像受了潮气一样无趣。这两天最喜欢的两句诗，一句是林则徐的“风雨冥冥极漏天”，一句是毛主席的“胜似闲庭信步”，两句深得我心。在爬山过程中，我做先锋，一路高歌猛进，森林栈道拾级而上，没料到台阶太密太紧凑，让人疲惫不堪。蘑菇石这里奇石林立，那些方砖似的巨石层叠而起，如天外来客，危险诡妙地搭在山顶。视觉上无比险峻易碎，可真实情况是这里的地质无比稳定，经久不变。蘑菇石甚至目睹沧海桑田，区区人类文明不足道也。</p><p>孤独的旅途中，我攀上峰顶，突然想拍张照，可是一时间找不到人。四周没有深渊巨谷，只有逼人窄道和沾衣的云露，伴着早早来此工作的僧侣和清洁工，我发了会呆，这里大概不属于我，我亦不属于这里。我想求神拜佛让我忘记烦恼，可我不能求“无求”，而烦恼大多生于所求。我怎么能用欲望来战胜欲望，用烦恼来解决烦恼呢？然而事实只能如此，所以佛门离我还是太远，真希望有一天我也能找到属于我的答案。不过神奇的是，今天山上寺院中两位僧人师父看了我许久，可是欲言又止，不知是我犯了禁忌还是面露凶光，大家都喜欢对我欲言又止，这可苦坏了我这个蠢人。</p><p>路上，天气突然转晴，那是从未见过的蓝天白云，然而转瞬即逝了。</p><h2 id="10日"><a href="#10日" class="headerlink" title="10日"></a>10日</h2><p>和父母出去，总不如自己一人出行更加完整，至少体验上看，不论是突然对某些问题发问，亦或是对拍照的执着，父母常常打断我游览的思路。如果说满状态的体验可以到达80分，那么父母主导的旅行最多50分。不过看在贵州山水的份上，这趟旅行还算没有失去灵魂。</p><p>今天早上仍然是无聊的购物环节，导游来之前大谈国学风水，还将迷信说成信仰，结果今早全都泡了汤，我们并没有领情。商场中宝石确实超出了我们的理解，在我看来毫无价值的石头，在偏僻无人烟的犄角旮旯这样一座藏宝宫里，竟然成倍地涨价，以至于完全消费不起。找到知情人了解了产业链，才知道这小小宝石养活了导游导购匠人还有批发商这么一群人，谁不想从中抽点东西分一杯羹呢？不过导购也十分尽职，至少她盯着我们走了一早上，甚至当我找不到同伴时，她会告诉我们此人所在。讲解与推销双管齐下，还专门挑出可能对我们口味的商品挨个询问，只可惜定价着实太高，都是些明摆着“谁买谁是大傻子”的东西，不然以导购之勤奋没有功劳也有苦劳，定能成功。</p><p>抛开购物不谈，今天的早中两顿饭都是极好的，四星酒店待遇真不同，早餐一改往日馒头咸菜，变成了多姿多彩的自助餐，一句诗来说“萧瑟秋风今又是，换了人间”，爸妈胃口大开，我还是量力而为。中午饭也不错，不再从头酸到脚，下饭者下饭，充饥者充饥，竟然各司其职起来，让我大快朵颐。</p><p>黄果树瀑布是好的。看完有诗为证：</p><blockquote><p>白龙破水自巍吟，骤雨穿林渐希音。<br>银河玉碎比拟俗，七进七出战袍轻。<br>散落人间星满镜，厮磨耳鬓石衔青。<br>闲庭信步岿然立，云露拌作落汤鸡。</p></blockquote><p>其实一路上感慨良多，但思来想去都是些和人相关的复杂情感，在大自然面前我仍然只能乖乖做个孩子，除了敬畏以外也不剩太多痴心妄想。这些年人造之景愈发多了，本来无甚可看，但经过修修造造总算能凑齐一个景点，总的来说还是没必要，整体质量下降了不少。黄果树瀑布是中国第一大瀑布，至少是我贫瘠的旅游生涯中所见的最大的瀑布了，适逢汛期，瀑布水大，看完后水汽沾衣浑身湿透，却连连大呼震撼爽快。</p><p>晚上在贵阳市里闲逛，碰巧天晴，看到了夜晚的蓝天。这里仗着地质稳定，飞楼百米接二连三，高楼林立。甲秀楼南明河夜景倒是普普通通，不过南门口粉面不错，尤其是谐音常旺的肠旺面，肠与血配上油炸小肉丁别有风味，深得我心。到隔壁叫了一碗玫瑰绿豆冰粉，做冰粉的小姐姐和我攀谈，在我将别之时推荐了一些好吃好玩，可以说非常遗憾了。</p><p>这两天接触的东西太多太杂，导致我在记忆中筛选得不是特别仔细，加上每天烦恼多多，操心多多，倍感时间飞逝，天色已晚，不再赘述了。</p><p>（完）</p><p>9月15日整理时记：旅行的最后一天没有记述，行程紧张3点才到家。其实白天也看了不少风景。旱溶洞和水溶洞，还有多彩贵州城，都挺有见闻，可惜淡忘了。触景生情，朋友说只有恰当的时机和恰当的人才能碰撞出无与伦比的绝美感情，我想确实是这样的。至少现在的意义和旅游时的意义全然不同了。我曾经是个猛男，现在又一次变回了二五仔，哈哈。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;第一次坐飞机。&lt;/p&gt;
&lt;p&gt;夜航|氦核20.07.06&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;芸芸灯火糅中盘，一子冲天战正酣。&lt;br&gt;班师星中我非客，翼稍挂月天外山。&lt;br&gt;明灯未知夜深浅，颠簸可猜云浓淡。&lt;br&gt;远电殷霞威颜厉，破雾勒马便坦然。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="文章" scheme="https://konelane.github.io/tags/%E6%96%87%E7%AB%A0/"/>
    
  </entry>
  
  <entry>
    <title>python联萌|pandas（国宝库</title>
    <link href="https://konelane.github.io/2020/02/06/200206pandaslearning/"/>
    <id>https://konelane.github.io/2020/02/06/200206pandaslearning/</id>
    <published>2020-02-05T16:00:00.000Z</published>
    <updated>2020-02-06T09:59:14.619Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最后编辑于：2020.02.06 18:00</p><h2 id="Pandas库"><a href="#Pandas库" class="headerlink" title="Pandas库"></a>Pandas库</h2><p>Pandas是基于NumPy 的一种工具，其出现是为了解决数据分析任务。（氦核：个人觉得更像是探索工具，没有模型，简单分析。）<br>Pandas吸纳了大量库和一些标准的数据模型，提供了高效操作大型数据集所需的工具。<br>Pandas中的函数和方法能够使我们快速便捷地处理数据。<br>它是使Python成为强大而高效的数据分析环境的重要因素之一。</p><p><a href="http://pandas.pydata.org/pandas-docs/stable/api.html" target="_blank" rel="noopener">http://pandas.pydata.org/pandas-docs/stable/api.html</a></p><p>本文参考<a href="https://www.windquant.com/" target="_blank" rel="noopener">万旷网教程</a>。</p><a id="more"></a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先导入pandas库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><p>numpy详见上一篇文章。</p><h2 id="一、序列Series"><a href="#一、序列Series" class="headerlink" title="一、序列Series"></a>一、序列Series</h2><p>序列Series是一个一维数组结构，可以存入任一种Python数据类型(integers, strings, floating point numbers, Python objects, 等等)</p><p>序列Series由两部分构成，一个是index，另一个是对应的值，注意两者的长度必须一样。序列Series和数组array很类似，大多数numpy的函数都可以直接应用于序列Series</p><p>序列Series也像一个固定大小的字典dict，可以通过index来赋值或者取值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'通过数组来生成序列Series'</span>)</span><br><span class="line">s_array = np.random.randn(<span class="number">5</span>)</span><br><span class="line">s = pd.Series(s_array, index = [<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>,<span class="string">'e'</span>])</span><br><span class="line">s</span><br></pre></td></tr></table></figure><pre><code>通过数组来生成序列Seriesa   -0.298058b   -1.095748c    1.333607d    1.119917e    1.595123dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'通过字典来生成序列Series'</span>)</span><br><span class="line">s_dict= &#123;<span class="string">'a'</span>:<span class="number">11</span>,<span class="string">'b'</span>:<span class="number">1000</span>,<span class="string">'c'</span>:<span class="number">123213</span>,<span class="string">'d'</span>:<span class="number">-1000</span>&#125;</span><br><span class="line">s = pd.Series(s_dict)</span><br><span class="line">s</span><br></pre></td></tr></table></figure><pre><code>通过字典来生成序列Seriesa        11b      1000c    123213d     -1000dtype: int64</code></pre><p>我们取一段金融时间序列给大家做更具体的分析：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> WindPy <span class="keyword">import</span> *</span><br><span class="line">w.start()</span><br><span class="line"></span><br><span class="line">list1 = w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"close"</span>, <span class="string">"2018-06-28"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>)</span><br><span class="line">list1</span><br></pre></td></tr></table></figure><pre><code>Welcome to use Wind Quant API for Python (WindPy)!COPYRIGHT (C) 2017 WIND INFORMATION CO., LTD. ALL RIGHTS RESERVED.IN NO CIRCUMSTANCE SHALL WIND BE RESPONSIBLE FOR ANY DAMAGES OR LOSSES CAUSED BY USING WIND QUANT API FOR Python..ErrorCode=0.Codes=[000001.SZ].Fields=[CLOSE].Times=[20180628,20180629,20180702,20180703,20180704,20180705,20180706,20180709,20180710,20180711].Data=[[8.92,9.09,8.61,8.67,8.61,8.6,8.66,9.03,8.98,8.78]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将收盘价转为</span></span><br><span class="line">ss = pd.Series(list1.Data[<span class="number">0</span>], index = list1.Times)</span><br><span class="line">ss</span><br></pre></td></tr></table></figure><pre><code>2018-06-28    8.922018-06-29    9.092018-07-02    8.612018-07-03    8.672018-07-04    8.612018-07-05    8.602018-07-06    8.662018-07-09    9.032018-07-10    8.982018-07-11    8.78dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以通过index来查看序列Series中的元素</span></span><br><span class="line">print(<span class="string">'查看序列中index为：'</span>,ss.index)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看序列中index为a的元素：'</span>,ss[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><pre><code>查看序列中index为： Index([2018-06-28, 2018-06-29, 2018-07-02, 2018-07-03, 2018-07-04, 2018-07-05,       2018-07-06, 2018-07-09, 2018-07-10, 2018-07-11],      dtype=&#39;object&#39;)查看序列中index为a的元素： 8.92</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于index 可以修改序列s中的元素</span></span><br><span class="line">print(<span class="string">'原序列：\n'</span>,ss)</span><br><span class="line">print()</span><br><span class="line">ss[<span class="number">0</span>] = <span class="number">11.4</span></span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'修改后的序列：\n'</span>,ss)</span><br></pre></td></tr></table></figure><pre><code>原序列： 2018-06-28    8.922018-06-29    9.092018-07-02    8.612018-07-03    8.672018-07-04    8.612018-07-05    8.602018-07-06    8.662018-07-09    9.032018-07-10    8.982018-07-11    8.78dtype: float64修改后的序列：2018-06-28    11.402018-06-29     9.092018-07-02     8.612018-07-03     8.672018-07-04     8.612018-07-05     8.602018-07-06     8.662018-07-09     9.032018-07-10     8.982018-07-11     8.78dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ss1 = pd.Series(np.random.randn(<span class="number">10</span>))</span><br><span class="line">print(<span class="string">'原序列：\n'</span>,ss)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'新序列：\n'</span>,ss1)</span><br><span class="line">print()</span><br><span class="line"><span class="comment"># 大多数numpy的函数可以直接应用于 序列 Series</span></span><br><span class="line">print(<span class="string">'序列相加：\n'</span>,pd.Series(ss.values+ss1.values,index=ss.index))</span><br></pre></td></tr></table></figure><pre><code>原序列： 2018-06-28    11.402018-06-29     9.092018-07-02     8.612018-07-03     8.672018-07-04     8.612018-07-05     8.602018-07-06     8.662018-07-09     9.032018-07-10     8.982018-07-11     8.78dtype: float64新序列： 0   -0.9557001    0.3915612    0.0024353   -0.1316214   -0.7913215    0.8412646   -0.0580347   -0.4866778    0.7088759    1.841834dtype: float64序列相加： 2018-06-28    10.4443002018-06-29     9.4815612018-07-02     8.6124352018-07-03     8.5383792018-07-04     7.8186792018-07-05     9.4412642018-07-06     8.6019662018-07-09     8.5433232018-07-10     9.6888752018-07-11    10.621834dtype: float64</code></pre><h2 id="二、DataFrame"><a href="#二、DataFrame" class="headerlink" title="二、DataFrame"></a>二、DataFrame</h2><p>DataFrame是一个二维数组结构，可以存入任一种Python数据类型(integers, strings, floating point numbers, Python objects, 等等)。<br>DataFrame由<strong>三部分</strong>构成，一个是行索引index，一个是列名，另一个则是取值。</p><h3 id="2-1-DataFrame的生成"><a href="#2-1-DataFrame的生成" class="headerlink" title="2.1 DataFrame的生成"></a>2.1 DataFrame的生成</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'由字典来产生数据框'</span>)</span><br><span class="line">data = &#123;<span class="string">'state'</span>: [<span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Nevada'</span>, <span class="string">'Nevada'</span>],</span><br><span class="line">        <span class="string">'year'</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>],</span><br><span class="line">        <span class="string">'pop'</span>: [<span class="number">1.5</span>, <span class="number">1.7</span>, <span class="number">3.6</span>, <span class="number">2.4</span>, <span class="number">2.9</span>]&#125;</span><br><span class="line">frame = pd.DataFrame(data)</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><pre><code>由字典来产生数据框</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>1.7</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>Nevada</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'由列表来产生数据框'</span>)</span><br><span class="line">data = [[<span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Nevada'</span>, <span class="string">'Nevada'</span>],</span><br><span class="line">        [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>],</span><br><span class="line">        [<span class="number">1.5</span>, <span class="number">1.7</span>, <span class="number">3.6</span>, <span class="number">2.4</span>, <span class="number">2.9</span>]]</span><br><span class="line">frame = pd.DataFrame(data,index=[<span class="string">'state'</span>,<span class="string">'year'</span>,<span class="string">'pop'</span>]).T</span><br><span class="line">frame</span><br></pre></td></tr></table></figure><pre><code>由列表来产生数据框</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>1.7</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>Nevada</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><h3 id="2-2-DataFrame的基本性质"><a href="#2-2-DataFrame的基本性质" class="headerlink" title="2.2 DataFrame的基本性质"></a>2.2 DataFrame的基本性质</h3><p>我们取一段金融时间序列给大家做更具体的分析：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">list2 = w.wsd(<span class="string">"000300.SH"</span>, <span class="string">"open,high,low,close"</span>, <span class="string">"2018-06-28"</span>, <span class="string">"2018-07-10"</span>, <span class="string">""</span>)</span><br><span class="line">list2</span><br></pre></td></tr></table></figure><pre><code>.ErrorCode=0.Codes=[000300.SH].Fields=[OPEN,HIGH,LOW,CLOSE].Times=[20180628,20180629,20180702,20180703,20180704,20180705,20180706,20180709,20180710].Data=[[3434.9441,3431.9619,3504.4571,3410.4767,3398.7788,3365.5547,3347.0624,3378.9056,3464.9064],[3477.0565,3512.3834,3506.8996,3422.0398,3418.3311,3398.4852,3396.2458,3459.3153,3474.1396],[3416.9476,3425.2159,3383.5006,3319.2889,3359.0861,3330.7113,3295.7296,3378.9056,3437.2706],[3423.5255,3510.9845,3407.9638,3409.2801,3363.7473,3342.4379,3365.1227,3459.1837,3467.5155]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(list2.Data,columns=list2.Times,index=list2.Fields)</span><br><span class="line">df = df.T</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>    </tr>  </thead>  <tbody>    <tr>      <td>2018-06-28</td>      <td>3434.9441</td>      <td>3477.0565</td>      <td>3416.9476</td>      <td>3423.5255</td>    </tr>    <tr>      <td>2018-06-29</td>      <td>3431.9619</td>      <td>3512.3834</td>      <td>3425.2159</td>      <td>3510.9845</td>    </tr>    <tr>      <td>2018-07-02</td>      <td>3504.4571</td>      <td>3506.8996</td>      <td>3383.5006</td>      <td>3407.9638</td>    </tr>    <tr>      <td>2018-07-03</td>      <td>3410.4767</td>      <td>3422.0398</td>      <td>3319.2889</td>      <td>3409.2801</td>    </tr>    <tr>      <td>2018-07-04</td>      <td>3398.7788</td>      <td>3418.3311</td>      <td>3359.0861</td>      <td>3363.7473</td>    </tr>    <tr>      <td>2018-07-05</td>      <td>3365.5547</td>      <td>3398.4852</td>      <td>3330.7113</td>      <td>3342.4379</td>    </tr>    <tr>      <td>2018-07-06</td>      <td>3347.0624</td>      <td>3396.2458</td>      <td>3295.7296</td>      <td>3365.1227</td>    </tr>    <tr>      <td>2018-07-09</td>      <td>3378.9056</td>      <td>3459.3153</td>      <td>3378.9056</td>      <td>3459.1837</td>    </tr>    <tr>      <td>2018-07-10</td>      <td>3464.9064</td>      <td>3474.1396</td>      <td>3437.2706</td>      <td>3467.5155</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'首先查看数据框的形状'</span>,df.shape)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看数据框的头部：'</span>)</span><br><span class="line">print(df.head()) </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看数据框的尾部：'</span>)</span><br><span class="line">print(df.tail())</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看数据框的索引index'</span>)</span><br><span class="line">print(df.index)</span><br></pre></td></tr></table></figure><pre><code>首先查看数据框的形状 (9, 4)查看数据框的头部：                 OPEN       HIGH        LOW      CLOSE2018-06-28  3434.9441  3477.0565  3416.9476  3423.52552018-06-29  3431.9619  3512.3834  3425.2159  3510.98452018-07-02  3504.4571  3506.8996  3383.5006  3407.96382018-07-03  3410.4767  3422.0398  3319.2889  3409.28012018-07-04  3398.7788  3418.3311  3359.0861  3363.7473查看数据框的尾部：                 OPEN       HIGH        LOW      CLOSE2018-07-04  3398.7788  3418.3311  3359.0861  3363.74732018-07-05  3365.5547  3398.4852  3330.7113  3342.43792018-07-06  3347.0624  3396.2458  3295.7296  3365.12272018-07-09  3378.9056  3459.3153  3378.9056  3459.18372018-07-10  3464.9064  3474.1396  3437.2706  3467.5155查看数据框的索引indexIndex([2018-06-28, 2018-06-29, 2018-07-02, 2018-07-03, 2018-07-04, 2018-07-05,       2018-07-06, 2018-07-09, 2018-07-10],      dtype=&#39;object&#39;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'查看数据框的列名'</span>)</span><br><span class="line">print(df.columns)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看数据框的值，其格式为数组array'</span>)</span><br><span class="line">print(df.values)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看数据框的基础描述性统计'</span>)</span><br><span class="line">print(df.describe())</span><br></pre></td></tr></table></figure><pre><code>查看数据框的列名Index([&#39;OPEN&#39;, &#39;HIGH&#39;, &#39;LOW&#39;, &#39;CLOSE&#39;], dtype=&#39;object&#39;)查看数据框的值，其格式为数组array[[3434.9441 3477.0565 3416.9476 3423.5255] [3431.9619 3512.3834 3425.2159 3510.9845] [3504.4571 3506.8996 3383.5006 3407.9638] [3410.4767 3422.0398 3319.2889 3409.2801] [3398.7788 3418.3311 3359.0861 3363.7473] [3365.5547 3398.4852 3330.7113 3342.4379] [3347.0624 3396.2458 3295.7296 3365.1227] [3378.9056 3459.3153 3378.9056 3459.1837] [3464.9064 3474.1396 3437.2706 3467.5155]]查看数据框的基础描述性统计              OPEN         HIGH          LOW        CLOSEcount     9.000000     9.000000     9.000000     9.000000mean   3415.227522  3451.655144  3371.850689  3416.640111std      49.780741    44.488942    49.698315    55.264867min    3347.062400  3396.245800  3295.729600  3342.43790025%    3378.905600  3418.331100  3330.711300  3365.12270050%    3410.476700  3459.315300  3378.905600  3409.28010075%    3434.944100  3477.056500  3416.947600  3459.183700max    3504.457100  3512.383400  3437.270600  3510.984500</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在原有的数据框中新加入一列</span></span><br><span class="line">df[<span class="string">'名称'</span>] = [<span class="string">'HS300'</span>] * len(df)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>      <th>名称</th>    </tr>  </thead>  <tbody>    <tr>      <td>2018-06-28</td>      <td>3434.9441</td>      <td>3477.0565</td>      <td>3416.9476</td>      <td>3423.5255</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-06-29</td>      <td>3431.9619</td>      <td>3512.3834</td>      <td>3425.2159</td>      <td>3510.9845</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-02</td>      <td>3504.4571</td>      <td>3506.8996</td>      <td>3383.5006</td>      <td>3407.9638</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-03</td>      <td>3410.4767</td>      <td>3422.0398</td>      <td>3319.2889</td>      <td>3409.2801</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-04</td>      <td>3398.7788</td>      <td>3418.3311</td>      <td>3359.0861</td>      <td>3363.7473</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-05</td>      <td>3365.5547</td>      <td>3398.4852</td>      <td>3330.7113</td>      <td>3342.4379</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-06</td>      <td>3347.0624</td>      <td>3396.2458</td>      <td>3295.7296</td>      <td>3365.1227</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-09</td>      <td>3378.9056</td>      <td>3459.3153</td>      <td>3378.9056</td>      <td>3459.1837</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-10</td>      <td>3464.9064</td>      <td>3474.1396</td>      <td>3437.2706</td>      <td>3467.5155</td>      <td>HS300</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据框的转置</span></span><br><span class="line">df.T</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>2018-06-28</th>      <th>2018-06-29</th>      <th>2018-07-02</th>      <th>2018-07-03</th>      <th>2018-07-04</th>      <th>2018-07-05</th>      <th>2018-07-06</th>      <th>2018-07-09</th>      <th>2018-07-10</th>    </tr>  </thead>  <tbody>    <tr>      <td>OPEN</td>      <td>3434.94</td>      <td>3431.96</td>      <td>3504.46</td>      <td>3410.48</td>      <td>3398.78</td>      <td>3365.55</td>      <td>3347.06</td>      <td>3378.91</td>      <td>3464.91</td>    </tr>    <tr>      <td>HIGH</td>      <td>3477.06</td>      <td>3512.38</td>      <td>3506.9</td>      <td>3422.04</td>      <td>3418.33</td>      <td>3398.49</td>      <td>3396.25</td>      <td>3459.32</td>      <td>3474.14</td>    </tr>    <tr>      <td>LOW</td>      <td>3416.95</td>      <td>3425.22</td>      <td>3383.5</td>      <td>3319.29</td>      <td>3359.09</td>      <td>3330.71</td>      <td>3295.73</td>      <td>3378.91</td>      <td>3437.27</td>    </tr>    <tr>      <td>CLOSE</td>      <td>3423.53</td>      <td>3510.98</td>      <td>3407.96</td>      <td>3409.28</td>      <td>3363.75</td>      <td>3342.44</td>      <td>3365.12</td>      <td>3459.18</td>      <td>3467.52</td>    </tr>    <tr>      <td>名称</td>      <td>HS300</td>      <td>HS300</td>      <td>HS300</td>      <td>HS300</td>      <td>HS300</td>      <td>HS300</td>      <td>HS300</td>      <td>HS300</td>      <td>HS300</td>    </tr>  </tbody></table></div><h3 id="2-3-DataFrame截取"><a href="#2-3-DataFrame截取" class="headerlink" title="2.3 DataFrame截取"></a>2.3 DataFrame截取</h3><h4 id="2-3-1-行截取"><a href="#2-3-1-行截取" class="headerlink" title="2.3.1 行截取"></a>2.3.1 行截取</h4><p>氦核：不推荐使用ix进行截取，因为ix既可以对名称截取，又可以索引截取。如果index是整数，会很迷惑。一般使用loc和iloc函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'查看df索引为1的行——方法一'</span>)</span><br><span class="line">print(df.ix[<span class="number">1</span>])   <span class="comment"># print(df.iloc[1]) 推荐使用</span></span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看df前3行'</span>)</span><br><span class="line">print(df[:<span class="number">3</span>])</span><br></pre></td></tr></table></figure><pre><code>查看df索引为1的行——方法一OPEN     3431.96HIGH     3512.38LOW      3425.22CLOSE    3510.98名称         HS300Name: 2018-06-29, dtype: object查看df前3行                 OPEN       HIGH        LOW      CLOSE     名称2018-06-28  3434.9441  3477.0565  3416.9476  3423.5255  HS3002018-06-29  3431.9619  3512.3834  3425.2159  3510.9845  HS3002018-07-02  3504.4571  3506.8996  3383.5006  3407.9638  HS300D:\anaconda\lib\site-packages\ipykernel_launcher.py:2: FutureWarning: .ix is deprecated. Please use.loc for label based indexing or.iloc for positional indexingSee the documentation here:http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated</code></pre><h4 id="2-3-2-列截取"><a href="#2-3-2-列截取" class="headerlink" title="2.3.2 列截取"></a>2.3.2 列截取</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'df的一列选取'</span>)</span><br><span class="line">print(df[<span class="string">'OPEN'</span>])</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'df的两列同时选取'</span>)</span><br><span class="line">print(df[[<span class="string">'OPEN'</span>,<span class="string">'LOW'</span>]])</span><br></pre></td></tr></table></figure><pre><code>df的一列选取2018-06-28    3434.94412018-06-29    3431.96192018-07-02    3504.45712018-07-03    3410.47672018-07-04    3398.77882018-07-05    3365.55472018-07-06    3347.06242018-07-09    3378.90562018-07-10    3464.9064Name: OPEN, dtype: float64df的两列同时选取                 OPEN        LOW2018-06-28  3434.9441  3416.94762018-06-29  3431.9619  3425.21592018-07-02  3504.4571  3383.50062018-07-03  3410.4767  3319.28892018-07-04  3398.7788  3359.08612018-07-05  3365.5547  3330.71132018-07-06  3347.0624  3295.72962018-07-09  3378.9056  3378.90562018-07-10  3464.9064  3437.2706</code></pre><h4 id="2-3-3-DataFrame行列同时截取"><a href="#2-3-3-DataFrame行列同时截取" class="headerlink" title="2.3.3 DataFrame行列同时截取"></a>2.3.3 DataFrame行列同时截取</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'截取df的前4行的close和low列'</span>)</span><br><span class="line">df.ix[:<span class="number">4</span>,[<span class="string">'CLOSE'</span>,<span class="string">'LOW'</span>]]</span><br></pre></td></tr></table></figure><pre><code>截取df的前4行的close和low列D:\anaconda\lib\site-packages\ipykernel_launcher.py:2: FutureWarning: .ix is deprecated. Please use.loc for label based indexing or.iloc for positional indexingSee the documentation here:http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated</code></pre><p>​    </p><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>CLOSE</th>      <th>LOW</th>    </tr>  </thead>  <tbody>    <tr>      <td>2018-06-28</td>      <td>3423.5255</td>      <td>3416.9476</td>    </tr>    <tr>      <td>2018-06-29</td>      <td>3510.9845</td>      <td>3425.2159</td>    </tr>    <tr>      <td>2018-07-02</td>      <td>3407.9638</td>      <td>3383.5006</td>    </tr>    <tr>      <td>2018-07-03</td>      <td>3409.2801</td>      <td>3319.2889</td>    </tr>  </tbody></table></div><h4 id="2-3-4-DataFrame条件截取"><a href="#2-3-4-DataFrame条件截取" class="headerlink" title="2.3.4 DataFrame条件截取"></a>2.3.4 DataFrame条件截取</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'截取df CLOSE大于等于3500的记录'</span>)</span><br><span class="line">print(df[df[<span class="string">'CLOSE'</span>]&gt;=<span class="number">3500</span>])  </span><br><span class="line">print(<span class="string">''</span>)</span><br><span class="line">print(<span class="string">'截取df CLOSE大于3300且LOW小于3400的记录'</span>)</span><br><span class="line">print(df[(df[<span class="string">'CLOSE'</span>]&gt;<span class="number">3300</span>)&amp;(df[<span class="string">'LOW'</span>]&lt;<span class="number">3400</span>)])   </span><br><span class="line">print(<span class="string">''</span>)</span><br></pre></td></tr></table></figure><pre><code>截取df CLOSE大于等于3500的记录                 OPEN       HIGH        LOW      CLOSE     名称2018-06-29  3431.9619  3512.3834  3425.2159  3510.9845  HS300截取df CLOSE大于3300且LOW小于3400的记录                 OPEN       HIGH        LOW      CLOSE     名称2018-07-02  3504.4571  3506.8996  3383.5006  3407.9638  HS3002018-07-03  3410.4767  3422.0398  3319.2889  3409.2801  HS3002018-07-04  3398.7788  3418.3311  3359.0861  3363.7473  HS3002018-07-05  3365.5547  3398.4852  3330.7113  3342.4379  HS3002018-07-06  3347.0624  3396.2458  3295.7296  3365.1227  HS3002018-07-09  3378.9056  3459.3153  3378.9056  3459.1837  HS300</code></pre><p>​    </p><h3 id="2-4-DataFrame缺失值处理"><a href="#2-4-DataFrame缺失值处理" class="headerlink" title="2.4 DataFrame缺失值处理"></a>2.4 DataFrame缺失值处理</h3><p>例如下面这个数据框data，其中就存在缺失值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = &#123;<span class="string">'state'</span>: [<span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Ohio'</span>, <span class="string">'Nevada'</span>, <span class="string">'Nevada'</span>],</span><br><span class="line">        <span class="string">'year'</span>: [<span class="number">2000</span>, <span class="number">2001</span>, <span class="number">2002</span>, <span class="number">2001</span>, <span class="number">2002</span>],</span><br><span class="line">        <span class="string">'pop'</span>: [<span class="number">1.5</span>, <span class="number">1.7</span>, <span class="number">3.6</span>, <span class="number">2.4</span>, <span class="number">2.9</span>]&#125;</span><br><span class="line">data = pd.DataFrame(data)</span><br><span class="line">data.loc[<span class="number">1</span>,<span class="string">'pop'</span>] = np.NaN</span><br><span class="line">data.loc[<span class="number">3</span>,<span class="string">'state'</span>] = <span class="keyword">None</span></span><br><span class="line">data</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>NaN</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>None</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#删除含有缺失的行</span></span><br><span class="line">data.dropna()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#表示该行都为缺失的行才删除 注意是这一行中的每一个元素都为缺失才删除这一行</span></span><br><span class="line">data.dropna(how=<span class="string">"all"</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>NaN</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>None</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#表示该列若都为缺失的列则删除,注意是这一列的每个元素都为缺失才会删除这一列</span></span><br><span class="line">data.dropna(how=<span class="string">"all"</span>, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>NaN</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>None</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#表示保留至少存在3个非NaN的行，即如果某一行的非缺失值个数小于3个，则会被删除</span></span><br><span class="line">data.dropna(thresh=<span class="number">3</span>, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#表示保留至少存在3个非NaN的列，即如果某一列的非缺失值个数小于3个，则会被删除</span></span><br><span class="line">data.dropna(thresh=<span class="number">3</span>, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>NaN</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>None</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>NaN</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>None</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'用0填充数据框中的缺失值,0是可选参数之一'</span>)</span><br><span class="line">data.fillna(value=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><pre><code>用0填充数据框中的缺失值,0是可选参数之一</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>0.0</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>0</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#填充缺失值 用缺失值所在列的前一个非NaN值来进行填充  </span></span><br><span class="line">data.fillna(method=<span class="string">'ffill'</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>1.5</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>Ohio</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#用缺失值所在列的后一个非NaN来填充</span></span><br><span class="line">data.fillna(method=<span class="string">"bfill"</span>)</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>state</th>      <th>year</th>      <th>pop</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>Ohio</td>      <td>2000</td>      <td>1.5</td>    </tr>    <tr>      <td>1</td>      <td>Ohio</td>      <td>2001</td>      <td>3.6</td>    </tr>    <tr>      <td>2</td>      <td>Ohio</td>      <td>2002</td>      <td>3.6</td>    </tr>    <tr>      <td>3</td>      <td>Nevada</td>      <td>2001</td>      <td>2.4</td>    </tr>    <tr>      <td>4</td>      <td>Nevada</td>      <td>2002</td>      <td>2.9</td>    </tr>  </tbody></table></div><p>氦核：这些填补都是什么鬼方法，无语。</p><h3 id="2-5-DataFrame排序"><a href="#2-5-DataFrame排序" class="headerlink" title="2.5 DataFrame排序"></a>2.5 DataFrame排序</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>      <th>名称</th>    </tr>  </thead>  <tbody>    <tr>      <td>2018-06-28</td>      <td>3434.9441</td>      <td>3477.0565</td>      <td>3416.9476</td>      <td>3423.5255</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-06-29</td>      <td>3431.9619</td>      <td>3512.3834</td>      <td>3425.2159</td>      <td>3510.9845</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-02</td>      <td>3504.4571</td>      <td>3506.8996</td>      <td>3383.5006</td>      <td>3407.9638</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-03</td>      <td>3410.4767</td>      <td>3422.0398</td>      <td>3319.2889</td>      <td>3409.2801</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-04</td>      <td>3398.7788</td>      <td>3418.3311</td>      <td>3359.0861</td>      <td>3363.7473</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-05</td>      <td>3365.5547</td>      <td>3398.4852</td>      <td>3330.7113</td>      <td>3342.4379</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-06</td>      <td>3347.0624</td>      <td>3396.2458</td>      <td>3295.7296</td>      <td>3365.1227</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-09</td>      <td>3378.9056</td>      <td>3459.3153</td>      <td>3378.9056</td>      <td>3459.1837</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-10</td>      <td>3464.9064</td>      <td>3474.1396</td>      <td>3437.2706</td>      <td>3467.5155</td>      <td>HS300</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'df按列OPEN降序排序'</span>)</span><br><span class="line">df.sort_values(<span class="string">'OPEN'</span>)</span><br></pre></td></tr></table></figure><pre><code>df按列OPEN降序排序</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>      <th>名称</th>    </tr>  </thead>  <tbody>    <tr>      <td>2018-07-06</td>      <td>3347.0624</td>      <td>3396.2458</td>      <td>3295.7296</td>      <td>3365.1227</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-05</td>      <td>3365.5547</td>      <td>3398.4852</td>      <td>3330.7113</td>      <td>3342.4379</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-09</td>      <td>3378.9056</td>      <td>3459.3153</td>      <td>3378.9056</td>      <td>3459.1837</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-04</td>      <td>3398.7788</td>      <td>3418.3311</td>      <td>3359.0861</td>      <td>3363.7473</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-03</td>      <td>3410.4767</td>      <td>3422.0398</td>      <td>3319.2889</td>      <td>3409.2801</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-06-29</td>      <td>3431.9619</td>      <td>3512.3834</td>      <td>3425.2159</td>      <td>3510.9845</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-06-28</td>      <td>3434.9441</td>      <td>3477.0565</td>      <td>3416.9476</td>      <td>3423.5255</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-10</td>      <td>3464.9064</td>      <td>3474.1396</td>      <td>3437.2706</td>      <td>3467.5155</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-02</td>      <td>3504.4571</td>      <td>3506.8996</td>      <td>3383.5006</td>      <td>3407.9638</td>      <td>HS300</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'df按列LOW升序排序'</span>)</span><br><span class="line">df.sort_values(<span class="string">'LOW'</span>,ascending=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><pre><code>df按列LOW升序排序</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>      <th>名称</th>    </tr>  </thead>  <tbody>    <tr>      <td>2018-07-06</td>      <td>3347.0624</td>      <td>3396.2458</td>      <td>3295.7296</td>      <td>3365.1227</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-03</td>      <td>3410.4767</td>      <td>3422.0398</td>      <td>3319.2889</td>      <td>3409.2801</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-05</td>      <td>3365.5547</td>      <td>3398.4852</td>      <td>3330.7113</td>      <td>3342.4379</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-04</td>      <td>3398.7788</td>      <td>3418.3311</td>      <td>3359.0861</td>      <td>3363.7473</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-09</td>      <td>3378.9056</td>      <td>3459.3153</td>      <td>3378.9056</td>      <td>3459.1837</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-02</td>      <td>3504.4571</td>      <td>3506.8996</td>      <td>3383.5006</td>      <td>3407.9638</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-06-28</td>      <td>3434.9441</td>      <td>3477.0565</td>      <td>3416.9476</td>      <td>3423.5255</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-06-29</td>      <td>3431.9619</td>      <td>3512.3834</td>      <td>3425.2159</td>      <td>3510.9845</td>      <td>HS300</td>    </tr>    <tr>      <td>2018-07-10</td>      <td>3464.9064</td>      <td>3474.1396</td>      <td>3437.2706</td>      <td>3467.5155</td>      <td>HS300</td>    </tr>  </tbody></table></div><h3 id="2-6-DataFrame的基本函数"><a href="#2-6-DataFrame的基本函数" class="headerlink" title="2.6 DataFrame的基本函数"></a>2.6 DataFrame的基本函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'按列求均值'</span>)</span><br><span class="line">df.mean()</span><br></pre></td></tr></table></figure><pre><code>按列求均值OPEN     3415.227522HIGH     3451.655144LOW      3371.850689CLOSE    3416.640111dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'按行求均值'</span>)</span><br><span class="line">df.mean(axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><pre><code>按行求均值2018-06-28    3438.1184252018-06-29    3470.1364252018-07-02    3450.7052752018-07-03    3390.2713752018-07-04    3384.9858252018-07-05    3359.2972752018-07-06    3351.0401252018-07-09    3419.0775502018-07-10    3460.958025dtype: float64</code></pre><h4 id="函数汇总"><a href="#函数汇总" class="headerlink" title="函数汇总"></a>函数汇总</h4><p>下面的函数都是通过数据框.函数名(参数设置)来进行调用，一般的参数是axis=0/1，选择为0则是按行来实现函数，1则是按列来实现函数</p><div class="table-container"><table><thead><tr><th>序号</th><th>函数</th><th>函数含义</th></tr></thead><tbody><tr><td>1</td><td>count</td><td>计数非na值</td></tr><tr><td>2</td><td>describe</td><td>针对Series或个DataFrame列基本描述统计</td></tr><tr><td>3</td><td>min、max</td><td>计算最小值和最大值</td></tr><tr><td>4</td><td>argmin、argmax</td><td>获取到最大值和最小值的索引位置（整数）</td></tr><tr><td>5</td><td>idxmin、idxmax</td><td>计算能够获取到最大值和最小值得索引值</td></tr><tr><td>6</td><td>quantile</td><td>计算样本的分位数（0到1）</td></tr><tr><td>7</td><td>sum</td><td>求和</td></tr><tr><td>8</td><td>mean</td><td>求平均数</td></tr><tr><td>9</td><td>median</td><td>求中位数（50%分位数）</td></tr><tr><td>10</td><td>mad</td><td>计算平均绝对离差</td></tr><tr><td>11</td><td>var</td><td>样本方差</td></tr><tr><td>12</td><td>std</td><td>样本标准差</td></tr><tr><td>13</td><td>skew</td><td>样本偏度（三阶矩）</td></tr><tr><td>14</td><td>kurt</td><td>样本峰度（四阶矩）</td></tr><tr><td>15</td><td>cumsum</td><td>样本累计和</td></tr><tr><td>16</td><td>cummin，cummax</td><td>样本累计最大值和累计最小值</td></tr><tr><td>17</td><td>cumprod</td><td>样本累计积</td></tr><tr><td>18</td><td>diff</td><td>计算一阶差分</td></tr><tr><td>19</td><td>pct_change</td><td>计算百分数变化</td></tr><tr><td>20</td><td>corr</td><td>计数相关性</td></tr></tbody></table></div><h3 id="2-7-DataFrame拼接"><a href="#2-7-DataFrame拼接" class="headerlink" title="2.7 DataFrame拼接"></a>2.7 DataFrame拼接</h3><p>下面介绍了三个函数来实现 DataFrame的拼接功能——concat函数，merge函数和join函数</p><h4 id="2-7-1-DataFrame拼接—pd-concat"><a href="#2-7-1-DataFrame拼接—pd-concat" class="headerlink" title="2.7.1 DataFrame拼接—pd.concat"></a>2.7.1 DataFrame拼接—pd.concat</h4><p>通过Wind API可以获取到各种金融数据，可以使用代码生成器生成获取数据的函数代码。获取到数据后，可参考一下代码将数据转换为DataFrame格式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> WindPy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame </span><br><span class="line">w.start()</span><br><span class="line"></span><br><span class="line">wsd_data = w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"lastradeday_s,sec_name,open,high,low,close"</span>, <span class="string">"2017-11-01"</span>, <span class="string">"2017-11-05"</span>, <span class="string">""</span>)</span><br><span class="line">data_df = DataFrame(wsd_data.Data,columns=wsd_data.Times,index=wsd_data.Fields)</span><br><span class="line">data_df = data_df.T <span class="comment">#转置数据表</span></span><br><span class="line">data_df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME</th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>    </tr>  </thead>  <tbody>    <tr>      <td>2017-11-01</td>      <td>2017-11-01</td>      <td>平安银行</td>      <td>11.56</td>      <td>11.59</td>      <td>11.32</td>      <td>11.4</td>    </tr>    <tr>      <td>2017-11-02</td>      <td>2017-11-02</td>      <td>平安银行</td>      <td>11.36</td>      <td>11.58</td>      <td>11.26</td>      <td>11.54</td>    </tr>    <tr>      <td>2017-11-03</td>      <td>2017-11-03</td>      <td>平安银行</td>      <td>11.49</td>      <td>11.68</td>      <td>11.35</td>      <td>11.39</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wsd_data1 = w.wsd(<span class="string">"000002.SZ"</span>, <span class="string">"lastradeday_s,sec_name,open,high,low,close"</span>, <span class="string">"2017-11-01"</span>, <span class="string">"2017-11-05"</span>, <span class="string">""</span>)</span><br><span class="line">data_df1 = DataFrame(wsd_data1.Data,columns=wsd_data.Times,index=wsd_data.Fields)</span><br><span class="line">data_df1 = data_df1.T <span class="comment">#转置数据表</span></span><br><span class="line">data_df1</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME</th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>    </tr>  </thead>  <tbody>    <tr>      <td>2017-11-01</td>      <td>2017-11-01</td>      <td>万科A</td>      <td>28.96</td>      <td>30.54</td>      <td>28.73</td>      <td>29.15</td>    </tr>    <tr>      <td>2017-11-02</td>      <td>2017-11-02</td>      <td>万科A</td>      <td>29.3</td>      <td>29.48</td>      <td>28.68</td>      <td>29.45</td>    </tr>    <tr>      <td>2017-11-03</td>      <td>2017-11-03</td>      <td>万科A</td>      <td>29.23</td>      <td>29.52</td>      <td>28.05</td>      <td>28.19</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'按行拼接'</span>)</span><br><span class="line">pd.concat([data_df,data_df1],axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><pre><code>按行拼接</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME</th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>    </tr>  </thead>  <tbody>    <tr>      <td>2017-11-01</td>      <td>2017-11-01</td>      <td>平安银行</td>      <td>11.56</td>      <td>11.59</td>      <td>11.32</td>      <td>11.4</td>    </tr>    <tr>      <td>2017-11-02</td>      <td>2017-11-02</td>      <td>平安银行</td>      <td>11.36</td>      <td>11.58</td>      <td>11.26</td>      <td>11.54</td>    </tr>    <tr>      <td>2017-11-03</td>      <td>2017-11-03</td>      <td>平安银行</td>      <td>11.49</td>      <td>11.68</td>      <td>11.35</td>      <td>11.39</td>    </tr>    <tr>      <td>2017-11-01</td>      <td>2017-11-01</td>      <td>万科A</td>      <td>28.96</td>      <td>30.54</td>      <td>28.73</td>      <td>29.15</td>    </tr>    <tr>      <td>2017-11-02</td>      <td>2017-11-02</td>      <td>万科A</td>      <td>29.3</td>      <td>29.48</td>      <td>28.68</td>      <td>29.45</td>    </tr>    <tr>      <td>2017-11-03</td>      <td>2017-11-03</td>      <td>万科A</td>      <td>29.23</td>      <td>29.52</td>      <td>28.05</td>      <td>28.19</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'按列拼接'</span>)</span><br><span class="line">pd.concat([data_df,data_df1],axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><pre><code>按列拼接</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME</th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME</th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>CLOSE</th>    </tr>  </thead>  <tbody>    <tr>      <td>2017-11-01</td>      <td>2017-11-01</td>      <td>平安银行</td>      <td>11.56</td>      <td>11.59</td>      <td>11.32</td>      <td>11.4</td>      <td>2017-11-01</td>      <td>万科A</td>      <td>28.96</td>      <td>30.54</td>      <td>28.73</td>      <td>29.15</td>    </tr>    <tr>      <td>2017-11-02</td>      <td>2017-11-02</td>      <td>平安银行</td>      <td>11.36</td>      <td>11.58</td>      <td>11.26</td>      <td>11.54</td>      <td>2017-11-02</td>      <td>万科A</td>      <td>29.3</td>      <td>29.48</td>      <td>28.68</td>      <td>29.45</td>    </tr>    <tr>      <td>2017-11-03</td>      <td>2017-11-03</td>      <td>平安银行</td>      <td>11.49</td>      <td>11.68</td>      <td>11.35</td>      <td>11.39</td>      <td>2017-11-03</td>      <td>万科A</td>      <td>29.23</td>      <td>29.52</td>      <td>28.05</td>      <td>28.19</td>    </tr>  </tbody></table></div><h3 id="2-7-3-DataFrame拼接—pd-merge"><a href="#2-7-3-DataFrame拼接—pd-merge" class="headerlink" title="2.7.3 DataFrame拼接—pd.merge"></a>2.7.3 DataFrame拼接—pd.merge</h3><p>pd.merge一般针对的是按列合并。</p><p>pd.merge(left, right, how=’inner’, on=None, left_on=None, right_on=None,<br>         left_index=False, right_index=False, sort=True,<br>         suffixes=(‘_x’, ‘_y’), copy=True, indicator=False)</p><p>left: 一个dataframe对象</p><p>right: 另一个dataframe对象</p><p>how: 可以是’left’, ‘right’, ‘outer’, ‘inner’. 默认为inner。</p><p>on: 列名，两个dataframe都有的列。如果不传参数，而且left_index和right_index也等于False，则默认把两者交叉/共有的列作为链接键（join keys）。可以是一个列名，也可以是包含多个列名的list。</p><p>left_on: 左边dataframe的列会用做keys。可以是列名，或者与dataframe长度相同的矩阵array。</p><p>right_on: 右边同上。</p><p>left_index: 如果为Ture，用左侧dataframe的index作为连接键。如果是多维索引，level数要跟右边相同才行。</p><p>right_index: 右边同上。</p><p>sort: 对合并后的数据框排序，以连接键。</p><p>suffixes: 一个tuple，包字符串后缀，用来加在重叠的列名后面。默认是(‘_x’,’_y’)。</p><p>copy: 默认Ture，复制数据。</p><p>indicator: 布尔型（True/FALSE），或是字符串。如果为True，合并之后会增加一列叫做_merge。是分类数据，用left_only, right_only, both来标记来自左边，右边和两边的数据。</p><p>参考：<a href="http://www.jianshu.com/p/dc8ba1c0eada" target="_blank" rel="noopener">http://www.jianshu.com/p/dc8ba1c0eada</a></p><p>希望将上面两个 DataFrame left_data和right_data拼接起来，但要求是按照时间来进行拼接</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'按LASTRADEDAY_S拼接，只保留共同的部分'</span>)</span><br><span class="line">pd.merge(data_df,data_df1,on=<span class="string">'LASTRADEDAY_S'</span>)</span><br></pre></td></tr></table></figure><pre><code>按LASTRADEDAY_S拼接，只保留共同的部分</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME_x</th>      <th>OPEN_x</th>      <th>HIGH_x</th>      <th>LOW_x</th>      <th>CLOSE_x</th>      <th>SEC_NAME_y</th>      <th>OPEN_y</th>      <th>HIGH_y</th>      <th>LOW_y</th>      <th>CLOSE_y</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>2017-11-01</td>      <td>平安银行</td>      <td>11.56</td>      <td>11.59</td>      <td>11.32</td>      <td>11.4</td>      <td>万科A</td>      <td>28.96</td>      <td>30.54</td>      <td>28.73</td>      <td>29.15</td>    </tr>    <tr>      <td>1</td>      <td>2017-11-02</td>      <td>平安银行</td>      <td>11.36</td>      <td>11.58</td>      <td>11.26</td>      <td>11.54</td>      <td>万科A</td>      <td>29.3</td>      <td>29.48</td>      <td>28.68</td>      <td>29.45</td>    </tr>    <tr>      <td>2</td>      <td>2017-11-03</td>      <td>平安银行</td>      <td>11.49</td>      <td>11.68</td>      <td>11.35</td>      <td>11.39</td>      <td>万科A</td>      <td>29.23</td>      <td>29.52</td>      <td>28.05</td>      <td>28.19</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'按LASTRADEDAY_S拼接，但所有的数据都保留下来'</span>)</span><br><span class="line">pd.merge(data_df,data_df1,on=<span class="string">'LASTRADEDAY_S'</span>,how=<span class="string">'outer'</span>)</span><br></pre></td></tr></table></figure><pre><code>按LASTRADEDAY_S拼接，但所有的数据都保留下来</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME_x</th>      <th>OPEN_x</th>      <th>HIGH_x</th>      <th>LOW_x</th>      <th>CLOSE_x</th>      <th>SEC_NAME_y</th>      <th>OPEN_y</th>      <th>HIGH_y</th>      <th>LOW_y</th>      <th>CLOSE_y</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>2017-11-01</td>      <td>平安银行</td>      <td>11.56</td>      <td>11.59</td>      <td>11.32</td>      <td>11.4</td>      <td>万科A</td>      <td>28.96</td>      <td>30.54</td>      <td>28.73</td>      <td>29.15</td>    </tr>    <tr>      <td>1</td>      <td>2017-11-02</td>      <td>平安银行</td>      <td>11.36</td>      <td>11.58</td>      <td>11.26</td>      <td>11.54</td>      <td>万科A</td>      <td>29.3</td>      <td>29.48</td>      <td>28.68</td>      <td>29.45</td>    </tr>    <tr>      <td>2</td>      <td>2017-11-03</td>      <td>平安银行</td>      <td>11.49</td>      <td>11.68</td>      <td>11.35</td>      <td>11.39</td>      <td>万科A</td>      <td>29.23</td>      <td>29.52</td>      <td>28.05</td>      <td>28.19</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'LASTRADEDAY_S，但所有的数据都保留下来，且生成一列来表示数据的来源'</span>)</span><br><span class="line">pd.merge(data_df,data_df1,on=<span class="string">'LASTRADEDAY_S'</span>,how=<span class="string">'outer'</span>,indicator=<span class="string">'数据来源'</span>)</span><br></pre></td></tr></table></figure><pre><code>LASTRADEDAY_S，但所有的数据都保留下来，且生成一列来表示数据的来源</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S</th>      <th>SEC_NAME_x</th>      <th>OPEN_x</th>      <th>HIGH_x</th>      <th>LOW_x</th>      <th>CLOSE_x</th>      <th>SEC_NAME_y</th>      <th>OPEN_y</th>      <th>HIGH_y</th>      <th>LOW_y</th>      <th>CLOSE_y</th>      <th>数据来源</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>2017-11-01</td>      <td>平安银行</td>      <td>11.56</td>      <td>11.59</td>      <td>11.32</td>      <td>11.4</td>      <td>万科A</td>      <td>28.96</td>      <td>30.54</td>      <td>28.73</td>      <td>29.15</td>      <td>both</td>    </tr>    <tr>      <td>1</td>      <td>2017-11-02</td>      <td>平安银行</td>      <td>11.36</td>      <td>11.58</td>      <td>11.26</td>      <td>11.54</td>      <td>万科A</td>      <td>29.3</td>      <td>29.48</td>      <td>28.68</td>      <td>29.45</td>      <td>both</td>    </tr>    <tr>      <td>2</td>      <td>2017-11-03</td>      <td>平安银行</td>      <td>11.49</td>      <td>11.68</td>      <td>11.35</td>      <td>11.39</td>      <td>万科A</td>      <td>29.23</td>      <td>29.52</td>      <td>28.05</td>      <td>28.19</td>      <td>both</td>    </tr>  </tbody></table></div><h3 id="2-7-4-DataFrame拼接—-join"><a href="#2-7-4-DataFrame拼接—-join" class="headerlink" title="2.7.4 DataFrame拼接—.join"></a>2.7.4 DataFrame拼接—.join</h3><p>DataFrame.join(other, on=None, how=’left’, lsuffix=’’, rsuffix=’’, sort=False)</p><p>other：一个DataFrame、Series（要有命名），或者DataFrame组成的list。</p><p>on：列名，包含列名的list或tuple，或矩阵样子的列 （如果是多列，必须有MultiIndex）。 跟上面的几种方法一样，用来指明依据哪一列进行合并。 如果没有赋值，则依据两个数据框的index合并。</p><p>how：合并方式， {‘left’, ‘right’, ‘outer’, ‘inner’}, 默认‘left‘。</p><p>lsuffix：字符串。用于左侧数据框的重复列。 把重复列重新命名，原来的列名+字符串。 【如果有重复列，必须添加这个参数。】</p><p>rsuffix：同上。右侧。</p><p>sort：布尔型，默认False。如果为True，将链接键（on的那列）按字母排序。</p><p>参考：<a href="http://www.jianshu.com/p/dc8ba1c0eada" target="_blank" rel="noopener">http://www.jianshu.com/p/dc8ba1c0eada</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'注意到两个拼接的数据框，含有相同的列LASTRADEDAY_S，故重新命名了这两个列'</span>)</span><br><span class="line">data_df.join(data_df1,lsuffix=<span class="string">'_left'</span>,rsuffix=<span class="string">'_right'</span>)</span><br></pre></td></tr></table></figure><pre><code>注意到两个拼接的数据框，含有相同的列LASTRADEDAY_S，故重新命名了这两个列</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>LASTRADEDAY_S_left</th>      <th>SEC_NAME_left</th>      <th>OPEN_left</th>      <th>HIGH_left</th>      <th>LOW_left</th>      <th>CLOSE_left</th>      <th>LASTRADEDAY_S_right</th>      <th>SEC_NAME_right</th>      <th>OPEN_right</th>      <th>HIGH_right</th>      <th>LOW_right</th>      <th>CLOSE_right</th>    </tr>  </thead>  <tbody>    <tr>      <td>2017-11-01</td>      <td>2017-11-01</td>      <td>平安银行</td>      <td>11.56</td>      <td>11.59</td>      <td>11.32</td>      <td>11.4</td>      <td>2017-11-01</td>      <td>万科A</td>      <td>28.96</td>      <td>30.54</td>      <td>28.73</td>      <td>29.15</td>    </tr>    <tr>      <td>2017-11-02</td>      <td>2017-11-02</td>      <td>平安银行</td>      <td>11.36</td>      <td>11.58</td>      <td>11.26</td>      <td>11.54</td>      <td>2017-11-02</td>      <td>万科A</td>      <td>29.3</td>      <td>29.48</td>      <td>28.68</td>      <td>29.45</td>    </tr>    <tr>      <td>2017-11-03</td>      <td>2017-11-03</td>      <td>平安银行</td>      <td>11.49</td>      <td>11.68</td>      <td>11.35</td>      <td>11.39</td>      <td>2017-11-03</td>      <td>万科A</td>      <td>29.23</td>      <td>29.52</td>      <td>28.05</td>      <td>28.19</td>    </tr>  </tbody></table></div><h3 id="2-8-DataFrame重复值剔除"><a href="#2-8-DataFrame重复值剔除" class="headerlink" title="2.8 DataFrame重复值剔除"></a>2.8 DataFrame重复值剔除</h3><p>有时候，希望能够剔除掉DataFrame中的重复记录。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每股基本收益指标</span></span><br><span class="line">error_code,df3 = w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"fa_eps_basic"</span>, <span class="string">"2017-08-07"</span>, <span class="string">"2017-08-15"</span>, <span class="string">"Days=Alldays;currencyType="</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">df3</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>FA_EPS_BASIC</th>    </tr>  </thead>  <tbody>    <tr>      <td>2017-08-07</td>      <td>0.31</td>    </tr>    <tr>      <td>2017-08-08</td>      <td>0.31</td>    </tr>    <tr>      <td>2017-08-09</td>      <td>0.31</td>    </tr>    <tr>      <td>2017-08-10</td>      <td>0.31</td>    </tr>    <tr>      <td>2017-08-11</td>      <td>0.68</td>    </tr>    <tr>      <td>2017-08-12</td>      <td>0.68</td>    </tr>    <tr>      <td>2017-08-13</td>      <td>0.68</td>    </tr>    <tr>      <td>2017-08-14</td>      <td>0.68</td>    </tr>    <tr>      <td>2017-08-15</td>      <td>0.68</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'查看DataFrame中是否存在重复记录，标记为True的为重复记录'</span>)</span><br><span class="line">df3.duplicated()</span><br></pre></td></tr></table></figure><pre><code>查看DataFrame中是否存在重复记录，标记为True的为重复记录2017-08-07    False2017-08-08     True2017-08-09     True2017-08-10     True2017-08-11    False2017-08-12     True2017-08-13     True2017-08-14     True2017-08-15     Truedtype: bool</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'剔除数据框中的重复记录'</span>)</span><br><span class="line">df3.drop_duplicates()</span><br></pre></td></tr></table></figure><pre><code>剔除数据框中的重复记录</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>FA_EPS_BASIC</th>    </tr>  </thead>  <tbody>    <tr>      <td>2017-08-07</td>      <td>0.31</td>    </tr>    <tr>      <td>2017-08-11</td>      <td>0.68</td>    </tr>  </tbody></table></div><h3 id="2-9-DataFrame分组及透视表（groupby）"><a href="#2-9-DataFrame分组及透视表（groupby）" class="headerlink" title="2.9 DataFrame分组及透视表（groupby）"></a>2.9 DataFrame分组及透视表（groupby）</h3><h4 id="2-9-1-分组——groupby函数"><a href="#2-9-1-分组——groupby函数" class="headerlink" title="2.9.1 分组——groupby函数"></a>2.9.1 分组——groupby函数</h4><p>氦核：这个函数很厉害。下面列几个用法：</p><p>1.根据DataFrame本身的某一列或多列内容进行分组聚合。</p><p>2.还可以利用for循环，对分组进行迭代。（下面举了个小栗子）</p><pre><code>for name,group in df.groupby(&#39;key1&#39;):    print(name)     print(group)</code></pre><p>若仅使用一个变量name,会影响输出结果的索引层次表达方式，且结果为元组。</p><p>3.对聚合后的数据片段，进行格式类型转化</p><p>4.利用groupby，根据dtypes对列进行分组,此时，需指定<code>axis=1</code>，否则，groupby默认根据<code>axis=0</code>进行分组，而行数据由于类型不统一，故无法根据dtypes对列进行分组。</p><pre><code>*#将聚合后df转化为字典格式，后根据df的数据类型对列进行分组* grouped=df.groupby(df.dtypes,axis=1) dict(list(grouped))</code></pre><p>我们设定，如果当天收益率大于0，我们标记为up，反之为down。把收盘价大于11的标记为good，反之为bad。正式举例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> WindPy <span class="keyword">import</span> *</span><br><span class="line">w.start()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 先取一个金融时间序列，以DataFrame的形式</span></span><br><span class="line">error_code,df4 = w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"open,close,pct_chg"</span>, <span class="string">"2018-04-20"</span>, <span class="string">"2018-04-30"</span>, <span class="string">""</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">df4[<span class="string">'standard'</span>] = df4.PCT_CHG.apply(<span class="keyword">lambda</span> x: <span class="string">'up'</span> <span class="keyword">if</span> x &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">'down'</span>)</span><br><span class="line">df4[<span class="string">'expression'</span>] = df4.CLOSE.apply(<span class="keyword">lambda</span> x: <span class="string">'good'</span> <span class="keyword">if</span> x &gt; <span class="number">11</span> <span class="keyword">else</span> <span class="string">'bad'</span>)</span><br><span class="line">df4</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>CLOSE</th>      <th>PCT_CHG</th>      <th>standard</th>      <th>expression</th>    </tr>  </thead>  <tbody>    <tr>      <td>2018-04-20</td>      <td>11.51</td>      <td>11.35</td>      <td>-1.046207</td>      <td>down</td>      <td>good</td>    </tr>    <tr>      <td>2018-04-23</td>      <td>11.30</td>      <td>11.57</td>      <td>1.938326</td>      <td>up</td>      <td>good</td>    </tr>    <tr>      <td>2018-04-24</td>      <td>11.63</td>      <td>11.86</td>      <td>2.506482</td>      <td>up</td>      <td>good</td>    </tr>    <tr>      <td>2018-04-25</td>      <td>11.76</td>      <td>11.68</td>      <td>-1.517707</td>      <td>down</td>      <td>good</td>    </tr>    <tr>      <td>2018-04-26</td>      <td>11.66</td>      <td>11.42</td>      <td>-2.226027</td>      <td>down</td>      <td>good</td>    </tr>    <tr>      <td>2018-04-27</td>      <td>11.49</td>      <td>10.85</td>      <td>-4.991243</td>      <td>down</td>      <td>bad</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grouped = df4[<span class="string">'CLOSE'</span>].groupby(df4[<span class="string">'standard'</span>])</span><br><span class="line">grouped</span><br></pre></td></tr></table></figure><pre><code>&lt;pandas.core.groupby.generic.SeriesGroupBy object at 0x0000020B26C63648&gt;</code></pre><p>氦核：上面这行是聚合后不适用配合函数的输出。</p><p>这是由于变量grouped是一个GroupBy对象，它实际上还没有进行任何计算，只是含有一些有关分组键<code>df[‘key1’]</code>的中间数据而已，然后我们可以调用配合函数（如：.mean()方法）来计算分组平均值等。<br>　　因此，一般为方便起见可直接在<strong>聚合之后+“配合函数”</strong>，默认情况下，所有数值列都将会被聚合，虽然有时可能会被过滤为一个子集。<br>　　一般，如果对df直接聚合时，<br><code>df.groupby([df[&#39;key1&#39;],df[&#39;key2&#39;]]).mean()</code>（分组键为：Series）与<code>df.groupby([&#39;key1&#39;,&#39;key2&#39;]).mean()</code>（分组键为：列名）是等价的，输出结果相同。<br>　　但是，如果对df的指定列进行聚合时，<br><code>df[&#39;data1&#39;].groupby(df[&#39;key1&#39;]).mean()</code>（分组键为：Series），唯一方式。<br>此时，直接使用“列名”作分组键，提示“Error Key”。<br>　　 注意：分组键中的任何缺失值都会被排除在结果之外。</p><p><a href="https://blog.csdn.net/weixin_42782150/article/details/90716533" target="_blank" rel="noopener">参考groupby用法博客链接</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grouped.mean()</span><br></pre></td></tr></table></figure><pre><code>standarddown    11.325up      11.715Name: CLOSE, dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">means = df4[<span class="string">'CLOSE'</span>].groupby([df4[<span class="string">'standard'</span>],df4[<span class="string">'expression'</span>]]).mean()</span><br><span class="line">means</span><br></pre></td></tr></table></figure><pre><code>standard  expressiondown      bad           10.850000          good          11.483333up        good          11.715000Name: CLOSE, dtype: float64</code></pre><p>对两个键进行了分组，得到的Series具有一个层次化索引。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">means.unstack()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>expression</th>      <th>bad</th>      <th>good</th>    </tr>    <tr>      <th>standard</th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <td>down</td>      <td>10.85</td>      <td>11.483333</td>    </tr>    <tr>      <td>up</td>      <td>NaN</td>      <td>11.715000</td>    </tr>  </tbody></table></div><p>你还可以将列名用作分组键。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df4.groupby(<span class="string">'standard'</span>).mean()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>CLOSE</th>      <th>PCT_CHG</th>    </tr>    <tr>      <th>standard</th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <td>down</td>      <td>11.605</td>      <td>11.325</td>      <td>-2.445296</td>    </tr>    <tr>      <td>up</td>      <td>11.465</td>      <td>11.715</td>      <td>2.222404</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df4.groupby([df4[<span class="string">'standard'</span>],df4[<span class="string">'expression'</span>]]).mean()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th></th>      <th>OPEN</th>      <th>CLOSE</th>      <th>PCT_CHG</th>    </tr>    <tr>      <th>standard</th>      <th>expression</th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <td rowspan="2" valign="top">down</td>      <td>bad</td>      <td>11.490000</td>      <td>10.850000</td>      <td>-4.991243</td>    </tr>    <tr>      <td>good</td>      <td>11.643333</td>      <td>11.483333</td>      <td>-1.596647</td>    </tr>    <tr>      <td>up</td>      <td>good</td>      <td>11.465000</td>      <td>11.715000</td>      <td>2.222404</td>    </tr>  </tbody></table></div><p>我们还可以用size方法，返回一个含有分组大小的Series。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df4.groupby([<span class="string">'standard'</span>,<span class="string">'expression'</span>]).size()</span><br></pre></td></tr></table></figure><pre><code>standard  expressiondown      bad           1          good          3up        good          2dtype: int64</code></pre><h4 id="2-9-2-对分组进行迭代"><a href="#2-9-2-对分组进行迭代" class="headerlink" title="2.9.2 对分组进行迭代"></a>2.9.2 对分组进行迭代</h4><p>GroupBy对象支持迭代，可以产生一组二元元组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name,group <span class="keyword">in</span> df4.groupby(<span class="string">'standard'</span>):</span><br><span class="line">    print(name)</span><br><span class="line">    print(group)</span><br></pre></td></tr></table></figure><pre><code>down             OPEN  CLOSE   PCT_CHG standard expression2018-04-20  11.51  11.35 -1.046207     down       good2018-04-25  11.76  11.68 -1.517707     down       good2018-04-26  11.66  11.42 -2.226027     down       good2018-04-27  11.49  10.85 -4.991243     down        badup             OPEN  CLOSE   PCT_CHG standard expression2018-04-23  11.30  11.57  1.938326       up       good2018-04-24  11.63  11.86  2.506482       up       good</code></pre><p>对于<strong>多重组件</strong>的情况，元素的第一个元素将会是有键值组成的元组：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (k1,k2), group <span class="keyword">in</span> df4.groupby([<span class="string">'standard'</span>,<span class="string">'expression'</span>]):</span><br><span class="line">    print(k1,k2)</span><br><span class="line">    print(group)</span><br></pre></td></tr></table></figure><pre><code>down bad             OPEN  CLOSE   PCT_CHG standard expression2018-04-27  11.49  10.85 -4.991243     down        baddown good             OPEN  CLOSE   PCT_CHG standard expression2018-04-20  11.51  11.35 -1.046207     down       good2018-04-25  11.76  11.68 -1.517707     down       good2018-04-26  11.66  11.42 -2.226027     down       goodup good             OPEN  CLOSE   PCT_CHG standard expression2018-04-23  11.30  11.57  1.938326       up       good2018-04-24  11.63  11.86  2.506482       up       good</code></pre><p>当然，你可以对这些数据片段做任何操作。将这些数据片段做成一个字典：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pieces = dict(list(df4.groupby(<span class="string">'standard'</span>)))</span><br><span class="line">pieces</span><br></pre></td></tr></table></figure><pre><code>{&#39;down&#39;:              OPEN  CLOSE   PCT_CHG standard expression 2018-04-20  11.51  11.35 -1.046207     down       good 2018-04-25  11.76  11.68 -1.517707     down       good 2018-04-26  11.66  11.42 -2.226027     down       good 2018-04-27  11.49  10.85 -4.991243     down        bad, &#39;up&#39;:              OPEN  CLOSE   PCT_CHG standard expression 2018-04-23  11.30  11.57  1.938326       up       good 2018-04-24  11.63  11.86  2.506482       up       good}</code></pre><p>groupby默认是在<code>axis=0</code>上进行分组的。通过设置也可以对其他任何轴上进行分组。比如我们可以根据dtype对列进行分组：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df4.dtypes</span><br></pre></td></tr></table></figure><pre><code>OPEN          float64CLOSE         float64PCT_CHG       float64standard       objectexpression     objectdtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grouped = df4.groupby(df4.dtypes,axis=<span class="number">1</span>)</span><br><span class="line">dict(list(grouped))</span><br></pre></td></tr></table></figure><pre><code>{dtype(&#39;float64&#39;):              OPEN  CLOSE   PCT_CHG 2018-04-20  11.51  11.35 -1.046207 2018-04-23  11.30  11.57  1.938326 2018-04-24  11.63  11.86  2.506482 2018-04-25  11.76  11.68 -1.517707 2018-04-26  11.66  11.42 -2.226027 2018-04-27  11.49  10.85 -4.991243, dtype(&#39;O&#39;):            standard expression 2018-04-20     down       good 2018-04-23       up       good 2018-04-24       up       good 2018-04-25     down       good 2018-04-26     down       good 2018-04-27     down        bad}</code></pre><h4 id="2-9-3-选取一个或一组列"><a href="#2-9-3-选取一个或一组列" class="headerlink" title="2.9.3 选取一个或一组列"></a>2.9.3 选取一个或一组列</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df4.groupby([<span class="string">'standard'</span>,<span class="string">'expression'</span>])[[<span class="string">'CLOSE'</span>]].mean() <span class="comment"># 在['CLOSE']前后再多加一组[]即可</span></span><br></pre></td></tr></table></figure><p>氦核：再加一个中括号。</p><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th></th>      <th>CLOSE</th>    </tr>    <tr>      <th>standard</th>      <th>expression</th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <td rowspan="2" valign="top">down</td>      <td>bad</td>      <td>10.850000</td>    </tr>    <tr>      <td>good</td>      <td>11.483333</td>    </tr>    <tr>      <td>up</td>      <td>good</td>      <td>11.715000</td>    </tr>  </tbody></table></div><p>或者是以分组的Series:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s_grouped = df4.groupby([<span class="string">'standard'</span>,<span class="string">'expression'</span>])[<span class="string">'CLOSE'</span>]</span><br><span class="line">s_grouped.mean()</span><br></pre></td></tr></table></figure><pre><code>standard  expressiondown      bad           10.850000          good          11.483333up        good          11.715000Name: CLOSE, dtype: float64</code></pre><h4 id="2-9-4-通过字典或者Series进行分组"><a href="#2-9-4-通过字典或者Series进行分组" class="headerlink" title="2.9.4 通过字典或者Series进行分组"></a>2.9.4 通过字典或者Series进行分组</h4><p>除数组以外，分组信息还可以以其他形式存在。我们新构建一个DataFrame。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">error_code,df_wss = w.wss(<span class="string">"000001.SZ,000088.SZ,002626.SZ,600021.SH,600036.SH"</span>, <span class="string">"open,high,low,volume,amt,pct_chg"</span>, <span class="string">"tradeDate=2018-05-29;priceAdj=1;cycle=1"</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">df_wss</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>VOLUME</th>      <th>AMT</th>      <th>PCT_CHG</th>    </tr>  </thead>  <tbody>    <tr>      <td>000001.SZ</td>      <td>10.58</td>      <td>10.63</td>      <td>10.35</td>      <td>88949497.0</td>      <td>9.303870e+08</td>      <td>-1.983003</td>    </tr>    <tr>      <td>000088.SZ</td>      <td>7.65</td>      <td>7.79</td>      <td>7.61</td>      <td>9731389.0</td>      <td>7.493758e+07</td>      <td>-0.260756</td>    </tr>    <tr>      <td>002626.SZ</td>      <td>19.13</td>      <td>19.72</td>      <td>18.97</td>      <td>7058799.0</td>      <td>1.367769e+08</td>      <td>-0.679561</td>    </tr>    <tr>      <td>600021.SH</td>      <td>8.15</td>      <td>8.20</td>      <td>8.10</td>      <td>2065681.0</td>      <td>1.685831e+07</td>      <td>-0.368098</td>    </tr>    <tr>      <td>600036.SH</td>      <td>28.65</td>      <td>28.98</td>      <td>28.41</td>      <td>48053415.0</td>      <td>1.376605e+09</td>      <td>0.486111</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加几个空值NAN</span></span><br><span class="line">df_wss.ix[<span class="number">2</span>:<span class="number">3</span>, [<span class="string">'OPEN'</span>,<span class="string">'HIGH'</span>]] = np.nan</span><br><span class="line">df_wss</span><br></pre></td></tr></table></figure><pre><code>D:\anaconda\lib\site-packages\ipykernel_launcher.py:2: FutureWarning: .ix is deprecated. Please use.loc for label based indexing or.iloc for positional indexingSee the documentation here:http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated</code></pre><p>​    </p><p>氦核：依然不建议使用ix。</p><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>VOLUME</th>      <th>AMT</th>      <th>PCT_CHG</th>    </tr>  </thead>  <tbody>    <tr>      <td>000001.SZ</td>      <td>10.58</td>      <td>10.63</td>      <td>10.35</td>      <td>88949497.0</td>      <td>9.303870e+08</td>      <td>-1.983003</td>    </tr>    <tr>      <td>000088.SZ</td>      <td>7.65</td>      <td>7.79</td>      <td>7.61</td>      <td>9731389.0</td>      <td>7.493758e+07</td>      <td>-0.260756</td>    </tr>    <tr>      <td>002626.SZ</td>      <td>NaN</td>      <td>NaN</td>      <td>18.97</td>      <td>7058799.0</td>      <td>1.367769e+08</td>      <td>-0.679561</td>    </tr>    <tr>      <td>600021.SH</td>      <td>8.15</td>      <td>8.20</td>      <td>8.10</td>      <td>2065681.0</td>      <td>1.685831e+07</td>      <td>-0.368098</td>    </tr>    <tr>      <td>600036.SH</td>      <td>28.65</td>      <td>28.98</td>      <td>28.41</td>      <td>48053415.0</td>      <td>1.376605e+09</td>      <td>0.486111</td>    </tr>  </tbody></table></div><p>假设已知列的分组关系，并希望根据分组计算列的总和：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mapping = &#123;<span class="string">'OPEN'</span>:<span class="string">'r'</span>,<span class="string">'HIGH'</span>:<span class="string">'r'</span>,<span class="string">'LOW'</span>:<span class="string">'b'</span>,<span class="string">'VOLUME'</span>:<span class="string">'b'</span>,<span class="string">'AMT'</span>:<span class="string">'b'</span>,<span class="string">'PCT_CHG'</span>:<span class="string">'o'</span>&#125;</span><br></pre></td></tr></table></figure><p>只需要将这个字典传给groupby即可：（行方向）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">by_colum = df_wss.groupby(mapping,axis=<span class="number">1</span>)</span><br><span class="line">by_colum.sum()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>b</th>      <th>o</th>      <th>r</th>    </tr>  </thead>  <tbody>    <tr>      <td>000001.SZ</td>      <td>1.019336e+09</td>      <td>-1.983003</td>      <td>21.21</td>    </tr>    <tr>      <td>000088.SZ</td>      <td>8.466897e+07</td>      <td>-0.260756</td>      <td>15.44</td>    </tr>    <tr>      <td>002626.SZ</td>      <td>1.438358e+08</td>      <td>-0.679561</td>      <td>0.00</td>    </tr>    <tr>      <td>600021.SH</td>      <td>1.892400e+07</td>      <td>-0.368098</td>      <td>16.35</td>    </tr>    <tr>      <td>600036.SH</td>      <td>1.424658e+09</td>      <td>0.486111</td>      <td>57.63</td>    </tr>  </tbody></table></div><p>Series也有这样的功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">map_series = pd.Series(mapping)</span><br><span class="line">map_series</span><br></pre></td></tr></table></figure><pre><code>OPEN       rHIGH       rLOW        bVOLUME     bAMT        bPCT_CHG    odtype: object</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_wss.groupby(map_series,axis=<span class="number">1</span>).count()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>b</th>      <th>o</th>      <th>r</th>    </tr>  </thead>  <tbody>    <tr>      <td>000001.SZ</td>      <td>3</td>      <td>1</td>      <td>2</td>    </tr>    <tr>      <td>000088.SZ</td>      <td>3</td>      <td>1</td>      <td>2</td>    </tr>    <tr>      <td>002626.SZ</td>      <td>3</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <td>600021.SH</td>      <td>3</td>      <td>1</td>      <td>2</td>    </tr>    <tr>      <td>600036.SH</td>      <td>3</td>      <td>1</td>      <td>2</td>    </tr>  </tbody></table></div><h4 id="2-9-5-根据索引级别分组"><a href="#2-9-5-根据索引级别分组" class="headerlink" title="2.9.5 根据索引级别分组"></a>2.9.5 根据索引级别分组</h4><p>层次化索引数据最方便的地方就是在于它能够根据索引级别进行聚合。要实现该目的，通过level关键字传入级别编号或名称即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_wss</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>VOLUME</th>      <th>AMT</th>      <th>PCT_CHG</th>    </tr>  </thead>  <tbody>    <tr>      <td>000001.SZ</td>      <td>10.58</td>      <td>10.63</td>      <td>10.35</td>      <td>88949497.0</td>      <td>9.303870e+08</td>      <td>-1.983003</td>    </tr>    <tr>      <td>000088.SZ</td>      <td>7.65</td>      <td>7.79</td>      <td>7.61</td>      <td>9731389.0</td>      <td>7.493758e+07</td>      <td>-0.260756</td>    </tr>    <tr>      <td>002626.SZ</td>      <td>NaN</td>      <td>NaN</td>      <td>18.97</td>      <td>7058799.0</td>      <td>1.367769e+08</td>      <td>-0.679561</td>    </tr>    <tr>      <td>600021.SH</td>      <td>8.15</td>      <td>8.20</td>      <td>8.10</td>      <td>2065681.0</td>      <td>1.685831e+07</td>      <td>-0.368098</td>    </tr>    <tr>      <td>600036.SH</td>      <td>28.65</td>      <td>28.98</td>      <td>28.41</td>      <td>48053415.0</td>      <td>1.376605e+09</td>      <td>0.486111</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">columns = pd.MultiIndex.from_arrays([[<span class="string">'行情'</span>,<span class="string">'行情'</span>,<span class="string">'行情'</span>,<span class="string">'量'</span>,<span class="string">'量'</span>,<span class="string">'幅度'</span>],</span><br><span class="line">                                     [<span class="string">'OPEN'</span>,<span class="string">'HIGH'</span>,<span class="string">'LOW'</span>,<span class="string">'VOLUME'</span>,<span class="string">'AMT'</span>,<span class="string">'PCT_CHG'</span>]],names=[<span class="string">'s1'</span>,<span class="string">'s2'</span>])</span><br><span class="line">hier_df = pd.DataFrame(df_wss.values, columns=columns,index=df_wss.index)</span><br><span class="line">hier_df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead tr th {        text-align: left;    }</style><table border="1" class="dataframe">  <thead>    <tr>      <th>s1</th>      <th colspan="3" halign="left">行情</th>      <th colspan="2" halign="left">量</th>      <th>幅度</th>    </tr>    <tr>      <th>s2</th>      <th>OPEN</th>      <th>HIGH</th>      <th>LOW</th>      <th>VOLUME</th>      <th>AMT</th>      <th>PCT_CHG</th>    </tr>  </thead>  <tbody>    <tr>      <td>000001.SZ</td>      <td>10.58</td>      <td>10.63</td>      <td>10.35</td>      <td>88949497.0</td>      <td>9.303870e+08</td>      <td>-1.983003</td>    </tr>    <tr>      <td>000088.SZ</td>      <td>7.65</td>      <td>7.79</td>      <td>7.61</td>      <td>9731389.0</td>      <td>7.493758e+07</td>      <td>-0.260756</td>    </tr>    <tr>      <td>002626.SZ</td>      <td>NaN</td>      <td>NaN</td>      <td>18.97</td>      <td>7058799.0</td>      <td>1.367769e+08</td>      <td>-0.679561</td>    </tr>    <tr>      <td>600021.SH</td>      <td>8.15</td>      <td>8.20</td>      <td>8.10</td>      <td>2065681.0</td>      <td>1.685831e+07</td>      <td>-0.368098</td>    </tr>    <tr>      <td>600036.SH</td>      <td>28.65</td>      <td>28.98</td>      <td>28.41</td>      <td>48053415.0</td>      <td>1.376605e+09</td>      <td>0.486111</td>    </tr>  </tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hier_df.groupby(level=<span class="string">'s1'</span>,axis=<span class="number">1</span>).count()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th>s1</th>      <th>幅度</th>      <th>行情</th>      <th>量</th>    </tr>  </thead>  <tbody>    <tr>      <td>000001.SZ</td>      <td>1</td>      <td>3</td>      <td>2</td>    </tr>    <tr>      <td>000088.SZ</td>      <td>1</td>      <td>3</td>      <td>2</td>    </tr>    <tr>      <td>002626.SZ</td>      <td>1</td>      <td>1</td>      <td>2</td>    </tr>    <tr>      <td>600021.SH</td>      <td>1</td>      <td>3</td>      <td>2</td>    </tr>    <tr>      <td>600036.SH</td>      <td>1</td>      <td>3</td>      <td>2</td>    </tr>  </tbody></table></div><p>（完）</p><p>依然鸣谢：某大哥假粉。愿四下空虚的灵魂皆能得以慰藉。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最后编辑于：2020.02.06 18:00&lt;/p&gt;
&lt;h2 id=&quot;Pandas库&quot;&gt;&lt;a href=&quot;#Pandas库&quot; class=&quot;headerlink&quot; title=&quot;Pandas库&quot;&gt;&lt;/a&gt;Pandas库&lt;/h2&gt;&lt;p&gt;Pandas是基于NumPy 的一种工具，其出现是为了解决数据分析任务。（氦核：个人觉得更像是探索工具，没有模型，简单分析。）&lt;br&gt;Pandas吸纳了大量库和一些标准的数据模型，提供了高效操作大型数据集所需的工具。&lt;br&gt;Pandas中的函数和方法能够使我们快速便捷地处理数据。&lt;br&gt;它是使Python成为强大而高效的数据分析环境的重要因素之一。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://pandas.pydata.org/pandas-docs/stable/api.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://pandas.pydata.org/pandas-docs/stable/api.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文参考&lt;a href=&quot;https://www.windquant.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;万旷网教程&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据分析" scheme="https://konelane.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>python联萌|今天康康numpy（怒骂朋友库</title>
    <link href="https://konelane.github.io/2020/02/05/200205numpy/"/>
    <id>https://konelane.github.io/2020/02/05/200205numpy/</id>
    <published>2020-02-04T16:00:00.000Z</published>
    <updated>2020-02-05T05:26:34.465Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最后编辑于：2020.02.05 12:30</p><h2 id="Numpy库"><a href="#Numpy库" class="headerlink" title="Numpy库"></a>Numpy库</h2><p>Numpy库是Python的一种开源的数值计算扩展。</p><p>Numpy可用来存储和处理大型矩阵，比Python自身的嵌套列表结构要高效很多。</p><p>据说Numpy将Pyhon变成了一种免费的更强大的Matlab系统。</p><p>本文介绍性文字转载自<a href="https://www.windquant.com/" target="_blank" rel="noopener">万旷网</a>。氦核感觉notebook形式更适合学习，有机会把丘比特文件给大家附上。</p><a id="more"></a><p>Numpy库包含了：</p><p>&gt;</p><blockquote><p>强大的N维数组对象<br>精密的函数<br>连接C/C++和Fortran代码的工具<br>常用的线性代数，傅里叶变换和随机数生成  </p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先导入 numpy 库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure><p>氦核：惯用的导入法，最好延用。</p><h2 id="一、数组array"><a href="#一、数组array" class="headerlink" title="一、数组array"></a>一、数组array</h2><p>数组array和列表list类似，但是数据array可以定义维度，且适合做数学代数运算</p><h3 id="1-数组array生成"><a href="#1-数组array生成" class="headerlink" title="1.数组array生成"></a>1.数组array生成</h3><p>数据使用windapi提取。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> WindPy <span class="keyword">import</span> *</span><br><span class="line">w.start()</span><br><span class="line">a = w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"close"</span>, <span class="string">"2018-07-05"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>)</span><br><span class="line">b = w.wsd(<span class="string">"000002.SZ"</span>, <span class="string">"close,open"</span>, <span class="string">"2018-07-05"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>)</span><br><span class="line">b</span><br></pre></td></tr></table></figure><p>氦核：取的是收盘价和开盘价。</p><pre><code>.ErrorCode=0.Codes=[000002.SZ].Fields=[CLOSE,OPEN].Times=[20180705,20180706,20180709,20180710,20180711].Data=[[23.05,23.21,24.01,24.15,23.46],[23.02,23.34,23.37,24.2,23.48]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a1 = np.array(a.Data[<span class="number">0</span>])</span><br><span class="line">a2 = np.array(b.Data)</span><br><span class="line">print(<span class="string">'这是一个一维数组：\n'</span>,a1)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'这是一个二维数组：\n'</span>,a2)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看a1的长度：\n'</span>,len(a1))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'查看a2的长度：\n'</span>,len(a2))</span><br></pre></td></tr></table></figure><p>氦核：len可以求数组长度，指数组里有几个list。</p><pre><code>这是一个一维数组： [8.6  8.66 9.03 8.98 8.78]这是一个二维数组： [[23.05 23.21 24.01 24.15 23.46] [23.02 23.34 23.37 24.2  23.48]]查看a1的长度： 5查看a2的长度： 2</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a2</span><br></pre></td></tr></table></figure><pre><code>array([[23.05, 23.21, 24.01, 24.15, 23.46],       [23.02, 23.34, 23.37, 24.2 , 23.48]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a2[<span class="number">0</span>,<span class="number">1</span>]</span><br></pre></td></tr></table></figure><pre><code>23.21</code></pre><h3 id="1-2-数组array性质"><a href="#1-2-数组array性质" class="headerlink" title="1.2 数组array性质"></a>1.2 数组array性质</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''数组元素整数转化为浮点数'''</span></span><br><span class="line">print(<span class="string">'数组类型：'</span>,a1.dtype)</span><br><span class="line">float_arr = a1.astype(np.int)</span><br><span class="line">print(<span class="string">'改变数组类型后：'</span>,float_arr.dtype)</span><br></pre></td></tr></table></figure><p>氦核：dtype可以查看类型，astype可以转换类型。不同类型变换后会产生不同结果。</p><pre><code>数组类型： float64改变数组类型后： int32</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''字符串数字转化为浮点数'''</span></span><br><span class="line">numeric_string = np.array([<span class="string">'1.11'</span>,<span class="string">'2.22'</span>,<span class="string">'3.33'</span>])</span><br><span class="line">print(numeric_string, numeric_string.dtype)</span><br><span class="line">print(numeric_string.astype(np.float),numeric_string.astype(np.float).dtype)</span><br></pre></td></tr></table></figure><pre><code>[&#39;1.11&#39; &#39;2.22&#39; &#39;3.33&#39;] &lt;U4[1.11 2.22 3.33] float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''字符串数字转化为浮点数'''</span></span><br><span class="line">numeric_string = np.array([<span class="string">'1.11'</span>,<span class="string">'2.22'</span>,<span class="string">'3.33'</span>])</span><br><span class="line">print(numeric_string, numeric_string.dtype)</span><br><span class="line">print(numeric_string.astype(np.float),numeric_string.astype(np.float).dtype)</span><br></pre></td></tr></table></figure><pre><code>[&#39;1.11&#39; &#39;2.22&#39; &#39;3.33&#39;] &lt;U4[1.11 2.22 3.33] float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">print(a2)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'第二行第三列元素(第二行索引为1，第三列索引为2)：\n'</span>,a2[<span class="number">1</span>,<span class="number">2</span>]) </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'倒数第一行(注意索引为-1)：\n'</span>,a2[<span class="number">-1</span>,:]) </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'第三列(索引为2)：\n'</span>,a2[:,<span class="number">2</span>])</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'a2形状：\n'</span>,a2.shape)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'a2形状重构：\n'</span>,a2.reshape(<span class="number">5</span>,<span class="number">2</span>))</span><br></pre></td></tr></table></figure><pre><code>[[23.05 23.21 24.01 24.15 23.46] [23.02 23.34 23.37 24.2  23.48]]第二行第三列元素(第二行索引为1，第三列索引为2)： 23.37倒数第一行(注意索引为-1)： [23.02 23.34 23.37 24.2  23.48]第三列(索引为2)： [24.01 23.37]a2形状： (2, 5)a2形状重构： [[23.05 23.21] [24.01 24.15] [23.46 23.02] [23.34 23.37] [24.2  23.48]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'维度解锁：'</span>,a2.ravel())  <span class="comment">#  ravel()函数可以将高维数组转化为一维数组</span></span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按列求和：'</span>,a2.sum(axis=<span class="number">0</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按列求积：'</span>,a2.prod(axis=<span class="number">0</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'全局最大值：'</span>,a2.max(),<span class="string">'全局最小值：'</span>,a2.min())</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按行求最大值：'</span>,a2.max(axis=<span class="number">0</span>),<span class="string">'按列求最小值：'</span>,a2.min(axis=<span class="number">1</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按列求均值：'</span>,a2.mean(axis=<span class="number">0</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按行求标准差：'</span>,a2.std(axis=<span class="number">0</span>))</span><br></pre></td></tr></table></figure><pre><code>维度解锁： [23.05 23.21 24.01 24.15 23.46 23.02 23.34 23.37 24.2  23.48]按列求和： [46.07 46.55 47.38 48.35 46.94]按列求积： [530.611  541.7214 561.1137 584.43   550.8408]全局最大值： 24.2 全局最小值： 23.02按行求最大值： [23.05 23.34 24.01 24.2  23.48] 按列求最小值： [23.05 23.02]按列求均值： [23.035 23.275 23.69  24.175 23.47 ]按行求标准差： [0.015 0.065 0.32  0.025 0.01 ]</code></pre><p>氦核：这些计算都是可以接受方向的。按列或按行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'原矩阵：\n'</span>,a2)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按列求和：\n'</span>,a2.sum(axis=<span class="number">0</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按行求均值：\n'</span>,a2.mean(axis=<span class="number">1</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'按行累加：\n'</span>,a2.cumsum(axis=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><pre><code>原矩阵： [[23.05 23.21 24.01 24.15 23.46] [23.02 23.34 23.37 24.2  23.48]]按列求和： [46.07 46.55 47.38 48.35 46.94]按行求均值： [23.576 23.482]按行累加： [[ 23.05  46.26  70.27  94.42 117.88] [ 23.02  46.36  69.73  93.93 117.41]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'矩阵所有元素求指数：\n'</span>,np.exp(a2))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵所有元素求根号：\n'</span>,np.sqrt(a2))</span><br></pre></td></tr></table></figure><p>氦核：np.exp功能是“求e的幂次方”。</p><pre><code>矩阵所有元素求指数： [[1.02444302e+10 1.20219502e+10 2.67553422e+10 3.07759692e+10  1.54364896e+10] [9.94166153e+09 1.36909381e+10 1.41078893e+10 3.23538868e+10  1.57483274e+10]]矩阵所有元素求根号： [[4.80104155 4.81767579 4.9        4.91426495 4.84355242] [4.79791621 4.83114893 4.83425279 4.91934955 4.84561658]]</code></pre><p>小数位数控制和取整</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'小数位数：\n'</span>,a1.round(decimals=<span class="number">2</span>)) <span class="comment">#控制小数位数</span></span><br></pre></td></tr></table></figure><pre><code>小数位数： [8.6  8.66 9.03 8.98 8.78]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'原数组：\n'</span>,a1)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'向上取整：\n'</span>,np.floor(a1))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'向下取整：\n'</span>,np.ceil(a1))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'四舍五入(控制小数为2位)：\n'</span>,np.round(a1,<span class="number">2</span>))</span><br></pre></td></tr></table></figure><pre><code>原数组： [8.6  8.66 9.03 8.98 8.78]向上取整： [8. 8. 9. 8. 8.]向下取整： [ 9.  9. 10.  9.  9.]四舍五入(控制小数为2位)： [8.6  8.66 9.03 8.98 8.78]</code></pre><h4 id="数组——一元函数"><a href="#数组——一元函数" class="headerlink" title="数组——一元函数"></a>数组——一元函数</h4><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>abs、fabs</td><td>计算整数、浮点数或复数的绝对值。对于非复数，使用fabs更快</td></tr><tr><td>sqrt、square、exp</td><td>计算各元素的平方根、平方、指数𝑒𝑥</td></tr><tr><td>log、log10、log2、log1p</td><td>自然对数、底数10的对数、底数2的对数、𝑙𝑛(1+𝑥)</td></tr><tr><td>sign</td><td>计算各元素的正负号：正1,零0,负-1</td></tr><tr><td>ceil</td><td>计算各元素的取整：大于等于该数的最小整数</td></tr><tr><td>floor</td><td>计算各元素的取整：小于等于该数的最大整数</td></tr><tr><td>rint</td><td>各元素四舍五入最接近的整数，dtype不变</td></tr><tr><td>modf</td><td>将数组各元素的小数和整数部分以两个独立数组的形式返回</td></tr><tr><td>isnan、isfinite、isinf</td><td>判断各元素是否为NaN、是否有穷、是否为无穷</td></tr><tr><td>cos、cosh、sin、sinh、tan、tanh</td><td>一般和双曲型的三角函数</td></tr><tr><td>arccos、arccosh、arcsin、arcsinh、arctan、arctanh</td><td>反三角函数</td></tr><tr><td>sum、mean</td><td>数组全部或者按某个轴的方向进行求和、求均值</td></tr><tr><td>std、var</td><td>标准差、方差，自由度可以调整</td></tr><tr><td>min、max、argmin、argmax</td><td>最小和最大值、最小和最大元素的索引</td></tr><tr><td>cumsum、cumprod</td><td>数组全部或者按某个轴的方向进行累计和、累计积</td></tr></tbody></table></div><h3 id="1-3-数组array间运算"><a href="#1-3-数组array间运算" class="headerlink" title="1.3 数组array间运算"></a>1.3 数组array间运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">c, r = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]), np.array([<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">print(c)</span><br><span class="line">print(r)</span><br></pre></td></tr></table></figure><pre><code>[1 2 3 4][2 3 4 5]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'数组相加：'</span>,c + r)</span><br><span class="line">print(<span class="string">'数组相乘：'</span>,c * r)</span><br><span class="line">print(<span class="string">'数组乘方：'</span>,c **r)</span><br><span class="line">print(<span class="string">'数组判断：'</span>,c &gt;= <span class="number">2</span>)</span><br><span class="line">print(<span class="string">'向量内积：'</span>,c.dot(r.T))</span><br></pre></td></tr></table></figure><pre><code>数组相加： [3 5 7 9]数组相乘： [ 2  6 12 20]数组乘方： [   1    8   81 1024]数组判断： [False  True  True  True]向量内积： 40</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'取两个数组中的较大值组成新的数组：'</span>,np.maximum(c,r))</span><br><span class="line">print(<span class="string">'取两个数组中的较小者组成新的数组：'</span>,np.minimum(c,r))</span><br></pre></td></tr></table></figure><pre><code>取两个数组中的较大值组成新的数组： [2 3 4 5]取两个数组中的较小者组成新的数组： [1 2 3 4]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x1 = np.array([<span class="keyword">True</span>,<span class="keyword">False</span>,<span class="keyword">True</span>])</span><br><span class="line">x2 = np.array([<span class="keyword">False</span>,<span class="keyword">False</span>,<span class="keyword">True</span>])</span><br><span class="line">print(x1)</span><br><span class="line">print(x2)</span><br><span class="line">print(np.logical_and(x1,x2))</span><br><span class="line">print(np.logical_or(x1,x2))</span><br><span class="line">print(np.logical_xor(x1,x2))</span><br></pre></td></tr></table></figure><p>氦核：逻辑运算一样很简单，logical_xor是异或运算。一般逻辑函数用于检验数组内容，筛选出需要的元素（通常得到的是位置）。可以完成“检查a中元素是否存在于b中”这样的问题。简便操作详细见下面集合运算。</p><pre><code>[ True False  True][False False  True][False False  True][ True False  True][ True False False]</code></pre><h4 id="数组——二元函数"><a href="#数组——二元函数" class="headerlink" title="数组——二元函数"></a>数组——二元函数</h4><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>add、multiply</td><td>数组中对应的元素相加、相乘</td></tr><tr><td>substract</td><td>第一个数组减去第二个数组中的元素</td></tr><tr><td>divide、floor_divide</td><td>除法、向下圆整除法(余数直接舍弃)</td></tr><tr><td>power</td><td>对于第一个数组中的元素，根据第二个数组中的对应元素，进行幂运算</td></tr><tr><td>maximum、fmax</td><td>元素级的最大值、fmax功能相同只是忽略NaN</td></tr><tr><td>minimum、fmin</td><td>元素级的最小值、fmin功能相同只是忽略NaN</td></tr><tr><td>mod</td><td>元素级的求余</td></tr><tr><td>copysign</td><td>将第二个数组中的值的符号复制给第一个数组中的值</td></tr><tr><td>greater、greater_equal、less、less_equal、equal、not_equal</td><td>元素级的比较运算，产生True或者False为元素的数组</td></tr><tr><td>logical_and、logical_or、logical_xor</td><td>元素级的逻辑判断(且、或者、不等于)</td></tr></tbody></table></div><h3 id="1-4-数组array集合运算"><a href="#1-4-数组array集合运算" class="headerlink" title="1.4 数组array集合运算"></a>1.4 数组array集合运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">10</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>])</span><br><span class="line">y = np.array([<span class="number">100</span>,<span class="number">20</span>,<span class="number">40</span>,<span class="number">10</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">print(<span class="string">'数组x中的唯一元素：\n'</span>,np.unique(x))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'数组x和y的公共元素：\n'</span>,np.intersect1d(x,y))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'数组x和y的并集：\n'</span>,np.union1d(x,y))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'数组x中的元素是否包含于y：\n'</span>,np.in1d(x,y))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'集合差_在x中而不在y中的元素：\n'</span>,np.setdiff1d(x,y))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'只存在某个数组中，而不同时存在于两个数组中：\n'</span>,np.setxor1d(x,y))</span><br></pre></td></tr></table></figure><pre><code>数组x中的唯一元素： [ 1  2  3  4  5 10 20 30]数组x和y的公共元素： [ 1  2  3 10 20]数组x和y的并集： [  1   2   3   4   5  10  20  30  40 100]数组x中的元素是否包含于y： [ True  True  True  True  True  True False False  True  True  True False]集合差_在x中而不在y中的元素： [ 4  5 30]只存在某个数组中，而不同时存在于两个数组中： [  4   5  30  40 100]</code></pre><h3 id="1-5-数组array切片进阶"><a href="#1-5-数组array切片进阶" class="headerlink" title="1.5 数组array切片进阶"></a>1.5 数组array切片进阶</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#还是以000001收盘价为例</span></span><br><span class="line">a1</span><br></pre></td></tr></table></figure><pre><code>array([8.6 , 8.66, 9.03, 8.98, 8.78])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果我们想 按偶数来选取 即选择数组中的0,2,4,6,8</span></span><br><span class="line">print(a1[::<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果想 按奇数来选择呢</span></span><br><span class="line">print(a1[<span class="number">1</span>::<span class="number">2</span>]) <span class="comment">#这里的1表示从索引1开始截取</span></span><br></pre></td></tr></table></figure><p>氦核：上面片段中的2代表步长。</p><pre><code>[8.6  9.03 8.78][8.66 8.98]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#我们取多个指标看一下</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#五粮液</span></span><br><span class="line"><span class="keyword">from</span> WindPy <span class="keyword">import</span> *</span><br><span class="line">w.start()</span><br><span class="line">w = w.wsd(<span class="string">"000858.SZ"</span>, <span class="string">"open,high,low,close,pct_chg"</span>, <span class="string">"2018-07-05"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>)</span><br><span class="line">w</span><br></pre></td></tr></table></figure><p>氦核：开，高，低，收。</p><pre><code>.ErrorCode=0.Codes=[000858.SZ].Fields=[OPEN,HIGH,LOW,CLOSE,PCT_CHG].Times=[20180705,20180706,20180709,20180710,20180711].Data=[[71.69,69.9,71.58,73.57,71.2],[72.71,71.98,73.55,74.13,72.64],[69.7,68.88,70.4,72.08,70.93],[70.82,70.62,73.54,73.37,72.08],[0.16973125884014886,1.5822798147378172,4.134806003964902,-0.23116671199347652,-1.7582118031893383]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w1 = np.array(w.Data)</span><br><span class="line">w1</span><br></pre></td></tr></table></figure><pre><code>array([[71.69      , 69.9       , 71.58      , 73.57      , 71.2       ],       [72.71      , 71.98      , 73.55      , 74.13      , 72.64      ],       [69.7       , 68.88      , 70.4       , 72.08      , 70.93      ],       [70.82      , 70.62      , 73.54      , 73.37      , 72.08      ],       [ 0.16973126,  1.58227981,  4.134806  , -0.23116671, -1.7582118 ]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'截取第1行第4,5个元素：\n'</span>,w1[<span class="number">0</span>, <span class="number">3</span>:<span class="number">5</span>])</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'截取第5行至最后，第5列至最后的元素：\n'</span>,w1[<span class="number">4</span>:, <span class="number">4</span>:])</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'截取第3，5行，第1,3,5列\n'</span>,w1[<span class="number">2</span>::<span class="number">2</span>, ::<span class="number">2</span>])</span><br></pre></td></tr></table></figure><pre><code>截取第1行第4,5个元素： [73.57 71.2 ]截取第5行至最后，第5列至最后的元素： [[-1.7582118]]截取第3，5行，第1,3,5列 [[69.7        70.4        70.93      ] [ 0.16973126  4.134806   -1.7582118 ]]</code></pre><h3 id="1-6-数组排序"><a href="#1-6-数组排序" class="headerlink" title="1.6 数组排序"></a>1.6 数组排序</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> WindPy <span class="keyword">import</span> *</span><br><span class="line">w.start()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 000001.SZ收益率为例</span></span><br><span class="line">sy = w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"pct_chg"</span>, <span class="string">"2018-07-05"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>)</span><br><span class="line">sy</span><br></pre></td></tr></table></figure><pre><code>.ErrorCode=0.Codes=[000001.SZ].Fields=[PCT_CHG].Times=[20180705,20180706,20180709,20180710,20180711].Data=[[-0.11614401858303243,0.6976744186046501,4.272517321016162,-0.5537098560354228,-2.2271714922049117]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sy2 = np.array(sy.Data[<span class="number">0</span>])</span><br><span class="line">sy2</span><br></pre></td></tr></table></figure><pre><code>array([-0.11614402,  0.69767442,  4.27251732, -0.55370986, -2.22717149])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对一个数组array，想找到其中大于0的数所在的索引位置 可以用where函数</span></span><br><span class="line">print(<span class="string">'大于0元素所在的索引：\n'</span>,np.where(sy2&gt;<span class="number">0</span>))</span><br></pre></td></tr></table></figure><pre><code>大于0元素所在的索引： (array([1, 2], dtype=int64),)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于exp这个数组，希望对其按元素大小进行排序</span></span><br><span class="line">print(<span class="string">'从小到大排序：\n'</span>,np.sort(sy2))</span><br></pre></td></tr></table></figure><pre><code>从小到大排序： [-2.22717149 -0.55370986 -0.11614402  0.69767442  4.27251732]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'排序后元素所在的原索引位置'</span>,np.argsort(sy2))</span><br></pre></td></tr></table></figure><pre><code>排序后元素所在的原索引位置 [4 3 0 1 2]</code></pre><h3 id="1-7-数组拼接"><a href="#1-7-数组拼接" class="headerlink" title="1.7 数组拼接"></a>1.7 数组拼接</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a1</span><br></pre></td></tr></table></figure><pre><code>array([8.6 , 8.66, 9.03, 8.98, 8.78])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a3 = np.array(w.wsd(<span class="string">"000858.SZ"</span>, <span class="string">"close"</span>, <span class="string">"2018-07-05"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>).Data)[<span class="number">0</span>]</span><br><span class="line">a3</span><br></pre></td></tr></table></figure><pre><code>array([70.82, 70.62, 73.54, 73.37, 72.08])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'纵向拼接:\n'</span>,np.vstack((a1,a3)))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'横向拼接:\n'</span>,np.hstack((a1,a3)))</span><br></pre></td></tr></table></figure><pre><code>纵向拼接: [[ 8.6   8.66  9.03  8.98  8.78] [70.82 70.62 73.54 73.37 72.08]]横向拼接: [ 8.6   8.66  9.03  8.98  8.78 70.82 70.62 73.54 73.37 72.08]</code></pre><p>使用np.r_和np.c_也可以实现拼接的功能</p><p>注意纵向拼接的时候，np.c_产生的结果是5∗2，而np.r_产生的结果是2∗5</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'横向拼接：\n'</span>,np.r_[a1,a3])</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'纵向拼接：\n'</span>,np.c_[a1,a3])</span><br></pre></td></tr></table></figure><pre><code>横向拼接： [ 8.6   8.66  9.03  8.98  8.78 70.82 70.62 73.54 73.37 72.08]纵向拼接： [[ 8.6  70.82] [ 8.66 70.62] [ 9.03 73.54] [ 8.98 73.37] [ 8.78 72.08]]</code></pre><h3 id="1-8-数组分解"><a href="#1-8-数组分解" class="headerlink" title="1.8 数组分解"></a>1.8 数组分解</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a4 = np.array(w.wsd(<span class="string">"000858.SZ"</span>, <span class="string">"close,open,low"</span>, <span class="string">"2018-07-05"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>).Data)</span><br><span class="line">a4</span><br></pre></td></tr></table></figure><pre><code>array([[70.82, 70.62, 73.54, 73.37, 72.08],       [71.69, 69.9 , 71.58, 73.57, 71.2 ],       [69.7 , 68.88, 70.4 , 72.08, 70.93]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'横向分解为5个数组：\n'</span>,np.hsplit(a4,<span class="number">5</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'纵向分解为3个数组：\n'</span>,np.vsplit(a4,<span class="number">3</span>))</span><br></pre></td></tr></table></figure><pre><code>横向分解为5个数组： [array([[70.82],       [71.69],       [69.7 ]]), array([[70.62],       [69.9 ],       [68.88]]), array([[73.54],       [71.58],       [70.4 ]]), array([[73.37],       [73.57],       [72.08]]), array([[72.08],       [71.2 ],       [70.93]])]纵向分解为3个数组： [array([[70.82, 70.62, 73.54, 73.37, 72.08]]), array([[71.69, 69.9 , 71.58, 73.57, 71.2 ]]), array([[69.7 , 68.88, 70.4 , 72.08, 70.93]])]</code></pre><h2 id="二、常用数组"><a href="#二、常用数组" class="headerlink" title="二、常用数组"></a>二、常用数组</h2><p>在工作或者学习中，有些数组是我们常用的，利用numpy中的函数可以容易地产生这些数组。</p><h3 id="2-1-np-arange-起始数，终止数，间隔"><a href="#2-1-np-arange-起始数，终止数，间隔" class="headerlink" title="2.1 np.arange(起始数，终止数，间隔)"></a>2.1 np.arange(起始数，终止数，间隔)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># np.arange()函数 终止数并不产生 </span></span><br><span class="line">print(np.arange(<span class="number">1</span>,<span class="number">10</span>,<span class="number">1</span>)) </span><br><span class="line">print()</span><br><span class="line">print(np.arange(<span class="number">1</span>,<span class="number">10</span>,<span class="number">0.1</span>))</span><br></pre></td></tr></table></figure><pre><code>[1 2 3 4 5 6 7 8 9][1.  1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.  2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 3.  3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9 4.  4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9 5.  5.1 5.2 5.3 5.4 5.5 5.6 5.7 5.8 5.9 6.  6.1 6.2 6.3 6.4 6.5 6.6 6.7 6.8 6.9 7.  7.1 7.2 7.3 7.4 7.5 7.6 7.7 7.8 7.9 8.  8.1 8.2 8.3 8.4 8.5 8.6 8.7 8.8 8.9 9.  9.1 9.2 9.3 9.4 9.5 9.6 9.7 9.8 9.9]</code></pre><h3 id="2-2-np-linspace-起始数-终止数-产生数的个数"><a href="#2-2-np-linspace-起始数-终止数-产生数的个数" class="headerlink" title="2.2 np.linspace(起始数,终止数,产生数的个数)"></a>2.2 np.linspace(起始数,终止数,产生数的个数)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在指定区间返回均匀间隔的数字</span></span><br><span class="line">print(np.linspace(<span class="number">1</span>,<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">print()</span><br><span class="line">print(np.linspace(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">20</span>))</span><br><span class="line"><span class="comment"># np.linspace()函数 终止数是产生的</span></span><br></pre></td></tr></table></figure><pre><code>[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.][-1.         -0.89473684 -0.78947368 -0.68421053 -0.57894737 -0.47368421 -0.36842105 -0.26315789 -0.15789474 -0.05263158  0.05263158  0.15789474  0.26315789  0.36842105  0.47368421  0.57894737  0.68421053  0.78947368  0.89473684  1.        ]</code></pre><h3 id="2-3-常用矩阵"><a href="#2-3-常用矩阵" class="headerlink" title="2.3 常用矩阵"></a>2.3 常用矩阵</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'元素都为1的方阵：\n'</span>,np.ones((<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'元素都为0的方阵：\n'</span>,np.zeros((<span class="number">3</span>,<span class="number">3</span>)))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'单位阵：\n'</span>,np.eye(<span class="number">3</span>))</span><br></pre></td></tr></table></figure><pre><code>元素都为1的方阵： [[1. 1. 1.] [1. 1. 1.] [1. 1. 1.]]元素都为0的方阵： [[0. 0. 0.] [0. 0. 0.] [0. 0. 0.]]单位阵： [[1. 0. 0.] [0. 1. 0.] [0. 0. 1.]]</code></pre><h3 id="2-4-np-tile-函数"><a href="#2-4-np-tile-函数" class="headerlink" title="2.4 np.tile()函数"></a>2.4 np.tile()函数</h3><p>该函数的作用是重复某个对象为一定的结构</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">short = np.arange(<span class="number">1</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line">print(short)</span><br><span class="line">long = np.tile(short,<span class="number">3</span>)</span><br><span class="line">print(long)</span><br></pre></td></tr></table></figure><pre><code>[1 2 3][1 2 3 1 2 3 1 2 3]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">small = np.eye(<span class="number">2</span>)</span><br><span class="line">print(small)</span><br><span class="line">big = np.tile(small, (<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">print(big)</span><br></pre></td></tr></table></figure><pre><code>[[1. 0.] [0. 1.]][[1. 0. 1. 0.] [0. 1. 0. 1.] [1. 0. 1. 0.] [0. 1. 0. 1.]]</code></pre><h2 id="三、Numpy常用常量"><a href="#三、Numpy常用常量" class="headerlink" title="三、Numpy常用常量"></a>三、Numpy常用常量</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'自然底数：'</span>,np.e)</span><br><span class="line">print(<span class="string">'缺失值：'</span>,np.NaN)</span><br><span class="line">print(<span class="string">'无穷大：'</span>,np.inf)</span><br><span class="line">print(<span class="string">'圆周率：'</span>,np.pi)</span><br></pre></td></tr></table></figure><pre><code>自然底数： 2.718281828459045缺失值： nan无穷大： inf圆周率： 3.141592653589793</code></pre><h2 id="四、Numpy随机数产生"><a href="#四、Numpy随机数产生" class="headerlink" title="四、Numpy随机数产生"></a>四、Numpy随机数产生</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'一维正态随机数：\n'</span>,np.random.randn(<span class="number">5</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'二维正态随机数：\n'</span>,np.random.randn(<span class="number">2</span>,<span class="number">2</span>)) </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'二维0-1均匀分布随机数：\n'</span>,np.random.rand(<span class="number">2</span>,<span class="number">2</span>))   </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'5个10-20的均匀随机整数：'</span>,np.random.randint(<span class="number">10</span>,<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'二维均匀随机整数：\n'</span>,np.random.randint(<span class="number">10</span>,<span class="number">50</span>,(<span class="number">2</span>,<span class="number">2</span>)))</span><br></pre></td></tr></table></figure><pre><code>一维正态随机数： [-0.65240628  1.07426523 -0.86730208 -0.91339241  1.20066541]二维正态随机数： [[ 0.9663628  -1.32891237] [-0.54264665 -1.29035995]]二维0-1均匀分布随机数： [[0.52527192 0.17719291] [0.10103986 0.41623399]]5个10-20的均匀随机整数： [17 18 14 12 11]二维均匀随机整数： [[38 24] [24 38]]</code></pre><p><strong>numpy.random函数</strong></p><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>seed</td><td>随机数生成器的种子</td></tr><tr><td>permutation</td><td>序列的随机排列或者随机排列的范围，不改变原数组</td></tr><tr><td>shuffle</td><td>序列就地随机排列，改变原数组</td></tr><tr><td>rand</td><td>均匀分布样本值</td></tr><tr><td>randint</td><td>给定上下限随机产生整数</td></tr><tr><td>randn</td><td>正态分布样本值</td></tr><tr><td>binomial</td><td>二项分布样本值</td></tr><tr><td>normal</td><td>正态分布样本值</td></tr><tr><td>beta</td><td>beta分布样本值</td></tr><tr><td>chisquare</td><td>卡方分布样本值</td></tr><tr><td>gamma</td><td>Gamma分布样本值</td></tr><tr><td>uniform</td><td>[0,1)均匀分布样本值</td></tr><tr><td>choice</td><td>从数组中随机选择若干个元素</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = np.arange(<span class="number">1</span>,<span class="number">11</span>,<span class="number">1</span>)</span><br><span class="line">print(a)</span><br><span class="line">np.random.shuffle(a)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'随机打乱a中的元素顺序：\n'</span>,a)</span><br></pre></td></tr></table></figure><pre><code>[ 1  2  3  4  5  6  7  8  9 10]随机打乱a中的元素顺序： [10  3  2  6  1  9  8  7  4  5]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(a)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'随机从a中选取5个元素：\n'</span>,np.random.choice(a,<span class="number">5</span>))</span><br></pre></td></tr></table></figure><pre><code>[10  3  2  6  1  9  8  7  4  5]随机从a中选取5个元素： [5 3 8 9 4]</code></pre><h2 id="五、Numpy矩阵性质"><a href="#五、Numpy矩阵性质" class="headerlink" title="五、Numpy矩阵性质"></a>五、Numpy矩阵性质</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">print(<span class="string">'原矩阵：\n'</span>,x)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵对角线：\n'</span>,np.diag(x))  </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵上三角：\n'</span>,np.triu(x))  </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵下三角：\n'</span>,np.tril(x))  </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵的迹：\n'</span>,np.trace(x))  </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵的转置：\n'</span>,x.T)</span><br></pre></td></tr></table></figure><pre><code>原矩阵： [[4 3 6] [2 7 1] [2 3 8]]矩阵对角线： [4 7 8]矩阵上三角： [[4 3 6] [0 7 1] [0 0 8]]矩阵下三角： [[4 0 0] [2 7 0] [2 3 8]]矩阵的迹： 19矩阵的转置： [[4 2 2] [3 7 3] [6 1 8]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = np.random.randint(<span class="number">1</span>,<span class="number">10</span>,(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">print(<span class="string">'原矩阵：\n'</span>,x)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵元素向右循环移动2位：\n'</span>,np.roll(x,<span class="number">2</span>))</span><br></pre></td></tr></table></figure><pre><code>原矩阵： [[1 1 6] [7 3 3] [7 6 5]]矩阵元素向右循环移动2位： [[6 5 1] [1 6 7] [3 3 7]]</code></pre><h2 id="六、Numpy矩阵运算"><a href="#六、Numpy矩阵运算" class="headerlink" title="六、Numpy矩阵运算"></a>六、Numpy矩阵运算</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># numpy下的子模块linalg是一个线性代数运算库，关于矩阵运算主要使用该库来完成</span></span><br><span class="line"><span class="keyword">import</span> numpy.linalg <span class="keyword">as</span> la</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以000001行情数据为例</span></span><br><span class="line">a5 = np.array(w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"close,open,low"</span>, <span class="string">"2018-07-08"</span>, <span class="string">"2018-07-11"</span>, <span class="string">""</span>).Data)</span><br><span class="line">a5</span><br></pre></td></tr></table></figure><pre><code>array([[9.03, 8.98, 8.78],       [8.69, 9.02, 8.76],       [8.68, 8.89, 8.68]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'原矩阵：\n'</span>,a5)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵的行列式：\n'</span>,la.det(a5)) </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵的逆：\n'</span>,la.inv(a5)) </span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵的特征值分解：\n'</span>,la.eig(a5))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">'矩阵的奇异值分解：\n'</span>,la.svd(a5))</span><br></pre></td></tr></table></figure><pre><code>原矩阵： [[9.03 8.98 8.78] [8.69 9.02 8.76] [8.68 8.89 8.68]]矩阵的行列式： 0.0967539999999976矩阵的逆： [[  4.31196643   1.11416582  -5.48607809] [  6.27984373  22.42801331 -28.98691527] [-10.74374186 -24.08479236  35.28949708]]矩阵的特征值分解： (array([2.65036938e+01, 2.08824580e-01, 1.74815890e-02]), array([[-0.58362007, -0.78625042, -0.09211654],       [-0.57657184,  0.5886538 , -0.64732544],       [-0.57179763,  0.18787491,  0.75662693]]))矩阵的奇异值分解： (array([[-0.58355077,  0.78217367, -0.21834112],       [-0.5766266 , -0.58842029, -0.56680096],       [-0.57181314, -0.20485584,  0.79439526]]), array([2.65057682e+01, 2.11310491e-01, 1.72745790e-02]), array([[-0.57510827, -0.58571691, -0.57112711],       [ 0.81163598, -0.49595222, -0.30867203],       [-0.10245733, -0.64106715,  0.76061515]]))</code></pre><p><strong>numpy.linalg函数</strong></p><div class="table-container"><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>diag</td><td>以一维数组的形式返回方阵的对角线元素或将一维数组转化为方阵</td></tr><tr><td>dot、trace、det</td><td>矩阵乘法、矩阵的迹运算、矩阵行列式</td></tr><tr><td>eig、inv、pinv</td><td>方阵的特征值和特征向量、方阵的逆、矩阵的Moore-Penrose伪逆</td></tr><tr><td>qr、svd</td><td>矩阵的QR分解、奇异值分解</td></tr><tr><td>solve</td><td>解线性方程组 $𝑋\beta = 𝑦$，其中$𝑋$为方阵</td></tr><tr><td>lstsq</td><td>计算$𝑋\beta = 𝑦$的最小二乘解</td></tr></tbody></table></div><h2 id="七、多项式曲线拟合"><a href="#七、多项式曲线拟合" class="headerlink" title="七、多项式曲线拟合"></a>七、多项式曲线拟合</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt   <span class="comment"># 导入作图库  为了更好展示曲线拟合的结果</span></span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br></pre></td></tr></table></figure><p>例如，对于下面的这些散点进行多项式拟合。观察散点的形态，采用直线取拟合</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = np.linspace(<span class="number">-10</span>,<span class="number">10</span>,<span class="number">100</span>)</span><br><span class="line">y = <span class="number">2</span>*x + <span class="number">1</span> + np.random.randn(<span class="number">100</span>)*<span class="number">2</span></span><br><span class="line">fig = plt.subplots(figsize=(<span class="number">14</span>,<span class="number">8</span>))</span><br><span class="line">plt.plot(x, y, <span class="string">'rx'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="/2020/02/05/200205numpy/02/05/200205numpy/tu1.png" title="图1"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> polyfit,poly1d</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">coef_fit = polyfit(x, y, <span class="number">1</span>)  <span class="comment">#进行线性拟合 1代表的是多项式拟合的多项式的阶数  这里指的是线性拟合</span></span><br><span class="line">coef_fit    <span class="comment">#查看拟合的系数</span></span><br></pre></td></tr></table></figure><pre><code>array([1.96386726, 1.11375232])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.subplots(figsize=(<span class="number">14</span>,<span class="number">8</span>))</span><br><span class="line">plt.plot(x, y, <span class="string">'rx'</span>,label=<span class="string">'真实散点'</span>)</span><br><span class="line">plt.plot(x, coef_fit[<span class="number">0</span>] * x + coef_fit[<span class="number">1</span>], <span class="string">'k-'</span>,label=<span class="string">'拟合直线'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 30495 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 23454 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 25955 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 28857 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 25311 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 21512 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 30452 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:211: RuntimeWarning: Glyph 32447 missing from current font.  font.set_text(s, 0.0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 30495 missing from current font.  font.set_text(s, 0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 23454 missing from current font.  font.set_text(s, 0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 25955 missing from current font.  font.set_text(s, 0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 28857 missing from current font.  font.set_text(s, 0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 25311 missing from current font.  font.set_text(s, 0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 21512 missing from current font.  font.set_text(s, 0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 30452 missing from current font.  font.set_text(s, 0, flags=flags)D:\anaconda\lib\site-packages\matplotlib\backends\backend_agg.py:180: RuntimeWarning: Glyph 32447 missing from current font.  font.set_text(s, 0, flags=flags)</code></pre><img src="/2020/02/05/200205numpy/02/05/200205numpy/tu2.png" title="图2"><p>从上图可以看到，直线拟合的结果还是比较好的（报错可能是汉字bug</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">f = poly1d(coef_fit)   <span class="comment">#也可以直接产生拟合的函数解析式</span></span><br><span class="line">print(<span class="string">'拟合函数：'</span>,f)</span><br></pre></td></tr></table></figure><pre><code>拟合函数：  1.964 x + 1.114</code></pre><p>氦核：numpy库很有“大计算器”的味道了，其实不会用的时候再去查也可以，主要是应该了解有什么基础功能，否则就会出现“自己实现某些基础算法”的乌龙（某种意义上也是好事，笑）。一起加油吧。</p><p>（完）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最后编辑于：2020.02.05 12:30&lt;/p&gt;
&lt;h2 id=&quot;Numpy库&quot;&gt;&lt;a href=&quot;#Numpy库&quot; class=&quot;headerlink&quot; title=&quot;Numpy库&quot;&gt;&lt;/a&gt;Numpy库&lt;/h2&gt;&lt;p&gt;Numpy库是Python的一种开源的数值计算扩展。&lt;/p&gt;
&lt;p&gt;Numpy可用来存储和处理大型矩阵，比Python自身的嵌套列表结构要高效很多。&lt;/p&gt;
&lt;p&gt;据说Numpy将Pyhon变成了一种免费的更强大的Matlab系统。&lt;/p&gt;
&lt;p&gt;本文介绍性文字转载自&lt;a href=&quot;https://www.windquant.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;万旷网&lt;/a&gt;。氦核感觉notebook形式更适合学习，有机会把丘比特文件给大家附上。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据分析" scheme="https://konelane.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>python联萌|初探WindAPI</title>
    <link href="https://konelane.github.io/2020/02/01/20200201WindAPI/"/>
    <id>https://konelane.github.io/2020/02/01/20200201WindAPI/</id>
    <published>2020-01-31T16:00:00.000Z</published>
    <updated>2020-02-05T04:31:48.447Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最后编辑于：2020.02.05 12:30</p><h2 id="Wind-API使用说明"><a href="#Wind-API使用说明" class="headerlink" title="Wind API使用说明"></a>Wind API使用说明</h2><p>windAPI是一个很好的工具，可以不通过客户端获取数据（不过前提是要有土豪的账号加持，笑）本文大部分介绍性文字转载自<a href="https://www.windquant.com/" target="_blank" rel="noopener">万旷网</a>。本文的分析全部通过python完成。配置安装略过不表，请致电客服经理小哥哥（声音奶声奶气有点温柔！</p><a id="more"></a><h2 id="0-综述"><a href="#0-综述" class="headerlink" title="0. 综述"></a>0. 综述</h2><p>目前万矿网支持的API函数有：</p><p>1、WSD日期序列函数：支持股票、债券、基金、期货、指数等多种证券的基本资料、股东信息、市场行情、证券分析、预测评级、财务数据等各种数据。WSD可以支持取 <code>多品种单指标</code> 或者 <code>单品种多指标</code> 的时间序列数据。（氦核：可以说是最重要的函数）</p><p>2、WSS多维函数：同样支持股票、债券、基金、期货、指数等多种证券的基本资料、股东信息、市场行情、证券分析、预测评级、财务数据等各种数据。但是WSS支持取多品种多指标某个时间点的截面数据。</p><p>3、WSQ行情数据函数：支持股票、债券、基金、期货、指数等多种证券品种的实时行情数据，既可以选择获取一次性的快照数据，也可以选择订阅数据（即交易所有新的行情就推送）。</p><p>4、WSET数据集：支持股票、债券、基金、期货、指数等多种证券品种板块成分、指数历史成分股以及权重，以及各种市场常用报表的获取。</p><p>5、TDays 日期函数：日期函数包含日期序列函数（TDays)、日期偏移函数(TDaysOffset) 以及日期区间统计函数（TDaysCount）。</p><p>下面为大家介绍各个函数的详细用法。</p><p>注： 建议用户在使用取数函数时<strong>直接借助API函数</strong>生成相应的取数代码，然后修改其中的参数使其满足自己的取数需求。(氦核注：这个很好使，点点点就能拿到代码。)</p><h2 id="1-WSD日期序列函数"><a href="#1-WSD日期序列函数" class="headerlink" title="1. WSD日期序列函数"></a>1. WSD日期序列函数</h2><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>该命令用来获取选定证券品种的历史序列数据，包括日间的行情数据、基本面数据以及技术数据指标。（氦核注：有些数据被限制获取的数量了，有些是最多五十个，这倒是很不方便。如果看实盘还好，但是做分析就不舒服了。）</p><h4 id="函数输入"><a href="#函数输入" class="headerlink" title="函数输入"></a>函数输入</h4><p>WSD函数结构 w.wsd（security,fields,startdate,enddate,option）</p><div class="table-container"><table><thead><tr><th></th><th>Element</th><th>Type</th><th>Description</th><th></th></tr></thead><tbody><tr><td><strong>证券（必选）</strong></td><td>Security</td><td>String</td><td>获取数据的证券列表</td><td>范例1：’600030.SH’说明：证券列表支持Wind代码及证券转换类工具函数输出的Wind代码结果</td></tr><tr><td><strong>指标（必选）</strong></td><td>Fields</td><td>String</td><td>获取数据的指标列表</td><td>范例1：’CLOSE,HIGH,LOW,OPEN’</td></tr><tr><td><strong>起始日期（必选）</strong></td><td>StartDate</td><td></td><td>时间序列的起始日期</td><td>范例1：’2017-01-01’,’-5w’说明：支持日期类工具函数输出的标准日期结果，支持相对日期宏表达方式，日期宏具体使用方式参考’日期宏’部分内容</td></tr><tr><td><strong>截止日期（必选）</strong></td><td>EndDate</td><td></td><td>时间序列的截止日期，若为空默认为系统当前日期</td><td>范例1：’2017-05-30’，Sys.Date()，支持相对日期，比如’0w’; 不输入的话为当前时间说明：支持日期类工具函数输出的标准日期结果，支持相对日期宏表达方式</td></tr><tr><td>指标参数（可选）</td><td>Parameter/Value</td><td>String</td><td>提取指标时使用的参数名/指定参数的值</td><td>范例：’TRADE_DATE=20110301;FUND_DATE=20101231’说明：多指标参数支持在不同引号内分开取值</td></tr><tr><td>变频参数（可选）</td><td>Period</td><td>String</td><td>每天一值:D/每周一值:W/每月一值:M/每季度一值:Q/每半年一值:S/每年一值:Y</td><td>范例：’Period=D’ ，默认Period=D</td></tr><tr><td>输出日期（可选）</td><td>Days</td><td>String</td><td>所有工作日:Weekdays/所有日历日:Alldays/排除所有非交易日:Trading</td><td>范例：’Days=Trading’，默认Days=Trading</td></tr><tr><td>填充方式（可选）</td><td>Fill</td><td>String</td><td>沿用之前数据:Previous/返回空值:Blank</td><td>范例：’Fill=Previous’，默认Fill=Blank</td></tr><tr><td>日期排序（可选）</td><td>Order</td><td>String</td><td>升序:A/ 降序:D，最近日期在先</td></tr><tr><td>交易日历（可选）</td><td>TradingCalendar</td><td>String</td><td>选择不同交易所所在国家地区日历</td><td>范例1：’ TradingCalendar =SSE’，默认TradingCalendar =SSE;SSE表示上交所，SZSE表示深圳证券交易所，CFFE表示中金所……</td></tr><tr><td>输出币种（可选）</td><td>Currency</td><td>String</td><td>使用货币设置： ORIGINAL:原始货币/HKD：港币/USD：美元/CNY：人民币</td><td>范例1：’Currency =Original’，默认Currency =Original</td></tr></tbody></table></div><p>关于指标参数的详细说明见 <strong>7.指标常见参数说明</strong></p><h4 id="函数输出"><a href="#函数输出" class="headerlink" title="函数输出"></a>函数输出</h4><div class="table-container"><table><thead><tr><th></th><th>输出内容</th><th>说明</th></tr></thead><tbody><tr><td>错误ID</td><td>ErrorCode</td><td>返回值为0 ，则表示代码运行正常。若为其他则需查找原因</td></tr><tr><td>数据列表</td><td>Data</td><td>函数读取的数据存到此列表中，比如：读取000592.SZ 的close,open指标从’2017-05-08’到’2017-05-18’区间的数据.Data=[[5.12,5.16,5.02,4.9,4.91,5.13,5.35,5.42,5.32],[5.3,5.12,5.17,4.98,4.94,4.93,5.1,5.4,5.4]]</td></tr><tr><td>证券代码列表</td><td>Codes</td><td>输入的证券代码列表 .Codes=[000592.SZ]</td></tr><tr><td>字段列表</td><td>Field</td><td>函数输入中请求的字段列表 .Fields=[CLOSE,OPEN]</td></tr><tr><td>时间列表</td><td>Times</td><td>输出时间序列.Times=[20170508,20170509,20170510,20170511,20170512,20170515,20170516,20170517,20170518]</td></tr></tbody></table></div><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载相关的包</span></span><br><span class="line"><span class="keyword">from</span> WindPy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">w.start()</span><br></pre></td></tr></table></figure><p>w.start是启动函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例1、 取富士康概念股近七个交易日的每天机构资金流入额</span></span><br><span class="line">date=time.strftime(<span class="string">"%Y-%m-%d"</span>, time.localtime()) </span><br><span class="line">stock=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date="</span>+date+<span class="string">";sectorid=1000011346000000"</span>).Data[<span class="number">1</span>]  <span class="comment">#富士康概念股最新板块成分</span></span><br><span class="line">buyamt=w.wsd(stock, <span class="string">"mfd_buyamt_d"</span>, <span class="string">"ED-7TD"</span>, date, <span class="string">"unit=1;traderType=1"</span>) <span class="comment">#traderType表示类型，如机构、大户、中户、散户，具体参数设置可以借助API函数了解</span></span><br><span class="line">buyamt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(buyamt.Data,index=stock,columns=buyamt.Times).T</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例2、 任取一只国债010107.SH六月份以来的净值历史行情数据</span></span><br><span class="line">history_data=w.wsd(<span class="string">"010107.SH"</span>, <span class="string">"sec_name,ytm_b,volume,duration,convexity,open,high,low,close,vwap"</span>, <span class="string">"2018-06-01"</span>, <span class="string">"2018-06-11"</span>, <span class="string">"returnType=1;PriceAdj=CP"</span>) <span class="comment"># returnType表示到期收益率计算方法，PriceAdj表示债券价格类型‘</span></span><br><span class="line"><span class="comment">#pd.DataFrame(history_data.Data,index=history_data.Fields,columns=history_data.Times).T</span></span><br><span class="line">pd.DataFrame(history_data.Data,index=[<span class="string">"中文简称"</span>,<span class="string">"YTM"</span>,<span class="string">"成交量"</span>,<span class="string">"久期"</span>,<span class="string">"凸性"</span>,<span class="string">"开盘价"</span>,<span class="string">"最高价"</span>,<span class="string">"最低价"</span>,<span class="string">"收盘价"</span>,<span class="string">"均价"</span>],columns=history_data.Times).T</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例3、 取国内所有农产品主力合约不同日期所对应的具体合约</span></span><br><span class="line">future=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date="</span>+date+<span class="string">";sectorid=1000009337000000"</span>) <span class="comment">#农产品主力合约板块</span></span><br><span class="line">tradecode=w.wsd(future.Data[<span class="number">1</span>], <span class="string">"trade_hiscode"</span>, <span class="string">"2018-01-01"</span>, <span class="string">"2018-06-11"</span>, <span class="string">""</span>)</span><br><span class="line">pd.DataFrame(tradecode.Data,index=future.Data[<span class="number">2</span>],columns=tradecode.Times).T</span><br></pre></td></tr></table></figure><h2 id="2-WSS多维数据函数"><a href="#2-WSS多维数据函数" class="headerlink" title="2. WSS多维数据函数"></a>2. WSS多维数据函数</h2><h4 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h4><p>命令用来获取选定证券品种的历史截面数据</p><p>命令原型为：data= w.wss(品种代码,指标,可选参数)</p><h4 id="函数输入-1"><a href="#函数输入-1" class="headerlink" title="函数输入"></a>函数输入</h4><p>WSS函数输入 w.wss（security,fields, option）</p><div class="table-container"><table><thead><tr><th></th><th>Element</th><th>Type</th><th>Description</th><th></th></tr></thead><tbody><tr><td>证券（必选）</td><td>Security</td><td>String</td><td>获取数据的证券列表</td><td>范例：’600030.SH,600031.SH 说明：证券列表支持Wind代码及证券转换类工具函数输出的Wind代码结果</td></tr><tr><td>指标（必选）</td><td>Fields</td><td>String</td><td>获取数据的指标列表</td><td>范例1：’CLOSE,HIGH,LOW,OPEN’ 范例2：[‘CLOSE’,’HIGH’,’LOW’,’OPEN’]</td></tr><tr><td>指标参数（可选）</td><td>Parameter/Value</td><td>String</td><td>提取指标时使用的参数名/指定参数的值</td><td>范例：’TRADE_DATE=20170601;FUND_DATE=’20161231’ 说明：多指标参数支持在不同引号内分开取值</td></tr><tr><td>输出币种（可选）</td><td>Currency</td><td>String</td><td>使用什么货币 ORIGINAL/HKD/USD/CNY</td><td>范例：’Currency =Original’，默认Currency =Original</td></tr></tbody></table></div><p>关于指标参数的详细说明见 7.指标常见参数说明</p><h4 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例4、 取A股纳入MSCI各成分股的基本资料信息</span></span><br><span class="line">MSCI_stock=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date="</span>+date+<span class="string">";sectorid=1000027970000000"</span>)</span><br><span class="line">infor=w.wss(MSCI_stock.Data[<span class="number">1</span>] , <span class="string">"sec_name,ipo_date,mkt,stockclass,industry_sw,indexcode_sw,SHSC,SHSC2"</span>,<span class="string">"tradeDate="</span>+date+<span class="string">";industryType=1"</span>)</span><br><span class="line">pd.DataFrame(infor.Data,index=infor.Fields,columns=MSCI_stock.Data[<span class="number">1</span>]).T</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例5、 取截止日期 上海证券交易所 发行的国债 基本资料</span></span><br><span class="line">bond=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date=2018-06-11;sectorid=a101010201000000"</span>).Data[<span class="number">1</span>]</span><br><span class="line">error_code,bond_data=w.wss(bond, <span class="string">"sec_name,issueamount,term,issue_issueprice,couponrate,coupon,interesttype,interestfrequency,carrydate,maturitydate,ptmyear,trade_status"</span>,<span class="string">"unit=1;tradeDate=20180611"</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">bond_data.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例6、 取被动指数型基金最新业绩排名</span></span><br><span class="line">fund=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date=2018-06-11;sectorid=2001010102000000"</span>).Data[<span class="number">1</span>]</span><br><span class="line">error_code,returns=w.wss(fund, <span class="string">"sec_name,return_1w,return_1m,return_3m,return_6m,return_1y,return_ytd,fund_fundmanager"</span>,<span class="string">"annualized=0;tradeDate=20180611"</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">returns.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按今年以来总回报排序</span></span><br><span class="line">returns_sort=returns.sort_values(by = <span class="string">'RETURN_YTD'</span>,ascending=<span class="keyword">False</span>) </span><br><span class="line">returns_sort.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">first_fund=list(returns_sort.index.values)</span><br><span class="line">first_fund[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> WindCharts <span class="keyword">import</span> *</span><br><span class="line">error_code,nav=w.wsd(first_fund[<span class="number">0</span>], <span class="string">"NAV_adj"</span>, <span class="string">'2017-01-01'</span>, <span class="string">"2018-06-11"</span>, usedf=<span class="keyword">True</span>)</span><br><span class="line">chart=WLine(title=<span class="string">"复权单位净值走势图"</span>,subtitle=first_fund[<span class="number">0</span>],data=nav)</span><br><span class="line">chart.plot()</span><br></pre></td></tr></table></figure><h2 id="3-WSQ行情数据函数"><a href="#3-WSQ行情数据函数" class="headerlink" title="3. WSQ行情数据函数"></a>3. WSQ行情数据函数</h2><h3 id="3-1-实时行情取数函数说明"><a href="#3-1-实时行情取数函数说明" class="headerlink" title="3.1 实时行情取数函数说明"></a>3.1 实时行情取数函数说明</h3><h4 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h4><p>命令用来获取选定证券品种的当天实时指标数据，数据可以一次性请求，也可以通过订阅的方式获取</p><p>命令原型为： data=w.wsq(品种代码,指标,可选参数,回调函数)</p><h4 id="函数输入-2"><a href="#函数输入-2" class="headerlink" title="函数输入"></a>函数输入</h4><p>函数名: w.wsq（security,fields,func = None)</p><div class="table-container"><table><thead><tr><th></th><th>Element</th><th>Type</th><th>Description</th><th></th></tr></thead><tbody><tr><td>证券（必选）</td><td>Security</td><td>String</td><td>获取数据的证券列表</td><td>范例：’600030.SH’说明：实时行情所支持品种较多，基本上终端中有的行情接口中皆可取得</td></tr><tr><td>指标（必选）</td><td>Fields</td><td>String</td><td>获取数据的指标列表</td><td>范例：’rt_open,rt_high,rt_last’</td></tr><tr><td>回调函数（可选）</td><td>Func</td><td>指定回测函数</td><td>范例：’ func=w.demoCallback’</td></tr></tbody></table></div><p>返回选定品种的实时数据，支持一次请求和订阅两种方式。</p><h4 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例7. 获取沪股通最新一笔的行情数据</span></span><br><span class="line">hksh=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date=2018-06-12;sectorid=1000014938000000"</span>).Data[<span class="number">1</span>]</span><br><span class="line">mk_data=w.wsq(hksh,<span class="string">"rt_last,rt_vol,rt_amt,rt_chg,rt_pct_chg,rt_swing,rt_vwap,rt_upward_vol,rt_downward_vol,rt_ask1,rt_ask2,rt_ask3,rt_ask4,rt_ask5,rt_bid1,rt_bid2,rt_bid3,rt_bid4,rt_bid5"</span>)</span><br><span class="line"><span class="comment">#pd.DataFrame(tradecode.Data,index=future.Data[2],columns=tradecode.Times).T</span></span><br><span class="line">pd.DataFrame(data.Data,index=data.Fields,columns=data.Codes).T</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#任意订阅一只股票的最新行情</span></span><br><span class="line">w.wsq(<span class="string">"000001.SZ"</span>, <span class="string">"rt_last"</span>, func=DemoWSQCallback)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#订阅行情后当交易所发送新的行情数据时，这里就会推送</span></span><br><span class="line"><span class="comment"># 上面订阅后会返回一个RequestID，此ID作为后面取消订阅函数的传入参数</span></span><br><span class="line"><span class="comment">#当传入ID为0时表示取消所有订阅 </span></span><br><span class="line">w.cancelRequest(<span class="number">3</span>)</span><br></pre></td></tr></table></figure><h2 id="4-WSET数据集函数"><a href="#4-WSET数据集函数" class="headerlink" title="4. WSET数据集函数"></a>4. WSET数据集函数</h2><h4 id="定义-3"><a href="#定义-3" class="headerlink" title="定义"></a>定义</h4><p>命令用来获取数据集信息，包括板块成分、指数成分、ETF申赎成分信息、分级基金明细、融资标的、融券标的、融资融券担保品、回购担保品、停牌股票、复牌股票、分红送转等</p><p>参数设置为起止日期、板块名称等，不同的报表有不同的参数设置</p><p>命令原型为： data=w.wset(数据集名称,可选参数)</p><h4 id="函数输入-3"><a href="#函数输入-3" class="headerlink" title="函数输入"></a>函数输入</h4><p>函数名: w.wset（view，options），返回股票，基金，债券，商品等专题统计报表的数据。</p><div class="table-container"><table><thead><tr><th></th><th>Element</th><th>Type</th><th>Description</th><th></th></tr></thead><tbody><tr><td>数据集（必选）</td><td>view</td><td>String</td><td>提取数据集的VIEW名</td><td>范例1：’SectorConstituent’</td></tr><tr><td>View参数（可选）</td><td>Parameter/Value</td><td>String</td><td>提取指标时使用的参数名/指定参数的值</td><td>范例1：’date=20130531’;</td></tr><tr><td>板块列表（可选）</td><td>sectorid</td><td>String</td><td>获取数据的板块ID</td><td>范例1： ‘sector=全部A股’ 范例2：’sectorid=a001010100000000’</td></tr><tr><td>字段列表（可选）</td><td>Field</td><td>String</td><td>获取字段列表的数据</td><td>范例1：’field=wind_code,i_weight’</td></tr></tbody></table></div><p>基本获取某些板块的数据方法在上面的函数介绍中已经涉及了，这里就不再赘述</p><h4 id="示例-3"><a href="#示例-3" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例8、 获取申万一级行业的成分股</span></span><br><span class="line">sw_index=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date=2018-06-12;sectorid=a39901011g000000"</span>) <span class="comment">#申万一级行业指数代码</span></span><br><span class="line">sw_index</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面分别取各行业指数的成分股</span></span><br><span class="line">result=pd.DataFrame()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(sw_index.Data[<span class="number">0</span>])):</span><br><span class="line">    x=pd.DataFrame(w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date=2018-06-12;windcode="</span>+sw_index.Data[<span class="number">1</span>][i]+<span class="string">""</span>).Data[<span class="number">1</span>],columns=[sw_index.Data[<span class="number">1</span>][i]])</span><br><span class="line">    result=pd.concat([result,x], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例9、 获取A股纳入MSCI成分股的2017年报的股票分红实施情况</span></span><br><span class="line"><span class="comment"># MSCI_stock=w.wset("sectorconstituent","date="+date+";sectorid=1000027970000000") MSCI股票代码上文已经取出</span></span><br><span class="line">error_code,bonus=w.wset(<span class="string">"bonus"</span>,<span class="string">"orderby=报告期;year=2017;period=y1;sectorid=1000027970000000"</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">bonus.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例10、 沪深交易所期权列表</span></span><br><span class="line">error_code,option=w.wset(<span class="string">"optioncontractbasicinfo"</span>,<span class="string">"exchange=sse;windcode=510050.SH;status=trading"</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">option.head(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><h2 id="5-TDays-日期函数"><a href="#5-TDays-日期函数" class="headerlink" title="5. TDays 日期函数"></a>5. TDays 日期函数</h2><h3 id="5-1-返回区间内的日期序列w-tdays"><a href="#5-1-返回区间内的日期序列w-tdays" class="headerlink" title="5.1 返回区间内的日期序列w.tdays"></a>5.1 返回区间内的日期序列w.tdays</h3><h4 id="定义-4"><a href="#定义-4" class="headerlink" title="定义"></a>定义</h4><p>命令用来获取一个时间区间内的某种规则下的日期序列。</p><h4 id="函数输入-4"><a href="#函数输入-4" class="headerlink" title="函数输入"></a>函数输入</h4><p>函数名：TDays(startDate,endDate,[Optional argument])</p><div class="table-container"><table><thead><tr><th></th><th>Element</th><th>Type</th><th>Description</th><th></th></tr></thead><tbody><tr><td>起始日期（必选）</td><td>StartDate</td><td>String</td><td>时间序列的起始日期</td><td>范例1：”2015-01-01”，支持日期宏</td></tr><tr><td>截止日期（必选）</td><td>EndDate</td><td>String</td><td>时间序列的截止日期，置空取当前最新日期</td><td>范例1：”2015-06-30”，支持日期宏</td></tr><tr><td>日期类型（可选）</td><td>Days</td><td>String</td><td>所有工作日：Weekdays，所有日历日：Alldays，排除所有非交易日：Trading</td><td>范例：’Days=Trading’，默认Days=Trading</td></tr><tr><td>变频参数（可选）</td><td>Period</td><td>String</td><td>每天一值：D， 每周一值：W，每月一值M：，每季度一值：Q ，每半年一值：S ，每年一值：Y</td><td>范例：’Period=D’</td></tr><tr><td>交易日历（可选）</td><td>TradingCalendar</td><td>String</td><td></td><td>TradingCalendar默认为上海证券交易所，当DAYS为日历日的时候，这个参数不起作用,只有当DAYS为交易日的时候，这个参数才起作用,默认“TradingCalendar=SSE”(上海证券交易所)</td></tr></tbody></table></div><h4 id="示例-4"><a href="#示例-4" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例11 取上交所2018年以来的交易日期序列，交易所为空默认为上交所</span></span><br><span class="line">date_list=w.tdays(<span class="string">"2018-05-13"</span>, <span class="string">"2018-06-13"</span>,<span class="string">" "</span>)</span><br><span class="line">date_list</span><br></pre></td></tr></table></figure><h3 id="5-2-返回某个偏移值对应的日期w-tdaysoffset"><a href="#5-2-返回某个偏移值对应的日期w-tdaysoffset" class="headerlink" title="5.2 返回某个偏移值对应的日期w.tdaysoffset"></a>5.2 返回某个偏移值对应的日期w.tdaysoffset</h3><h4 id="定义-5"><a href="#定义-5" class="headerlink" title="定义"></a>定义</h4><p>命令用来获取基于某个基准时间前推(<0) 或者后推(="">0)指定天数的日期。</0)></p><p>命令原型为：data=w.tdaysoffset(偏移值，基准时间,可选参数)</p><h4 id="函数输入-5"><a href="#函数输入-5" class="headerlink" title="函数输入"></a>函数输入</h4><p>函数名:TDaysOffset(offset, refDate, [Optional argument])</p><div class="table-container"><table><thead><tr><th></th><th>Element</th><th>Type</th><th>Description</th><th></th></tr></thead><tbody><tr><td>参考日期</td><td>refDate</td><td>String</td><td>参照日期</td><td>范例1：”2015-01-01”，支持日期宏</td></tr><tr><td>日期类型（可选）</td><td>Days</td><td>String</td><td>所有工作日：Weekdays，所有日历日：Alldays，排除所有非交易日：Trading</td><td>范例：’Days=Trading’，默认Days=Trading</td></tr><tr><td>变频参数（可选）</td><td>Period</td><td>String</td><td>每天一值：D， 每周一值：W，每月一值M：，每季度一值：Q ，每半年一值：S ，每年一值：Y</td><td>范例：’Period=D’，默认Period=D</td></tr><tr><td>交易日历（可选）</td><td>TradingCalendar</td><td>String</td><td></td><td>TradingCalendar默认为上海证券交易所，当DAYS为日历日的时候，这个参数不起作用,只有当DAYS为交易日的时候，这个参数才起作用。默认“TradingCalendar=SSE”(上海证券交易所)</td></tr><tr><td>偏移量（可选）</td><td>Offset</td><td></td><td>偏移参数</td><td>偏移参数，为整数，&gt;0后推，&lt;0前推，默认为0</td></tr></tbody></table></div><h4 id="示例-5"><a href="#示例-5" class="headerlink" title="示例"></a>示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例12 取从今天往前推10个月的日历日</span></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line">today = datetime.date.today() </span><br><span class="line">w.tdaysoffset(<span class="number">-10</span>, today.isoformat(), <span class="string">"Period=M;Days=Alldays"</span>)</span><br></pre></td></tr></table></figure><h3 id="5-3-返回某个区间内日期数量w-tdayscount"><a href="#5-3-返回某个区间内日期数量w-tdayscount" class="headerlink" title="5.3 返回某个区间内日期数量w.tdayscount"></a>5.3 返回某个区间内日期数量w.tdayscount</h3><h4 id="定义-6"><a href="#定义-6" class="headerlink" title="定义"></a>定义</h4><p>命令用来获取两个时间区间内的某种规则下的日期序列个数</p><p>命令原型为：data= w.tdayscount(开始时间，结束时间,可选参数)</p><h4 id="函数输入-6"><a href="#函数输入-6" class="headerlink" title="函数输入"></a>函数输入</h4><p>函数名：TDaysCount(startDate,endDate, [Optional argument])</p><div class="table-container"><table><thead><tr><th></th><th>Element</th><th>Type</th><th>Description</th><th></th></tr></thead><tbody><tr><td>起始日期（必选）</td><td>StartDate</td><td>String</td><td>时间序列的起始日期</td><td>范例1：”2017-01-01”，支持日期宏</td></tr><tr><td>截止日期</td><td>EndDate</td><td>String</td><td>时间序列的截止日期，置空取当前最新日期</td><td>范例1：”2017-06-30”，支持日期宏</td></tr><tr><td>日期类型（可选）</td><td>Days</td><td>String</td><td>所有工作日:Weekdays，所有日历日：Alldays，排除所有非交易日：Trading</td><td>范例：’Days=Trading’，默认Days=Trading</td></tr><tr><td>交易日历（可选）</td><td>TradingCalendar</td><td>String</td><td></td><td>TradingCalendar默认为上海证券交易所，当DAYS为日历日的时候，这个参数不起作用,只有当DAYS为交易日的时候，这个参数才起作用，默认“TradingCalendar=SSE”(上海证券交易所)</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例13 统计2017年交易日天数</span></span><br><span class="line">days=w.tdayscount(<span class="string">"2017-01-01"</span>, <span class="string">"2017-12-31"</span>, <span class="string">""</span>).Data[<span class="number">0</span>]</span><br><span class="line">days</span><br></pre></td></tr></table></figure><h2 id="6-日期宏的说明"><a href="#6-日期宏的说明" class="headerlink" title="6. 日期宏的说明"></a>6. 日期宏的说明</h2><h3 id="6-1-通用日期"><a href="#6-1-通用日期" class="headerlink" title="6.1 通用日期"></a>6.1 通用日期</h3><p>支持相对日期表达方式，相对日期周期包括:交易日TD、日历日：D、日历周：W、日历月：M、日历季：Q、日历半年：S、日历年：Y。</p><p>相关说明：<br>1、以’-’代表前推，数字代表N个周期，只支持整数；后推没有负号，比如’-5D’表示从当前最新日期前推5个日历日；<br>2、截止日期若为’’空值，取系统当前日期；<br>3、可对日期宏进行加减运算，比如’ED-10d’。</p><p>举例：<br>1、起始日期为1个月前，截至日期为最新 StartDate=’-1M’,EndDate=’’<br>2、起始日期为前推10个交易日，截至日期为前推5个交易日 StartDate=’-10TD’,EndDate=’-5TD’</p><h3 id="6-2-特殊日期宏"><a href="#6-2-特殊日期宏" class="headerlink" title="6.2 特殊日期宏"></a>6.2 特殊日期宏</h3><div class="table-container"><table><thead><tr><th>宏名称</th><th>截止日期</th><th>开始日期</th><th>去年一季</th><th>去年二季</th><th>去年三季</th><th>去年年报</th><th>今年一季</th><th>今年二季</th><th>今年三季</th><th>最新一期</th><th>本年初</th><th>下半年初</th><th>本月初</th><th>本周一</th><th>上周末</th><th>上月末</th><th>上半年末</th><th>上年末</th><th>上市首日</th></tr></thead><tbody><tr><td>宏助记符</td><td>ED</td><td>SD</td><td>LQ1</td><td>LQ2</td><td>LQ3</td><td>LYR</td><td>RQ1</td><td>RQ2</td><td>RQ3</td><td>MRQ</td><td>RYF</td><td>RHYF</td><td>RMF</td><td>RWF</td><td>LWE</td><td>LME</td><td>LHYE</td><td>LYE</td><td>IPO</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例14 用日期宏IPO的示例</span></span><br><span class="line">error_code,data=w.wsd(<span class="string">"000001.SZ"</span>, <span class="string">"close"</span>, <span class="string">'IPO'</span>, <span class="string">"2018-06-11"</span>, usedf=<span class="keyword">True</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure><h2 id="7-指标参数的说明"><a href="#7-指标参数的说明" class="headerlink" title="7. 指标参数的说明"></a>7. 指标参数的说明</h2><p>关于WSD/WSS中常见指标参数的举例说明</p><div class="table-container"><table><thead><tr><th>element</th><th>description</th><th>value</th><th>Indicator examples</th><th>demo</th></tr></thead><tbody><tr><td>tradeDate</td><td>交易日期</td><td>自填</td><td>开盘价</td><td>‘tradeDate=20180618’</td></tr><tr><td>startDate</td><td>开始日期</td><td>自填</td><td>区间开盘价</td><td>‘startDate=20180618’</td></tr><tr><td>endDate</td><td>截止日期</td><td>自填</td><td>区间开盘价</td><td>‘endDate=20180618’</td></tr><tr><td>adjDate</td><td>复权基期</td><td>自填</td><td>收盘价(支持定点复权)</td><td>‘adjDate=20180618’</td></tr><tr><td>rptDate</td><td>报告期</td><td>自填</td><td>净利润</td><td>‘rptDate=20171231’</td></tr><tr><td>priceAdj</td><td>复权方式</td><td>不复权/前复权/后复权/定点复权</td><td>收盘价</td><td>‘priceAdj=U’</td></tr><tr><td>cycle</td><td>周期</td><td>日/月/……</td><td>成交量</td><td>‘cycle=D’</td></tr><tr><td>bondPriceType</td><td>债券价格类型</td><td>全价/净价/收益率/市价</td><td>涨跌幅(债券)</td><td>‘bondPriceType=2’</td></tr><tr><td>currencyType</td><td>币种</td><td>原始币种/人民币/美元……</td><td>未平仓卖空金额</td><td>‘currencyType=Cur=CNY’</td></tr><tr><td>ndays</td><td>天数(用负号表示前推)</td><td>自填</td><td>N日涨跌幅</td><td>‘ndays=-5’</td></tr><tr><td>rptType</td><td>报表类型</td><td>合并报表/母公司报表……</td><td>杠杆率</td><td>‘rptType=1’</td></tr><tr><td>dataType</td><td>数据类型</td><td>本外币/本币/……</td><td>贷款利息收入-短期</td><td>‘dataType=2’</td></tr><tr><td>traderType</td><td>类型</td><td>机构/大户/散户……</td><td>流入单数</td><td>‘traderType=1’</td></tr><tr><td>exchangeType</td><td>交易所</td><td>上海/深圳/银行间……</td><td>跨市场代码</td><td>‘exchangeType=SSE’</td></tr><tr><td>index</td><td>所属指数</td><td>上证50指数/上证180指数/沪深300指数……</td><td>是否属于重要指数成份</td><td>‘index=1’</td></tr><tr><td>unit</td><td>单位</td><td>元、股、份、张、户</td><td>总市值、注册资本、持有人持有数量、单一投资者报告期末持有份额合计、股东户数……</td><td>‘unit=1’</td></tr><tr><td>industryType/category/industryStandard</td><td>行业级别/行业标准</td><td>一级行业/二级行业……</td><td>全部明细、中信行业/申万行业……</td><td>所属行业名称(支持历史)、所属恒生行业名称</td><td>‘industryType=1’，’category=1’,’industryStandard=3’</td></tr><tr><td>adminType</td><td>行政区划级别</td><td>省级/地级/县级</td><td>所属行政区划</td><td>‘adminType=1’</td></tr><tr><td>year</td><td>年度</td><td>2018/2017/2016……</td><td>管理层年度薪酬总额</td><td>‘year=2017’</td></tr><tr><td>month</td><td>月份</td><td>1月/2月/……</td><td>五星基金占比</td><td>‘month=2’</td></tr><tr><td>order</td><td>大股东排名、名次</td><td>第一名/第二名/……</td><td>持有人持有数量、基金经理年限</td><td>‘order=1’</td></tr><tr><td>instituteType</td><td>机构类别    基金公司/证券公司/……</td><td>配售对象名称</td><td>‘instituteType=1’</td></tr><tr><td>topNum</td><td>名次</td><td>第1名/第2名……</td><td>离职日期</td><td>‘topNum=1’</td></tr><tr><td>shareType</td><td>股本类型</td><td>流通股本/总股本</td><td>户均持股比例</td><td></td><td>‘shareType=1’</td></tr><tr><td>reportDateType</td><td>报告期</td><td>第一季度(1-3月)/第二季度(4-6月)……</td><td>单一投资者报告期末持有份额合计</td><td>‘reportDateType=1’</td></tr><tr><td>Type</td><td>资产池资产级别</td><td>次级/优先级/次优级</td><td>各级发行总额</td><td>‘reportDateType=1’</td></tr><tr><td>type</td><td>选择权类型、评级对象类型</td><td>赎回/回售/……、主体信用评级/不限……</td><td>行权资金到帐日</td><td>‘type=Pr’、’type=3’</td></tr><tr><td>serial</td><td>第N次提前偿还</td><td>手动输入数字</td><td>提前还本比例</td><td>‘serial=1’</td></tr><tr><td>ratingAgency</td><td>评级机构</td><td>标普/穆迪……</td><td>债项评级</td><td>‘ratingAgency=16’</td></tr><tr><td>bondTypeIndex</td><td>债券类型</td><td>短期融资券/中期票据/……</td><td>历史累计注册额度</td><td>‘bondTypeIndex=2’</td></tr><tr><td>bondType</td><td>债券类型</td><td>金融债/同业存单……</td><td>存量债券余额</td><td>‘bondType=1’</td></tr><tr><td>termType</td><td>期限类型</td><td>1年期内/1-3年期内……</td><td>存量债券余额(按期限)</td><td>termType=2</td></tr><tr><td>credibility</td><td>估值类型</td><td>推荐/不推荐/行权……</td><td>日终估价全价</td><td>‘credibility=2’</td></tr><tr><td>fundType</td><td>基金分类</td><td>投资类型(一级分类)/投资类型(二级分类)</td><td>同类基金数量</td><td>‘fundType=1’</td></tr><tr><td>fundRatingAgency</td><td>评级机构</td><td>1/2……</td><td>四星基金占比</td><td>‘fundRatingAgency=2’</td></tr><tr><td>chargesType</td><td>收费类型</td><td>前端/后端</td><td>认购费率</td><td>‘chargesType=1’</td></tr><tr><td>returnType</td><td>收益率计算方法</td><td>普通收益率/对数收益率</td><td>几何平均年化收益率</td><td>‘returnType=1’</td></tr><tr><td>annualized</td><td>是否年化</td><td>是/否</td><td>近1周回报</td><td>‘annualized=0’</td></tr><tr><td>netType</td><td>报告期净值数据项</td><td>过去1个月/过去3个月/……</td><td>报告期净值增长率</td><td>‘netType=1’</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">例<span class="number">16</span> 指标参数说明案例</span><br><span class="line">w.wss(<span class="string">"510010.SH"</span>, <span class="string">"fund_fullname,fund_similarfundno,fund_purchasefee,fund_redemptionfee,fund_dq_status,fund_pchredm_largepchmaxamt,fund_manager_totalnetasset,fund_manager_arithmeticannualizedyield,fund_manager_totalreturnoverbenchmark,fund_corp_fivestarfundsprop,fund_corp_fourstarfundsprop,fund_corp_teamstability,issue_etfdealshareonmarket,fund_etfpr_estcash,fund_etfpr_cashratio"</span>, <span class="string">"fundType=1;chargesType=0;tradeDate=20180619;unit=1;order=2;returnType=1;year=2018;month=1;fundRatingAgency=2;startDate=20180520;endDate=20180620"</span>)</span><br></pre></td></tr></table></figure><h2 id="8-财务数据的说明"><a href="#8-财务数据的说明" class="headerlink" title="8.财务数据的说明"></a>8.财务数据的说明</h2><p>Python如图，万矿的财务数据都是传入报告期，然后返回相应报告期的财务数据；在参数设置中可以直接设置报表类型为合并报表/母公司报表/合并报表（调整）/母公司报表（调整）。</p><p>万矿是取每个季度最后一天作为报告期,如取2017年的四个定期报告数据，那报告期设置分别为 ：一季报：2017-03-31，半年报：2017-06-30，三季报：2017-09-30，年报:2017-12-31</p><p>如果要用wsd取多个报告期的公告数据，则需要将周期设置为季，日期类型设置为日历日(因为有的季度最后一天不是交易日)</p><p>财务数据回填说明：<br>1、比如说某公司A在2018年3月22日公布2017年年报，那在2018年3月22以前取2017年年报数据则为空，A公司公布年报数据后，我们会将公布的数据回填到2017-12-31，用户传入相应的报告期参数即可取出对应的年报数据；<br>2、如果用户直接取出年报数据做回测则会引入未来数据，所以如果要用财报数据做回测要先按照定期报告披露日期拉平至时间序列再做回测。</p><p>下面举例说明如何获取各个报告期的财务数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例 17 用wsd函数取000001.SZ[平安银行]近十年的利润表(合并报表)数据</span></span><br><span class="line">error_code,finance_data=w.wsd(<span class="string">"000001.SZ"</span>,<span class="string">"tot_oper_rev,oper_rev,int_inc,insur_prem_unearned,handling_chrg_comm_inc,tot_prem_inc,reinsur_inc,prem_ceded,unearned_prem_rsrv_withdraw,net_inc_agencybusiness,net_inc_underwriting-business,net_inc_customerasset-managementbusiness,other_oper_inc,net_int_inc,net_fee_and_commission_inc,net_other_oper_inc,tot_oper_cost,oper_cost,int_exp,handling_chrg_comm_exp,oper_exp,taxes_surcharges_ops,selling_dist_exp,gerl_admin_exp,fin_exp_is,impair_loss_assets,prepay_surr,net_claim_exp,net_insur_cont_rsrv,dvd_exp_insured,reinsurance_exp,claim_exp_recoverable,Insur_rsrv_recoverable,reinsur_exp_recoverable,other_oper_exp,net_inc_other_ops,net_gain_chg_fv,net_invest_inc,inc_invest_assoc_jv_entp,net_gain_fx_trans,opprofit,non_oper_rev,non_oper_exp,net_loss_disp_noncur_asset,tot_profit,tax,unconfirmed_invest_loss_is"</span>, <span class="string">"2007-01-01"</span>, <span class="string">"2017-12-31"</span>, <span class="string">"unit=1;rptType=1;Period=Q;Days=Alldays"</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">finance_data</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例18 用wss取上证50的常见财务指标的2017年年报数据</span></span><br><span class="line">sh_50=w.wset(<span class="string">"sectorconstituent"</span>,<span class="string">"date=2018-06-20;sectorid=1000000087000000"</span>).Data[<span class="number">1</span>]</span><br><span class="line">error_code,Y_finance_data=w.wss(sh_50, <span class="string">"tot_oper_rev,tot_oper_cost,opprofit,tot_profit,net_profit_is,np_belongto_parcomsh,extraordinary,wgsd_deductedprofit,researchanddevelopmentexpenses,ebit,ebitda,tot_cur_assets,fix_assets,long_term_eqy_invest,tot_assets,tot_cur_liab,tot_non_cur_liab,tot_liab,cap_rsrv,surplus_rsrv,undistributed_profit,cash_recp_sg_and_rs,cash_pay_acq_const_fiolta"</span>,<span class="string">"unit=1;rptDate=20171231;rptType=1;currencyType="</span>,usedf=<span class="keyword">True</span>)</span><br><span class="line">Y_finance_data</span><br></pre></td></tr></table></figure><p>（完）<br>特别鸣谢：我家松鼠</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最后编辑于：2020.02.05 12:30&lt;/p&gt;
&lt;h2 id=&quot;Wind-API使用说明&quot;&gt;&lt;a href=&quot;#Wind-API使用说明&quot; class=&quot;headerlink&quot; title=&quot;Wind API使用说明&quot;&gt;&lt;/a&gt;Wind API使用说明&lt;/h2&gt;&lt;p&gt;windAPI是一个很好的工具，可以不通过客户端获取数据（不过前提是要有土豪的账号加持，笑）本文大部分介绍性文字转载自&lt;a href=&quot;https://www.windquant.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;万旷网&lt;/a&gt;。本文的分析全部通过python完成。配置安装略过不表，请致电客服经理小哥哥（声音奶声奶气有点温柔！&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据分析" scheme="https://konelane.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>遍历山河|南京</title>
    <link href="https://konelane.github.io/2020/01/22/20200122%E5%8D%97%E4%BA%AC%E6%97%85%E8%A1%8C%E6%97%A5%E5%BF%97/"/>
    <id>https://konelane.github.io/2020/01/22/20200122%E5%8D%97%E4%BA%AC%E6%97%85%E8%A1%8C%E6%97%A5%E5%BF%97/</id>
    <published>2020-01-21T16:00:00.000Z</published>
    <updated>2020-01-21T16:44:39.439Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>旅行结束，慢慢添加我的心绪啦。有人说旅行是痛并快乐着，我觉得没错。偶尔快乐多，偶尔痛苦多。但是南京不太一样，在这里，我几乎没有痛苦，只有一些遗憾和无穷快乐。</p><a id="more"></a><h2 id="14日-旅行日志"><a href="#14日-旅行日志" class="headerlink" title="14日 旅行日志"></a>14日 旅行日志</h2><p>告别我纯白如仙的松鼠，我独自拎着箱子，踏上了这次期待不算太久，但我绝对足够向往的旅行。</p><p>直达车不直达，特快车不特快，临客不会真的零客，只有高铁和动车还没有辱没名号。或许正是因为他们的出现，其他的客车才相形见绌，铁路系统从此认知失调。车上从各处来的人，混着不同的口音乱杂开放。我很少坐长时间的硬座，今晚恐怕会是个令人记忆深刻的不眠夜。</p><p>我初次独自远行去陌生的城市旅游，但也不算完全陌生，还好有认识的长辈在那里，还有松鼠一起，热心地帮我打点安排，让我才能安心地踏上旅途。看着满满当当的旅途安排，我心中说不上来的复杂。自己曾经标榜“读万卷书，行万里路”，然而真正做到还得靠自己一时冲动，当然也归功于周围人们的帮助。虽然很想细细品味，可是走得地方实在太多，眼花缭乱免不了落入走马观花之流，不知所向，只能到现场慢慢品味，再做取舍了。</p><p>听说哥哥做打算往往提前两个月，安排行程，预订酒店，这应该很清醒的旅行状态。很期待父母能策划一场出行，但是他们也碍于时间空间的距离，没法随心所欲。松鼠也在帝都寻了一份差事做，于是只留我一个孤独上路。我首次尝试独自出行，我期待一场奇妙的旅行，但是也在不断为之准备着。我着实向往着南京，以至于定下了行程才察觉天气不如意的问题，但冷暖或许已经无妨，我偶尔意决，今天算一次。</p><p>有一件值得在意的事：在火车上，教室里，坐着的时候，感觉自己的位置很清晰。但一站起来就瞬间失去方向感，不知自己身处何方。究其原因，或许是同一个视角看的太久，在升维瞬间失了格吧。</p><h2 id="15日-旅行日志"><a href="#15日-旅行日志" class="headerlink" title="15日 旅行日志"></a>15日 旅行日志</h2><p>冬雨不寒马蹄疾，一日看尽金陵花。<br>湿身方嫌寡情雨，酩酊难解太浮夸。</p><p>突然吟诗，说明开心。作为一个本意独行这个城市的旅人，没想到获得了异常热情的款待，在一个伯伯的帮助下，我今天辗转了无数景点，尝遍了千万小吃，大饱眼福的同时也大快朵颐，精神和肉体皆是满载而归。</p><p>白天刚到南京，漆黑混杂着大雾混沌成一片，南京像个封存老窖中的佳酿，像黑暗中待开启的宝箱，像迎进屋子但披着盖头的新娘，待人一探究竟。逐渐习惯了那些随心所欲的道路规则和巨大显示屏展示的宜人的红绿灯倒计时灯，其实这座城市没有我一开始想象的那么井然，但是在我眼中这般混乱之下，竟也有可以寻找的规则和有序。人人在这里都可以大摇大摆地做天王老子，享受每一刻在路上的时光。我也很享受在这里大街小巷行走的快乐。</p><p>我行程飞快。从长江大桥江底隧道，路过狮子山阅江楼，草草翻过毗芦寺，梅园新村，六朝博物馆，再到小九华山，鸡鸣寺和玄武湖，雨中闯入大钟亭，鼓楼和南京大学，夜里的狮子市，夫子庙，穿街走巷雨中狂奔才赶到的1912，没有哪一处突兀多余。这些或自然或历史或现代的风光景色，都已和南京融为一体，俨然成了南京现代生活的一部分。在意想不到的地方，总会突如其来杀出一座山，一座楼，一道水，一院佛。这里充满了人文和自然气息，物华天宝、人杰地灵。这里据说寸土寸金，跨过三五步一条马路突然就是一个崭新的迥然不同的世界，每一步都可能产生新的邂逅，这种未知的刺激令我着迷。南京也多美女，平日里原子弹炸不到一个，南京一颗手榴弹能炸一片，松鼠还嫉妒。</p><p>城市的诗情画意，还有它不为人知的小心思，我都有所理解。不仅仅是小面包车上与伯伯一字一句的对谈和学习，更多的是一种气质：城市的气质、人的气质、全部自然总体总和的气质。我听到了地道的南京话，插科打诨，无比惬意，虽然不习惯其中个中洒脱粗鄙，但是想到儒雅如我这个三秦猛男也常常口吐芬芳当街骂娘的事实，我也笑着理解了这种调侃性质的口癖。南京话总有种火药味，还是不要太较真的好。</p><p>明天还要早起，今天走着玩几万步，像是玩着走。白天五点到站还没睡够觉，实在困累之至，加上本应该成为东道主的松鼠也沉迷游戏，不搭理我，夜里雨中骑车狂奔尽兴而归才发觉丢了伞，浑身湿透地回了宾馆。大欢喜背后总是一个个小失落。松鼠也质疑我、嗔责我，虽然看起来像是口是心非，有了些南京人互怼的味道，但依然令我十分难受，可是又不想反驳什么，坏了我的期待和焦渴就算了，让松鼠批评一下舒服舒服也无妨。且熄一熄我这团让我膨胀到无所适从的火焰吧。</p><p>明天还有明天的旅途，眼皮打架，不说了。</p><h2 id="16日-旅行日志"><a href="#16日-旅行日志" class="headerlink" title="16日 旅行日志"></a>16日 旅行日志</h2><p>早起我就感受到了南京别样的一面，至少在没有暖气这一点上，就宣告了它是一座冰冷的城市。融入和接受恐怕很难，我想只有熬得住寒冷、耐得住性子，才能和这座城市打成一片，才更加接近这座城市的灵魂所在。我还是在寻找神奇的路上，从未停止。我也住过很久没有暖气的房子，全靠电暖气续命，每天起床前一定要把冰凉的衣服在暖气上烤一下，起床才不至于那么煎熬。</p><p>今天的目标颇多，本来只与昨天持平，结果今天伯伯突然有事，无力再送我。我已经心怀感激，哪敢多做要求，于是今天的路成全了昨日口中奢望的“独行”。就结果来看，我还是奢望有车接车送只管参观的旅途。不过今天去的景点都是需要用双脚踏踏实实丈量的，倒也完全没有投机取巧的空间，要车也无用。于是就诞生了这近乎4万的超越极限的旅程，从表面看来有车的旅行效率可以提高一倍。</p><p>气度雍容的美龄宫开启了这段钟山之旅，皇气浩瀚的明孝陵，排衙端庄的颜真卿碑林，肃穆清白中山陵，绝景入云的灵谷塔，还有一些情趣无限的小地方：三绝碑、音乐台、无梁殿、四方城。虽然走马观花，对历史由来也一知半解，但我总算是将那奇人奇景刻进脑海，待之后再品味。没顾上吃饭，斩了根烤肠，又转头向环环相扣的瞻园，途经深街老巷的老门东，又仰止中华门，行止雨花台。这么多还不够我体验，晚上又补足了第一天遗憾的玄武湖，还去了夜幕下的三山街熙南里，新街口商圈，论充实，这一天的容量比起考研的长途作战有过之无不及，我也好久没有来过这样的高强度旅行了，导致我写文章这会儿只能像一张煎饼一样在旅店中摊开来任人宰割，甚至因为太累了，害怕泡澡堂子散了紧绷的神，最后没去。</p><p>一路上都是人文景观，而绝美的风景并非很多，触动内心的更少。南京还在雨中，紫金山烟雾蒸腾。雨让天地模糊了界限，这混沌让我有些烦躁，可是微雨再不增添更多烦恼之上，把凝重和游人从景区一同抹去，留给我肆意想象和发挥的空间。在过年前的下雨的工作日游览南京，或许这体验只有现在才可能得到。这个季节的钟山树林红褐色与深绿色交融，错综的枝桠遮天蔽日，只有登高临台才有如此疏朗的开阔视野。但真正居高的时刻，我又没了高屋建瓴的气势，变得不知所向，无所适从。年轻时候，爱登高楼，待我再成熟一些，怕是就失去登楼心劲了。现在总觉得高楼如家乡这般，珍惜之处想去可是又不敢去，顺心和忧愁总是相伴而生，这就是爱吧。</p><p>颜真卿的碑林和刘勰文心雕龙纪念馆在钟山一角，本就与帝王伟人陵寝格格不入，但更出格的是一座无人的小园子还夹在两个建筑物之间，毫无征兆地撞出来，园虽小，但阁廊水木应有尽有，明明修在一个平面上，竟也有小曲折和错落的层次感，可能南京的园子有难名且优雅的修葺之道吧。我很喜欢这个没有名字的园子，更多是情景之喜，先前的凝重的地气在此行不通，进去出来竟然变成一园的清淡芳香，有如解油化腻的饭后小汤，沁人心脾。</p><p>其实我对园林毫无体验，来之前甚至只有一些北方园子的印象。观赏中若觉得某处入眼甚是契合我美感，凭空而爱，毫无理由，因此不好意思多说。看了瞻园，层层叠叠，钦佩和沉浸感无以复加，惬意凉亭。只是零落季节的园子，竟都有此等魅力，引得我反复穿行，寻找角度，左看右看，去留频繁。园子的窗门给出无限空间、亭廊自如穿梭带给人想置身其中的欲望、山水花草有情有据铺陈摆放十分讲究，惊为天作。雕梁画栋、星星灯火，与这季节的残花败柳，相映成趣，爱至深，盖我已成园内人。但这种“同化”有例外，我在园中发现了一只猫，在雨中漫步，愁眉苦脸，仿佛并不开心。我笨拙地学了几声猫叫，企图诱骗，反倒逼它使出浑身解数，飞檐走壁消失在楼台间。或许我不会骗人，更不会骗猫。我的体会就连我自己都不能完全把握，异想天开地企图把喜悦传递给猫猫，简直是乐昏了头。不过有趣的是，察觉到自己似乎“很快乐”的我自己，就接着认真地快乐起来。</p><p>猫猫是有灵气的，每一只猫都有，于是我喜欢看猫。人不一定，但也有灵气。昨天在小九华山的一条幽径中，一直黑猫欣然路过，丝毫不在意一旁赶路的我，瞬间隐匿，留我略略遗憾。今天晚上玄武湖的湖中小洲上也遇见了小黑猫，自顾自躲雨，看我几眼，又故作高冷，转身翻窗离去，似乎还被窗子卡了几秒钟。我本来想帮它，但觉得猫猫灵性至此，我一介庸人又能改变什么呢，或许不论它能不能穿过那条窗缝，我都不该出手才是。</p><p>可是，猫猫不改本性，我的认知上限却是容易被改变的。神道漫长，上山路上遇见一位高人，内力颇深，一曲《青藏高原》响彻整条路，我们身形交错瞬间，竟有种被浩然之气浇透打穿的感觉。我很少为了看人而回头，但这次如同一定要确认什么似的回了头。我也趁没人唱了两句，除了遭了报应绊了一跤差点滑倒，好像没有什么场地的加成。我猜想可能有两个原因：一是我不该放浪形骸，陕西人有时邪，说曹操曹操就到，陵寝高歌还是不好；二是我的唱歌内力太稀薄，遇见高手甚至会反噬自己，平时多是献丑。</p><p>其实，这一趟转悠下来，我也不知自己真正喜欢上了南京的什么，也不知道自己不喜欢什么。心中也像下了一场雨，界线模糊了。但明显的一点是，原本我不喜欢或者丝毫不感兴趣的东西，我开始尝试了，甚至会用心找它的特点。就比如我把主打甜味的梅花糕，形容为嬉笑怒骂，我自以为完全合理。粘和脆，苦和甜，硬和软，彩和白，一对对矛盾交织，共同构成了这一口梅花糕。或许真应该用“嬉笑怒骂”来形容，着实难忘。松鼠觉得不该把外壳做糊掉，糊掉生出多余苦味，可是那样的甜可能也单调，而且恐怕也只有高明的店家才能做到，并非是人们常常吃到的那种，少了一种地气吧。</p><p>吃的事之后专门写一篇。很晚了，休息。明天还要拼一拼，不过早上可以慢悠悠吃个早茶。人总是忙碌的，就拿我来说，担心的事有很多，我还悬着一颗梦想抢改签票的心，现在还担心松鼠的身体，坏的发展都是受罪。我不想松鼠受罪，我也不想受罪，可是有时候确实得为了所爱的什么拼一把。人是成长的，有些人走不了那么多路，可是热情驱使着，就会毫无征兆地焕发出超越身体机能的力量。</p><h2 id="17日-旅行日志"><a href="#17日-旅行日志" class="headerlink" title="17日 旅行日志"></a>17日 旅行日志</h2><p>今天去总统府，天下文枢坊，莫愁湖，奥体公园，还有大屠杀纪念馆，为南京之游收了官。每一处都有独特的感官体验。吃得好，玩得好，虽然走马观花，但也算肤浅到极致，极尽三天之能事，算是不虚此行。每每看到它新的面貌，有时是市井平常，有时是青春自由，有时是工作辛劳，不管什么样子，当我更加了解南京时，就又多几分喜爱。</p><p>从来没有高强度这么拼命地走过路，我很少如此用痛感苦感来强记某些旅程，但若旅途中带着一些苦痛和不顺利，那此行也会愈加刻骨。整条路也多亏只有我一人，我可以随心所欲走南闯北，当然也因为计划不周耽误了很多时间。所幸，南京是个交通便利的城市，用不着我在路上费劲，就能轻松地兜转访寻。限制自己的只有昨天透支的腿，让今天确实无力实现出格的想法，脑子都不灵光了许多。若说前两天在旅行，今天却像是一种修炼和补救错误。</p><p>这次出游，没做什么攻略，没写什么太长的安排，每次游览景点，也只是按照一个深度随心逛下去。也不知道有什么美食和根源，只好误打误撞，有时现场搜索，或蹭蹭别团的导游。狼狈不堪。今天也萌发了一种无力感，起因于我偶然听到总统府中的一位导游讲起府门前八字台阶和某“森”楼奥秘，我才察觉自己的充实只是肤浅的充实，有些事有些来由根本不是我一个人能查到或者体会到的。除了对先前的自满自惭形秽，我也更加喜爱南京这座城。</p><p>其实和松鼠聊过，但是免不了再提一嘴。在我眼里，南京无疑是一座“城”，有声有色，有古有今。但我不曾了解南京的那部分，却在我心底呼之欲出，而那一部分更像是一座“市”。人们日出而作日落而息，每个人都寻着一份事儿做。我独潇洒，逆流而动，这些天还真无人与我争，可能是因为天寒又下雨，还赶上年前大家都忙碌，基本都是独享美景，宛如包场。吃东西也一样，我作为半个吃货，常苦于选择困难，很少能搏得最好吃的头彩。但尽管这样，我还是被南京本地美食所征服，足见南京美食同文化一样博大精深。</p><p>其实，我总在渴望从不同的角度认识南京，渴望从最真实又最深刻的一面认识人事物。这次走马观花，我抱着能触碰这座城市除了历史以外的全部表象的另类的渴望，我想融入这里早上的忙碌生活，想度过不眠的灯火秦淮，体会拥堵和顺畅，看遍美食与美人，我喜欢更平常的南京，而非更“南京”的南京。或许这些微妙的差别只有等我再咀嚼时，才会体会。不过我想，这次快速游览，大概并非毫无意义，对我来说这算是已经铺好纸笔，只待我闲暇时再去看两眼，便能描画挥洒了。</p><p>说了许多大话空话客套话，可是没学会最想了解的南京话。当然，就算学会，我也不敢在老南京们面前班门弄斧，最多调侃一下松鼠。但是一点可以肯定，南京人的普通话不怎么好，至少这一路我时刻注意着，和我对话的人，讲普通话的不超过一手之数，大多数普通市民都会带着点南京的口音。通常，本地人对本地方言都有些特别的情节，我听了几天，虽然有些难名的词根和语缀记了几个，南京话虽然听着像北方话，却抛去了很多太刚坚的词，剩下一些令我摸不着头脑的婉转语调，以及一种鞭辟入里的直爽，和一种说完就抛的洒脱。出口成脏是常事，有人确实喜欢拿腔拿调还吹胡子瞪眼，只是听者不必钻牛角尖，应该用脏字还一口回去才是正解。看他们聊得火热，我感叹语言排外的严重，初来乍到完全假装不了本地人，可能也因此没能混进想看的学校。不管如何，南京话稍稍让我有些羡慕。</p><p>想到今天又去夫子庙，这次奔着几个文化展馆去的，个中展馆确实值得玩味。再回味前两次来这里，总觉得看到的秦淮灯火只是一种虚假的繁华。有趣的小玩意琳琅满目，可我不屑一顾；当地独特的美食飘香穿巷，可我吃过后便无心驻足。然而我偏爱这里的砖瓷碑匾，飞檐叠壁，亭台廊阁，我深醉这里的兵戈祸中，天下文枢，古都气韵。这一城氤氲于书香食色，融化于绵山长水，烙刻于时代纵横，这样的城，只南京一座。</p><p>你们又要说，去过南京就开始吹南京，是不是收了钱奉了旨，屁颠屁颠地傻乐呵。南京是个普通城市，也有着普通的一面，那是每个城市都有的市井市侩的一面。主干道上还在修建便民交通，拥堵是不可避免的，这座城市还在发展之中，还在成长之中，还好相见不晚，未来可期。</p><p>我眼中的平凡事也多，有取纸巾铲屎的路人老奶奶，有骂骂咧咧却又热心的公交司机，有高唱分手快乐的醉酒小情侣当街大戏，有书包加身的名校学子匆忙赶路尽显惫色，有早点摊、总统府、瞻园、玄武湖和小九华数不清的悠闲猫猫，有不喜欢戴手表手机的晨练大爷和急着下班地铁引导员，有追出五十米把落下东西送还的餐厅服务员，有无心逛街还等在商场门口的寂寞小男友，有快下班了还特意为我重启设施的景点管理员，有好心过问冷暖的酒店前台，有不给好脸色的公事公办学校门卫，有飞行在街巷的电动车手，有遛狗带娃不栓绳的小阿姨，有酒吧街用生命力高谈阔论的落魄青年，有串摊指点附近美食攻略的温柔小哥……明明只有三天，我遇见的人们比我想象中的要更多更丰富。不管事由如何，这一切的人一起组成了我眼中的南京市民，正是他们生活在这片城市中，带给这座城市无限生命力。刷新了我对南方人和南京人的认识。</p><p>你若问他们怎么看我，我觉得像是在看一只外地来的金丝猴：操着听不出籍贯的口音和生得一副独特的面貌身材，带着目中无人怼天怼地的气魄，三步并一步飞快穿行的孤独旅人。外地人来南京，南京人都无比自豪，开始话六朝古都，十洲云水。作为半个西安人，我对历史有莫名的感情，可惜这次没去成最为推崇的南京博物院，是最大的遗憾了，但也不算遗憾，反正走马观花看博物馆，那才是真的浪费时间。</p><p>之后再专门写点美食吧，在此不做赘述。我喜欢南京。</p><p>（未完待续，还有春运和美食没写qwq）</p><h2 id="附录：美食记录"><a href="#附录：美食记录" class="headerlink" title="附录：美食记录"></a>附录：美食记录</h2><p>15晨<br>桂花糖芋苗<br>赤豆元宵<br>鸡汁汤包<br>鸡汁回卤干</p><p>15午<br>慈悲素鹅面<br>沉鱼落雁（松鼠素鱼）<br>煮干丝</p><p>15晚<br>清炖狮子头<br>江南水乡一桶仙<br>蟹黄汤包<br>香干马兰头<br>清炒芦蒿<br>肥肠臭豆腐砂锅<br>千层油糕<br>桂花拉糕<br>糯米糖藕</p><p>16日晨<br>油条<br>烧麦<br>南瓜红枣粥</p><p>16晚<br>张三生煎+垃圾锅贴<br>梅花糕</p><p>17早<br>酥饼<br>鸭血粉丝汤</p><p>17午<br>喜妞炸串 鸭肠<br>晨祥记牛肉锅贴<br>桂花双皮奶<br>酱汁鸭肉卷<br>奇异果青麦汁<br>芋圆bobo鲜奶茶</p><p>17晚<br>香辣牛肉锅盔<br>酱汁烤鸭</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;旅行结束，慢慢添加我的心绪啦。有人说旅行是痛并快乐着，我觉得没错。偶尔快乐多，偶尔痛苦多。但是南京不太一样，在这里，我几乎没有痛苦，只有一些遗憾和无穷快乐。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="文章" scheme="https://konelane.github.io/tags/%E6%96%87%E7%AB%A0/"/>
    
  </entry>
  
  <entry>
    <title>软件初探|matlab之空间计量</title>
    <link href="https://konelane.github.io/2019/12/30/191230%E7%A9%BA%E9%97%B4%E8%AE%A1%E9%87%8F/"/>
    <id>https://konelane.github.io/2019/12/30/191230%E7%A9%BA%E9%97%B4%E8%AE%A1%E9%87%8F/</id>
    <published>2019-12-29T16:00:00.000Z</published>
    <updated>2020-10-29T01:08:04.888Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最后修改日期：191231，18:31</p><h4 id="事由"><a href="#事由" class="headerlink" title="事由"></a>事由</h4><p>松鼠有难，正派学长自然要拿出一点正派学长的样子。从零开始自学matlab，写写作业，不过如此。好啦，话不多说爱不多示，进入正题吧。</p><a id="more"></a><h2 id="一、介绍说明"><a href="#一、介绍说明" class="headerlink" title="一、介绍说明"></a>一、介绍说明</h2><p>数据为1978年-2011年华东<strong>七城市</strong>（上海、山东、安徽、江苏、浙江、江西、福建）各省区的<strong>GDP（GDP）、人口（RENKOU）、财政收入（GSH）、财政支出（GZH）、投资（TZ）、消费（XF）、进口（JK）</strong>。（氦核：别问我为什么起这些low爆的变量名，某松鼠的老师起的</p><p>以GDP为因变量，其他六个变量为解释变量，详细情况见表1。</p><p><strong>表1  变量介绍表</strong>  </p><div class="table-container"><table><thead><tr><th>变量名</th><th>含义</th><th>变量水平</th><th>单位</th></tr></thead><tbody><tr><td>GDP</td><td>地区生产总值</td><td>连续型</td><td>亿元</td></tr><tr><td>RENKOU</td><td>人口</td><td>连续型</td><td>万人</td></tr><tr><td>GSH</td><td>财政收入</td><td>连续型</td><td>亿元</td></tr><tr><td>GZH</td><td>财政支出</td><td>连续型</td><td>亿元</td></tr><tr><td>TZ</td><td>投资</td><td>连续型</td><td>亿元</td></tr><tr><td>XF</td><td>消费</td><td>连续型</td><td>亿元</td></tr><tr><td>JK</td><td>进出口</td><td>连续型</td><td>亿元</td></tr></tbody></table></div><p>利用matlab软件构造<strong>空间自回归模型、空间误差模型、空间杜宾模型和空间面板数据模型</strong>。其中空间自回归模型、空间误差模型、空间杜宾模型均使用2017年数据，空间面板数据模型使用40年全部数据构造。（氦核：切莫手滑一上来就panel函数。。。空间面板数据模型和空间xx模型有微妙的区别。血的教训</p><p>基于邻域关系的空间权重矩阵weight1由<em>“华东省区公路邻域.xlsx”</em>得出，基于距离关系的空间权重矩阵weight1由<em>“华东各省会城市的距离”</em>得出，基于GDP差距的经济距离关系的空间权重矩阵由<em>“华东2014年GDP计算的经济距离”</em>得出。综合权重矩阵取<strong>a=b=c=1/3</strong>（毫无梦想和灵魂的取值）。最后利用matlab构造出模型并进行检验。（氦核：文件在文末附件，你们看看我多好</p><blockquote><p>注1：<br>（1）空间自回归模型：<script type="math/tex">y=ρWy+βX+μ</script><br>（2）空间误差模型：<script type="math/tex">y=βX+μ     μ=ρWμ+ε</script><br>（3）空间杜宾模型：<script type="math/tex">y=ρW_1 y+Xβ_1+W_2 Xβ_2+μ</script><br>（4）空间面板数据模型：<script type="math/tex">y_it=ρWy_it+βX_it+μ_it</script></p><p>注2：<br>空间权重矩阵的选择，要有基于邻域关系的空间权重矩阵，基于距离关系的空间权重矩阵，基于某个经济指标的经济距离关系的空间权重矩阵。提倡构建组合空间权重矩阵<script type="math/tex">W=aW_1+(1-a)W_2（0＜a＜1）</script>；或 <script type="math/tex">W=aW_1+bW_2+ cW_3（a+b+c=1）</script>。</p></blockquote><h2 id="二、代码"><a href="#二、代码" class="headerlink" title="二、代码"></a>二、代码</h2><p>贴代码之前，先说几个坑。</p><p>sar函数，sem函数，sdm函数，一定不能做多年的数据，只能使用一年数据，否则报错。（氦核：不知道谁没搞清楚原理就开始写代码了呢。。。</p><p>松鼠的老师还是有意思，自己派人写了个有趣的包：fanzhuan（将上/下三角矩阵变成对称矩阵），里面还有几个对空间权重矩阵做标准化的函数，不想找的话<strong>normw()</strong>也可以，具体内容实在不想看了。</p><p>这次用到的方法，是空间计量，对于我来说很新奇，同时觉得很有趣。matlab空间计量需要最关键的<strong>jplv7</strong>工具包，下载安装这里也略过。</p><p>准备结束，下来就要开工了。这次代码注释写的很详细，原因不表，读者心领神会即可。</p><h3 id="工作开始"><a href="#工作开始" class="headerlink" title="工作开始"></a>工作开始</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">clear all;</span><br><span class="line"></span><br><span class="line">% 工作路径</span><br><span class="line">userpath(&apos;C:\Users\Surface\Desktop&apos;); </span><br><span class="line">% 读取数据</span><br><span class="line">[data,name] = xlsread(&apos;data&apos;,1); % 原数据为原始面板数据，需要转化为空间面板数据</span><br><span class="line"></span><br><span class="line">% 读取几个权重矩阵</span><br><span class="line">weight1 = xlsread(&apos;华东各省会城市距离&apos;,1);            % 基于距离关系的空间权重矩阵</span><br><span class="line">weight2 = xlsread(&apos;华东省区公路邻域&apos;,1);              % 基于邻域关系的空间权重矩阵</span><br><span class="line">weight3t = xlsread(&apos;华东2014GDP计算的经济距离&apos;,1);    % 基于GDP的经济距离关系的空间权重矩阵</span><br><span class="line">weight3 = fanzhuan(weight3t);                        % 将上三角矩阵反转为实对称矩阵，需要fanzhuan包</span><br><span class="line">% 空间权重标准化,函数需要fanzhuan包</span><br><span class="line">W1 = hbzh(weight1);</span><br><span class="line">W2 = lyhbzh(weight2);</span><br><span class="line">W3 = hbzh(weight3);</span><br><span class="line">W = 1/3*W1+1/3*W2+1/3*W3    % 加权构建复合矩阵</span><br><span class="line"></span><br><span class="line">% 问题的维度</span><br><span class="line">T = 40; % 时期数量 </span><br><span class="line">N = 7; % 地区数量</span><br></pre></td></tr></table></figure><p>最最重要的一个地方来了，要使用空间计量分析函数，就要明白其数据结构。</p><h3 id="调整数据结构"><a href="#调整数据结构" class="headerlink" title="调整数据结构"></a>调整数据结构</h3><p>空间面板数据结构<br>时间1 个体1  x1 x2 x3<br>时间1 个体2  x1 x2 x3<br>时间1 个体3  x1 x2 x3<br>……<br>时间2 个体1  x1 x2 x3<br>时间2 个体2  x1 x2 x3<br>时间2 个体3  x1 x2 x3<br>……<br>时间T 个体1  x1 x2 x3<br>时间T 个体2  x1 x2 x3<br>时间T 个体3  x1 x2 x3  </p><p>原始的面板结构如下，需要变换调整：</p><div class="table-container"><table><thead><tr><th></th><th>个体1</th><th>个体2</th><th>个体3</th><th>个体4</th></tr></thead><tbody><tr><td>时间1</td><td><script type="math/tex">x_{11}^{(1)},…… x_{1k}^{(1)}</script></td><td><script type="math/tex">x_{11}^{(2)},…… x_{1k}^{(2)}</script></td><td><script type="math/tex">x_{11}^{(3)},…… x_{1k}^{(3)}</script></td><td><script type="math/tex">x_{11}^{(4)},…… x_{1k}^{(4)}</script></td></tr><tr><td><script type="math/tex">时间2</script></td><td><script type="math/tex">x_{21}^{(1)},…… x_{2k}^{(1)}</script></td><td><script type="math/tex">x_{21}^{(2)},…… x_{2k}^{(2)}</script></td><td><script type="math/tex">x_{21}^{(3)},…… x_{2k}^{(3)}</script></td><td><script type="math/tex">x_{21}^{(4)},…… x_{2k}^{(4)}</script></td></tr><tr><td><script type="math/tex">时间3</script></td><td><script type="math/tex">x_{31}^{(1)},…… x_{3k}^{(1)}</script></td><td><script type="math/tex">x_{31}^{(2)},…… x_{3k}^{(2)}</script></td><td><script type="math/tex">x_{31}^{(3)},…… x_{3k}^{(3)}</script></td><td><script type="math/tex">x_{31}^{(4)},…… x_{3k}^{(4)}</script></td></tr><tr><td><script type="math/tex">时间4</script></td><td><script type="math/tex">x_{41}^{(1)},…… x_{4k}^{(1)}</script></td><td><script type="math/tex">x_{41}^{(2)},…… x_{4k}^{(2)}</script></td><td><script type="math/tex">x_{41}^{(3)},…… x_{4k}^{(3)}</script></td><td><script type="math/tex">x_{41}^{(4)},…… x_{4k}^{(4)}</script></td></tr><tr><td><script type="math/tex">……</script></td><td><script type="math/tex">……</script></td><td><script type="math/tex">……</script></td><td><script type="math/tex">……</script></td><td><script type="math/tex">……</script></td></tr></tbody></table></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">% 调整数据结构,从原始数据转化为空间面板数据</span><br><span class="line">temp =  zeros(T,7);  % 构建存储面板数据的0矩阵</span><br><span class="line">for i = 1:T         % 第i年至第40年</span><br><span class="line">    </span><br><span class="line">    shh = data(i,[2:8]);  % SHH上海当年的全部数据</span><br><span class="line">    shd = data(i,[9:15]); % SHD山东当年的全部数据</span><br><span class="line">    ah = data(i,[16:22]);  % AH 安徽当年的全部数据</span><br><span class="line">    js = data(i,[23:29]);  % JS 江苏当年的全部数据</span><br><span class="line">    zhj = data(i,[30:36]); % ZHJ浙江当年的全部数据</span><br><span class="line">    jx = data(i,[37:43]);  % JX 江西当年的全部数据</span><br><span class="line">    fj = data(i,[44:50]);  % FJ 福建当年的全部数据</span><br><span class="line">    temp&#123;(7*i-6):(7*i),:) = vertcat(shh,shd,ah,js,zhj,jx,fj);  % 将每一年的数据贴进准备好的0矩阵</span><br><span class="line">    </span><br><span class="line">    if i&gt;40</span><br><span class="line">        break</span><br><span class="line">    end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>完事了，建模。先做个简单最小二乘法的回归对比一哈。</p><h3 id="OLS回归"><a href="#OLS回归" class="headerlink" title="OLS回归"></a>OLS回归</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">% 0 OLS模型</span><br><span class="line">% 提取变量</span><br><span class="line">y = temp(:,[1]);           % 华东各地区GDP</span><br><span class="line">x_ols = temp(:,[2:7]); </span><br><span class="line">% 变量名</span><br><span class="line">vnames=strvcat(&apos;gdp&apos;,&apos;renkou&apos;,&apos;gsh&apos;,&apos;gzh&apos;,&apos;tz&apos;,&apos;xf&apos;,&apos;jk&apos;); </span><br><span class="line">% 因变量：GDP（亿元），自变量：人口(万人)，财政收入（亿元），财政支出（亿元），投资（亿元），消费（亿元），进出口（亿元）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">% 建模</span><br><span class="line">results_ols = ols(y,x_ols); % 进行最小二乘法回归</span><br><span class="line">prt_reg(results_ols,vnames,1); </span><br><span class="line"></span><br><span class="line">I = eye(T);W1 = kron(I,W);</span><br><span class="line">res = moran(y,x_ols,W1); % moran 检验</span><br><span class="line">prt(res); %moran值较大，在0.01显著性水平下，依据空间分布的特征显著</span><br></pre></td></tr></table></figure><p>做完空间相关性检验后，一切才刚刚开始。空间相关性检验一般就moran和LR、LM检验。都有现成的函数，适合新手。</p><h3 id="空间计量模型SAR-SEM-SDM"><a href="#空间计量模型SAR-SEM-SDM" class="headerlink" title="空间计量模型SAR,SEM,SDM"></a>空间计量模型SAR,SEM,SDM</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">% ---------------------------------------------------------------------</span><br><span class="line">% 1 SAR模型</span><br><span class="line">% 提取变量：2017年数据</span><br><span class="line">y = temp(274:280,[1]);         </span><br><span class="line">x_sar = temp(274:280,[2,3,4,5,6,7]);      </span><br><span class="line">% 因变量：GDP（亿元），自变量：人口(万人)，财政收入（亿元），财政支出（亿元），投资（亿元），消费（亿元），进出口（亿元）</span><br><span class="line"></span><br><span class="line">% 建模</span><br><span class="line">results_sar = sar(y,x_sar,W);</span><br><span class="line">prt(results_sar,vnames);</span><br><span class="line"></span><br><span class="line">results_sar.tstat        % t检验统计量的值</span><br><span class="line">results_sar.rho          % 空间自回归系数rho</span><br><span class="line">results_sar.beta         % 模型估计的beta值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">% ---------------------------------------------------------------------</span><br><span class="line">% 2 SEM模型</span><br><span class="line">% y = beta*x + mu ; mu = rho*W*mu + e </span><br><span class="line">% 选择变量：2017年数据</span><br><span class="line">y = temp(274:280,[1]); </span><br><span class="line">x_sem = temp(274:280,[2:7]); </span><br><span class="line"></span><br><span class="line">results_sem = sem(y,x_sem,W);</span><br><span class="line">prt(results_sem,vnames);</span><br><span class="line"></span><br><span class="line">results_sem.tstat    % 渐进t检验统计量的值(最后输入为rho空间自回归系数)</span><br><span class="line">results_sem.rho      % (p above)</span><br><span class="line">results_sem.beta     % 模型估计的beta值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">% ---------------------------------------------------------------------</span><br><span class="line">% 3 SDM空间杜宾模型</span><br><span class="line">% y = XB + u (optional) + v (optional) + s,  s = p*W*s + e</span><br><span class="line">% 选择变量:2017年数据</span><br><span class="line">y = temp(274:280,[1]);  </span><br><span class="line">x_sdm = temp(274:280,[2:4]); % 空间相关性影响变量</span><br><span class="line">vnames1=strvcat(&apos;gdp&apos;,&apos;renkou&apos;,&apos;gsh&apos;,&apos;gzh&apos;); </span><br><span class="line"></span><br><span class="line">% 建模</span><br><span class="line">results_sdm = sdm(y,x_sdm,W); </span><br><span class="line">prt(results_sdm,vnames1);</span><br><span class="line"></span><br><span class="line">results_sdm.tstat        % t检验统计量的值</span><br><span class="line">results_sdm.rho          % 最后输入为rho空间自回归系数</span><br><span class="line">results_sdm.beta         % 模型估计的beta值</span><br></pre></td></tr></table></figure><p>以上是三个一年数据的结果，下面是面板数据模型，平时网上搜到的基本都是面板数据模型。</p><p>工具箱目录jplv7→spatial→panel下有一个演示程序：demopanelscompare好像是随机效应与混合模型的选择，使用的方法是LR检验。</p><h3 id="空间面板数据模型"><a href="#空间面板数据模型" class="headerlink" title="空间面板数据模型"></a>空间面板数据模型</h3><p>真没什么好说的。要说的话只能怪罪LMsarsem_panel函数太猛了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">% 4 空间面板数据模型</span><br><span class="line"></span><br><span class="line">% 4.1 空间相关性检验</span><br><span class="line">%LM检验，大于6.635拒绝原假设（不存在空间自相关），即存在误差项空间自相关</span><br><span class="line">LMsarsem_panel(results_sar,W,y,x_sar) </span><br><span class="line">% 结果表明0.1显著性水平下，空间固定效应LR检验通过，空间固定效应的空间滞后的LM检验通过</span><br><span class="line">% 时间固定效应的的空间误差的LM检验不通过,时间固定效应的LR检验不通过</span><br><span class="line">% 故选择时间效应固定模型info.model=2</span><br><span class="line">info.model=2;</span><br><span class="line"></span><br><span class="line">% 4.2 提取变量：30年数据</span><br><span class="line">y = temp(:,[1]);         </span><br><span class="line">x_sar = temp(:,[2,3,4,5,6,7]);      </span><br><span class="line">% 因变量：GDP（亿元），自变量：人口(万人)，财政收入（亿元），财政支出（亿元），投资（亿元），消费（亿元），进出口（亿元）</span><br><span class="line"></span><br><span class="line">% 4.3 建模</span><br><span class="line">results_general = sar_panel_FE(y,x_sar,W,T,info); </span><br><span class="line">prt_spnew(results_general,vnames);</span><br><span class="line"></span><br><span class="line">results_general.corr2     % 模型的拟合优度调整的r方</span><br><span class="line">results_general.tstat     % t检验统计量的值</span><br><span class="line">results_general.rho       % 最后输入为rho空间自回归系数</span><br><span class="line">results_general.beta      % 模型估计的beta值</span><br></pre></td></tr></table></figure><p>info.model参数是设定模型是某种固定效应：<br>info.model=0：表示此模型为混合模型，即没有固定效应；<br>info.model=1：表示此模型为地区固定效应模型；<br>info.model=2：表示时间固定效应模型；<br>info.model=3：表示双向固定效应模型。  </p><h2 id="经验小总结"><a href="#经验小总结" class="headerlink" title="经验小总结"></a>经验小总结</h2><p><strong>help+函数名</strong>这个指令太有用了，任何软件的帮助文档都是学软件的最好老师。</p><p>matlab有个现象，你不加句末的分号，就会输出在下面。我一开始循环没有加分号，每次运行都很慢。</p><p>不知道为什么，他们读“马特拉布”，难道是北美口音？不得而知。</p><p>虽然没有系统学习过matlab，但是这次借着任务也算好好认识了这款传说中的软件，点一下，玩一年，help不花一分钱。真心感觉全部的语言都有相通之处。不过matlab在做统计的问题时，我总是觉得用着不趁手，不如真正的统计软件，输出结果也乱糟糟的。或许这就是没有把好钢用在刀刃上吧。</p><p>结果不贴了，有兴趣的人们可以跑跑看。<a href="https://github.com/konelane/konelane.github.io/blob/master/upload/data%26weight.rar" target="_blank" rel="noopener">数据传送门</a></p><p>松鼠作业一定很优秀了（老父亲笑容）</p><p>（后补，松鼠观罢：烦死了！）</p><p>（完）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最后修改日期：191231，18:31&lt;/p&gt;
&lt;h4 id=&quot;事由&quot;&gt;&lt;a href=&quot;#事由&quot; class=&quot;headerlink&quot; title=&quot;事由&quot;&gt;&lt;/a&gt;事由&lt;/h4&gt;&lt;p&gt;松鼠有难，正派学长自然要拿出一点正派学长的样子。从零开始自学matlab，写写作业，不过如此。好啦，话不多说爱不多示，进入正题吧。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据分析" scheme="https://konelane.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>寻找神奇|名字</title>
    <link href="https://konelane.github.io/2019/09/18/190918%E5%90%8D%E5%AD%97/"/>
    <id>https://konelane.github.io/2019/09/18/190918%E5%90%8D%E5%AD%97/</id>
    <published>2019-09-17T16:00:00.000Z</published>
    <updated>2019-09-18T09:39:47.647Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="名字"><a href="#名字" class="headerlink" title="名字"></a>名字</h2><h4 id="氦核-190918"><a href="#氦核-190918" class="headerlink" title="氦核 190918"></a>氦核 190918</h4><p>名字对于人来说，是十分珍贵的东西。当我们喜欢上某人某事某物时，往往就会给他起上一个爱称。当然笔名也是如此。我也有过很多称呼，有时爱了叫禾禾，有时不爱了叫呵呵，以外观特点取我名的倒没多少，可能是名字比起外貌更加容易记，谁的名字还没有个谐音之梗呢？我倒是不在意，好记就行了。</p><a id="more"></a><p>我曾经称呼自己单行道子，乍看不是人名，但事出有因。当年看了一部对我废话能力影响无穷的动漫，深爱其中某位一流恶党的“彻底”作风，于是在注册贴吧之时就起下此名，希望自己在单行道上一路前行。那时愿望单纯，希望自己在人生路上要永远能够前进，不要后退。变强，那时单纯而由衷的心愿，藏在这个名字中伴随我走了三年。倒是现在，提起这个名字就会掩面而笑，好似回忆起一段不愿意认真审视的二货黑历史。</p><p>后来上高中，视野开阔，脑洞清奇，偏爱理科。听说冥冥之中有一种名为“氦核”的物质，在粒子中力大无比，电子板上轨迹粗壮，单纯而专一，会影响周围而不受电子太多干扰，能够冲击未知带来新发现，种种特性，颇合我心。加上谐音近似我的昵称，不假思索就把它当作了名字。每每有人问起笔名何意，我便莞尔。多年来也无人猜透其中深意，只是认为不过非主流个性，正反约等于氢弹或者核弹。现在也有以我祖母为首直呼我为王源的，我有时会觉得什么真实的东西被掩盖了，但是名字本就是他人用来称呼自己的，对大家来说好记就行。</p><p>说到“氦核”，就不得不提封笔之事，前些日子写歌词的时候又犯了曾经纠正过的毛病：笔下虚浮，空无一物。自觉填词生命耗尽，于是歇了笔耕，改完最后之作后不再写词。虽然看见好词仍会心头悸动，可我知道，不够努力是无法超越某些界限的，不够安静也看不见那些词。明明情感丰富，却摘不出一句能说出口，这也是由于我读书太少、想的太多、说的太多。</p><p>近日我突然想，有没有什么新名字更适合现在得我，毕竟成长了一些，不会把“我要变强”的字眼放在嘴边，待世界也更加温柔，原来那希望发光发热的名字貌似不太适合我现在佛系的心。便寻机求问《易经》，占得一卦泽天夬，夬者，决也。懂的朋友应该已经懂了，不懂的朋友现在肯定是不懂。其实改不改名字，答案我心里早都明白，只不过又让我坚定了一个目标，厚积薄发，该发就发。天不生氦核，屁话界万古如长夜。</p><p>关于名字还有一件有趣的事。起一个好记的名字真的挺重要，但碰巧会被大家都记住的那种，偶尔会产生奇妙的化学反应。母亲的朋友是个老师，在我小学时候经常去他的办公室玩耍。有一天去了，他正在批评一个大哥哥，应该是他的学生，但口中全都是“胡锦涛，你怎么没写作业……胡锦涛怎么又旷课……”我觉着疑惑，觉得像是模仿新闻联播。后来听他讲，原来受批评的学生名叫胡锦涛，那人自号“西北猛汉”，据说某次受罚还一口气做了两百个俯卧撑，属实猛男。他还说，每次教育那个学生时，都有一种奇妙的感觉，仿佛自己是为了某种巨大存在的命运而从事了教育。我当时听了觉得可笑，只是名字相仿罢了。后来我听说了一个词，叫人类命运共同体，我觉得来形容这个应该差不多，反正名字看去相似，而且好记，就行了。</p><p>（完，纯属虚构）</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;名字&quot;&gt;&lt;a href=&quot;#名字&quot; class=&quot;headerlink&quot; title=&quot;名字&quot;&gt;&lt;/a&gt;名字&lt;/h2&gt;&lt;h4 id=&quot;氦核-190918&quot;&gt;&lt;a href=&quot;#氦核-190918&quot; class=&quot;headerlink&quot; title=&quot;氦核 190918&quot;&gt;&lt;/a&gt;氦核 190918&lt;/h4&gt;&lt;p&gt;名字对于人来说，是十分珍贵的东西。当我们喜欢上某人某事某物时，往往就会给他起上一个爱称。当然笔名也是如此。我也有过很多称呼，有时爱了叫禾禾，有时不爱了叫呵呵，以外观特点取我名的倒没多少，可能是名字比起外貌更加容易记，谁的名字还没有个谐音之梗呢？我倒是不在意，好记就行了。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="文章" scheme="https://konelane.github.io/tags/%E6%96%87%E7%AB%A0/"/>
    
  </entry>
  
  <entry>
    <title>寻找神奇|我的一个朋友</title>
    <link href="https://konelane.github.io/2019/08/03/190803%E6%88%91%E7%9A%84%E4%B8%80%E4%B8%AA%E6%9C%8B%E5%8F%8B/"/>
    <id>https://konelane.github.io/2019/08/03/190803%E6%88%91%E7%9A%84%E4%B8%80%E4%B8%AA%E6%9C%8B%E5%8F%8B/</id>
    <published>2019-08-02T16:00:00.000Z</published>
    <updated>2019-08-29T03:35:17.287Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="我的一个朋友"><a href="#我的一个朋友" class="headerlink" title="我的一个朋友"></a>我的一个朋友</h2><h4 id="氦核-190803"><a href="#氦核-190803" class="headerlink" title="氦核 190803"></a>氦核 190803</h4><p>写下这个标题，突然有些后悔，后悔自己似乎不好意思对大家讲这样的事。不过低头沉吟一刻又振作起来，反正要说的不是我的事，是我万能的朋友的故事，这样想来便又能好好说话了。</p><a id="more"></a><p>我这个朋友是个温柔的人，与其说温柔，不如说是闷骚，因为至少他看起来一脸凶相。他还算个性鲜明，名字平平凡凡却有浩瀚之格、显赫之气，念出来让你觉得西安城一半都是他家的；最显著的特点可能是他不太标准的普通话，经常是人未至而声可先辨之。他虽没做过惊天地泣鬼神的壮举，更谈不上有什么豪言壮语，不过活得潇洒。他偶尔当当墙头草二五仔，还算是有底线，否则我也不会成为他的朋友。总而言之我这位朋友是一位普通市民，包藏莫须有的祸心。</p><p>我们本来是同班同学，井水不犯河水，几乎没有交集。因为貌似憨厚可爱，他常被老师当作活跃气氛的调料，本人虽抱怨每每躺枪，却也习以为常，偶尔还引以为荣。我们结识于一场不怎么愉快的言论对撞，他的一段毫无立场可言的发言一度让我信服，可是后来渐渐对个中细节心生疑惑，便询问一二，结果年轻气盛擦枪走火，两人约好某年某月某日某时，李家村广场麦当劳后排雅座，当面辩论。我这位朋友虽说看似憨厚，但也是两百斤的猛男，胳膊弯起来比我大腿还粗，冲动答应了面谈之后，我只好叫上好友在旁掩护，情况不对便出手相救。结果到店虚惊一场，才知道这人深谙网战的无用，缺少形成交流所必要的要素，作为获得信息之处到也无妨，可显然无法加深感情。他并不讨厌我的刻薄（当时的确有些无理），有了倒戈卸甲以礼来降之意，虽然嘴上没有明说，但我们的关系从那时就建立起来。</p><p>当了朋友不要紧，这位朋友的世界虽然和我格格不入，不过也稍稍有些重合——都喜欢某一类作品。我们在那方面聊得甚多，不过他的爆炸发言我一般听之任之，不做太多理会。除过重合的世界，我们生活中剩下的都是难以相互理解的部分。我知道他对科幻文学如痴如醉，他当然也了解我的死宅面目。我请教他的少，但是他私下里常常会来讨教令他不解的死宅心性，在我看来简直不可理喻无法言明的，只能深夜躲在被窝里悄悄百度得那些羞耻问题，他也能面不改色地问出口来。我在掩面解释后，往往痛恨自己了解过多的如此没用死宅世界的知识。他了解了新的知识总会向我挑眉竖大拇指，然后痛骂“死宅真恶心”。我能猜到他的心情，但我也宽恕自己：被骂是被他逼的。</p><p>“放鸽子”指约好了却失约，而我这个朋友最喜欢鸽人。往往是约好的时间又过了一半个小时仍不见人影，久了也不想和他约什么局，但考虑到他又会大方请客请求我的原谅，只得耐心下来。这位朋友是个土豪，主动约我就大概率要请客。我们还实行过一段时间的“部分AA制”，即他请一部分，我们再平摊一部分，这样好像能减轻我白嫖的罪恶感。在他面前我会摇身一变成为一个小女人，只需要跟着他就有吃的，结果现在我却也有了他这样招摇撞骗的伎俩，约人百试不爽。不过我却不喜欢放鸽子，失约总是不好的，他每每提起这点就说我“只学到了功夫，没有内力”，我不以为然。</p><p>我们联系不多，既然是纯洁的君子之交，当然免不了慢慢淡去。虽说偶尔一起打个游戏，不过没了见面的机会，语音聊天的背后总是免不了产生距离感。他网上的言论越来越少，用他的话说叫做“闲人自作自受”，曾经网络键盘阵地的一把手，如今也高高挂起免战牌，一副“我不争，故天下莫能与我争”的阿Q心情，虽然可笑但也潇洒很多。我却依然喜欢争论，多少年本性难移。今天偶然想起他，却也是念着有人请客，但是其他人却怎么也想不起来，某种意义上他还是很成功的。</p><p>（完，本文纯属虚构）</p><p>后注：假期忙碌，内心空虚，学习之余，以文自娱。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;我的一个朋友&quot;&gt;&lt;a href=&quot;#我的一个朋友&quot; class=&quot;headerlink&quot; title=&quot;我的一个朋友&quot;&gt;&lt;/a&gt;我的一个朋友&lt;/h2&gt;&lt;h4 id=&quot;氦核-190803&quot;&gt;&lt;a href=&quot;#氦核-190803&quot; class=&quot;headerlink&quot; title=&quot;氦核 190803&quot;&gt;&lt;/a&gt;氦核 190803&lt;/h4&gt;&lt;p&gt;写下这个标题，突然有些后悔，后悔自己似乎不好意思对大家讲这样的事。不过低头沉吟一刻又振作起来，反正要说的不是我的事，是我万能的朋友的故事，这样想来便又能好好说话了。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="文章" scheme="https://konelane.github.io/tags/%E6%96%87%E7%AB%A0/"/>
    
  </entry>
  
  <entry>
    <title>不务正业|近期收集的有趣小链接</title>
    <link href="https://konelane.github.io/2019/06/04/190604%E6%9C%89%E8%B6%A3%E5%B0%8F%E9%93%BE%E6%8E%A5/"/>
    <id>https://konelane.github.io/2019/06/04/190604%E6%9C%89%E8%B6%A3%E5%B0%8F%E9%93%BE%E6%8E%A5/</id>
    <published>2019-06-03T16:00:00.000Z</published>
    <updated>2019-06-04T06:49:44.300Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="不务正业-近期收集的有趣小链接"><a href="#不务正业-近期收集的有趣小链接" class="headerlink" title="不务正业|近期收集的有趣小链接"></a>不务正业|近期收集的有趣小链接</h2><p>神经病人思路广，沙雕网友欢乐多。</p><p>下面是氦核收集的有趣api，希望大家喜欢</p><a id="more"></a><h3 id="NO-1-明日方舟公开招募计算器"><a href="#NO-1-明日方舟公开招募计算器" class="headerlink" title="NO.1 明日方舟公开招募计算器"></a>NO.1 明日方舟公开招募计算器</h3><p><a href="https://ak.graueneko.xyz/akhr" target="_blank" rel="noopener">传送门</a> 其实不仅仅是计算器，还包括升级花费计算，材料计算，干员表之类。热衷于收集图鉴的我自然不会放过这个有趣的小东西。希望再出几个高级资深tag啊！</p><h3 id="NO-2-王斌对联AI"><a href="#NO-2-王斌对联AI" class="headerlink" title="NO.2 王斌对联AI"></a>NO.2 王斌对联AI</h3><p><a href="https://ai.binwang.me/couplet/" target="_blank" rel="noopener">传送门</a> 这个ai曾经因为太 暴 力而遭到了封杀，今天，这个ai又回来了！支持逗号分句，建议少输入一些特有名词，毕竟会对出你想不到的爆句。</p><h3 id="NO-3-瞎子也要搞人工智能——deepmind的星际争霸2项目"><a href="#NO-3-瞎子也要搞人工智能——deepmind的星际争霸2项目" class="headerlink" title="NO.3 瞎子也要搞人工智能——deepmind的星际争霸2项目"></a>NO.3 瞎子也要搞人工智能——deepmind的星际争霸2项目</h3><p><a href="https://github.com/deepmind/pysc2" target="_blank" rel="noopener">传送门</a> 使用接口是python（无力咆哮），有能力的猛男可以尝试引进训练一波，感受ai的游戏世界，内存消耗不大，主要是费电。</p><h3 id="NO-4-steamspy游戏数据"><a href="#NO-4-steamspy游戏数据" class="headerlink" title="NO.4 steamspy游戏数据"></a>NO.4 steamspy游戏数据</h3><p><a href="http://steamspy.com/" target="_blank" rel="noopener">传送门</a> 我觉得如果要研究价格变化，这个地方你不得不去看看。</p><h3 id="NO-5-mikutap小游戏"><a href="#NO-5-mikutap小游戏" class="headerlink" title="NO.5 mikutap小游戏"></a>NO.5 mikutap小游戏</h3><p><a href="https://static.hfi.me/mikutap/" target="_blank" rel="noopener">传送门</a> 相信我，你会停不下来的，点一下，玩一年。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;不务正业-近期收集的有趣小链接&quot;&gt;&lt;a href=&quot;#不务正业-近期收集的有趣小链接&quot; class=&quot;headerlink&quot; title=&quot;不务正业|近期收集的有趣小链接&quot;&gt;&lt;/a&gt;不务正业|近期收集的有趣小链接&lt;/h2&gt;&lt;p&gt;神经病人思路广，沙雕网友欢乐多。&lt;/p&gt;
&lt;p&gt;下面是氦核收集的有趣api，希望大家喜欢&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="娱乐time" scheme="https://konelane.github.io/tags/%E5%A8%B1%E4%B9%90time/"/>
    
  </entry>
  
  <entry>
    <title>数据挖掘|某不科学的笔记总结（持续更新）</title>
    <link href="https://konelane.github.io/2019/05/17/190508%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%9F%90%E4%B8%8D%E7%A7%91%E5%AD%A6%E7%9A%84%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/"/>
    <id>https://konelane.github.io/2019/05/17/190508%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%9F%90%E4%B8%8D%E7%A7%91%E5%AD%A6%E7%9A%84%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/</id>
    <published>2019-05-16T16:00:00.000Z</published>
    <updated>2020-03-13T02:25:26.515Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="数据挖掘-某不科学的笔记总结（持续更新）"><a href="#数据挖掘-某不科学的笔记总结（持续更新）" class="headerlink" title="数据挖掘|某不科学的笔记总结（持续更新）"></a>数据挖掘|某不科学的笔记总结（持续更新）</h1><p><strong>记录：氦核   最后编辑时间：20190514</strong></p><p>文章主要参考马景义老师的<a href="https://github.com/CUFESAM/Algorithm/blob/master/steplm.ipynb" target="_blank" rel="noopener">数据挖掘教学</a>，与刘苗老师相应课件。笔记中间夹杂很多个人思考与经验，如有错误，请在下方评论区指出，欢迎讨论。</p><a id="more"></a><h2 id="主要算法一览"><a href="#主要算法一览" class="headerlink" title="主要算法一览"></a>主要算法一览</h2><p>基于乔利斯基分解的逐步回归 <a href="https://konelane.github.io/2019/03/22/190322%E9%80%90%E6%AD%A5%E5%9B%9E%E5%BD%92-Cholesky%E5%88%86%E8%A7%A3%E6%B3%95/">传送门</a><br>偏差方差分解&amp;五个模型评价相关指标  <a href="https://konelane.github.io/2019/03/06/190306%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE%E5%88%86%E8%A7%A3&amp;%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7/">传送门</a><br>最优子集回归&amp;最小角度回归  <a href="https://konelane.github.io/2019/03/26/190326%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%9C%80%E4%BC%98%E5%AD%90%E9%9B%86%E5%9B%9E%E5%BD%92&amp;%E6%9C%80%E5%B0%8F%E8%A7%92%E5%9B%9E%E5%BD%92/">传送门</a><br>基于lasso的LARSN  <a href="https://konelane.github.io/2019/04/16/190416LARSN/">传送门</a></p><p>决策树 <a href="https://konelane.github.io/2019/05/07/190507decisiontree/">传送门</a></p><p>adaboost算法介绍（含详细权重解释） <a href="https://konelane.github.io/2019/05/14/190514adaboost/">传送门</a></p><p>聚类分析、EM算法、数据爬取（py）暂缺</p><p>最近要写数据分析报告，笔记补充较晚，见谅（根本就没人看吧喂！）</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;数据挖掘-某不科学的笔记总结（持续更新）&quot;&gt;&lt;a href=&quot;#数据挖掘-某不科学的笔记总结（持续更新）&quot; class=&quot;headerlink&quot; title=&quot;数据挖掘|某不科学的笔记总结（持续更新）&quot;&gt;&lt;/a&gt;数据挖掘|某不科学的笔记总结（持续更新）&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;记录：氦核   最后编辑时间：20190514&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;文章主要参考马景义老师的&lt;a href=&quot;https://github.com/CUFESAM/Algorithm/blob/master/steplm.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;数据挖掘教学&lt;/a&gt;，与刘苗老师相应课件。笔记中间夹杂很多个人思考与经验，如有错误，请在下方评论区指出，欢迎讨论。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据分析" scheme="https://konelane.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>数据挖掘|adaboost原理</title>
    <link href="https://konelane.github.io/2019/05/14/190514adaboost/"/>
    <id>https://konelane.github.io/2019/05/14/190514adaboost/</id>
    <published>2019-05-13T16:00:00.000Z</published>
    <updated>2019-06-04T06:46:00.870Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="adaboost原理（包含权重详细解释）"><a href="#adaboost原理（包含权重详细解释）" class="headerlink" title="adaboost原理（包含权重详细解释）"></a>adaboost原理（包含权重详细解释）</h1><p><a href="https://blog.csdn.net/mousever/article/details/52038198" target="_blank" rel="noopener">参考网页</a></p><p>现阶段流行的boosting算法有adaboost，XGBboost，不要求对数据有什么假定，通过迭代不断完善对模型的建设，是非参数方向的升华，一定程度上解决了高维灾难。</p><p>最后更新时间：190514/23:31</p><a id="more"></a><h2 id="1-1-Adaboost是什么"><a href="#1-1-Adaboost是什么" class="headerlink" title="1.1 Adaboost是什么"></a>1.1 Adaboost是什么</h2><p>AdaBoost，是英文”Adaptive Boosting”（自适应增强）的缩写，由Yoav Freund和Robert Schapire在1995年提出。它的自适应在于：前一个基本分类器分错的样本会得到加强，加权后的全体样本再次被用来训练下一个基本分类器。同时，在每一轮中加入一个新的弱分类器，直到达到某个预定的足够小的错误率或达到预先指定的最大迭代次数。</p><p>具体说来，整个Adaboost 迭代算法就3步：</p><ol><li>初始化训练数据的权值分布。如果有N个样本，则每一个训练样本最开始时都被赋予相同的权值：1/N。</li><li>训练弱分类器（也叫做基分类器）。具体训练过程中，如果某个样本点已经被准确地分类，那么在构造下一个训练集中，它的权值就被降低；相反，如果某个样本点没有被准确地分类，那么它的权值就得到提高。然后，权值更新过的样本集被用于训练下一个分类器，整个训练过程如此迭代地进行下去。</li><li>将各个训练得到的弱分类器组合成强分类器。各个弱分类器的训练过程结束后，加大分类误差率小的弱分类器的权重，使其在最终的分类函数中起着较大的决定作用，而降低分类误差率大的弱分类器的权重，使其在最终的分类函数中起着较小的决定作用。换言之，误差率低的弱分类器在最终分类器中占的权重较大，否则较小。</li></ol><h3 id="1-2-Adaboost算法流程"><a href="#1-2-Adaboost算法流程" class="headerlink" title="1.2 Adaboost算法流程"></a>1.2 Adaboost算法流程</h3><p>给定一个训练数据集T={(x1,y1), (x2,y2)…(xN,yN)}，其中实例$x\in X$，而实例空间$X\subset \R^n​$ ，yi属于标记集合{-1,+1}，Adaboost的目的就是从训练数据中学习一系列弱分类器或基本分类器，然后将这些弱分类器组合成一个强分类器。</p><p>Adaboost的算法流程如下：</p><ul><li><strong>步骤1.</strong> 首先，初始化训练数据的权值分布。每一个训练样本最开始时都被赋予相同的权值：1/N。</li></ul><script type="math/tex; mode=display">D_1 = (w_{11},w_{12},w_{13},...,w_{1N}), w_{1i} = \frac{1}{N}, i = 1,2,...,N</script><ul><li><strong>步骤2.</strong> 进行多轮迭代，用m = 1,2, …, M表示迭代的第多少轮</li></ul><p><strong>a</strong>. 使用具有权值分布Dm的训练数据集学习，得到基本分类器（选取让误差率最低的阈值来设计基本分类器）：</p><script type="math/tex; mode=display">G_m(x): \chi -> {-1,+1}</script><p>会得到原始的和预测的y，+1，-1。</p><p><strong>b</strong>. 计算Gm(x)在训练数据集上的分类误差率</p><script type="math/tex; mode=display">e_m = P(G_m(x_i)≠y_i) = \sum_{i=1}^{N}I(G_m(x_i) ≠ y_i) \tag{误差率}</script><p>这是一个错分情况。</p><p>由上述式子可知，Gm(x)在训练数据集上的<strong>误差率</strong>em就是被Gm(x)误分类样本的权值之和</p><p><strong>c</strong>. 计算Gm(x)的系数，am表示Gm(x)在最终分类器中的重要程度（目的：得到基本分类器在最终分类器中所占的权重）：</p><script type="math/tex; mode=display">\alpha_m = \frac{1}{2}log\frac{1-e_m}{e_m}​</script><p>注：$\alpha_m​$是一棵树的权重，直接根据每棵树的错分情况来的。</p><p>由上述式子可知，$e_m \leq 1/2​$时，am &gt;= 0，且am随着em的减小而增大，意味着分类误差率越小的基本分类器在最终分类器中的作用越大。</p><p><strong>d</strong>. 更新训练数据集的权值分布（目的：得到样本的新的权值分布），用于下一轮迭代</p><script type="math/tex; mode=display">D_1 = (w_{m+1,1},w_{m+1,2},w_{m+1,3},...,w_{m+1,N}),​</script><script type="math/tex; mode=display">w_{m+1,i} = \frac{w_{m,i}}{Z_m}exp(-\alpha_m\gamma_iG_m(x_i)), i = 1,2,...,N \tag{权值更新公式}</script><p>这是一个指数损失$w_{1i}$,$Z_m$是在做规范化。</p><p>使得被基本分类器Gm(x)误分类样本的权值增大，而被正确分类样本的权值减小。就这样，通过这样的方式，AdaBoost方法能“重点关注”或“聚焦于”那些较难分的样本上。</p><p>其中，$Z_m$是规范化因子，使得$D_{m+1}$成为一个概率分布：</p><script type="math/tex; mode=display">Z_m = \sum_{i=1}^{N}exp(-\alpha_my_iG_m(x_i)) \tag{规范化因子}</script><ul><li><strong>步骤3.</strong> 组合各个弱分类器</li></ul><script type="math/tex; mode=display">f(x) = \sum_{m=1}^{M}\alpha_m G_m(x)​</script><p>注：分类对应投票，组合对应回归。</p><p>从而得到最终分类器，如下：</p><script type="math/tex; mode=display">G(x) = sign(f(x)) = sign(\sum_{m=1}^{M}\alpha_mG_m(x)) ​</script><p>如果概念模型很抽象，那么来看一个例子吧。</p><h3 id="1-3-Adaboost的一个例子"><a href="#1-3-Adaboost的一个例子" class="headerlink" title="1.3 Adaboost的一个例子"></a>1.3 Adaboost的一个例子</h3><p>下面，给定下列训练样本，请用AdaBoost算法学习一个强分类器。(二分类问题)</p><div class="table-container"><table><thead><tr><th>序号</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>X</th></tr></thead><tbody><tr><td>X</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td></tr><tr><td>Y</td><td>1</td><td>1</td><td>1</td><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>1</td><td>1</td><td>-1</td></tr></tbody></table></div><p>求解过程：初始化训练数据的权值分布，令每个权值$W_{1i} = \frac{1}{N} = 0.1​$，其中，N = 10，i = 1,2, …, 10，然后分别对于m = 1,2,3, …等值进行迭代。</p><p>拿到这10个数据的训练样本后，根据 X 和 Y 的对应关系，要把这10个数据分为两类，一类是“1”，一类是“-1”，根据数据的特点发现：“0 1 2”这3个数据对应的类是“1”，“3 4 5”这3个数据对应的类是“-1”，“6 7 8”这3个数据对应的类是“1”，9是比较孤独的，对应类“-1”。抛开孤独的9不讲，“0 1 2”、“3 4 5”、“6 7 8”这是3类不同的数据，分别对应的类是1、-1、1，直观上推测可知，可以找到对应的数据分界点，比如2.5、5.5、8.5 将那几类数据分成两类。当然，这只是主观臆测，下面实际计算下这个具体过程。</p><p><strong>迭代过程1</strong></p><p>对于m=1，在权值分布为D1（10个数据，每个数据的权值皆初始化为0.1）的训练数据上，经过计算可得：</p><ol><li>阈值v取2.5时误差率为0.3（x &lt; 2.5时取1，x &gt; 2.5时取-1，则6 7 8分错，误差率为0.3），</li><li>阈值v取5.5时误差率最低为0.4（x &lt; 5.5时取1，x &gt; 5.5时取-1，则3 4 5 6 7 8皆分错，误差率0.6大于0.5，不可取。故令x &gt; 5.5时取1，x &lt; 5.5时取-1，则0 1 2 9分错，误差率为0.4），<em>注：判错概率较高</em></li><li>阈值v取8.5时误差率为0.3（x &lt; 8.5时取1，x &gt; 8.5时取-1，则3 4 5分错，误差率为0.3）。</li></ol><p>可以看到，无论阈值v取2.5，还是8.5，总得分错3个样本，故可任取其中任意一个如2.5，弄成第一个基本分类器为：</p><script type="math/tex; mode=display">G_1(x) = \begin{cases}  1, & x < 2.5 \\-1& x>2.5\end{cases}​</script><p>上面说阈值v取2.5时则6 7 8分错，所以误差率为0.3，更加详细的解释是：因为样本集中</p><ol><li><ol><li>0 1 2对应的类（Y）是1，因它们本身都小于2.5，所以被G1(x)分在了相应的类“1”中，分对了。</li><li>3 4 5本身对应的类（Y）是-1，因它们本身都大于2.5，所以被G1(x)分在了相应的类“-1”中，分对了。</li><li>但6 7 8本身对应类（Y）是1，却因它们本身大于2.5而被G1(x)分在了类”-1”中，所以这3个样本被分错了。</li><li>9本身对应的类（Y）是-1，因它本身大于2.5，所以被G1(x)分在了相应的类“-1”中，分对了。</li></ol></li></ol><p>从而得到G1(x)在训练数据集上的<strong>误差率</strong>（被G1(x)误分类样本“6 7 8”的权值之和）<strong>e1=P(G1(xi)≠yi) = 3*0.1 = 0.3</strong>。</p><p>然后根据误差率e1计算G1的系数：</p><script type="math/tex; mode=display">\alpha_1 = \frac{1}{2} log\frac{1-e_1}{e_1} = 0.4236​</script><p>这个a1代表G1(x)在最终的分类函数中所占的权重（这颗树的权重），为0.4236。<br>接着更新训练数据的权值分布，用于下一轮迭代：</p><script type="math/tex; mode=display">D_1 = (w_{m+1,1},w_{m+1,2},w_{m+1,3},...,w_{m+1,N}),​</script><script type="math/tex; mode=display">w_{m+1,i} = \frac{w_{m,i}}{Z_m}exp(-\alpha_m\gamma_iG_m(x_i)), i = 1,2,...,N​</script><p>（注：原文上一个公式开头是$w_{m+i}​$，疑似写错）</p><p>值得一提的是，由权值更新的公式可知，<strong>每个样本的新权值是变大还是变小，取决于它是被分错还是被分正确。</strong></p><p>即如果某个样本被分错了，则yi <em> Gm(xi)为负，负负得正，结果使得整个式子变大（样本权值变大），否则变小。</em>注：简单地说，上一轮判错，权重则增大*</p><p>第一轮迭代后，最后得到各个数据<strong>新</strong>的权值分布<strong>D2</strong> = (0.0715, 0.0715, 0.0715, 0.0715, 0.0715,  0.0715,0.1666, 0.1666, 0.1666, 0.0715)。由此可以看出，因为样本中是数据“6 7 8”被G1(x)分错了，所以它们的权值由之前的0.1增大到0.1666，反之，其它数据皆被分正确，所以它们的权值皆由之前的0.1减小到0.0715。</p><p>分类函数<script type="math/tex">f1(x)= a1*G1(x) = 0.4236G1(x)​</script>.</p><p>此时，得到的第一个基本分类器sign(f1(x))在训练数据集上有3个误分类点（即6 7 8）。</p><p>从上述第一轮的整个迭代过程可以看出：被误分类样本的权值之和影响误差率，误差率影响基本分类器在最终分类器中所占的权重。</p><p><strong>迭代过程2</strong></p><p>对于m=2，在权值分布为<strong>D2</strong> = (0.0715, 0.0715, 0.0715, 0.0715, 0.0715,  0.0715, 0.1666, 0.1666, 0.1666, 0.0715)的训练数据上，经过计算可得：</p><ol><li><ol><li>阈值v取2.5时误差率为0.1666<em>3（x &lt; 2.5时取1，x &gt; 2.5时取-1，则6 7 8分错，误差率为0.1666</em>3），</li><li>阈值v取5.5时误差率最低为0.0715<em>4（x &gt; 5.5时取1，x &lt; 5.5时取-1，则0 1 2 9分错，误差率为0.0715</em>3 + 0.0715），</li><li><strong>阈值v取8.5</strong>时误差率为0.0715<em>3（x &lt; 8.5时取1，x &gt; 8.5时取-1，<strong>则3 4 5分错</strong>，误差率为0.0715</em>3）。</li></ol></li></ol><p>所以，阈值v取8.5时误差率最低，故第二个基本分类器为：</p><script type="math/tex; mode=display">G_2(x) = \begin{cases}  1, & x < 8.5 \\-1& x>8.5\end{cases}​</script><p>面对的还是下述样本：</p><div class="table-container"><table><thead><tr><th>序号</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>X</th></tr></thead><tbody><tr><td>X</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td></tr><tr><td>Y</td><td>1</td><td>1</td><td>1</td><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>1</td><td>1</td><td>-1</td></tr></tbody></table></div><p>很明显，G2(x)把样本“3 4 5”分错了，根据D2可知它们的权值为0.0715, 0.0715,  0.0715，所以G2(x)在训练数据集上的误差率e2=P(G2(xi)≠yi) = 0.0715 * 3 = 0.2143。</p><p>计算G2的系数：</p><script type="math/tex; mode=display">\alpha_2 = \frac{1}{2} log\frac{1-e_2}{e_2} = 0.6496​</script><p>更新训练数据的权值分布：</p><script type="math/tex; mode=display">D_{m+1} = (w_{m+1,1},w_{m+1,2},w_{m+1,3},...,w_{m+1,N}),​</script><script type="math/tex; mode=display">w_{m+i} = \frac{w_{mi}}{Z_m}exp(-\alpha_m\gamma_iG_m(x_i)), i = 1,2,...,N</script><p><strong>D3</strong> = (0.0455, 0.0455, 0.0455, 0.1667, 0.1667,  0.01667, 0.1060, 0.1060, 0.1060, 0.0455)。被分错的样本“3 4 5”的权值变大，其它被分对的样本的权值变小。<br>f2(x)=0.4236G1(x) + 0.6496G2(x)</p><p>此时，得到的第二个基本分类器sign(f2(x))在训练数据集上有3个误分类点（即3 4 5）。</p><p><strong>迭代过程3</strong></p><p>对于m=3，在权值分布为<strong>D3</strong> = (0.0455, 0.0455, 0.0455, 0.1667, 0.1667,  0.01667, 0.1060, 0.1060, 0.1060, 0.0455)的训练数据上，经过计算可得：</p><ol><li>阈值v取2.5时误差率为0.1060<em>3（x &lt; 2.5时取1，x &gt; 2.5时取-1，则6 7 8分错，误差率为0.1060</em>3），</li><li><strong>阈值v取5.5</strong>时误差率最低为0.0455<em>4（x &gt; 5.5时取1，x &lt; 5.5时取-1，<strong>则0 1 2 9分错</strong>，误差率为0.0455</em>3 + 0.0715），</li><li>阈值v取8.5时误差率为0.1667<em>3（x &lt; 8.5时取1，x &gt; 8.5时取-1，则3 4 5分错，误差率为0.1667</em>3）。</li></ol><p>所以阈值v取5.5时误差率最低，故第三个基本分类器为：</p><script type="math/tex; mode=display">G_3x) = \begin{cases}  1, & x < 5.5 \\-1& x>5.5\end{cases}</script><p>面对的还是下述样本</p><p>依然还是原样本：</p><div class="table-container"><table><thead><tr><th>序号</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>X</th></tr></thead><tbody><tr><td>X</td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td></tr><tr><td>Y</td><td>1</td><td>1</td><td>1</td><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>1</td><td>1</td><td>-1</td></tr></tbody></table></div><p>此时，被误分类的样本是：0 1 2 9，这4个样本所对应的权值皆为0.0455，</p><p>所以G3(x)在训练数据集上的<strong>误差率e3</strong> = P(G3(xi)≠yi) = <strong>0.0455*4</strong> = 0.1820。</p><p>计算G3的系数：</p><script type="math/tex; mode=display">\alpha_3 = \frac{1}{2} log\frac{1-e_3}{e_3} = 0.7514</script><p>更新训练数据的权值分布：</p><script type="math/tex; mode=display">D_{m+1} = (w_{m+1,1},w_{m+1,2},w_{m+1,3},...,w_{m+1,N}),</script><script type="math/tex; mode=display">w_{m+i} = \frac{w_{mi}}{Z_m}exp(-\alpha_m\gamma_iG_m(x_i)), i = 1,2,...,N</script><p><strong>D4</strong> = (0.125, 0.125, 0.125, 0.102, 0.102,  0.102, 0.065, 0.065, 0.065, 0.125)。被分错的样本“0 1 2 9”的权值变大，其它被分对的样本的权值变小。</p><p>f3(x)=0.4236G1(x) + 0.6496G2(x)+0.7514G3(x)</p><p>此时，得到的第三个基本分类器sign(f3(x))在训练数据集上有0个误分类点。至此，整个训练过程结束。</p><p>现在，咱们来总结下3轮迭代下来，各个样本权值和误差率的变化，如下所示（其中，样本权值D中加了下划线的表示在上一轮中被分错的样本的新权值）：</p><ol><li>训练之前，各个样本的权值被初始化为D1 = (0.1, 0.1,0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1)；</li><li><strong>第一轮迭代</strong>中，样本“<strong>6 7 8”</strong>被分错，对应的误差率为<script type="math/tex">e_1=P(G_1(x_i)≠y_i) = 3*0.1 = 0.3</script>，此第一个基本分类器在最终的分类器中所占的权重为<script type="math/tex">a_1 = 0.4236</script>。第一轮迭代过后，样本新的权值为<script type="math/tex">D_2 = (0.0715, 0.0715, 0.0715, 0.0715, 0.0715,  0.0715, 0.1666, 0.1666, 0.1666, 0.0715)；​</script></li><li><strong>第二轮迭代</strong>中，样本<strong>“3 4 5”</strong>被分错，对应的误差率为<script type="math/tex">e_2=P(G_2(x_i)≠y_i) = 0.0715 * 3 = 0.2143</script>，此第二个基本分类器在最终的分类器中所占的权重为<script type="math/tex">a_2 = 0.6496</script>。第二轮迭代过后，样本新的权值为D3 = (0.0455, 0.0455, 0.0455, 0.1667, 0.1667,  0.01667, 0.1060, 0.1060, 0.1060, 0.0455)；</li><li><strong>第三轮迭代</strong>中，样本<strong>“0 1 2 9”</strong>被分错，对应的误差率为<script type="math/tex">e_3 = P(G_3(x_i)≠y_i) = 0.0455*4 = 0.1820</script>，此第三个基本分类器在最终的分类器中所占的权重为<script type="math/tex">a_3 = 0.7514</script>。第三轮迭代过后，样本新的权值为<script type="math/tex">D_4 = (0.125, 0.125, 0.125, 0.102, 0.102,  0.102, 0.065, 0.065, 0.065, 0.125)。</script></li></ol><p>从上述过程中可以发现，如果某些个样本被分错，它们在下一轮迭代中的权值将被增大，反之，其它被分对的样本在下一轮迭代中的权值将被减小。就这样，分错样本权值增大，分对样本权值变小，而在下一轮迭代中，总是选取让误差率最低的阈值来设计基本分类器，所以误差率e（所有被Gm(x)误分类样本的权值之和）不断降低。</p><p>综上，将上面计算得到的a1、a2、a3各值代入G(x)中，<script type="math/tex">G(x) = sign[f3(x)] = sign[ a1 * G1(x) + a2 * G2(x) + a3 * G3(x) ]​</script>，得到<strong>最终的分类器</strong>为：</p><script type="math/tex; mode=display">G(x) = sign[f_3(x)] = sign[ 0.4236G_1(x) + 0.6496G_2(x)+0.7514G_3(x) ]。</script><h2 id="2-Adaboost的误差界-建议先学习第三部分"><a href="#2-Adaboost的误差界-建议先学习第三部分" class="headerlink" title="2 Adaboost的误差界(建议先学习第三部分)"></a>2 Adaboost的误差界(建议先学习第三部分)</h2><p>通过上面的例子可知，Adaboost在学习的过程中不断减少训练误差e，直到各个弱分类器组合成最终分类器，那这个最终分类器的误差界到底是多少呢？</p><p>事实上，Adaboost 最终分类器的训练误差的上界为：</p><script type="math/tex; mode=display">\frac{1}{N} \sum_{i=1}^{N}I(G(x_i)≠y_i)≤\frac{1}{N} \sum_{i=1}^{N}exp(-y_if(x_i)) = \prod_{m-1}^{M}Z_m​</script><p>注：$Z_m​$是将所有概率做归一化的那个因子</p><p>下面，咱们来通过推导来证明下上述式子。</p><p>当G(xi)≠yi时，yi<em>f(xi)&lt;0，因而exp(-yi</em>f(xi))≥1，因此前半部分得证。</p><p>关于后半部分，别忘了：（为下面的推导铺垫）</p><script type="math/tex; mode=display">w_{m+1,i} = \frac{w_{m,i}}{Z_m}exp(-\alpha_m\gamma_iG_m(x_i)), i = 1,2,...,N​</script><script type="math/tex; mode=display">Z_mw_{m+1,i} = w_{m,i}exp(-\alpha_m\gamma_iG_m(x_i))​</script><p>整个的推导过程如下：</p><script type="math/tex; mode=display">\frac{1}{N}\sum_{i}exp(-\sum_{m=1}^{M}\alpha_m\gamma_iG_m(x_i))</script><script type="math/tex; mode=display">=  w_{1i}\sum_{i}exp(-\sum_{m=1}^{M}\alpha_m\gamma_iG_m(x_i))$$ 注意：$\frac{1}{N}$第一次迭代的权重  $$ =  w_{1i}\prod_{m=1}^{M}exp(-\alpha_m\gamma_iG_m(x_i))​</script><script type="math/tex; mode=display">=  Z_1\sum_{i}w_{2i}\prod_{m=2}^{M}exp(-\alpha_m\gamma_iG_m(x_i))$$ 此步需要依靠上面的提到过的式子   $$ =  Z_1Z_2\sum_{i}w_{3i}\prod_{m=3}^{M}exp(-\alpha_m\gamma_iG_m(x_i))​</script><script type="math/tex; mode=display">=  Z_1Z_2...Z_{M-1}\sum_{i}w_{Mi}exp(-\alpha_m\gamma_iG_m(x_i))</script><script type="math/tex; mode=display">= \prod_{m-1}^{M}Z_m</script><p><strong>结论：这个结果说明，可以在每一轮选取适当的Gm使得Zm最小，从而使训练误差下降最快。</strong></p><p>接着，咱们来继续求上述结果的上界。</p><p>对于二分类而言，有如下结果：</p><blockquote><p><a href="http://static.yihaodou.com/tec_data/2016/03/56400756efeba718bd6UyH7Q.jpg" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56400756efeba718bd6UyH7Q.jpg" alt="Adaboost 算法的原理,by 5lulu.com"></a></p></blockquote><p>其中，<a href="http://static.yihaodou.com/tec_data/2016/03/56401556efebaf547888bI18.jpg" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56401556efebaf547888bI18.jpg" alt="Adaboost 算法的原理,by 5lulu.com"></a>。</p><p>继续证明下这个结论。</p><p>由之前Zm的定义式跟本节最开始得到的结论可知：</p><blockquote><p><a href="http://static.yihaodou.com/tec_data/2016/03/56402456efebb8252e3qBm8H.jpg" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56402456efebb8252e3qBm8H.jpg" alt="Adaboost 算法的原理,by 5lulu.com"></a></p></blockquote><p>而这个不等式<a href="http://static.yihaodou.com/tec_data/2016/03/56403256efebc0df292cbfn8.jpg" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56403256efebc0df292cbfn8.jpg" alt="Adaboost 算法的原理,by 5lulu.com"></a>可先由e^x和1-x的开根号，在点x的泰勒展开式推出。</p><p>值得一提的是，如果取γ1, γ2… 的最小值，记做γ（显然，γ≥γi&gt;0，i=1,2,…m），则对于所有m，有：</p><blockquote><p><a href="http://static.yihaodou.com/tec_data/2016/03/56404156efebc97f7e5JYTHI.jpg" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56404156efebc97f7e5JYTHI.jpg" alt="Adaboost 算法的原理,by 5lulu.com"></a></p></blockquote><p>这个结论表明，AdaBoost的训练误差是以指数速率下降的。另外，AdaBoost算法不需要事先知道下界γ，AdaBoost具有自适应性，它能适应弱分类器各自的训练误差率 。</p><p>最后，Adaboost 还有另外一种理解，即可以认为其模型是加法模型、损失函数为指数函数、学习算法为前向分步算法的二类分类学习方法，下个月即12月份会再推导下，然后更新此文。而在此之前，有兴趣的可以参看《统计学习方法》第8.3节或其它相关资料。</p><h2 id="3-Adaboost-指数损失函数推导"><a href="#3-Adaboost-指数损失函数推导" class="headerlink" title="3 Adaboost 指数损失函数推导"></a>3 Adaboost 指数损失函数推导</h2><p>事实上，在上文1.2节Adaboost的算法流程的步骤3中，我们构造的各个基本分类器的线性组合</p><script type="math/tex; mode=display">f(x) = \sum_{m=1}^{M}\alpha_mG_m(x)</script><p>是一个<strong>加法模型</strong>，而Adaboost算法其实是前向分步算法的特例。那么问题来了，什么是加法模型，什么又是前向分步算法呢？</p><p>注意，adaboost算法理论性质并非提出伊始就全部得知，后来在公认的好的解释中逐渐完善。了解：<strong>可加模型，指数损失，二分类算法</strong></p><h3 id="3-1-加法模型和前向分步算法"><a href="#3-1-加法模型和前向分步算法" class="headerlink" title="3.1 加法模型和前向分步算法"></a>3.1 加法模型和前向分步算法</h3><p>如下图所示的便是一个<strong>加法模型</strong></p><script type="math/tex; mode=display">f(x) = \sum_{m=1}^{M}\beta_mb(x;\gamma_m)​</script><p>其中，$b(x;\gamma_m)​$称为基函数，$\gamma_m​$称为基函数的参数，$\beta_m​$称为基函数的系数。</p><p>在给定训练数据及损失函数$L(y,f( x))$的条件下，学习加法模型$f(x)$成为<strong>经验风险</strong>极小化问题，即损失函数极小化问题：</p><script type="math/tex; mode=display">\underset{\beta_m,\gamma_m}{min} \underset{m=1} {\overset{M} \sum}\beta_m b(x_i;\gamma_m)</script><p>注：boosting中可以有各种各样的损失，这只是两种损失而已（指数损失，经验风险损失）。同时注意，adaboost并未对总体做假定，使用的更倾向于非参数的方法，在较低维空间有好效果，高维会出现维数灾难（详情见LASSO算法的介绍章节）</p><p>随后，该问题可以作如此简化：从前向后，每一步只学习一个基函数及其系数，逐步逼近上式，即：每步只优化如下损失函数：</p><script type="math/tex; mode=display">\underset{\beta,\gamma}\min\sum_{i=1}^{N},L(y_i,\beta b(x_i;\gamma))</script><p>这个优化方法便就是所谓的前向分步算法。</p><p>下面，咱们来具体看下<strong>前向分步算法</strong>的算法流程：</p><ul><li><p>输入：训练数据集$T = {(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}​$</p></li><li><p>损失函数：$L(y,f(x))​$</p></li><li><p>基函数集：${b(x;\gamma)}$</p></li><li><p>输出：加法模型$f(x )$</p></li><li><p>算法步骤：</p><p>1.初始化$f_0(x) = 0$</p><p>2.对于m=1,2,..M</p><ul><li>a)极小化损失函数</li></ul></li></ul><blockquote><script type="math/tex; mode=display">(\beta_m,\gamma_m) = arg \underset{\beta,\gamma}{min} \sum_{i=1}^{N},L(y_i,f(_{m-1}(x_i) + \beta b(x_i;\gamma))​</script><p>得到参数<script type="math/tex">\beta_m,\gamma_m​</script></p></blockquote><ul><li>b)更新</li></ul><script type="math/tex; mode=display">f_m(x) = f_{m-1}(x) + \beta_mb(x;\gamma_m)​</script><ul><li>3.最终得到加法模型</li></ul><script type="math/tex; mode=display">f(x) = f_{M}(x) = \underset{m=1} {\overset{M}\sum} \beta_mb(x;\gamma_m)​</script><p>就这样，前向分步算法将同时求解从m=1到M的所有参数（<a href="http://tec.5lulu.com/upload/2016/03/56426056efeca4ed1e3ffsxX.png" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56426056efeca4ed1e3ffsxX.png" alt="img"></a>、<a href="http://tec.5lulu.com/upload/2016/03/56427256efecb0f1ee8gntDJ.png" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56427256efecb0f1ee8gntDJ.png" alt="img"></a>）的优化问题简化为逐次求解各个<a href="http://tec.5lulu.com/upload/2016/03/56426056efeca4ed1e3ffsxX.png" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56426056efeca4ed1e3ffsxX.png" alt="img"></a>、<a href="http://static.yihaodou.com/tec_data/2016/03/56427256efecb0f1ee8gntDJ.png" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56427256efecb0f1ee8gntDJ.png" alt="Adaboost 算法的原理,by 5lulu.com"></a>（1≤m≤M）的优化问题。</p><h3 id="3-2-前向分步算法与Adaboost的关系"><a href="#3-2-前向分步算法与Adaboost的关系" class="headerlink" title="3.2 前向分步算法与Adaboost的关系"></a>3.2 前向分步算法与Adaboost的关系</h3><p>在上文第2节最后，我们说Adaboost 还有另外一种理解，即可以认为其模型是加法模型、损失函数为指数函数、学习算法为前向分步算法的二类分类学习方法。其实，Adaboost算法就是前向分步算法的一个特例，Adaboost 中，各个基本分类器就相当于加法模型中的基函数，且其损失函数为指数函数。</p><p>换句话说，当前向分步算法中的基函数为Adaboost中的基本分类器时，加法模型等价于Adaboost的最终分类器</p><script type="math/tex; mode=display">f( x) = \underset{m=1} {\overset{M}\sum} \alpha_mG_m(x )</script><p>你甚至可以说，这个最终分类器其实就是一个加法模型。只是这个加法模型由基本分类器<a href="http://tec.5lulu.com/upload/2016/03/56436356efed0b0d6a8XTjJo.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56436356efed0b0d6a8XTjJo.gif" alt="img"></a>及其系数<a href="http://static.yihaodou.com/tec_data/2016/03/56435556efed031f385djuKh.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56435556efed031f385djuKh.gif" alt="Adaboost 算法的原理,by 5lulu.com"></a>组成，m = 1, 2, …, M。前向分步算法逐一学习基函数的过程，与Adaboost算法逐一学习各个基本分类器的过程一致。</p><p>下面，咱们便来证明：<strong>当前向分步算法的损失函数是指数损失函数</strong></p><script type="math/tex; mode=display">L(y,f(x)) = exp(-yf(x))​</script><p><strong>时，其学习的具体操作等价于Adaboost算法的学习过程</strong>。</p><p>假设经过m-1轮迭代，前向分步算法已经得到$f_{m-1}(x)$：</p><script type="math/tex; mode=display">f_{m-1}(x) = f_{m-2}(x) + \alpha_{m-1}G_{m-1}(x) = \alpha_{1}G_{1}(x) + ... + \alpha_{m-1}G_{m-1}(x)​</script><p>而后在第m轮迭代得到$\alpha_m$、$G_m(x)$、$f_m(x)$，其中$f_m(x)$为：</p><script type="math/tex; mode=display">f_m(x) = f_{m-1}(x) + \alpha_mG_m(x)  \tag{模型 }</script><p>而<a href="http://tec.5lulu.com/upload/2016/03/56435556efed031f385djuKh.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56435556efed031f385djuKh.gif" alt="img"></a>和<a href="http://tec.5lulu.com/upload/2016/03/56436356efed0b0d6a8XTjJo.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56436356efed0b0d6a8XTjJo.gif" alt="img"></a>未知。所以，现在咱们的目标便是根据前向分步算法训练<a href="http://tec.5lulu.com/upload/2016/03/56435556efed031f385djuKh.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56435556efed031f385djuKh.gif" alt="img"></a>和<a href="http://tec.5lulu.com/upload/2016/03/56436356efed0b0d6a8XTjJo.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56436356efed0b0d6a8XTjJo.gif" alt="img"></a>，使得最终<a href="http://static.yihaodou.com/tec_data/2016/03/56437356efed15438a5ABAwY.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56437356efed15438a5ABAwY.gif" alt="Adaboost 算法的原理,by 5lulu.com"></a>在训练数据集T上的指数损失最小，即</p><script type="math/tex; mode=display">(\alpha_m,G_m(x)) = arg \underset{\alpha,G}{min} \sum_{i=1}^{N}exp(-y_i(f_{m-1}(x_i) + \alpha G(x_i) ))​</script><p>针对这种需要求解多个参数的情况，可以先固定其它参数，求解其中一两个参数，然后逐一求解剩下的参数。例如我们可以固定<script type="math/tex">G_1(x),...,G_{m-1}(x)​</script>和<script type="math/tex">\alpha_1,...,\alpha_{m-1}​</script>，只针对$G_m(x)​$,$\alpha_m ​$做优化。</p><p>换言之，在面对<script type="math/tex">G_1(x),...,G_{m-1}(x),G_m(x)​</script>和<script type="math/tex">\alpha_1,...,\alpha_{m-1},\alpha_m ​</script> 这2m个参数都未知的情况下，可以：</p><ol><li>先假定<script type="math/tex">G_1(x),...,G_{m-1}(x)</script>和<script type="math/tex">\alpha_1,...,\alpha_{m-1}</script>已知，求解出$G_m(x)$和$\alpha_m $；</li><li>然后再逐一求解其它未知参数。</li></ol><p>且考虑到上式中的 <script type="math/tex">exp(-y_if_{m-1}(x_i))</script>既不依赖 $\alpha$ 也不依赖G，所以是个与最小化无关的固定值，记为<script type="math/tex">\bar{w}_{mi }</script>，即<script type="math/tex">\bar{w}_{mi } = exp(-y_if_{m-1}(x_i))</script>，则上式可以表示为（后面要多次用到这个式子，简记为<script type="math/tex">(\alpha_m, G_m(x ))</script>：</p><script type="math/tex; mode=display">(\alpha_m,G_m(x)) = arg \underset{\alpha,G}{min} \sum_{i=1}^{N} \bar{w}_{mi } exp(-y_i \alpha G(x_i))</script><p>只需要找到<script type="math/tex">(\alpha_m,G_m(x)) ​</script>使得式子最小就行了。</p><p>值得一提的是，$\bar{w}_{mi}​$虽然与最小化无关，但$\bar{w}_{mi}​$依赖于$f_{m-1}(x)​$，随着每一轮迭代而发生变化。</p><p>接下来，便是要证<strong>使得上式达到最小的<script type="math/tex">\alpha_m^* 和 G^*_m(x)​</script>就是Adaboost算法所求解得到的</strong><script type="math/tex">\alpha_m 和 G_m(x)​</script>。</p><p>为求解上式，咱们先求<script type="math/tex">G^*_m(x)​</script>再求<script type="math/tex">\alpha_m^* ​</script>。</p><p>首先求<script type="math/tex">G^*_m(x)</script>。对于任意<script type="math/tex">\alpha >0</script>，<strong>使上式<script type="math/tex">(\alpha_m,G_m(x))</script>最小的G(x)由下式得到：</strong></p><script type="math/tex; mode=display">G_m^*(x) = arg \underset{G}{min}\sum_{i=1}^N\bar{w}_{mi}I(y_i ≠ G(x_i))​</script><p>注意：$y_i ≠G(x_i)​$的时候示性函数取值为1。</p><p>别忘了，<script type="math/tex">\bar{w}_{mi} = exp(-y_i,f_{m-1}(x_i))​</script>。</p><p>跟1.2节所述的误差率的计算公式对比下：</p><script type="math/tex; mode=display">e_m = P(G_m(x_i) ≠ y_i)  =  \sum _{i=1}^{N} w_{mi}I(y_i ≠ G_m(x_i))​</script><p>可知，上面得到的<a href="http://tec.5lulu.com/upload/2016/03/56476556efee9d70e34hyQO7.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56476556efee9d70e34hyQO7.gif" alt="img"></a>便是Adaboost算法的基本分类器<a href="http://tec.5lulu.com/upload/2016/03/56477756efeea91d0f0a0MzR.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56477756efeea91d0f0a0MzR.gif" alt="img"></a>，因为它是在第m轮加权训练数据时，使分类误差率最小的基本分类器。换言之，这个<a href="http://tec.5lulu.com/upload/2016/03/56476556efee9d70e34hyQO7.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56476556efee9d70e34hyQO7.gif" alt="img"></a>便是Adaboost算法所要求的<a href="http://static.yihaodou.com/tec_data/2016/03/56477756efeea91d0f0a0MzR.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56477756efeea91d0f0a0MzR.gif" alt="Adaboost 算法的原理,by 5lulu.com"></a>，别忘了，在Adaboost算法的每一轮迭代中，都是选取让误差率最低的阈值来设计基本分类器。</p><p><strong>然后求<img src="http://static.yihaodou.com/tec_data/2016/03/56479356efeeb9a19f899ez6.gif" alt="img"></strong>。还是回到之前的这个式子<a href="http://static.yihaodou.com/tec_data/2016/03/56475756efee95ba0a6yWnd7.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56475756efee95ba0a6yWnd7.gif" alt="Adaboost 算法的原理,by 5lulu.com"></a>上：</p><script type="math/tex; mode=display">(\alpha_m,G_m(x))=  arg \underset{\alpha, G}{min} \sum _{i=1}^{N} \bar{w}_{mi}exp(-y_i \alpha G(x_i))​</script><p>这个式子的后半部分可以进一步化简，得：<strong>（这一部分是求解目标）</strong></p><blockquote><script type="math/tex; mode=display">\sum_{i=1}^{N}\bar{w}_{mi}exp(-y_i\alpha G(x_i))</script><script type="math/tex; mode=display">= \sum_{y_i = G_m(x_i)}\bar{w}_{mii}e^{-\alpha} + \sum_{y_i ≠ G_m(x_i)}\bar{w}_{mii}e^{\alpha}</script><script type="math/tex; mode=display">= (e^\alpha - e^{-\alpha})\sum_{i=1}^{N}\bar{w}_{mi}I(y_i ≠ G(x_i)) + e^{-\alpha}\sum_{i=1}^{N}\bar{w}_{mi}</script></blockquote><p>疑问：第二行拆开之后如何理解呢？这两项求和是什么东西呢？</p><p>前一个看成一个1，后一个看成错误率，再求导就好算了</p><p>接着将上面求得的$G_m^*(x)$</p><script type="math/tex; mode=display">G_m^*(x) = arg \underset{G}{min} \sum _{i=1}^{N} \bar{w}_{mi}I(y_i ≠ G_m(x_i))​</script><p>代入上式中，且对<a href="http://tec.5lulu.com/upload/2016/03/56469856efee5ae57dfwaAa5.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56469856efee5ae57dfwaAa5.gif" alt="img"></a>求导，令其求导结果为0，即得到使得<a href="http://tec.5lulu.com/upload/2016/03/56470756efee63d9c62cMKGX.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56470756efee63d9c62cMKGX.gif" alt="img"></a>一式最小的<a href="http://static.yihaodou.com/tec_data/2016/03/56469856efee5ae57dfwaAa5.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56469856efee5ae57dfwaAa5.gif" alt="Adaboost 算法的原理,by 5lulu.com"></a>，即为：</p><blockquote><p><a href="http://static.yihaodou.com/tec_data/2016/03/56449956efed9384397XiGA6.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56449956efed9384397XiGA6.gif" alt="Adaboost 算法的原理,by 5lulu.com"></a></p></blockquote><p>这里的<a href="http://tec.5lulu.com/upload/2016/03/56472156efee713bdf6gdBEF.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56472156efee713bdf6gdBEF.gif" alt="img"></a>跟上文1.2节中<strong><img src="http://static.yihaodou.com/tec_data/2016/03/56435556efed031f385djuKh.gif" alt="Adaboost 算法的原理,by 5lulu.com"></strong>的计算公式完全一致。</p><p>此外，毫无疑问，上式中的<a href="http://static.yihaodou.com/tec_data/2016/03/56464856efee2865cf9bAxXM.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56464856efee2865cf9bAxXM.gif" alt="Adaboost 算法的原理,by 5lulu.com"></a>便是误差率：</p><script type="math/tex; mode=display">e_m = \frac{\sum_{i=1}^{N} \bar{w}_{mi } I(y_i ≠G(x_i))} {\sum_{i=1}^{N} \bar{w}_{mi } } = \sum_{i=1}^{N} \bar{w}_{mi } I(y_i ≠G(x_i)) ​</script><p>即$e_m $就是被$G_m(x) $误分类样本的权值之和。</p><p>就这样，结合模型<script type="math/tex">f_m(x) = f_{m-1}(x) + \alpha_mG_m(x)</script>，跟<script type="math/tex">\bar{w}_{mi } = exp[-y_if_{m-1}(x_i)]</script>，可以推出</p><script type="math/tex; mode=display">\bar{w}_{m+1,i} = exp[-y_if_m(x_i)]​</script><script type="math/tex; mode=display">= exp[-y_i(f_{m-1}(x_i)+ \alpha_mG_m(x))]​</script><script type="math/tex; mode=display">= exp[-y_if_{m-1}(x_i)]+ exp[-y_i\alpha_mG_m(x))]​</script><p>从而有：</p><script type="math/tex; mode=display">\bar{w}_{m+1,i} = \bar{w}_{m,i} exp(-y_i \alpha_mG_m(x))​</script><p>与上文1.2节介绍的权值更新公式</p><script type="math/tex; mode=display">\bar{w}_{m+1,i} = \frac{\bar{w}_{m,i}}{Z_m} exp(-\alpha_m y_i G_m(x_i)), i = 1,2,...,N</script><p>相比，只相差一个规范化因子，即后者多了一个</p><script type="math/tex; mode=display">Z_m = \sum_{i=1}^{N}exp(- \alpha_m y_iG_m(x_i))​</script><p>所以，整个过程下来，我们可以看到，前向分步算法逐一学习基函数的过程，确实是与Adaboost算法逐一学习各个基本分类器的过程一致，两者完全等价。</p><p>综上，本节不但提供了Adaboost的另一种理解：加法模型，损失函数为指数函数，学习算法为前向分步算法，而且也解释了最开始1.2节中基本分类器<a href="http://tec.5lulu.com/upload/2016/03/56436356efed0b0d6a8XTjJo.gif" target="_blank" rel="noopener"><img src="http://static.yihaodou.com/tec_data/2016/03/56436356efed0b0d6a8XTjJo.gif" alt="img"></a>及其系数<strong><img src="http://static.yihaodou.com/tec_data/2016/03/56435556efed031f385djuKh.gif" alt="Adaboost 算法的原理,by 5lulu.com"></strong>的由来，以及对权值更新公式的解释，你甚至可以认为本节就是对上文整个1.2节的解释</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;adaboost原理（包含权重详细解释）&quot;&gt;&lt;a href=&quot;#adaboost原理（包含权重详细解释）&quot; class=&quot;headerlink&quot; title=&quot;adaboost原理（包含权重详细解释）&quot;&gt;&lt;/a&gt;adaboost原理（包含权重详细解释）&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/mousever/article/details/52038198&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考网页&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;现阶段流行的boosting算法有adaboost，XGBboost，不要求对数据有什么假定，通过迭代不断完善对模型的建设，是非参数方向的升华，一定程度上解决了高维灾难。&lt;/p&gt;
&lt;p&gt;最后更新时间：190514/23:31&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据分析" scheme="https://konelane.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>数据挖掘|决策树</title>
    <link href="https://konelane.github.io/2019/05/07/190507decisiontree/"/>
    <id>https://konelane.github.io/2019/05/07/190507decisiontree/</id>
    <published>2019-05-06T16:00:00.000Z</published>
    <updated>2019-05-08T13:08:20.138Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="数据挖掘-决策树和相关算法"><a href="#数据挖掘-决策树和相关算法" class="headerlink" title="数据挖掘|决策树和相关算法"></a>数据挖掘|决策树和相关算法</h1><p>数据挖掘笔记</p><p>记录：氦核   最后编辑时间：20190508</p><p>前排简介，本文不涉及实战，仅仅举例。文章中间夹杂很多个人思考与经验，如有错误，请在下方评论区指出，欢迎讨论。</p><a id="more"></a><h2 id="预测数据集"><a href="#预测数据集" class="headerlink" title="预测数据集"></a>预测数据集</h2><p>年龄、性别、家庭所得、是否购买</p><p>目标：用前面三列的数据预测是否购买</p><p>&gt;<br>root node根节点<br>non-leaf node：非叶结点<br>branches：分支<br>leaf node：叶子节点</p><p>注：树不一定对称。很多时候会有一个偏态<br>树分为两种，一种是分类树（离散变量），一种是回归树（连续变量）。</p><p>对每一个变量进行大致分类：  </p><blockquote><p>1.年龄-小于35、大于等于35<br>2.家庭所得：低、高、小康<br>3.性别：男、女    </p></blockquote><p>此时，只有年龄是我们希望看到的根节点分类。</p><p>如何分节点呢？最常见的方式是计算<strong>信息增益</strong></p><h3 id="信息增益的计算"><a href="#信息增益的计算" class="headerlink" title="信息增益的计算"></a>信息增益的计算</h3><h4 id="方法1：ID3"><a href="#方法1：ID3" class="headerlink" title="方法1：ID3"></a>方法1：ID3</h4><script type="math/tex; mode=display">I = -(P_1*log_2(p_1) + ... + P_k*log_2(p_k)) = - \sum_{i = 1}^{k}{P_i*log_2(p_i)}</script><script type="math/tex; mode=display">Gain(X) = I(n,n_1) - E(X)  ​</script><p>注：  </p><script type="math/tex; mode=display">I(n,n_1) = -(n_1/n)*log_2(n_1/n) + (n-n_1)/n *log_2((n-n_1)/n)</script><script type="math/tex; mode=display">E(X) = m_1 /n * I(m_1,m_{11}) + m_2 /n * I(m_2,m_{21}) +...+ m_k /n * I(m_k,m_{k1})</script><p>节点分开后，对另外的变量进行信息增益的计算</p><p>一棵树，三个节点</p><p>总结一下：信息增益——基于熵的概念（搞信息的人常用）</p><p>做分支前后熵的差值</p><h4 id="方法2：GINI-INDEX"><a href="#方法2：GINI-INDEX" class="headerlink" title="方法2：GINI INDEX"></a>方法2：GINI INDEX</h4><script type="math/tex; mode=display">i(t) = \sum_{i≠j}p(i/t)p(j/t)​</script><script type="math/tex; mode=display">gini_{split}(T) = \frac{N_1}{N} gini(T_1) + \frac{N_2}{N} gini(T_2)​</script><p>将基尼系数最小的作为划分属性</p><p>做统计的常用，比较简便</p><p>注：ID3（信息增益）</p><p>当ID3确定根节点以及后续节点后，当满足一下条件该分支可以结束：  </p><p>1.该群数据的每一个数据都已经归类到同一类别中</p><p>2.该群数据已经没办法找到新的属性进行节点分割</p><p>3.该群数据已经没有尚未处理的数据</p><h4 id="过度拟合问题"><a href="#过度拟合问题" class="headerlink" title="过度拟合问题"></a>过度拟合问题</h4><p>并不一定是好事，有可能发生过度拟合，在推广模型时产生较大误差。</p><p>两种过度拟合：</p><p>1.噪声导致的过度拟合，如错误的分类，或者属性值</p><p>2.缺乏代表性的样本导致，如数据有偏</p><p>出现过度拟合时处理方式：剪枝</p><h2 id="剪枝"><a href="#剪枝" class="headerlink" title="剪枝"></a>剪枝</h2><h3 id="预剪枝：提前停止树的构建"><a href="#预剪枝：提前停止树的构建" class="headerlink" title="预剪枝：提前停止树的构建"></a>预剪枝：提前停止树的构建</h3><p>1.定义一个高度，到达时停止生长</p><p>2.达到某个节点的实例具有相同的特征向量，即使这些实例不属于同一类，也可以停止决策树的生长。这个方法对于处理数据的数据冲突问题比较有效</p><p>3.定义一个阈值，当达到某个节点的实例个数小于阈值时，停止生长（常用）</p><p>4.定义一个阈值，通过计算每次扩张对系统性能的增益，并比较增益值与该阈值大小来决定是否停止生长</p><p>思考：有没有什么不太好的地方</p><p>第二个比较特别，特殊情况特殊考虑。第四个更容易接受，理由是比较客观。因为阈值不好设置，需要经验。</p><p>因此预剪枝的方式好理解，但是多采用后剪枝的方式。但是要求计算量和计算速度。</p><h3 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a>后剪枝</h3><p>首先构造完整的决策树，允许树过度拟合训练数据，然后对那些置信度不够的结点子树用叶子结点来代替，该叶子的类标号用该结点子树中最频繁的类标记。</p><p>相比于预剪枝，这种方法更常用。</p><h3 id="其他剪枝方法"><a href="#其他剪枝方法" class="headerlink" title="其他剪枝方法"></a>其他剪枝方法</h3><p>Minimal cost-complexity  pruning<br><strong>CCP代价复杂度剪枝</strong></p><script type="math/tex; mode=display">R_\alpha(T) = R(T) + \alpha |T| ​</script><script type="math/tex; mode=display">R_\alpha(T(\alpha)) = min_{T <= T_(max) } R_\alpha (T) ​</script><p>该算法为子树<script type="math/tex">T_t</script>定义了代价和复杂度以及一个可由用户设置的衡量代价与复杂度之间关系的参数<script type="math/tex">\alpha</script></p><p><strong>代价</strong>指在剪枝过程中因子树<script type="math/tex">T_t</script>被叶节点替代而增加的错分样本</p><p>复杂度表示剪枝后子树<script type="math/tex">T_t​</script>减少的叶结点数</p><script type="math/tex; mode=display">\alpha$$ 则表示剪枝后树的复杂度降低程度与代价间的关系$$ \alpha =  \frac{R(t) - R(T_t)}{|N_1| - 1} ​</script><p>|N1|：子树<script type="math/tex">T_t</script>中的叶节点数，衡量树的复杂度</p><p>R(t) ：结点t的错误代价</p><p>R(t) = r(t) ∗p(t) ， r(t)为结点t的错分样本率 p(t)为落入结点t的样本占所有样本的比例</p><p>R(<script type="math/tex">T_t</script>)：子树Tt错误代价</p><p>R(<script type="math/tex">T_t</script>)=$\sum$R(i)，i为子树<script type="math/tex">T_t​</script>的叶节点</p><p><strong>步骤：</strong></p><p>1.对于完全决策树T的每个非叶结点计算α值，<strong>循环剪掉</strong>具有最小α值的子树，直到剩下根节点。在该步可得到一系列的剪枝树｛T0，T1，T2……Tm｝,其中T0为原有的完全决策树，Tm为根结点，$T_{i+1}​$为对$T_i​$进行剪枝的结果；</p><p>2.从子树序列中，根据真实的误差估计选择最佳决策树。</p><p>即：几个分对了，几个分错了</p><h3 id="一倍标准差规则"><a href="#一倍标准差规则" class="headerlink" title="一倍标准差规则"></a>一倍标准差规则</h3><p>有一个cp（复杂度参量）取不同值的table，</p><p>展示每个样本的CP，nsplit，rel error，xerror，xstd</p><p>原则首先保证一定的预测误差（通过交叉验证获得，训练模型放进预测模型验证，k轮交叉验证后获得误差的平均xerror）尽量小，但不一定要取最小值，而是允许它在<em>“最小的误差+或-一个相应标准差”</em>的范围内，然后再此范围内选取尽量小的复杂性参量，进而以它为依据进行剪枝。</p><p>CP值越大模型越精简（小的时候需要剪枝），CP不断减小时，xerror先变小后变大（树预测结果先变好，后过拟合）。我们要找xerror最小的行，同时也要综合CP值，选一个较大的。</p><h2 id="连续型变量的树处理"><a href="#连续型变量的树处理" class="headerlink" title="连续型变量的树处理"></a>连续型变量的树处理</h2><p>自变量连续条件可以由树处理</p><p>甚至因变量连续也可以（决策树回归）</p><p>如何处理？也得分支，建树</p><p>利用<strong>大于小于分支</strong></p><h2 id="部分代码实现（R"><a href="#部分代码实现（R" class="headerlink" title="部分代码实现（R)"></a>部分代码实现（R)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">fit &lt;- rpart(Species~., data=iris,method=&quot;class&quot;)</span><br><span class="line">    #建立分类树的模型</span><br><span class="line">fit2 &lt;-rpart(Species~.,data=iris,control=rpart.control(cp=.05))</span><br><span class="line"></span><br><span class="line">print(fit)                      #展示分类树的主要输出结果</span><br><span class="line">path.rpart(fit, node=c(1,2,3))  #展示前四个节点的分枝情况</span><br><span class="line"></span><br><span class="line">plot(fit, asp=4, compress=T)</span><br><span class="line">text(fit, cex=1,use.n=T)        #画出分类树的图</span><br></pre></td></tr></table></figure><p>method参数：class“离散型”，anova“连续型”，poisson”计数型“，exp“生存分析型”</p><p>control：用来控制每个节点的最小样本量、交叉验证的次数、复杂性参量（cp）。这个参数意味着对每一步拆分，模型的拟合优度必须提高的程度</p><h3 id="其他实操要注意的（其实是讲代码时候突然提到的，没地方记了）"><a href="#其他实操要注意的（其实是讲代码时候突然提到的，没地方记了）" class="headerlink" title="其他实操要注意的（其实是讲代码时候突然提到的，没地方记了）"></a>其他实操要注意的（其实是讲代码时候突然提到的，没地方记了）</h3><p>混淆矩阵再两分类比较好分析，错分情况的概率好解释。但如果维数较高，就不好解释了。实际含义与二维相比可能有所不同。</p><h2 id="决策树方法不好的地方"><a href="#决策树方法不好的地方" class="headerlink" title="决策树方法不好的地方"></a>决策树方法不好的地方</h2><p>鸢尾花数据，抽选部分数据做模型，“建一棵树”的方法用在不同的数据集上时，结果会一样吗？</p><p>决策树方法很不稳定</p><h3 id="如何评价树的好坏？"><a href="#如何评价树的好坏？" class="headerlink" title="如何评价树的好坏？"></a>如何评价树的好坏？</h3><blockquote><p>1.K 折交叉验证</p><p>2.留1验证</p><p>3.oob估计</p></blockquote><p>k折交叉验证是以前讲过的方法，做很多轮。k取很大或很小都不好：k取很大时即留1验证；k取很小时测试得到的误差太不稳定。</p><p>留1验证即每次只留一个作为测试样本</p><h2 id="几个处理决策树精度的方法"><a href="#几个处理决策树精度的方法" class="headerlink" title="几个处理决策树精度的方法"></a>几个处理决策树精度的方法</h2><h3 id="boostrap（自助法）"><a href="#boostrap（自助法）" class="headerlink" title="boostrap（自助法）"></a>boostrap（自助法）</h3><p>最重要特点：从n个样品中，<strong>等概率</strong>地<strong>有放回</strong>地抽样。</p><p>抽出n个，抽多轮。称为bootstrap抽样集。</p><p>对训练集L进行bootstrap抽样(样本量为n)获得新的训练集，从训练集中等概率、有放回的重新抽取样本，得到bootstrap抽样数据集。</p><p>对于一个样本点i来说，它出现在bootstrap抽样数据集$Z^∗$中的概率 </p><script type="math/tex; mode=display">P(x_i,y_i )∈Z^∗)=1-(1-1/N)^N≈0.632</script><p>换句话说，由于bootstrap抽样的性质，<strong>L中大约每次约有37%的样本点不在$L_m$中</strong>。</p><p>可以将bootstrap抽样理解成从数据Z的经验分布中的抽样。即可以将训练集和bootstrap抽样训练集理解为<strong>来自同一分布</strong>的。</p><p>每一轮抽取时，未被bootstrap抽中的（37%），当作测试集。</p><h3 id="Out-Of-Bag"><a href="#Out-Of-Bag" class="headerlink" title="Out Of Bag"></a>Out Of Bag</h3><p>对训练集L进行bootstrap抽样(样本量为N)获得新的训练集${ L_m,m = 1,2,…,M}​$时，由于bootstrap抽样的性质，L中大约每次有37%的样本点不在$L_m​$中，这些样本点对于应用$L_m​$构建的预测器$H_m(x,L_m)​$来说，可以看作是未被使用的测试样本。</p><p>假设M=100，则某一个固定的样本点$(x_n,y_n)$，大概有37个$H_m(x,L_m) $没有使用该样本点。我们称这些样本点为“out-of-bag”样本点.</p><p>对这些样本点的预测可以用来准确估计某些重要指标:</p><blockquote><p>–比如在分类树中，可以用“out-of-bag”估计每个样本点属于第j类的概率，也可以用来估计节点概率；</p><p>–应用到回归树中，可以用来估计节点均方误差；</p><p>–应用“out-of-bag”的预测值可以用来构建更准确的回归树；</p><p>–也可以用来估计组合预测器的推广误差(generalization error)。</p></blockquote><h3 id="Bagging方法"><a href="#Bagging方法" class="headerlink" title="Bagging方法"></a>Bagging方法</h3><p>Bagging 是bootstrap aggregating的缩写</p><p>它指的是利用bootstrap 抽样的方法对训练集抽样，得到一系列新的训练集，对每个训练集构建一个预测器，最后组合所有的预测器得到最终的预测模型。</p><p><strong>对于分类问题</strong>，最终的预测模型是所有基预测器“投票”的结果。</p><p><strong>对于回归问题</strong>，最终的预测模型是所有基预测器“平均”的结果。</p><p>基预测器：我的理解是第一次预测产生的模型，称为最初的预测器</p><p>例如组合的是一棵树（基预测器），那么得到最终的预测模型会变比开始要稳定；如果基预测器组合的是k近邻方法（自身本来就相对稳定的方法），那么得到最终的预测模型提升肯定不会高。</p><h4 id="分类问题的bagging方法"><a href="#分类问题的bagging方法" class="headerlink" title="分类问题的bagging方法"></a>分类问题的bagging方法</h4><p>设训练样本集合L为$((x_n,y_n),n = 1,2,…,N)$其中$x_n$为p 维向量，是预测变量；$y_n$为因变量，是取值$(1,2,…,J)$的分类变量。</p><p>对此数据集，我们可以构建一棵决策树$H_B(x,L)$(也可以使用其它基分类器)来预测y。</p><p>假设我们有一系列与L有同样分布的训练集${ L_m,m = 1,2,…,M}$，每个训练集$L_m$都包含N个独立样本。因此我们可以构建M棵决策树$H_m(x,L_m)$，我们的目的是组合这M棵树得到最终分类器$H_{agg}$，以提高预测精度。</p><p>一种自然而然可以想到的组合方法是“投票”(voting)。令<script type="math/tex">N_j = \sum_{m=1}^{M}(I(H_m(x,L_m) = j))</script></p><p>其中$I(.)$为示性函数，在$H_m(x,L_m) = j$时取值为1，其它情况取值为0。那么$N_j$表示所有M棵树预测x属于类$j$的总个数；则$H_{agg}(x) = arg max_jN_j$，即最终组合的分类器$H_{agg}$预测x属于使得$N_j$取最大值的$j$ 。</p><p>通常我们只有一个训练样本集合L，我们如何得到与其具有相同分布的训练集$L_m$呢？答案是对L进行Bootstrap 抽样。即对$((x_n,y_n),n = 1,2,…,N)$中N个样本点进行概率为1/N的等概率有放回的抽样，样本量为N。通过这样的抽样方法得到的最终组合分类器$H_{agg}$记为$H_B$，该预测方法称为bagging预测方法。</p><p>综上所述，分类问题的Bagging算法如下：</p><p>(1) $m = 1,2,…,M​$</p><p>对L进行Bootstrap 抽样，得到样本量为N的训练样本集$L_m$，对$L_m$构建分类器(决策树)$H_m(x,L_m)$</p><p>(2) 组合M棵决策树得到最终分类器$H_B$，$H_B$对x的预测为：$argmax_jN_j$，即使得$N_j$取最大值的$j$。</p><p>其中<script type="math/tex">N_j = \sum_{m=1}^{M}(I(H_m(x,L_m) = j))</script>，$I(.)$为示性函数。</p><p>注：回归问题的Bagging算法如下：</p><p>(1)  $m = 1,2,…,M$</p><p>对L进行Bootstrap 抽样，得到样本量为N的训练样本集$L_m$，对$L_m$构建回归(回归树)$f_m(x,L_m)$</p><p>(2) 组合M棵决策树得到最终分类器$F_B$，$F_B$对x的预测为：</p><script type="math/tex; mode=display">F_B(x) = \sum_{m=1}^{M}(f_m(x,L_m))/M</script><h4 id="一些讨论"><a href="#一些讨论" class="headerlink" title="一些讨论"></a>一些讨论</h4><p>可以看到，对于不稳定的基预测器(比如说决策树)，使用bagging算法虽然我们失去了一个简单的可解释的树型结构，但是却大大提高了预测的准确度。</p><p>但是它也有局限性，我们在应用该算法的时候应该注意以下几点。如果预测结果很糟，那么bagging方法还能将结果变好吗？</p><p>如分类的结果都在0~0.5附近时，bagging甚至会让结果更加糟糕。</p><p>Bagging算法对于基预测器不稳定的情况很有作用，对于稳定的基预测器，bagging并不有效。</p><p>在分类问题的bagging 算法中我们进行bootstrap抽样50次，即M=50，在回归问题中M=25。这并不表示25或者50是充分的，也不表示其是必要的，只是比较合理的。</p><p>对于waveform数据集我们分别对M=10,25, 50和100进行了计算。可以看到在M=25之后，分类误差的提高已经并不明显。且M过大时，会将原始训练集的数据过多得使用在分类器上，产生过拟合问题（不确定是不是这个原因），总之不好。</p><div class="table-container"><table><thead><tr><th></th><th>CART</th><th>Bagging M=10</th><th>M=25</th><th>M=50</th><th>M=100</th></tr></thead><tbody><tr><td>错分率</td><td>29.5</td><td>23.1</td><td>21.8</td><td>20.7</td><td>21.1</td></tr></tbody></table></div><p>Breiman建议对于回归问题的M值可以取得小一些，对于分类问题，尤其是y的类别比较多的时候，M的取值应该相应的大一些。</p><p>M取值的大小对于bagging CART影响并不明显，因为相对来讲构建CART决策树的时间比较快。但是对于神经网络算法，因为其耗时较长，所以如果M取值很大的话，通常需要很久才能得到结果。</p><p>注：M在实战中就多做几个，看看，选合适的。</p><p>每次进行bootstrap抽样的时候，我们选择的样本量相等于原始训练集的样本量。因为bootstrap是有放回的重复抽样，所以有些样本点被抽中的次数超过一次，有些样本点没有被抽中。</p><p>根据bootstrap抽样的理论，当样本量为时，大约有37%的样本点没有被抽中。增加bootstrap抽样样本量的个数(我们知道，按照bootstrap抽样技术，一般是按照等于原始数据集的样本量进行抽样，但从理论上讲，bootstrap抽样的样本量既可以大于又可以小于)，是否可以提高bagging算法的精度呢？</p><p>对这个问题的经验回答是否定的，当提高bootstrap抽样样本量的个数至2后，大约有14%的样本点没有被抽中，但是bagging算法的精度并没有提高。</p><p>如果从偏差方差分解的角度理解bagging算法，它可以提高不稳定基预测器的预测精度，<strong>实质上是减小了预测的方差(variance)，但并没有降低偏差(bias)</strong>。</p><p>从这个角度出发，Breiman(2001)提出了迭代(iterated) bagging算法同时减小预测的偏差及方差。</p><p>Breiman, Leo (2001a), Using Iterated Bagging to Debias Regressions, <em>Machine Learning</em>, 45, 261-277</p><p>Buhlmann 和 Yu (2002)进一步从理论上探讨了bagging方法对偏差及方差的降低，提出了subbagging算法，与bagging方法相比，它有相同的预测精度，但却可以大大节省计算时间。这人厉害。</p><h3 id="Adaboost算法"><a href="#Adaboost算法" class="headerlink" title="Adaboost算法"></a>Adaboost算法</h3><p>相较于bagging，更加精细，更好。</p><p>具体步骤如下：</p><p>(1) <em>m=</em>1，以bootstrap方法(即等概率$p_1(n)=1/N$有放回重复抽样)对训练样本集$L{(x_n,y_n), n=1,…,N}$抽样得到新的训练集$L_1$，样本量为<em>N</em>。</p><p>对$L_1​$构建决策树$H_1(x,L_1)​$。应用$H_1(x,L_1)​$预测训练集<em>L</em>中所有样本点$(x_n,y_n), n=1,…,N​$，如果$H_1​$对$(x_n,y_n)​$预测错误，</p><p>令$d_1(n)=1$，否则$d_1(n)=0$。d_1(n)就是预测正误标记，对了就是0，错了就是1.</p><p>计算:</p><script type="math/tex; mode=display">\epsilon_1 = \sum_{n}p_1(n)d_1(n);​</script><script type="math/tex; mode=display">\beta_1 = (1-\epsilon_1)/\epsilon_1;$$ 先理解为正确和错误的比重$$C_1 = log(\beta_1)​</script><p>(2) 对于<em>m</em>=2,…,<em>M</em></p><p>更新第<em>m</em>次抽样概率为</p><script type="math/tex; mode=display">p_m(n) = p_{m-1}(n)\beta_{m-1}^{d_{m-1}(n)}/\sum_{n}p_{m-1}(n) \beta_{m-1}^{d_{m-1}(n)}</script><p>以概率$p_m(n)​$对训练集<em>L</em>进行有放回重复抽样得到新的训练集$L_m​$，并对$L_m$构建决策树$H_m(x,L_m)​$</p><p>应用$H_m(x,L_m)$预测训练集<em>L</em>中所有样本点$(x_n,y_n), n=1,…,N$，如果$H_m$对$(x_n,y_n)$预测错误，令$d_m(n)=1$，否则$d_m(n)=0$。</p><p>计算:</p><script type="math/tex; mode=display">\epsilon_m = \sum_{n}p_m(n)d_m(n);​</script><script type="math/tex; mode=display">\beta_m = (1-\epsilon_m)/\epsilon_m;$$ 先理解为正确和错误的比重$$C_m = log(\beta_m)</script><p>(3) 计算$W_m=C_m/\sum_{m}C_m$，（类似权重）</p><p>组合<em>M</em>棵决策树得到最终分类器$H_A (x)$ ，使得</p><script type="math/tex; mode=display">H_A (x) = arg max_{y∈(1,2,...,K)}(\sum_{m=1}^{M}W_mI(h_B(x,L_m)=y))</script><p> 其中$I(.) ​$为示性函数。</p><p>这个判别是一个递进的过程，是统计可加模型。</p><p>现在最流行的是XGBboost</p><h3 id="关于决策树的一些说明"><a href="#关于决策树的一些说明" class="headerlink" title="关于决策树的一些说明"></a>关于决策树的一些说明</h3><h4 id="1-二叉树还是多叉树"><a href="#1-二叉树还是多叉树" class="headerlink" title="1.二叉树还是多叉树"></a>1.二叉树还是多叉树</h4><p>多叉树经常导致数据被分到每个节点，没有足够的数据进行后续的分枝。多叉树可以通过多层二叉树实现，<strong>建议使用二叉树</strong>。</p><p>多个水平如何二分叉：有一些专门的方法进行选择。自变量多水平，有时也可以当作连续变化（ordered var） </p><h4 id="2-单棵树构建的探讨"><a href="#2-单棵树构建的探讨" class="headerlink" title="2.单棵树构建的探讨"></a>2.单棵树构建的探讨</h4><p>ID3是最早的，后来又经历商业包装，出现了其他算法C4.0、C5.0等</p><h4 id="3-缺失值的处理"><a href="#3-缺失值的处理" class="headerlink" title="3.缺失值的处理"></a>3.缺失值的处理</h4><p>删除、替代、保留：保留方法很重要，在决策树这里有很好的效果。</p><h4 id="4-算法的稳定性"><a href="#4-算法的稳定性" class="headerlink" title="4.算法的稳定性"></a>4.算法的稳定性</h4><p>如果生成基预测器的算法是不稳定的(unstable)，通过bagging得到的最终预测模型的预测精度往往会大大高于单个基预测器的预测精度。</p><p><strong>“不稳定” ：</strong>当训练样本集合有很小的变动，由此生成的预测器有很大的变化。</p><p><strong>不稳定的算法</strong>: 决策树，神经网络，MARS (multivariate splines)，和子集回归(subset regression)等等；</p><p><strong>稳定的算法</strong>:岭回归(ridge regression)，最近邻方法(K-nearest neighbor)，和线性判别方法(Linear discriminate)等等。</p><p>（未完</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;数据挖掘-决策树和相关算法&quot;&gt;&lt;a href=&quot;#数据挖掘-决策树和相关算法&quot; class=&quot;headerlink&quot; title=&quot;数据挖掘|决策树和相关算法&quot;&gt;&lt;/a&gt;数据挖掘|决策树和相关算法&lt;/h1&gt;&lt;p&gt;数据挖掘笔记&lt;/p&gt;
&lt;p&gt;记录：氦核   最后编辑时间：20190508&lt;/p&gt;
&lt;p&gt;前排简介，本文不涉及实战，仅仅举例。文章中间夹杂很多个人思考与经验，如有错误，请在下方评论区指出，欢迎讨论。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据分析" scheme="https://konelane.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
</feed>
